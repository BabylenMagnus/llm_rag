{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:39:07.951115Z",
     "start_time": "2024-03-04T09:39:07.919114Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "from llama_index.readers.web import TrafilaturaWebReader\n",
    "from llama_index.vector_stores import FaissVectorStore\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, Document, StorageContext, load_index_from_storage\n",
    "from IPython.display import Markdown, display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "websites_dir = \"websites/\"\n",
    "data_dir = \"dataset\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:39:09.739024Z",
     "start_time": "2024-03-04T09:39:09.721027Z"
    }
   },
   "id": "9f628b41e7002cc9",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_metadata = lambda x: {\"filename\": x}\n",
    "documents = SimpleDirectoryReader(\n",
    "    data_dir, file_metadata=file_metadata, recursive=True, required_exts= [\".pdf\", \".doc\", \".docx\", \".txt\", \".xml\"]\n",
    ").load_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:39:10.816928Z",
     "start_time": "2024-03-04T09:39:10.774400Z"
    }
   },
   "id": "ac39fac4799193a5",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "llama_index.schema.Document"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:39:11.798188Z",
     "start_time": "2024-03-04T09:39:11.783181Z"
    }
   },
   "id": "ad133938a57575c5",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(id_='7be4136e-7771-4b02-adee-c9960c97e403', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='c5a13861-8104-4844-ae19-53157dfe6caa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='a32083f3-c691-41f7-9885-ff1a886d1815', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='a101a15c-8502-4a3f-a895-ce5c7eccd28b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='f6cedc76-92a1-4a52-b37e-97cb1846c906', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='6dc55b02-980a-4c27-96f8-616b3d9b6958', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='5b87df0e-97e5-4d02-b5a1-2e642156139f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='d7d474bb-85c2-4073-a2a3-13e675268304', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='fdbb12dc-54f5-4270-b171-42a620b2a5c6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='77eafc26-8f71-4666-b52a-3b293d36d70d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='03712f95-e773-4b6d-9494-0011b8a01424', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='5ab4a707-7299-4546-a247-1639be10d08c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='5650aa3c-bc8f-4221-a4c1-46a5f7579a06', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='a9c08f64-7d78-4b0b-b67b-e344c34ccb77', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='063fe793-dd78-4873-9672-52a4b2639219', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='da1f4b38-4704-47da-8696-3ffa78c4e8f6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='a12da101-2612-4e73-b211-93b3b6b4b9ef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='cf7231a5-2854-402e-acbe-cddd288acea3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='1f4f4bba-879f-4081-b4ef-169becec8f5d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f3f8415a7672cf17a7843ba6e3ebc30590713f8ca0c66eb50ad20791fb3241', text='Welcome to the Northern Eurasia Regional Contests!\\nThe ICPC, the “International Collegiate Programming Contest”, is an extra-curricular, competitive programming sport for students at universities around the world. ICPC competitions provide gifted students opportunities to interact, demonstrate, and improve their teamwork, programming, and problem-solving process. The ICPC is a global platform for academia, industry, and community to shine the spotlight on and raise the aspirations of the next generation of computing professionals as they pursue excellence.\\nNorthern Eurasia Finals 2023-2023 is scheduled for December 11-13, 2023 and will be collocated with Russia Team Open, High School Programming Contest! Save the date!\\nДобро пожаловать на соревнования студенческого командного чемпионата мира по программированию ICPC в Северной Евразии!\\nВ сезоне 2023-2024, финальные соревнования Северной Евразии пройдут одновременно с ВКОШП с 11 по 13 декабря!\\nРасписание региональных соревнований\\nВидеоинструкция по регистрации.\\nТекущие результаты основного тура:\\n- Northern Eurasia Finals Standings\\n- Astana Site Standings\\n- St. Petersburg Site Standings\\n- Kutaisi Site Standings\\n- Novosibirsk Site Standings\\nУсловия основного тура:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='58989bcf-658d-4c3a-b6d2-6b855e0535be', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4ae21a370e9ba3810db531d745502a4fdf28c74b528b73a010efa75fee3798f5', text='Общие понятия\\nСодержание\\n- 1 Понятие машинного обучения в искусственном интеллекте\\n- 2 Задача обучения\\n- 3 Классификация задач машинного обучения\\n- 3.1 Обучение с учителем (англ. Supervised learning [3])\\n- 3.2 Обучение без учителя (англ. Unsupervised learning)\\n- 3.3 Обучение с частичным привлечением учителя (англ. Semi-supervised learning[4])\\n- 3.4 Обучение с подкреплением (англ. Reinforcement learning)\\n- 3.5 Активное обучение (англ. Active learning)\\n- 3.6 Обучение в реальном времени (англ. Online learning)\\n- 4 Примеры задач\\n- 5 Открытые наборы данных для обучения\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nПонятие машинного обучения в искусственном интеллекте\\nОдним из первых, кто использовал термин \"машинное обучение\", был изобретатель первой самообучающейся компьютерной программы игры в шашки А. Л. Самуэль в 1959 г. [1]\\n|Определение:\\n|Машинное обучение (англ. Machine learning) — процесс, который даёт возможность компьютерам обучаться выполнять что-то без явного написания кода.\\nЭто определение не выдерживает критики, так как не понятно, что означает наречие \"явно\". Более точное определение дал намного позже Т. М. Митчелл. [2]\\n|Определение:\\n|Компьютерная программа обучается на основе опыта $E$ по отношению к некоторому классу задач $T$ и меры качества $P$, если качество решения задач из $T$, измеренное на основе $P$, улучшается с приобретением опыта $E$.\\nЗадача обучения\\n$X$ — множество объектов (англ. object set, or input set)\\n$Y$ — множество меток классов (англ. label set, or output set)\\n$\\\\hat y∶ X → Y$ — неизвестная зависимость (англ. unknown target function (dependency))\\nДано\\n${x_1, . . . , x_l} ⊂ X$ — обучающая выборка (англ. training sample set)\\n$y_i = \\\\hat y(x_i), i = 1, . . . , l $ — известные метки классов\\nНайти\\nНайти $ a ∶ X → Y $ — алгоритм, решающую функцию (англ. decision function), приближающую $y$ на всём множестве $X$.\\nПризнаки\\nКомпьютер всегда имеет дело с признаковым описанием объектов. Например, пациента можно описать признаками: имя, возраст, номер полиса, жалобы, давление, температура, результаты анализов.\\n$f_j∶ X → D_j,j = 1, ... , n$ — признаки (англ. features, or attributes).\\nТипы признаков:\\n- бинарный (binary): $D_j = \\\\{0, 1\\\\}$;\\n- номинальный, или категориальный (categorical): $D_j$ конечно;\\n- упорядоченный (ordinal): $D_j$ конечно и упорядоченно;\\n- числовой (numerical): $D_j = \\\\mathbb{R}$.\\nт.е. объект представляется как набор признаков $(f_1(x),... ,f_n(x))$. Данные обычно представляются в виде матрицы объектов-признаков\\nТипы задач\\nКлассификация (англ. classification)\\n- $Y = \\\\{−1, +1\\\\}$ — классификация на 2 класса;\\n- $Y = \\\\{1, . . . , M\\\\}$ — на $M$ непересекающихся классов;\\n- $Y = \\\\{0, 1\\\\}^M$— на $M$ классов, которые могут пересекаться.\\nЦель: научиться определять, к какому классу принадлежит объект.\\nПримеры: распознавание текста по рукописному вводу; определение того, находится на фотографии человек или кот; определение, является ли письмо спамом.\\nМетоды: метод ближайших соседей, дерево решений, логистическая регрессия, метод опорных векторов, байесовский классификатор, cверточные нейронные сети.\\nВосстановление регрессии (англ. regression)\\n- $Y = \\\\mathbb{R}$ или $Y = \\\\mathbb{R}^m$.\\nЦель: получать прогноз на основе выборки объектов.\\nПримеры: предсказание стоимости акции через полгода; предсказание прибыли магазина в следующем месяце; предсказание качества вина на слепом тестировании.\\nМетоды: линейная регрессия, дерево решений, метод опорных векторов.\\nРанжирование (англ. ranking)\\n- $Y$ — конечное упорядоченное множество.\\nЦель: научиться по множеству объектов получать множество рейтингов, упорядоченное согласно заданному отношению порядка.\\nПримеры: выдача поискового запроса; подбор интересных новостей для пользователя.\\nМетоды: поточечный подход, попарный подход, списочный подход.\\nКластеризация (англ. clustering)\\nЦель: разбить множество объектов на подмножества (кластеры) таким образом, чтобы объекты из одного кластера были более похожи друг на друга, чем на объекты из других кластеров по какому-либо критерию.\\nПримеры: разбиение клиентов сотового оператора по платёжеспособности; разбиение космических объектов на похожие (галактики, планеты, звезды).\\nМетоды: иерархическая кластеризация, эволюционные алгоритмы кластеризации, EM-алгоритм.\\nВспомогательные типы задач\\nУменьшение размерности (англ. dimensionality reduction)\\nЦель: научиться описывать данные не $N$ признаками, а меньшим числом для повышения точности модели или последующей визуализации.\\nПримеры: визуализация в двумерном или трехмерном пространстве; сжатие данных.\\nМетоды: гребневая регрессия, лассо-регрессия, метод главных компонент, стохастическое вложение соседей с t-распределением.\\nВыявление аномалий (англ. anomaly detection)\\nЦель: научиться выявлять аномалии в данных. Отличительная особенность задачи от классификации — примеров аномалий для тренировки модели очень мало, либо нет совсем; поэтому для ее решения необходимы специальные методы.\\nПримеры: определение мошеннических транзакций по банковской карте; обнаружение событий, предвещающих землетрясение.\\nМетоды: экстремальный анализ данных, аппроксимирующий метод, проецирующие методы.\\nКлассификация задач машинного обучения\\nОбучение с учителем (англ. Supervised learning [3])\\nМетки классов $y_i$ доступны все сразу (известны ответы для поставленной задачи).\\nЗадачи, которые могут решаться этим способом: классификация, регрессия.\\nОбучение без учителя (англ. Unsupervised learning)\\nИзучает широкий класс задач обработки данных, в которых известны только описания множества объектов (обучающей выборки), и требуется обнаружить внутренние взаимосвязи, зависимости, закономерности, существующие между объектами. Т.е. тренировочные данные доступны все сразу, но ответы для поставленной задачи неизвестны.\\nЗадачи, которые могут решаться этим способом: кластеризация, нахождение ассоциативных правил, выдача рекомендаций (например, реклама), уменьшение размерности датасета, обработка естественного языка.\\nОбучение с частичным привлечением учителя (англ. Semi-supervised learning[4])\\nЗанимает промежуточное положение между обучением с учителем и без учителя. Каждый прецедент представляет собой пару «объект, ответ», но ответы известны только на части прецедентов (Размечено мало, либо малоинформативная часть).\\nПримером частичного обучения может послужить сообучение: два или более обучаемых алгоритма используют один и тот же набор данных, но каждый при обучении использует различные — в идеале некоррелирующие — наборы признаков объектов.\\nОбучение с подкреплением (англ. Reinforcement learning)\\nЧастный случай обучения с учителем, сигналы подкрепления (правильности ответа) выдаются не учителем, а некоторой средой, с которой взаимодействует программа. Размеченность данных зависит от среды.\\nОкружение обычно формулируется как марковский процесс принятия решений (МППР) с конечным множеством состояний, и в этом смысле алгоритмы обучения с подкреплением тесно связаны с динамическим программированием. Вероятности выигрышей и перехода состояний в МППР обычно являются величинами случайными, но стационарными в рамках задачи.\\nПри обучении с подкреплением, в отличие от обучения с учителем, не предоставляются верные пары \"входные данные-ответ\", а принятие субоптимальных решений (дающих локальный экстремум) не ограничивается явно. Обучение с подкреплением пытается найти компромисс между исследованием неизученных областей и применением имеющихся знаний (англ. exploration vs exploitation tradeoff).\\nАктивное обучение (англ. Active learning)\\nОтличается тем, что обучаемый имеет возможность самостоятельно назначать следующий прецедент, который станет известен. Применяется когда получение истиной метки для объекта затруднительно. Поэтому алгоритм должен уметь определять, на каких объектах ему надо знать ответ, чтобы лучше всего обучиться, построить наилучшую модель.\\nОбучение в реальном времени (англ. Online learning)\\nМожет быть как обучением с учителем, так и без учителя. Специфика в том, что тренировочные данные поступают последовательно. Требуется немедленно принимать решение по каждому прецеденту и одновременно доучивать модель зависимости с учётом новых прецедентов. Здесь существенную роль играет фактор времени.\\nПримеры задач\\n- Предсказание месторождений полезных ископаемых\\nПризнаками являются данные геологической разведки.\\n- Бинарные признаки: наличие/отсутствие тех или иных пород на территории района;\\n- Числовые признаки: физико-химические свойства пород можно описать количественной характеристикой.\\nОбучающая выборка состоит из двух классов:\\n- районы известных месторождений;\\n- похожие районы, в которых интересующее ископаемое обнаружено не было.\\nПри поиске редких полезных ископаемых количество объектов может оказаться намного меньше, чем количество признаков. В этой ситуации плохо работают классические статистические методы. Задача решается путём поиска закономерностей в имеющемся массиве данных. В процессе решения выделяются короткие наборы признаков, обладающие наибольшей информативностью — способностью наилучшим образом разделять классы (\"синдромы\" месторождений).\\n- Оценивание кредитоспособности заёмщиков\\nЭта задача решается банками при выдаче кредитов. Объектами в данном случае являются физические или юридические лица, претендующие на получение кредита.\\nВ случае физических лиц признаковое описание состоит из:\\n- анкеты, которую заполняет сам заёмщик;\\n- дополнительной информации, которую банк собирает о нём из собственных источников.\\nМожно выделить следующие признаки:\\n- Бинарные признаки: пол, наличие телефона;\\n- Номинальные признаки: место проживания, профессия, работодатель;\\n- Порядковые признаки: образование, занимаемая должность;\\n- Числовые признаки:сумма кредита, возраст, стаж работы, доход семьи, размер задолженностей в других банках.\\nОбучающая выборка составляется из заёмщиков с известной кредитной историей.\\nНа стадии обучения производится синтез и отбор информативных признаков и определяется, сколько баллов назначать за каждый признак, чтобы риск принимаемых решений был минимален. Чем выше суммарное число баллов заёмщика, набранных по совокупности информативных признаков, тем более надёжным считается заёмщик.\\n- Задачи медицинской диагностики\\nВ роли объектов выступают пациенты. Признаки характеризуют результаты обследований, симптомы заболевания и применявшиеся методы лечения.\\n- Бинарные признаки: пол, наличие головной боли, слабости;\\n- Порядковый признак: тяжесть состояния (удовлетворительное, средней тяжести, тяжёлое, крайне тяжёлое);\\n- Числовые признаки:возраст, пульс, артериальное давление, содержание гемоглобина в крови, доза препарата.\\nПризнаковое описание пациента является, по сути дела, формализованной историей болезни.\\nНакопив достаточное количество данных, можно решать различные задачи:\\n- классифицировать вид заболевания (дифференциальная диагностика);\\n- определять наиболее целесообразный способ лечения;\\n- предсказывать длительность и исход заболевания;\\n- оценивать риск осложнений;\\n- находить наиболее характерные для данного заболевания совокупности симптомов.\\nЦенность такого рода систем в том, что они способны мгновенно анализировать и обобщать огромное количество прецедентов — возможность, недоступная специалисту-врачу.\\nОткрытые наборы данных для обучения\\nКомпьютерное зрение\\n- MNIST: один из самых востребованных наборов для проверки работоспособности. Есть датасеты 25x25, отцентрованные, рукописные чёрно-белые цифры;\\n- CIFAR10 & CIFAR100: цветные изображения 32x32. Сегодня используется нечасто, но может быть хорошим вариантов для проверки работоспособности;\\n- ImageNet: датасет изображений для проверки новых алгоритмов.\\nЕстественные языки\\n- WikiText: большой свод данных для языкового моделирования из статей Википедии, собранный Salesforce MetaMind.\\nРечь\\n- LibriSpeech: около 500 часов начитки аудиокниг, в исполнении разных людей. Данные организованы по главам книг, содержат текст и записи.\\nСистемы рекомендаций и ранжирования\\n- Million Song Dataset: большой open source-датасет Kaggle, насыщенный метаданными. Хороший вариант для тех, кто экспериментирует с гибридными системами рекомендаций.\\nСети и графы\\n- Amazon Co-Purchasing и Amazon Reviews: данные, собранные из раздела «Пользователи, купившие это, также выбирают…» на Amazon, а также обзоры сопутствующих товаров. Хорош для экспериментов рекомендательными системами в соцсетях.\\nГеопространственные данные\\n- OpenStreetMap: векторные картографические данные для всей планеты, с бесплатной лицензией. Включает в себя старую версию данных TIGER Бюро переписи США.\\nСм. также\\n- Переобучение\\n- Модель алгоритма и ее выбор\\n- Оценка качества в задаче кластеризации\\n- Кросс-валидация\\n- Обзор библиотек для машинного обучения на Python\\nПримечания\\n- ↑ A.L. Samuel \"Some Studies in Machine Learning Using the Game of Checkers\" (IBM Journal. July 1959. P. 210–229)\\n- ↑ T.M. Mitchell \"Machine Learning\" (McGraw-Hill, 1997)\\n- ↑ Обучение с учителем\\n- ↑ Semi-supervised learning\\n- ↑ Задача классификации видов ириса\\n- ↑ Презентация \"Основные понятия машинного обучения\"', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='fe4a4ea6-56b1-4fdc-b513-486a3ca69070', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d978a6a1d449d83c14b5782ab4050c29d58c59fb1d4a4f780909ab909e8d7ae4', text='Переобучение\\nПереобучение (англ. overfitting) — негативное явление, возникающее, когда алгоритм обучения вырабатывает предсказания, которые слишком близко или точно соответствуют конкретному набору данных и поэтому не подходят для применения алгоритма к дополнительным данным или будущим наблюдениям.\\nНедообучение (англ. underfitting) — негативное явление, при котором алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. Недообучение возникает при использовании недостаточно сложных моделей.\\nСодержание\\n- 1 Примеры\\n- 2 Кривые обучения\\n- 3 High variance и high bias\\n- 4 Возможные решения\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nПримеры\\nНа примере линейной регрессии\\nПредставьте задачу линейной регрессии. Красные точки представляют исходные данные. Синие линии являются графиками полиномов различной степени M, аппроксимирующих исходные данные.\\nКак видно из Рис. 1, данные не поддаются линейной зависимости при небольшой степени полинома и по этой причине модель, представленная на данном рисунке, не очень хороша.\\nНа Рис. 2 представлена ситуация, когда выбранная полиномиальная функция подходит для описания исходных данных.\\nРис. 3 иллюстрирует случай, когда высокая степень полинома ведет к тому, что модель слишком заточена на данные обучающего датасета.\\nНа примере логистической регрессии\\nПредставьте задачу классификации размеченных точек. Красные точки представляют данные класса 1. Голубые круглые точки — класса 2. Синие линии являются представлением различных моделей, которыми производится классификация данных.\\nРис. 4 показывает результат использования слишком простой модели для представленного датасета\\nКривые обучения\\nКривая обучения — графическое представление того, как изменение меры обученности (по вертикальной оси) зависит от определенной единицы измерения опыта (по горизонтальной оси)[1]. Например, в примерах ниже представлена зависимость средней ошибки от объема датасета.\\nКривые обучения при переобучении\\nПри переобучении небольшая средняя ошибка на обучающей выборке не обеспечивает такую же малую ошибку на тестовой выборке.\\nРис. 7 демонстрирует зависимость средней ошибки для обучающей и тестовой выборок от объема датасета при переобучении.\\nКривые обучения при недообучении\\nПри недообучении независимо от объема обучающего датасета как на обучающей выборке, так и на тестовой выборке небольшая средняя ошибка не достигается.\\nРис. 8 демонстрирует зависимость средней ошибки для обучающей и тестовой выборок от объема датасета при недообучении.\\nHigh variance и high bias\\nBias — ошибка неверных предположений в алгоритме обучения. Высокий bias может привести к недообучению.\\nVariance — ошибка, вызванная большой чувствительностью к небольшим отклонениям в тренировочном наборе. Высокая дисперсия может привести к переобучению.\\nПри использовании нейронных сетей variance увеличивается, а bias уменьшается с увеличением количества скрытых слоев.\\nДля устранения high variance и high bias можно использовать смеси и ансамбли. Например, можно составить ансамбль (boosting) из нескольких моделей с высоким bias и получить модель с небольшим bias. В другом случае при bagging соединяются несколько моделей с низким bias, а результирующая модель позволяет уменьшить variance.\\nДилемма bias–variance\\nДилемма bias–variance — конфликт в попытке одновременно минимизировать bias и variance, тогда как уменьшение одного из негативных эффектов, приводит к увеличению другого. Данная дилемма проиллюстрирована на Рис 10.\\nПри небольшой сложности модели мы наблюдаем high bias. При усложнении модели bias уменьшается, но variance увеличится, что приводит к проблеме high variance.\\nВозможные решения\\nВозможные решения при переобучении\\n- Увеличение количества данных в наборе;\\n- Уменьшение количества параметров модели;\\n- Добавление регуляризации / увеличение коэффициента регуляризации.\\nВозможные решения при недообучении\\n- Добавление новых параметров модели;\\n- Использование для описания модели функций с более высокой степенью;\\n- Уменьшение коэффициента регуляризации.\\nСм. также\\n- Модель алгоритма и ее выбор\\n- Оценка качества в задачах классификации и регрессии[на 28.01.19 не создан]\\n- Оценка качества в задаче кластеризации\\nПримечания\\nИсточники информации\\n- The Problem of Overfitting on Coursera, Andrew Ng\\n- Overfitting: when accuracy measure goes wrong\\n- The Problem of Overfitting Data\\n- Overfitting in Machine Learning\\n- Overfitting - статься на Википедии\\n- Переобучение - вводная статься на MachineLearning.ru\\n- The Problem of Overfitting - курс Andrew Ng\\n- Hastie, T., Tibshirani, R., Friedman, J. The Elements of Statistical Learning, 2nd edition. — Springer, 2009. — 533 p.\\n- Vapnik V.N. Statistical learning theory. — N.Y.: John Wiley & Sons, Inc., 1998.\\n- Воронцов, К. В. Комбинаторная теория надёжности обучения по прецедентам: Дис. док. физ.-мат. наук: 05-13-17. — Вычислительный центр РАН, 2010. — 271 с.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='b4883dfd-361d-4197-a0c9-d6e302b1456d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6590e02280d60751f9427a5e36039cb6cf5135d5edf40db72a4596e2d9eaca1f', text='Кросс-валидация\\nКросс-валидация или скользящий контроль — процедура эмпирического оценивания обобщающей способности алгоритмов. С помощью кросс-валидации эмулируется наличие тестовой выборки, которая не участвует в обучении, но для которой известны правильные ответы.\\nСодержание\\n- 1 Определения и обозначения\\n- 2 Разновидности кросс-валидации\\n- 2.1 Валидация на отложенных данных (Hold-Out Validation)\\n- 2.2 Полная кросс-валидация (Complete cross-validation)\\n- 2.3 k-fold кросс-валидация\\n- 2.4 t×k-fold кросс-валидация\\n- 2.5 Кросс-валидация по отдельным объектам (Leave-One-Out)\\n- 2.6 Случайные разбиения (Random subsampling)\\n- 2.7 Критерий целостности модели (Model consistency criterion)\\n- 3 См. также\\n- 4 Примечания\\n- 5 Источники информации\\nОпределения и обозначения\\nПусть признаков, описывающих объекты, а — конечное множество меток.— множество\\n— обучающая выборка,\\n— мера качества,\\n— алгоритм обучения.\\nРазновидности кросс-валидации\\nВалидация на отложенных данных (Hold-Out Validation)\\nОбучающая выборка один раз случайным образом разбивается на две части\\nПосле чего решается задача оптимизации:\\n,\\nМетод Hold-out применяется в случаях больших датасетов, т.к. требует меньше вычислительных мощностей по сравнению с другими методами кросс-валидации. Недостатком метода является то, что оценка существенно зависит от разбиения, тогда как желательно, чтобы она характеризовала только алгоритм обучения.\\nПолная кросс-валидация (Complete cross-validation)\\n- Выбирается значение ;\\n- Выборка разбивается всеми возможными способами на две части .\\n,\\nЗдесь число разбиенийстановится слишком большим даже при сравнительно малых значениях t, что затрудняет практическое применение данного метода.\\nk-fold кросс-валидация\\n- Обучающая выборка разбивается на непересекающихся одинаковых по объему частей;\\n- Производится\\nитераций. На каждой итерации происходит следующее:\\n- Модель обучается на части обучающей выборки;\\n- Модель тестируется на части обучающей выборки, которая не участвовала в обучении.\\nКаждая изчастей единожды используется для тестирования. Как правило, (5 в случае малого размера выборки).\\n.\\n# Пример кода для k-fold кросс-валидации: # Пример классификатора, cпособного проводить различие между всего лишь двумя # классами, \"пятерка\" и \"не пятерка\" из набор данных MNIST import numpy as np from sklearn.model_selection import StratifiedKFold from sklearn.datasets import fetch_openml from sklearn.base import clone from sklearn.linear_model import SGDClassifier mnist = fetch_openml(\\'mnist_784\\', version=1) X, y = mnist[\"data\"], mnist[\"target\"] y = y.astype(np.uint8) X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] y_train_5 = (y_train == 5) # True для всех пятерок, False для всех остальных цифр. Задача опознать пятерки y_test_5 = (y_test == 5) sgd_clf = SGDClassifier(random_state=42) # классификатор на основе метода стохастического градиентного спуска (Stochastic Gradient Descent SGD) # Разбиваем обучающий набора на 3 блока # выработку прогнозов и их оценку осуществляем на каждом блоке с использованием модели, обученной на остальных блоках</font> skfolds = StratifiedKFold(n_splits=3, random_state=42) for train_index, test_index in skfolds.split(X_train, y_train_5): clone_clf = clone(sgd_clf) X_train_folds = X_train[train_index] y_train_folds = y_train_5[train_index] X_test_fold = X_train[test_index] y_test_fold = y_train_5[test_index] clone_clf.fit(X_train_folds, y_train_folds) y_pred = clone_clf.predict(X_test_fold) n_correct = sum(y_pred == y_test_fold) print(n_correct / len(y_pred)) # print 0.95035 # 0.96035 # 0.9604\\nt×k-fold кросс-валидация\\n- Процедура выполняется\\nраз:\\n- Обучающая выборка случайным образом разбивается на непересекающихся одинаковых по объему частей;\\n- Производится\\nитераций. На каждой итерации происходит следующее:\\n- Модель обучается на части обучающей выборки;\\n- Модель тестируется на части обучающей выборки, которая не участвовала в обучении.\\n,\\n.\\nКросс-валидация по отдельным объектам (Leave-One-Out)\\nВыборка разбивается наи 1 объект раз.\\n, где .\\nПреимущества LOO в том, что каждый объект ровно один раз участвует в контроле, а длина обучающих подвыборок лишь на единицу меньше длины полной выборки.\\nНедостатком LOO является большая ресурсоёмкость, так как обучаться приходитсяраз. Некоторые методы обучения позволяют достаточно быстро перенастраивать внутренние параметры алгоритма при замене одного обучающего объекта другим. В этих случаях вычисление LOO удаётся заметно ускорить.\\nСлучайные разбиения (Random subsampling)\\nВыборка разбивается в случайной пропорции. Процедура повторяется несколько раз.\\nКритерий целостности модели (Model consistency criterion)\\nНе переобученый алгоритм должен показывать одинаковую эффективность на каждой части.\\n,\\nМетод может быть обобщен как аналог.\\nСм. также\\nПримечания\\nИсточники информации\\n- Скользящий контроль - статья на MachineLearning.ru\\n- Model assessment and selection', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='8ab6455d-05c8-4e5b-af7f-9b8ce7931220', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='08a45fa3da52ee636a72ec2fc2f1fca47d3899187413b6df9ed4f7cdd758363f', text='Стохастический градиентный спуск\\nСтохастический градиентный спуск (англ. stochastic gradient descent) $-$ оптимизационный алгоритм, отличающийся от обычного градиентного спуска тем, что градиент оптимизируемой функции считается на каждом шаге не как сумма градиентов от каждого элемента выборки, а как градиент от одного, случайно выбранного элемента.\\nСодержание\\nОбычный градиентный спуск\\nДля начала вспомним, как работает обычный градиентный спуск. Пусть объекты задаются $n$ числовыми признаками $f_j : X \\\\to R, j = 1 ... n$ и пространство признаковых описаний в таком случае $X = R^n$. Пусть $Y$ $-$ конечное множество меток классов и задана обучающая выборка пар «объект-ответ»Пусть семейство алгоритмов $a(x, {\\\\bf w})$ имеет параметр вектор весов $\\\\bf w$. И пускай мы выбрали какую-нибудь функцию потерь. Для $i$-го объекта выборки для алгоритма с весами ${\\\\bf w}$ обозначим ее . Необходимо минимизировать эмпирический риск, т.е. . Если функция потерь принадлежит классу $C_1(X)$, то можно применить метод градиентного спуска. Выберем ${\\\\bf w}^{(0)}$ $-$ начальное приближение. Тогда каждый следующий вектор параметров будет вычисляться как ${\\\\bf w}^{(t+1)}={\\\\bf w}^{(t)} - h\\\\sum\\\\limits_{i=1}^{l}\\\\nabla \\\\mathscr{L}_i({\\\\bf w}^{(t)})$, где $h$ - градиентный шаг, смысл которого заключается в том, насколько сильно менять вектор весов в направлении градиента. Остановка алгоритма будет определяться сходимостью $Q$ или $\\\\bf w$.\\nСтохастический градиентный спуск\\nПроблема предыдущего алгоритма заключается в том, что чтобы определить новое приближение вектора весов необходимо вычислить градиент от каждого элемента выборки, что может сильно замедлять алгоритм. Идея ускорения алгоритма заключается в использовании только одного элемента, либо некоторой подвыборки для подсчета нового приближения весов. То есть теперь новое приближение будет вычисляться как ${\\\\bf w}^{(t+1)}={\\\\bf w}^{(t)} - h\\\\nabla \\\\mathscr{L}_i({\\\\bf w}^{(t)})$, где $i$ $-$ случайно выбранный индекс. Так как теперь направление изменения $\\\\bf w$ будет определяться за $O(1)$, подсчет $Q$ на каждом шаге будет слишком дорогостоящим. Для того, чтобы ускорить оценку $Q$, будем использовать приближенную рекуррентную формулу. Можно выбрать одну из следующих формул:\\n- среднее арифметическое: $\\\\overline{Q}_m = \\\\dfrac{1}{m}\\\\varepsilon_m + \\\\dfrac{1}{m}\\\\varepsilon_{m - 1} + \\\\dfrac{1}{m}\\\\varepsilon_{m - 2} + \\\\dots = \\\\dfrac{1}{m}\\\\varepsilon_m + (1 - \\\\dfrac{1}{m})\\\\overline{Q}_{m-1}$;\\n- экспоненциальное скользящее среднее: $\\\\overline{Q}_m = \\\\lambda\\\\varepsilon_m + (1 - \\\\lambda)\\\\varepsilon_{m - 1} + (1 - \\\\lambda)^2\\\\varepsilon_{m - 2} + \\\\dots = \\\\lambda\\\\varepsilon_m + (1-\\\\lambda)\\\\overline{Q}_{m - 1},$ где $\\\\lambda$ $-$ темп забывания предыстории ряда.\\nПсевдокод\\ndef SGD(X, h, $\\\\lambda$): # где X $-$ выборка, h $-$ градиентный шаг, а $\\\\lambda$ $-$ темп забывания ${\\\\bf w} =$ initialize_weights() # инициализировать веса $\\\\overline{Q} = \\\\frac{1}{l} \\\\sum_{i=1}^{l}\\\\mathscr{L}_i({\\\\bf w})$ # инициализировать оценку функционала while $Q$ not converges or ${\\\\bf w}$ not converges: $i =$ rand() % $l$ # случайно выбрать элемент, по которому будет считаться градиент $\\\\varepsilon = \\\\mathscr{L}_i({\\\\bf w})$ # вычислить потерю ${\\\\bf w} = {\\\\bf w} - h \\\\nabla \\\\mathscr{L}_i({\\\\bf w})$ # обновить вектор весов в направлении антиградиента $\\\\overline{Q} = \\\\lambda\\\\varepsilon + (1 - \\\\lambda)\\\\overline{Q}$ # оценить функционал return w\\nЭвристики\\nСуществует несколько способов инициализировать веса:\\n- ${\\\\bf w} = {\\\\bf 0}$;\\n- $w_j = random(-\\\\dfrac{1}{2n}, \\\\dfrac{1}{2n})$. Стоит брать небольшие случайные веса, так как если выбрать их слишком большими, в некоторых случаях (к примеру в случае нейрона с функцией активациии равной арктангенсу) большие начальные значения веса могут привести в область с малыми по модулю производными, в связи с чем из такой области будет трудно выбраться;\\n- $w_j = \\\\dfrac{\\\\langle y, f_j \\\\rangle}{\\\\langle f_j, f_j \\\\rangle}$, где $f_j = (f_j(x_i))_{i=1}^l$. Оценка оптимальная в случае, если функция потерь квадратична и признаки нескоррелированы, то есть $\\\\langle f_j, f_k \\\\rangle = 0, j \\\\neq k$.\\nТак же можно запустить спуск несколько раз с разными начальными приближениями и выбрать лучшее решение.\\nПри выборе случайного элемента можно использовать следующие эвристики:\\n- брать объекты из разных классов;\\n- брать объекты, на которых ошибка больше, то есть чем меньше отступ (в метрических классификаторах расстояние от разделяющей поверхности до объекта) i-го объекта $M_i$, тем больше вероятность взять этот объект;\\n- брать объекты, на которых уверенность меньше, то есть чем меньше $|M_i|$, тем больше вероятность взять этот объект;\\n- не брать объекты, на которых уже высокая уверенность ($M_i > \\\\mu_+$) либо не брать объекты-выбросы ($M_i<\\\\mu_i$);\\nВыбирать величину градиентного шага можно следующими способами:\\n- $h_t = \\\\dfrac{1}{t}$;\\n- метод скорейшего градиентного спуска: $\\\\mathscr{L}_i({\\\\bf w} - h\\\\nabla \\\\mathscr{L}_i({\\\\bf w})) \\\\rightarrow \\\\min\\\\limits_h$;\\n- при квадратичной функции потерь можно использовать $h = ||x_i||^2$;\\n- иногда можно выполнять пробные шаги, а именно увеличивать $h$ для выбивания процесса из локальных минимумов;\\n- метод Левенберга-Марквардта;\\nРегуляризация\\nОсновным способом уменьшить переобучение является регуляризация, т.е. сокращение весов. Будем штрафовать за увеличение нормы вектора весов, для этого перепишем функцию потерь $\\\\tilde{\\\\mathscr{L}}_i({\\\\bf w}) = \\\\mathscr{L}_i({\\\\bf w}) + \\\\dfrac{\\\\tau}{2}||w||^2 = \\\\mathscr{L}_i({\\\\bf w}) + \\\\dfrac{\\\\tau}{2} \\\\sum\\\\limits_{j=1}^nw_j^2 \\\\rightarrow \\\\min\\\\limits_w$, где $\\\\tau$ $-$ коэффициент регуляризации.\\nТогда градиент будет следующим: $\\\\nabla \\\\tilde{\\\\mathscr{L}}_i({\\\\bf w}) = \\\\nabla \\\\mathscr{L}_i({\\\\bf w}) + \\\\tau {\\\\bf w}$, а градиентный шаг будет выглядеть так: ${\\\\bf w} = {\\\\bf w}(1 - h\\\\tau) - h\\\\nabla \\\\mathscr{L}_i({\\\\bf w})$.\\nДостоинства и недостатки\\nДостониства:\\n- легко реализуется;\\n- функция потерь и семейство алгоритмов могут быть любыми (если функция потерь не дифференцируема, ее можно аппроксимировать дифференцируемой);\\n- легко добавить регуляризацию;\\n- возможно потоковое обучение;\\n- подходит для задач с большими данными, иногда можно получить решение даже не обработав всю выборку;\\nНедостатки\\n- нет универсального набора эвристик, их нужно выбирать для конкретной задачи отдельно;\\nПример кода scikit-learn\\nКлассификатор sklearn.linear_model.SGDClassifier имеет несколько параметров, например:\\nloss $-$ функция потерь. По умолчанию используется \"hinge\", дающая алгоритм линейного SVM;\\npenalty $-$ метод регуляризации. По умолчанию \"l2\";\\nalpha $-$ $\\\\tau$, коэффициент регуляризации;\\nlearning_rate $-$ алгоритм изменения градиентного шага;\\neta0 $-$ начальный градиентный шаг;\\nshuffle перемешивать тренировочную выборку после каждой итерации;\\n- Импортируем нужные библиотеки:\\nfrom sklearn.linear_model import SGDClassifier from sklearn import datasets from sklearn.model_selection import train_test_split\\n- Выберем тренировочное и тестовое множества:\\niris = datasets.load_iris() X = iris.data y = iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\\n- Обучение:\\nclf = SGDClassifier(shuffle = True) model = clf.fit(X_train, y_train)\\n- Предсказание:\\ny_pred = model.predict(X_test) model.score(X_test, y_test)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='83bbd08f-38b8-467b-8119-17f621034611', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7f0c7c46425cbf78a1472a7d2761aac358ec7c7d6b0823d38a84c140653ebc21', text='Регуляризация\\n|Определение:\\n|Регуляризация (англ. regularization) в статистике, машинном обучении, теории обратных задач — метод добавления некоторых дополнительных ограничений к условию с целью решить некорректно поставленную задачу или предотвратить переобучение. Чаще всего эта информация имеет вид штрафа за сложность модели.\\nСодержание\\n- 1 Мотивация\\n- 2 Основные виды регуляризации\\n- 3 Вероятностная интерпретация регуляризации\\n- 4 Регуляризация в линейной регрессии\\n- 5 Регуляризация в алгоритмах\\n- 6 Другие использования регуляризации\\n- 7 См. также\\n- 8 Примечания\\n- 9 Источники информации\\nМотивация\\nКак говорилось ранее, регуляризация полезна для борьбы с переобучением. Если вы выбрали сложную модель, и при этом у вас недостаточно данных, то легко можно получить итоговую модель, которая хорошо описывает обучающую выборку, но не обобщается на тестовую.\\nНа примере линейной регрессии\\nВ качестве наглядного примера рассмотрим линейные регрессионные модели. Восстановить зависимость для нескольких точек можно пытаться полиномами разной степени $M$.\\nНа Рис. 1 представлена зависимость, которая хорошо подходит для описания данных, а на Рис. 2 — модель, слишком сильно заточенная под обучающую выборку.\\nОднин из способов бороться с негативным эффектом излишнего подстраивания под данные — использование регуляризации, т. е. добавление некоторого штрафа за большие значения коэффициентов у линейной модели. Тем самым запрещаются слишком \"резкие\" изгибы, и предотвращается переобучение.\\nНа примере логистической регрессии\\nНеобходимость регуляризации можно увидеть и на другом примере — при использовании логистической регресии. Представьте, что ваша обучающая выборка была линейно разделима. В таком случае в процессе оптимизации значения весов модели уйдут в бесконечность, и вместо сигмойды получится \"ступенька\", представленная на Рис. 3.\\nЭто плохо, ибо произошло затачивание под обучающую выборку. Как и в предыдущем примере, побороться с этим можно путем добавления регуляризатора, не дающего весам принимать слишком большие значения.\\nОсновные виды регуляризации\\nПереобучение в большинстве случаев проявляется в том, что итоговые модели имеют слишком большие значения параметров. Соответственно, необходимо добавить в целевую функцию штраф за это. Наиболее часто используемые виды регуляризации —и , а также их линейная комбинация — эластичная сеть.\\nВ представленных ниже формулах для эмпирического риска модели алгоритма, а — неотрицательный гиперпараметр, являющийся коэффициентом регуляризации.: является функцией потерь, а — вектором параметров из\\n-регуляризация\\n|Определение:\\n|-регуляризация, или регуляризация Тихонова (англ. ridge regularization или Tikhonov regularization):\\nМинимизация регуляризованного cоответствующим образом эмпирического риска приводит к выбору такого вектора параметров, которое не слишком сильно отклоняется от нуля. В линейных классификаторах это позволяет избежать проблем мультиколлинеарности и переобучения.\\n-регуляризация\\n|Определение:\\n| манхэттенское расстояние:\\n-регуляризация (англ. lasso regularization), или регуляризация через\\nДанный вид регуляризации также позволяет ограничить значения вектора. Однако, к тому же он обладает интересным и полезным на практике свойством — обнуляет значения некоторых параметров, что в случае с линейными моделями приводит к отбору признаков.\\nЗапишем задачу настройки вектора параметров:\\n- ,\\nгде— некоторая ограниченная гладкая функция потерь. Сделаем замену переменных, чтобы функционал стал гладким. Каждой переменной поставим в соответствие две новые неотрицательные переменные:\\nТогда:\\nВ новых переменных функционал становится гладким, но добавляются ограничения-неравенства:\\nДля любогохотя бы одно из ограничений и обращается в равенство, иначе второе слагаемое в можно было бы уменьшить, не изменив первое. Если гиперпараметр устремить к , в какой-то момент все ограничений обратятся в равенство. Постепенное увеличение гиперпараметра приводит к увеличению числа таких , для которых , откуда следует, что . Как говорилось ранее, в линейных моделях это означает, что значения -го признака игнорируются, и его можно исключить из модели.\\nЭластичная сеть\\n|Определение:\\n|Эластичная сеть (англ. elastic net regularization):\\nПриведенная регуляризация использует как, так и регуляризации, учитывая эффективность обоих методов. Ее полезной особенностью является то, что она создает условия для группового эффекта при высокой корреляции переменных, а не обнуляет некоторые из них, как в случае с -регуляризацией.\\nВероятностная интерпретация регуляризации\\nЭквивалентная вероятностная задача\\nПеред нами стоит задача — минимизировать эмпирический риск:\\nВероятностная модель данных дает возможность по-другому взглянуть на задачу. Пусть — является вероятностным пространством. Тогда вместо задана совместная плотность распределение объектов и классов .\\nДля настройки вектора параметров $\\\\beta$ воспользуемся принципом максимума правдоподобия:\\nУдобнее рассматривать логарифм правдоподобия:\\nМожно заключить, что задачи в исходном и вероятностном представлении эквивалентны, если положить:\\nПринцип максимума совместного правдоподобия данных и модели\\nДопустим, что наряду с параметрической моделью плотности распределенияимеется еще и априорное распределение в пространстве параметров модели . Чтобы ослабить априорные ограничения, вместо фиксированной функции вводится параметрическое семейство априорных распределений , где — гиперпараметр.\\nПринцип максимума правдоподобия теперь будет записываться по-другому, так как не только появление выборки, но и появление модели также является случайным. Их совместное появление описывается, согласно формуле условной вероятности, плотностью распределения:\\nТаким образом, приходим к принципу максимума совместного правдоподобия данных и модели:\\nФункционалраспадается на два слагаемых: логарифм правдоподобия и регуляризатор, не зависящий от данных. Второе слагаемое ограничивает вектор параметров модели, не позволяя ему быть каким угодно.\\nВ итоге мы получили, что с байесовской точки зрения многие методы регуляризации соответствуют добавлению некоторых априорных распределений на параметры модели. При этом можно определить распределения, которые соответствуют представленным ранееи регуляризаторам.\\nНормальный регуляризатор\\nПусть вектор [1], все его компоненты независимы и имеют равные дисперсии:имеет нормальное распределение\\nЛогарифмируя, получаем квадратичный регуляризатор:\\nгде— слагаемое, не зависящее от , которым можно пренебречь, поскольку оно не влияет на решение оптимизационной задачи. В итоге имеем -регуляризатор.\\nЛапласовский регуляризатор\\nПусть вектор [2], все его компоненты независимы и имеют равные дисперсии:имеет распределение Лапласа\\nТогда:\\nАналогично случаю с нормальным регуляризатором,можно опустить и, таким образом, получаем -регуляризатор.\\nРаспределение Лапласа имеет более острый пик и более тяжёлые «хвосты», по сравнению с нормальным распределением, как можно видеть на Рис. 4. Дисперсия Лапласовского распределения равна.\\nРегуляризация в линейной регрессии\\nВ линейной регрессии моделируется линейная зависимость между зависимой и независимой переменной. Каждому объекту $x \\\\in X^l$ соответствует признаковое описание $(f_{1}(x),\\\\dots,f_{n}(x))$, где $f_{j}:X \\\\rightarrow \\\\mathbb{R}$ — числовые признаки. Модель алгоритмов для линейной регрессии состоит из функций вида:\\n- $g(x, \\\\beta) = \\\\sum\\\\limits_{j}^n \\\\beta_{j} \\\\,f_{j}(x)$\\nВ итоге оптимизируемый функционал эмпирического риска выглядит следующим образом:\\n- $Q(a) = \\\\|F\\\\beta - y\\\\|^2$,\\nгде $F = (f_{j}(x_{i}))_{l \\\\times n}$ — матрица объекты-признаки, $y = (y_{i})_{l \\\\times 1}$ — целевой вектор, $\\\\beta = (\\\\beta_{j})_{n \\\\times 1}$ — вектор параметров. Приравняв нулю производную $Q(\\\\beta)$ по параметру $\\\\beta$, получаем:\\n- $\\\\beta^* = (F^TF)^{-1}F^Ty$\\nВ итоге, используя сингулярное разложение для представления $F$ и проведя МНК-аппроксимизацию целевого вектора $y$, имеем выражение для нормы вектора $\\\\beta$:\\n- $\\\\|\\\\beta^*\\\\|^2 = \\\\sum\\\\limits_{j=1}^n \\\\dfrac{1}{\\\\lambda_{j}}(v_{j}^Ty)^2$\\nК сожалению, могут возникнуть проблемы мультиколлинеарности и переобучения в случае, если ковариационная матрица $\\\\sum = F^T F$ плохо обусловлена. Одним из способов борьбы с этими проблемами, как говорилось ранее, является регуляризация.\\nВ статье о вариациях регрессии представлены модификации линейной регресиии с различными регуляризаторами ($L_{1}$ и $L_{2}$) и их отличие. Описание в данном разделе будет похожим, однако здесь будет рассмотрен эффект от добавления регуляризаторов немного подробнее.\\nГребневая регрессия\\nВ гребневой регрессии к функционалу $Q$ добавляется $L_{2}$-регуляризатор.\\nИтоговый минимизируемый функционал с поправкой:\\nИтоговое выражение для параметра $\\\\beta$:\\nТаким образом, перед обращением матрицы к ней добавляется \"гребень\" — диагональная матрица $\\\\tau I_{n}$. При этом все её собственные значения увеличиваются на $\\\\tau$, а собственные векторы не изменяются. В результате матрица становится хорошо обусловленной, оставаясь в то же время «похожей» на исходную.\\nОценим эффект, который оказывает добавление гребня. Выразим регуляризованное МНК-решение через сингулярное разложение:\\n- $\\\\beta_{t}^* = (UD^2U^T + \\\\tau I_{n})^{-1}UDV^{T}y=U(D^2+\\\\tau I_{n})^{-1}DV^Ty=\\\\sum\\\\limits_{j=1}^n \\\\dfrac{\\\\sqrt{\\\\lambda_{j}}}{\\\\lambda_{j} + \\\\tau}u_{j}(v_{j}^Ty)$\\nТеперь найдём регуляризованную МНК-аппроксимацию целевого вектора y:\\n- $F \\\\beta_{\\\\tau}^* = VDU^T \\\\beta_{\\\\tau}^* = V diag \\\\left(\\\\dfrac{\\\\lambda_{j}}{\\\\lambda_{j} + \\\\tau} \\\\right)V^Ty = \\\\sum\\\\limits_{j=1}^n \\\\dfrac{\\\\lambda_{j}}{\\\\lambda_{j} + \\\\tau}v_{j}(v_{j}^Ty)$\\nКак можно видеть, проекции на собственные векторы сокращаются, умножаясь $\\\\dfrac{\\\\lambda_{j}}{\\\\lambda_{j} + \\\\tau} \\\\in (0, 1)$.\\nВ сравнении с нерегуляризованным случаем, уменьшается и норма вектора $\\\\beta$:\\n- $\\\\|\\\\beta_{\\\\tau}^*\\\\|^2 = \\\\| D^2(D^2 + \\\\tau I_{n})^{-1}D^{-1}V^{T}y)\\\\|^2 = \\\\sum\\\\limits_{j=1}^n \\\\dfrac{1}{\\\\lambda_{j} + \\\\tau}(v_{j}^Ty)^2 < \\\\sum\\\\limits_{j=1}^n \\\\dfrac{1}{\\\\lambda_{j}}(v_{j}^Ty)^2 = \\\\|\\\\beta^*\\\\|^2$\\nПоэтому данный метод называют также сжатие или сокращение весов.\\nИз формул видно, что по мере увеличения параметра $\\\\tau$ вектор коэффициентов $\\\\beta_{\\\\tau}^*$ становится всё более устойчивым и жёстко определённым. Фактически, происходит понижение эффективной размерности решения — это второй смысл термина сжатие. Роль размерности играет след проекционной матрицы.\\nВ нерегуляризованном случае:\\n- $n_{effective} = tr\\\\:F(F^TF)^{-1}F^T = tr\\\\:(F^TF)^{-1}F^TF = tr\\\\:I_{n} = n$\\nВ случае с гребнем:\\n- $n_{effective} = tr\\\\:F(F^TF + \\\\tau I_{n})^{-1}F^T = tr\\\\:diag \\\\left(\\\\dfrac{\\\\lambda_{j}}{\\\\lambda_{j} + \\\\tau}\\\\right) = \\\\sum\\\\limits_{j=1}^n \\\\dfrac{1}{\\\\lambda_{j}} < n$\\nЛассо регрессия\\nВ лассо регрессии к функционалу $Q$ добавляется $L_{1}$-регуляризатор.\\nИтоговый минимизируемый функционал с поправкой:\\nЗапишем систему для этой регрессии в виде минимизации неизменного функционала $Q$ при неравенстве-ограничении:\\n- $\\\\begin{cases} Q(\\\\beta) = \\\\| F\\\\beta - y \\\\|^2 \\\\rightarrow \\\\min\\\\limits_{\\\\beta} \\\\\\\\ \\\\sum\\\\limits_{j=1}^n|\\\\beta_{j}| \\\\leq \\\\chi \\\\\\\\ \\\\end{cases}$\\nТак как используется $L_{1}$-регуляризатор, коэффициенты $\\\\beta_{j}$ постепенно обнуляются с уменьшением $\\\\chi$. Происходит отбор признаков, поэтому параметр $\\\\chi$ называют еще селективностью. Параметр $\\\\chi$ \"зажимает\" вектор коэффициентов $\\\\beta$, отсюда и название метода — лассо (англ. LASSO, least absolute shrinkage and selection operator).\\nСравнение гребневой и лассо регрессий\\nОсновное различие лассо и гребневой регрессий заключается в том, что первая может приводить к обращению некоторых независимых переменных в ноль (используется $L_{1}$-регуляризатор), тогда как вторая уменьшает их до значений, близких к нулю (используется $L_{2}$-регуляризатор).\\nПродублируем наглядный пример из статьи о вариациях регрессии. Рассмотрим для простоты двумерное пространство независимых переменных. В случае лассо регрессии органичение на коэффициенты представляет собой ромб ( ), в случае гребневой регрессии — круг ( ). Необходимо минимизировать функцию ошибки, но при этом соблюсти ограничения на коэффициенты. С геометрической точки зрения задача состоит в том, чтобы найти точку касания линии, отражающей функцию ошибки с фигурой, отражающей ограничения на . Из Рис. 5 интуитивно понятно, что в случае лассо регрессии эта точка с большой вероятностью будет находиться на углах ромба, то есть лежать на оси, тогда как в случае гребневой регрессии такое происходит очень редко. Если точка пересечения лежит на оси, один из коэффициентов будет равен нулю, а значит, значение соответствующей независимой переменной не будет учитываться.\\nТакже полезно будет рассмотреть простую модельную задачу. Пусть $l = n$ и матрица объекты-признаки является единичной $F = I$. Тогда МНК-решение дает вектор коэффициентов $\\\\beta$:\\n- $\\\\beta^* = argmin \\\\left(\\\\sum\\\\limits_{i=1}^l(\\\\beta_{i} - y_{i})^2\\\\right)$\\n- $\\\\beta_{j}^* = y_{j}$\\nВ случае с гребневой регрессией:\\n- $\\\\beta_{j}^* = \\\\dfrac{y_{j}}{1 + \\\\lambda}$\\nВ случае с лассо регрессией:\\n- $\\\\beta_{j}^* = \\\\begin{cases} y_{j} - \\\\lambda / 2, y_{j} > \\\\lambda / 2 \\\\\\\\ y_{j} + \\\\lambda / 2, y_{j} < -\\\\lambda / 2 \\\\\\\\ 0, |y_{j}| \\\\leq \\\\lambda / 2 \\\\end{cases}$\\nВ итоге на Рис. 6 на графиках с зависимостями $\\\\beta_{j}^*$ от $y_{j}$ можно увидеть описанные ранее особенности данных регуляризованных линейных регрессий.\\nРегуляризация в алгоритмах\\nГрадиентный спуск\\nАлгоритм градиентного спуска используют для нахождения аппроксимирующей зависимости, определяя вектор весов , при котором достигается минимум эмпирического риска:\\nВ этом методе выбирается некоторое начальное приближение для вектора весов, затем запускается итерационный процесс, на каждом шаге которого вектор $w$ изменяется в направлении наиболее быстрого убывания функционала $Q$ — противоположно вектору градиента :\\n- ,\\nгде— величина шага в направлении антиградиента.\\nРегуляризация — одна из эвристик улучшения градиентных методов обучения. Основным способом уменьшить переобучение является квадратичная регуляризация, называемая также сокращением весов. Чтобы ограничить рост абсолютных значений весов, к минимизируемому функционалудобавляется штрафное слагаемое:\\nЭто приводит к появлению аддитивной поправки в градиенте:\\nВ результате правило обновления весов принимает вид:\\nТаким образом, вся модификация сводится к появлению неотрицательного множителя, приводящего к постоянному уменьшению весов.\\nРегуляризация предовтращает паралич, повышает устойчивость весов в случае мультиколлинеарности, повышает обобщающую способность алгоритма и снижает риск переобучения. Однако есть и недостатки — параметр кросс-валидации, что связано с большими вычислительными затратами.необходимо выбирать с помощью\\nМетод опорных векторов\\nМетод опорных векторов (SVM) используется для задач классификации и регрессии. В нем строится гиперплоскость, разделяющая объекты выборки оптимальным образом.\\nК сожалению, зачастую выборка является линейно неразделимой. В таком случае приходится \"ослаблять ограничения\", позволяя некоторым объектам попадать на территорию другого класса. Для каждого объекта от отступа отнимается некоторая положительная величина $\\\\xi_i$, но требуется, чтобы введенные поправки были минимальны. В итоге постановка задачи SVM с мягким отступом (англ. soft-margin SVM) выглядит следующим образом: $\\\\begin{cases} \\\\dfrac{1}{2} \\\\lVert w \\\\rVert^2 + C \\\\sum\\\\limits_{i=1}^l \\\\xi_i \\\\to \\\\min\\\\limits_{w, b, \\\\xi} \\\\\\\\ M_i(w, b) \\\\geq 1 - \\\\xi_i, \\\\quad i = 1, \\\\ldots, l \\\\\\\\ \\\\xi_i \\\\geq 0, \\\\quad i = 1, \\\\ldots, l \\\\\\\\ \\\\end{cases}$\\nКак показано в соответствующем данному методу разделе, эквивалентной задачей безусловной минимизации является: $Q(w, b) = \\\\dfrac{1}{2C} \\\\lVert w \\\\rVert^2 + \\\\sum\\\\limits_{i=1}^l \\\\left(1 - M_i(w, b)\\\\right)_+ \\\\to \\\\min\\\\limits_{w, b}$\\nВ силу неравенства $[M_{i} < 0] \\\\leq (1 - M_{i})_{+}$, функционал $Q(w, b)$ можно рассматривать как верхнюю оценку эмпирического риска, к которому добавлен регуляризатор $\\\\dfrac{1}{2C} \\\\|w\\\\|^2$.\\nС введением регуляризатора устраняется проблема мультиколлинеарности, повышается устойчивость алгоритма, улучшается его обобщающая способность.\\nВ результате получаем, что принцип оптимальной разделяющей гиперплоскости или максимизации ширины разделяющей полосы в случае неразделимой выборки тесно связан с $L_{2}$-регуляризацией, которая возникает естественным образом из постановки задачи.\\nТакже существуют разновидности SVM с другими регуляризаторами.\\n- Метод релевантных векторов (англ. RVM, Relevance vector Machine):\\n- $\\\\dfrac{1}{2}\\\\sum\\\\limits_{i=1}^l\\\\left(\\\\ln w_{i} + \\\\dfrac{\\\\lambda_{i}^2}{w_{i}}\\\\right)$\\n- Метод опорных векторов с лассо (англ. LASSO SVM):\\n- $\\\\mu \\\\sum\\\\limits_{i=1}^n|w_{i}|$\\n- Метод опорных признаков (англ. Support feature machine):\\n- $\\\\sum\\\\limits_{i=1}^nR_{\\\\mu}(w_{i}), \\\\begin{cases} 2 \\\\mu |w_{i}|, |w_{i}|<\\\\mu \\\\\\\\ \\\\mu^2 + w_{i}^2, |w_{i}| \\\\geq \\\\mu \\\\end{cases}$\\nДругие использования регуляризации\\nЛогистическая регрессия\\nКак было показано в мотивационном примере, для логистической регрессии может быть полезно использовать регуляризацию.\\nДля настройки вектора коэффициентов $\\\\beta$ по обучающей выборке $X^l$ максимизируют логарифм правдоподобия:\\n- $L(\\\\beta, X^l) = log_{2}\\\\prod\\\\limits_{i=1}^lp(x_{i}, y_{i}) \\\\rightarrow \\\\max\\\\limits_{\\\\beta}$\\n- $L(\\\\beta, X^l) = \\\\sum\\\\limits_{i=1}^{l}log_{2}\\\\sigma(\\\\langle \\\\beta, x_{i} \\\\rangle y_{i}) + const(\\\\beta) \\\\rightarrow \\\\max\\\\limits_{\\\\beta}$\\n$L_{2}$-регуляризация:\\n- $L(\\\\beta, X^l) = \\\\sum\\\\limits_{i=1}^{l}log_{2}\\\\sigma(\\\\langle \\\\beta, x_{i} \\\\rangle y_{i}) - \\\\lambda \\\\| \\\\beta \\\\|^2 + const(\\\\beta) \\\\rightarrow \\\\max\\\\limits_{\\\\beta}$\\n$L_{1}$-регуляризация:\\n- $L(\\\\beta, X^l) = \\\\sum\\\\limits_{i=1}^{l}log_{2}\\\\sigma(\\\\langle \\\\beta, x_{i} \\\\rangle y_{i}) - \\\\lambda \\\\|\\\\beta \\\\|_{1} + const(\\\\beta) \\\\rightarrow \\\\max\\\\limits_{\\\\beta}$\\nАналогично можно использовать и другие регуляризаторы.\\nНейронные сети\\nРегуляризация также используется и в нейронных сетях для борьбы со слишком большими весами сети и переобучением. Однако, в этом случае зануление коэффициентов при использовании $L_{1}$-регуляризатора не несет в себе смысл \"отбора признаков\", как в случае с линейными моделями. К сожалению, регуляризация не снижает число параметров и не упрощает структуру сети.\\nДля нейронной сети помимо добавления штрафного слагаемого к эмпирическому риску активно используют и другой метод борьбы с переобучением — прореживание сети (англ. dropout), в ходе которого упрощают сеть, руководствуясь правилом — если функция ошибки не изменяется, то сеть можно упрощать и дальше. Подробнее об этом можно почитать в статье, рассказывающей о практике реализации нейронных сетей.\\nСм. также\\n- Переобучение\\n- Модель алгоритма и её выбор\\n- Байесовская классификация\\n- Вариации регрессии\\n- Линейная регрессия\\n- Логистическая регрессия\\n- Стохастический градиентный спуск\\n- Метод опорных векторов (SVM)\\n- Нейронные сети, перцептрон\\n- Практики реализации нейронных сетей\\nПримечания\\nИсточники информации\\n- Воронцов К.В. — Математические методы обучения по прецедентам\\n- Википедия — Регуляризация (математика)\\n- coursea.org — Регуляризация\\n- machinelearning.ru — L1-регуляризация линейной регрессии\\n- medium.com — 5 видов регрессии и их свойства\\n- Wikipedia — Elastic net regularization\\n- Keng B. — A Probabilistic Interpretation of Regularization', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='d928a297-fbe2-406b-9291-40672a6f030e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3b9410efef9b96bf0b04cdecbf782e245eac9690b542f041881016ec5e8440d7', text='Ранжирование\\nРанжирование (англ. learning to rank) — это класс задач машинного обучения с учителем, заключающихся в автоматическом подборе ранжирующей модели по обучающей выборке, состоящей из множества списков и заданных частичных порядков на элементах внутри каждого списка. Частичный порядок обычно задаётся путём указания оценки для каждого элемента (например, «релевантен» или «не релевантен»). Цель ранжирующей модели — наилучшим образом приблизить и обобщить способ ранжирования в обучающей выборке на новые данные.\\nСодержание\\n- 1 Постановка задачи\\n- 2 Примеры\\n- 3 Метрики качества ранжирования\\n- 4 Методы ранжирования\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nПостановка задачи\\n— множество объектов.\\n— обучающая выборка.\\nчастичный порядок на парах . \"Правильность\" зависит от постановки задачи, а именно запись может означать, что объект имеет ранг выше, чем объект , так и наоборот.— правильный\\nЗадача:\\nПостроить ранжирующую функциютакую, что: .\\nЛинейная модель ранжирования:\\n, где — вектор признаков объекта .\\nПримеры\\nЗадача ранжирования поисковой выдачи\\n— коллекция текстовых документов.\\n— множество запросов.\\n— множество документов, найденных по запросу .\\n— объектами являются пары (запрос, документ): .\\n— упорядоченное множество рейтингов.\\n— оценки релевантности, поставленные асессорами (экспертами): чем выше оценка , тем релевантнее документ по запросу .\\nПравильный порядок определен только между документами, найденными по одному и тому же запросу: .\\nРелевантные ответы запросу— это список документов , упорядоченных с помощью функции ранжирования .\\nКоллаборативная фильтрация\\n— пользователи.\\n— предметы (фильмы, книги и т.д.).\\n— объектами являются пары (пользователь, предмет).\\nПравильный порядок определён между предметами, которые выбирал или рейтинговал один и тот же пользователь:.\\nРекомендация пользователю— это список предметов , упорядоченный с помощью функции ранжирования .\\nМетрики качества ранжирования\\nТочность ранжирования\\nВ самой простой постановке задачи ранжирования целевая переменная принимает два значения, документ либо релевантен запросу, либо нет:\\nгде – целевая переменная, – запрос, – документ.\\nПусть также есть некоторая модель, оценивающая релевантность документа запросу. По значениям, полученным с помощью этой модели, можно отранжировать документы. будет обозначать -й по релевантности документ для запроса .\\nПосле того как введены обозначения можно задать простейшую метрику ранжирования. Это, точность среди первых документов ( — параметр метрики). Если ранжируется поисковая выдача, и на первой странице показываются 10 документов, то разумно выбирать . Данная метрика определяется как доля релевантных документов среди первых , полученных с помощью модели:\\n.\\nОднако у неё есть серьёзный недостаток: позиции релевантных документов никак не учитываются. Например, если присреди первых документов есть релевантных, то неважно, где они находятся: среди первых или последних документов. Обычно же хочется, чтобы релевантные документы располагались как можно выше.\\nОписанную проблему можно решить, модифицировав метрику, и определить среднюю точность (англ. average precision). Данная метрика тоже измеряется на уровнеи вычисляется следующим образом:\\n.\\nДанная величина уже зависит от порядка. Она достигает максимума, если все релевантные документы находятся вверху ранжированного списка. Если они смещаются ниже, значение метрики уменьшается.\\nИ точность, и средняя точность вычисляются для конкретного запроса. Если выборка большая и размечена для многих запросов, то значения метрик усредняются по всем запросам:\\n.\\nДисконтированный совокупный доход\\nВторой подход к измерению качества ранжирования — дисконтированный совокупный доход (англ. discounted cumulative gain) или DCG. Он используется в более сложной ситуации, когда оценки релевантностимогут быть вещественными: .\\nТо есть для каждого документа теперь существует градация между релевантностью и нерелевантностью. Остальные обозначения остаются теми же, что и для предыдущей метрики. Формула для вычисления DCG:\\n.\\nМетрика — это сумма дробей. Чем более релевантен документ, тем больше числитель в дроби. Знаменатель зависит от позиции документа, он штрафует за то, где находится документ. Если документ очень релевантен, но занимает низкую позицию, то штраф будет большим, если документ релевантен и находится вверху списка, штраф будет маленьким. Таким образом, метрика DCG учитывает и релевантность, и позицию документа. Она достигает максимума, если все релевантные документы находятся в топе списка, причём отсортированные по значению. Данную метрику принято нормировать:\\n, где — значение DCG при идеальном ранжировании. После нормировки метрика принимает значения от 0 до 1.\\nПример вычисления DCG и nDCG:\\nДано множество документов, где каждый документ оценивается отдо , где — очень релевантен, а — не релевантен. Пусть таким множеством будет , где оценка релевантности по опросу пользователей задается(в том же порядке) множеством .\\nТогда.\\n|i\\nИдеальный порядок оценок релевантности. DCG для данного множества будет следующим: .\\n|i\\nИтого.\\nМетоды ранжирования\\nВсего выделяют три подхода к решению задачи ранжирования: поточечный (англ. pointwise), попарный (англ. pairwise), списочный (англ. listwise). Выбор метода зависит от качества ранжирования данных. Теоретически, списочный подход считается наилучшим, однако, на практике, например в Яндексе, лучше всего работает попарный подход.\\nПоточечный подход\\nСамый простой подход — это поточечный. В нём игнорируется тот факт, что целевая переменнаязадаётся на парах объектов, и оценка релевантности считается для каждого объекта.\\nЕсли речь идёт о задаче ранжирования поисковой выдачи, то пусть асессор поставил какую-то оценкукаждой паре (запрос, документ). Эта оценка и будет предсказываться. При этом никак не учитывается, что нужно предсказать порядок объектов, а не оценки. Этот подход является простым в том смысле, что в нём используются уже известные методы. Например, можно предсказывать оценки с использованием линейной регрессии и квадратичной ошибки:\\nИзвестно, как решать такую задачу, и таким образом будет получена релевантность. Далее по выходам модели можно ранжировать объекты.\\nПопарный подход\\nВ попарном подходе используются знания об устройстве целевой переменной. Модель строится сведением к минимуму количества дефектных пар, то есть таких, в которых моделью был предсказан неправильный порядок:\\nК сожалению, этот функционал дискретный (в него входят индикаторы), поэтому невозможно его минимизировать. Однако можно действовать так же, как и с классификаторами: оценить функционал сверху.\\nМожно считать, что разница между объектами— это отступ , и задать некоторую гладкую функцию :\\nЕсли использовать функцию как в логистической регрессии стохастического градиентного спуска., то полученный метод называется RankNet. Затем можно решать задачу, например, с помощью\\nСписочный подход\\nВ методе RankNet шаг стохастического градиентного спуска для линейной модели выглядит следующим образом:\\nЗаметим, что данная формула зависит от одной пары объектов, а также не учитываются зависимости между различными парами. Возникает вопрос, можно ли модифицировать данный метод (а именно формулу шага) так, чтобы минимизировался не исходный функционал, оценивающий долю дефектных пар, а DCG.\\nДействительно, можно домножить градиент исходного функционала на то, насколько изменится nDCG, если поменять местамии :\\nДанный метод называется LambdaRank[1].\\nОказывается, что при выполнении градиентного спуска с помощью данных шагов оптимизируется nDCG. Существуют и другие подходы к оптимизации nDCG, однако в них предпринимается попытка работы с функционалом, что гораздо сложнее.\\nСм. также\\n- Общие понятия\\n- Стохастический градиентный спуск\\n- Рекомендательные системы[на 17.03.19 не создан]\\nПримечания\\nИсточники информации\\n- Обучение ранжировнию — статья на machinelearning.ru\\n- Learning to rank — презентация на coursera.org\\n- Курс лекций по машинному обучению — Воронцов К.В.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='fe8e0228-a73f-4477-9e79-76b1b8540157', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9a07d911a3fc67c367473fbc198e1583d4a1efcf4563b401f568189e7f0f0f05', text='Рекомендательные системы\\nРекомендательные системы — программы, которые пытаются предсказать, какие объекты будут интересны пользователю, имея определенную информацию о его профиле.\\nСодержание\\n- 1 Обзор и постановка задачи\\n- 2 Кластеризация пользователей\\n- 3 Холодный старт\\n- 4 User-based и item-based алгоритмы\\n- 5 Алгоритм SVD\\n- 6 Решение проблемы матрицы оценок\\n- 7 Численная оптимизация\\n- 8 Измерение качества рекомендаций\\n- 9 См. также\\n- 10 Примечания\\n- 11 Источники информации\\nОбзор и постановка задачи\\nОсновная задача рекомендательных систем[1] — проинформировать пользователя о товарах или услугах, которые будут для него наиболее интересными и актуальными. Разнообразие таких систем можно проиллюстрировать основными характеристиками:\\n- предмет рекомендации;\\n- цель рекомендации;\\n- контекст рекомендации;\\n- источник рекомендации;\\n- степень персонализации;\\n- формат рекомендации;\\n- прозрачность рекомендации.\\nВ центре таких систем лежит матрица предпочтений. В этой матрице одна из осей отвечает за пользователей, вторая за объекты рекомендации. Заполнена же эта матрица значениями по заданной шкале (например отдо ). Так как каждый пользователь обычно может оценить только небольшую часть объектов, то данная матрица очень разрежена. Задача системы — обобщение информации и предсказание отношения пользователя к объекту (заполнение пропущенных значений матрицы).\\nДанные, сообщающие предпочтения пользователя, можно получить двумя способами:\\n- явно (англ. explicit feedback, explicit ratings);\\n- неявно (англ. implicit feedback, implicit ratings).\\nПри явном оценивании пользователь сам показывает, насколько ему интересен тот или иной объект. Типичным примером данных, полученных при явном оценивании, являются рейтинги, проставленные пользователями объектам. На практике таких данных обычно мало. Гораздо больше имеется информации о неявных предпочтениях пользователя: просмотры, клики, добавления в закладки. Однако по таким данным не всегда можно сделать явный вывод об отношении пользователя к объекту. Например, если пользователь посмотрел фильм, то это означает, что до просмотра он ему был интересен, но сделать вывод о том, понравился ли ему фильм, нельзя. В большинстве рекомендательных систем эти два подхода используются вместе, тем самым минимизируются недостатки каждого из них в отдельности.\\nФормализуем задачу. Имеется множество пользователей, множество объектов и множество событий (действия, которые совершают пользователи с объектами). Каждое событие задается пользователем , объектом , своим результатом и, возможно, но не обязательно, другими характеристиками. По итогу от рекомендательной системы требуется:\\n- предсказывать предпочтение пользователя к объекту :\\n- выдавать персональные рекомендации для пользователя :\\n- определять объекты, похожие на объект :\\nКластеризация пользователей\\n|Определение:\\n|Коллаборативная фильтрация (англ. collaborative filtering) — один из методов построения прогнозов (рекомендаций) в рекомендательных системах, использующий известные предпочтения (оценки) группы пользователей для прогнозирования неизвестных предпочтений другого пользователя.\\nОсновная идея метода — похожим пользователям нравятся похожие объекты.\\nАлгоритм можно разбить на следующие шаги:\\n- Выбор условной меры схожести пользователей по истории их оценок .\\n- Объединение пользователей в группы (кластеры) так, чтобы похожие пользователи оказывались в одном кластере .\\n- Предсказание оценки пользователя: средняя оценка кластера этому объекту .\\nПроблемы алгоритма:\\n- нечего рекомендовать новым пользователям, так как их невозможно отнести к какому-либо кластеру;\\n- не учитывается контекст и специфика пользователя;\\n- если в кластере нет оценки объекта, то предсказание невозможно.\\nХолодный старт\\n|Определение:\\n|Холодный старт (англ. cold start) — ситуация, когда ещё не накоплено достаточное количество данных для корректной работы рекомендательной системы.\\nДанная проблема актуальна для новых объектов или объектов, с которыми пользователи редко совершают действия. Если средний рейтинг посчитан по оценкам всего трёх пользователей, такая оценка явно не будет достоверной, и пользователи это понимают. Часто в таких ситуациях рейтинги искусственно корректируют.\\nПервый способ. Предлагается показывать не среднее значение, а сглаженное среднее (англ. damped mean). Смысл таков: при малом количестве оценок отображаемый рейтинг больше тяготеет к некому безопасному «среднему» показателю, а как только набирается достаточное количество новых оценок, «усредняющая» корректировка перестает действовать.\\nВторой способ. Для объекта считается средний рейтинг, затем определяется доверительный интервал(англ. сonfidence interval) этого рейтинга. Математически, чем больше оценок, тем меньше вариация среднего и, значит, больше уверенность в его корректности. А в качестве рейтинга объекта можно выводить, например, нижнюю границу интервала (англ. low CI bound). При этом понятно, что такая система будет достаточно консервативной, с тенденцией к занижению оценок по новым объектам.\\nUser-based и item-based алгоритмы\\nUser-based алгоритм\\nЗаменим жесткую кластеризацию на предположение, что объект понравится пользователю, если он понравился похожим пользователям. Тогда предпочтение пользователяк объекту можно записать следующим образом:\\n, где — средняя оценка, проставленная пользователем , а — мера схожести пользователей и .\\nОднако у этого алгоритма есть недостатки:\\n- холодный старт — новые объекты никому не рекомендуются;\\n- нечего рекомендовать новым/нетипичным пользователям.\\nItem-based алгоритм\\nТакже имеется абсолютно симметричный алгоритм. Теперь будем считать, что объект понравится пользователю, если ему понравились похожие объекты. Предпочтение пользователяк объекту запишется так:\\n, где — средняя оценка, проставленная объекту , а — мера схожести объектов и .\\nУ такого подхода остается недостаток в виде холодного старта и при этом рекомендации становятся тривиальными.\\nCтоит отметить, что ресурсоемкость вычислений такими методами высока: для предсказаний необходимо держать в памяти все оценки всех пользователей.\\nАлгоритм SVD\\nПопробуем воспользоваться сингулярным разложением (SVD) для задачи рекомендации.\\nРазложим матрицу оценокс использованием сингулярного разложения: . Применяя усеченное разложение, получим следующее: . Из свойств сингулярного разложения мы знаем, что матрица является наилучшим низкоранговым приближением с точки зрения средне-квадратичного отклонения. Несколько упростим запись выражения: запишем произведение первых двух матриц , а матрицу обозначим как . Получим формулу . Интерпретировать полученную формулу стоит следующим образом: приближенная матрица оценок может быть вычислена как произведение усеченных матриц пользователей и оценок.\\nБлагодаря использованию такого усечения можно решить одну из главных проблем всех ранее упомянутых алгоритмов: ресурсоемкость вычислений.\\nЧтобы предсказать оценку пользователядля объекта , берём некоторый вектор для данного пользователя и вектор данного объекта . Получаем необходимое предсказание: .\\nПомимо предсказания оценок, алгоритм позволяет выявлять скрытые признаки объектов и интересы пользователей. Например, может так получиться, что на первой координате вектора у каждого пользователя будет стоять число, показывающее, похож ли пользователь больше на мальчика или на девочку, на второй координате — число, отражающее примерный возраст пользователя. У фильма же первая координата будет показывать, интересен ли он больше мальчикам или девочкам, а вторая — какой возрастной группе пользователей он интересен.\\nОднако данный алгоритм имеет ряд проблем:\\n- матрица оценок полностью не известна, поэтому просто взять SVD разложение не представляется возможным;\\n- Сингулярное разложение не единственное, поэтому даже если какое-то разложение будет найдено, нет гарантии, что первая координата в нем будет соответствовать некоторым выбранным характеристикам пользователя.\\nРешение проблемы матрицы оценок\\nДля решения проблем, связанных с матрицей оценок, построим модель.\\nМодель будет зависеть от следующих параметров: вектор пользователей и вектор объектов. Для заданных параметрови возьмем вектор пользователя и вектор объекта , затем для предсказания оценки получим их скалярное произведение, как и в алгоритме SVD: , где .\\nНо вектора пока не известны, их нужно получить. Имеются оценки пользователей, при помощи которых можно найти оптимальные параметры, при которых модель предскажет оценки наилучшим образом:.\\nТо есть, нужно найти такие параметры регуляризацией. В качестве регуляризатора будет выступать слагаемое . Получим следующее: ., чтобы квадрат ошибки был наименьшим. Однако ситуация следующая: оптимизация приведет к наименьшим ошибкам в будущем, но как именно оценки будут спрашивать — неизвестно. Следовательно, это нельзя оптимизировать. Однако, так как оценки, уже проставленные пользователями, известны, постараемся минимизировать ошибку на тех данных, что у нас уже есть. Также воспользуемся\\nЧисленная оптимизация\\nЧтобы найти оптимальные параметры построенной модели необходимо оптимизировать следующий функционал:\\n.\\nМножество параметров: для каждого объекта и пользователя есть свой вектор, который нужно оптимизировать. Чтобы найти минимум функции можно использовать метод градиентного спуска. Для этого нам понадобится градиент — вектор из частных производных по каждому параметру, который в нашем случае будет выглядеть так:\\n.\\nШаг градиентного спуска можно записать следующим образом:, где — коэффициент скорости обучения.\\nИзмерение качества рекомендаций\\nЗачастую качество рекомендаций измеряется с помощью функции ошибки RMSE:\\n.\\nДанный способ, хоть и является стандартным для измерением качества, имеет ряд недостатков:\\n- пользователи с большим разбросом оценок будут влиять на значение метрики больше, чем остальные;\\n- ошибка в предсказании высокой оценки имеет такой же вес, что и ошибка в предсказании низкой оценки;\\n- есть риск плохого ранжирования при почти идеальной RMSE и наоборот.\\nСуществуют при этом и другие метрики — метрики ранжирования, на основе полноты и точности. Однако они не так популярны и используются значительно реже.\\nСм. также\\n- Кластеризация\\n- Регуляризация\\n- Оценка качества в задаче кластеризации\\n- Оценка качества в задачах классификации и регрессии', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='46aff671-c3de-4dc7-bf6e-7f6a94ef9596', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1fe33fdd1cf95801056c12deca2d77fc84e6df53c928b67c19709f6430a377d6', text='Интерпретируемые модели\\nИнтерпретируемая модель — модель, обладающая свойством интерпретируемости.\\nИнтерпретируемость — это свойство модели, которое показывает, что структуру данной модели может объяснить человек. При этом структура модели не противоречит данным, на которых данная модель построена, а также она сохраняет некоторые свойства предоставленных данных. При интерпретации модели могут быть объяснены принципы и закономерности, которые использует сама модель для предсказания меток класса на конкретных данных.\\nСодержание\\n- 1 Практическая польза\\n- 2 Классификая моделей\\n- 3 Примеры моделей\\n- 4 Свойства интерпретируемых моделей\\n- 5 Способы создания интерпретируемой модели\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nПрактическая польза\\nЕсли модель машинного обучения работает хорошо, почему мы просто не доверяем модели и игнорируем факторы, из-за которых она приняла то или иное решение? Проблема в том, что используя только метрику для измерения точности предсказания, возможно такое, что мы решим задачу не полностью или даже не правильно. Нас могут интересовать причины, по которым модель сделала это предсказание.[1]\\nНапример: модель решает, когда нужно класть ковидного больного в палату, а когда отправлять лечиться дома. По статистике люди болеющие астмой выживают чаще, чем здоровые, и логично предположить, что их можно отправлять лечится дома, но дело в том, что этих людей врачи лечат более тщательней, поэтому они и выживают чаще. Если бы мы верили модели в слепую, то люди с астмой просто бы умирали. Поэтому нам важно понять, почему модель пришла к тому или иному выводу.\\nКогда нужна интерпретируемость\\n- Когда целью является получение каких-либо знаний с помощью изучения построенной модели.\\n- Когда алгоритм оптимизировал неполную цель. Например, когда автомобильный инженер получает предсказания о параметрах двигателя, но ему нужно построит в целом достаточно хороший и надёжный автомобиль.\\n- Для безопасности сложных систем. Такие системы, в большинстве случаев, нельзя протестировать от начала до конца. Вычислительно тяжело просмотреть все возможное входные данные и сценарии развития событий.\\n- Интерпретация тренировных данных, поиск выбросов в них.\\n- Поиск ошибок в выводе модели.\\n- Пользователь может больше доверять модели.\\nКогда интерпретируемость не требуется\\n- Влияние модели мало, а сама интерпретация требует большого количества ресурсов (предложение новых покупок на основе предыдущих в онлайн магазинах).\\n- Проблема хорошо разработана, и специалистов обучают ещё в университетах.\\n- Класс модели широко применяется: линейные модели (стоимость квартиры: понятно, что это метраж, расстояние до метро, школы, детского сада и т.д., но когда параметров много, то уже сложно всё это держать в голове).\\n- Необходимость скрыть систему (кому давать кредит, качество работы сотрудника, поисковое ранжирование).\\nКлассификая моделей\\n- Post-Hoc (воспринимает модель как \"черный ящик\", например, нейросеть) vs Intrinsic (накладывают ограничения на сложность самой модели).\\n- Специфические (работают только для конкретной архитектуры модели) vs агностические (можно применить ко всем моделям для решения конкретной задачи).\\n- Локальные (позволяют понять предсказание для конкретного объекта) vs глобальные (понимание в целом, какие признаки влияют на предсказание).\\nПримеры моделей\\nПример интерпретируемой модели\\n- Допустим есть модель в банке, которая помогает решить, давать ли кредит человеку или нет. Приходит в банк Вася, модель отказывает ему в кредите, вопрос почему? Интерпретируемая модель ответит, потому что у него, допустим, плохая кредитная история или маленькая зарплата, а по не интерпретируемой модели вряд ли будет что-то понятно.\\n- Есть данные и задача бинарной классификации, но у нас огромное количество признаков, и мы построили дерево решений для предсказания. И, например, мы заметили, что алгоритм построил нам дерево глубины 1, но при этом точность предсказания очень высока. Это значит, что у нас классы отлично разделимы, только по одному признаку. Это и есть пример хорошей интерпретируемости, смотреть на данные самому достаточно долго, а так же эксперт, работающий с данными, мог не подозревать о том, что для успешной классификации необходим только 1 признак, но проанализировав построенное дерево, все становится очевидно.\\nПример эффективной в предсказании, но не интерпретируемой модели\\n- Допустим есть данные и задача бинарной классификации, и 99% объектов имеют класс 1, остальные 0. Модель a(x) = 1, имеет точность 99%, но проинтерпретировать ее нельзя для каких-то наших исследований, особенно если нас интересуют, как возникает класс 0. Такая модель не интерпретируема, так как не информативна.\\n- Важным примером, являются данные, в которых присутствует мультиколлинеарность признаков. В таком случае, при обучении линейной модели, мы переобучимся. Для того, чтобы бороться с этой проблемой можно с помощью регуляризации. Но так как, теперь мы оптимизируем несколько другую функцию, то и веса для модели будут отличатся от реальной зависимости на данных, что повлечёт за собой потерю интерпретируемости.\\nСвойства интерпретируемых моделей\\n- Предсказуемость и моделируемость: свойства, при которых человек способен предсказывать поведение и ошибки модели, а так же умение \"симулировать\" их. Например: сложные физические модели, где часто возможно абстрагировать простые правила для примерного предсказания результатов.\\n- Разложимость и модульность: свойства, при которых человек способен декомпозировать модель на интепретируемые компоненты. Например: деревья решений или линейный модели для небольшой размерности.\\n- Доверие: пользователь доволен предсказаниями модели, также модель может показать, когда она не совсем уверена в своём предсказании.\\n- Информативность: из модели можно выявить вспомогательную информацию полезную для принятия какого-либо решения.\\n- Cтабильность: статистические и оптимизационные свойства\\nСпособы создания интерпретируемой модели\\nИспользовать только интерпретируемые модели\\n- Линейные модели.\\n- Деревья решений, списки правил, наборы правил.\\n- Модели основывающиеся на предыдущем опыте.\\nНо не всё хорошо описывается этими моделями.\\nПостроить интерпретируемую модель поверх эмбендинга\\nПример: у нас есть лук. Если “лук” находится рядом с “чесноком”, то модель думает о “луке” как об овоще, если “лук” находится рядом с “пистолетом”, “рогаткой”, то модель думает о “луке” как об оружии.\\nНо модель теперь интерпретируема, но сами признаки перестают быть таковым.\\nВажность признаков\\nОдна из возможностей проанализировать модель — оценить, насколько её решение зависит от отдельных признаков, какой признак внёс наибольший вес для нахождения решения модели.\\nОтчётливо это можно понять благодаря следующему примеру. Модель определяет кто на картинке собака или волк. Допустим выборка для обучения оказалось не самой удачной, и все картинки с волками были на снегу, а с собаками на асфальте. Соответственно модель могла начать определять собаку или волка по асфальту или снегу. Благодаря данному виду интерпретации, модель нам можешь сказать, что главным признаком для принятия решения было не само животное, а её окружение.\\nДанную идею реализуют с помощью значений Шепли.\\nЗначения Шепли (англ. Shapley values) — метод из коалиционной теории игр, который помогает определить, как наиболее честно распределить выигрыш между игроками в зависимости от их вклада в победу. Игроки объединяются в коалиции, чтобы полуучить некоторую выгоду от этого объединения. В машинном обучении в качестве игроков выступают признаки, а в качестве выигрыша — вклад в предсказание. Подходит для задач классификации и регрессии.\\nИз вклада коалиций рассчитывается вклад каждого признака в итоговый прогноз. Значение Шепли — среднее между маргинальными вкладами всех возможных коалиций[2].\\nНа основе значений Шепли Люндебергом и Ли предложен метод SHAP (SHapley Additive exPlanations), объясняющий индивидуальные предсказания. Доступна его реализация на Python [3].\\nВажность i-го признака здесь вычисляется по такой формуле:\\n[4],\\nгде:\\n— это предсказание модели с i-тым признаком,\\n— это предсказание модели без i-того признака,\\n— количество признаков,\\n— произвольный набор признаков без i-того признака.\\nВидно, что вычисление требует обучения модели на всевозможных подмножествах признаках, поэтому на практике применяют приближения формулы.\\nСуррогатные модели\\nДля интерпретации модели (далее именуемой как черный ящик) можно использовать интерпретируемую суррогатную модель, обученную на выводе черного ящика при различных входных данных. Так как суррогатная модель будет повторять поведение черного ящика, то на её основе можно интерпретировать данный черный ящик.\\nЕсть два типа суррогатных моделей: глобальная и локальная.\\n- Глобальная суррогатная модель обучена на всем выводе черного ящика. Такая модель полностью повторяет поведение черного ящика, соответственно интерпретирует его на всей выборке.\\n- Локальная суррогатная модель обучена на выводе в какой-то окрестности определенной точки (рис. 2, где ЧЯ — черный ящик). Такая модель зачастую плохо интерпретирует всю выборку, но хорошо справляется с этой задачей в данной окрестности.\\nГлобальную суррогатную модель довольно сложно построить, поэтому чаще всего прибегают к локальным моделям и интерпретируют определенные объекты.\\nLIME (англ. Local Interpretable Model-agnostic Explanations) [6] — это библиотека [7], которая строит локальную суррогатную модель.\\nСм. также\\nПримечания\\n- ↑ Doshi-Velez and Kim \"Towards A Rigorous Science of Interpretable Machine Learning\" 2017 Page 5\\n- ↑ Формулы смотрите здесь [1]\\n- ↑ Реализация SHAP [2]\\n- ↑ Павел Трошенков \"Как интерпретировать предсказания моделей в SHAP\" [3]\\n- ↑ Александр Дьяконов \"Интерпретации чёрных ящиков\" Рис.11 [4]\\n- ↑ Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin \"Explaining the Predictions of Any Classifier\" [5]\\n- ↑ Реализация Lime [6]\\nИсточники информации\\n- Doshi-Velez and Kim \"Towards A Rigorous Science of Interpretable Machine Learning\" 2017[7]\\n- Sanmi Koyejo \"Interpretability\" MACHINE LEARNING SUMMER SCHOOL 2019 [8]', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='863f0d83-95cd-41fa-aa2d-b35f79ed99d3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='27abfdb5faf104a54bd909d4473ae9f186390adc9bb32936e66031bce7b27f83', text='Жизненный цикл модели машинного обучения\\nЖизненный цикл модели машинного обучения — это многоэтапный процесс, в течении которого исследователи, инженеры и разработчики обучают, разрабатывают и обслуживают модель машинного обучения. Разработка модели машинного обучения принципиально отличается от традиционной разработки программного обеспечения и требует своего собственного уникального способа разработки. Модель машинного обучения — это приложение искусственного интеллекта (ИИ), которое дает возможность автоматически учиться и совершенствоваться на основе собственного опыта без явного участия человека. Основная цель модели заключается в том, чтобы компания смогла использовать преимущества алгоритмов искусственного интеллекта и машинного обучения для получения дополнительных конкурентных преимуществ. Над каждым этапом работает SCRUM-команда. Сотрудничество команд организуется по методике SCRUM of SCRUMs.\\nСодержание\\n- 1 Бизнес-анализ\\n- 2 Анализ и подготовка данных\\n- 3 Моделирование\\n- 4 Оценка решения\\n- 5 Внедрение\\n- 6 Тестирование и мониторинг\\n- 7 См.также\\n- 8 Источники информации\\nБизнес-анализ\\nНа этом этапе необходимо вместе с заказчиком сформулировать проблемы бизнеса, которые будет решать модель. Также, требуется понять, кто участвует в проекте со стороны заказчика, кто выделяет деньги под проект, и кто принимает ключевые решения. Вдобавок необходимо узнать существуют ли готовые решения и, если да, чем они не устраивают заказчика.\\nГлавная задача этого этапа — понять основные бизнес-переменные, которые будет прогнозировать модель. Такие переменные называются ключевыми показателями модели. После этого необходимо определить какие метрики будут использоваться, чтобы определить успешность проекта. Например, может потребоваться спрогнозировать количество абонентов, которые хотели уйти от своего оператора, но в итоге остались у него. К моменту завершения проекта требуется чтобы модель уменьшила отток абонентов на X%. С помощью этих данных можно составить рекламные предложения для минимизации оттока. Метрики должны быть составлены в соответствии с принципами SMART.\\nДалее необходимо оценить какие ресурсы потребуются в течении проекта: есть ли у заказчика доступное железо или его необходимо закупать, где и как хранятся данные, будет ли предоставлен доступ в эти системы, нужно ли дополнительно докупать/собирать внешние данные, сможет ли заказчик выделить своих экспертов для консультаций на данный проект.\\nНужно описать вероятные риски проекта, а также определить план действий по их уменьшению. Типичные риски следующие:\\n- Не успеть закончить проект к назначенной дате.\\n- Финансовые риски.\\n- Малое количество или плохое качество данных, которые не позволят получить эффективную модель.\\n- Данные качественные, но закономерности в принципе отсутствуют и, в результате, заказчик не заинтересован в полученной модели.\\nПосле того, как задача описана на языке бизнеса, необходимо поставить ее в терминах машинного обучения. Особенно нужно узнать ответы на следующие вопросы: Какая метрика будет использована для оценки результата модели(например: accuracy, precision, recall, MSE, MAE и т.д.)? Каков критерий успешности модели (например, считаем точность (англ. accuracy) равный 0.8 — минимально допустимым значением, 0.9 — оптимальным)?\\nПосле необходимо сформировать команду проекта, распределить роли и обязанности между его участниками; создать расширенный поэтапный план проекта, который будет дополняться по мере поступления новой информации. Команда проекта состоит из менеджера, исследователей, разработчиков, аналитиков и тестировщиков.\\nАнализ и подготовка данных\\nНа этом этапе осуществляется анализ, сбор и подготовка всех необходимых данных для использования в модели. Основные задача этого этапа состоит в том, чтобы получить обработанный, высококачественный набор данных, который подчиняется некоторой закономерности. Анализ и подготовка данных состоят из 4 стадий: анализ данных, сбор данных, нормализация данных и моделирование данных.\\nАнализ данных\\nЗадача этого шага – понять слабые и сильные стороны в имеющихся данных, определить их достаточность, предложить идеи, как их использовать, и лучше понять бизнес-процессы заказчика. Требуется провести анализ всех источников данных, к которым заказчик предоставляет доступ. Если собственных данных не хватает, тогда необходимо купить данные у третьих лиц или организовать сбор новых данных. Для начала нужно понимать, какие данные есть у заказчика. Данные могут быть: собственными, сторонними и «потенциальными» данными (нужно организовать сбор, чтобы их получить). Также требуется описать данные во всех источниках (таблица, ключ, количество строк, количество столбцов, объем на диске). Далее, с помощью таблиц и графиков смотрим на данные, чтобы сформулировать гипотезы о том, как данные помогут решить поставленную задачу. Обязательно до моделирования требуется оценить, насколько качественные нужны данные, так как любые ошибки на данном шаге могут негативно повлиять на ход проекта. Типичные проблемы, которые могут быть в данных: пропущенные значения, ошибки в данных, опечатки, неконсистентная кодировка значений (например «w» и «women» в разных системах).\\nСбор данных\\nСбор данных — это процесс сбора информации по интересующим переменным в установленной систематической форме, которая позволяет отвечать на поставленные вопросы исследования, проверять гипотезы и оценивать результаты. Правильный сбор данных имеет важное значение для обеспечения целостности исследований. Как выбор подходящих инструментов сбора данных, так и четко разграниченные инструкции по их правильному использованию снижают вероятность возникновения ошибок. Прогнозирующие модели хороши только для данных, из которых они построены, поэтому правильная практика сбора данных имеет решающее значение для разработки высокопроизводительных моделей. Данные не должны содержать ошибок и должны быть релевантными.\\nНормализация данных\\nСледующий шаг в процессе подготовки — это то место, где аналитики и инженеры данных обычно проводят большую часть своего времени: очистка и нормализация \"грязных\" данных. Часто это требует от них принимать решения на основе данных, которые они не совсем понимают, например, что делать с отсутствующими или неполными данными, а также с выбросами. Что еще хуже, эти данные нелегко соотнести с соответствующей единицей анализа: клиентом. Например, чтобы предсказать, уйдет ли один клиент (а не сегмент или целая аудитория), нельзя полагаться на данные из разрозненных источников. Инженер по данным подготавливает и объединяет все данные из этих источников в формат, который могут интерпретировать модели машинного обучения.\\nМоделирование данных\\nСледующим этапом подготовки данных является моделирование данных, которые мы хотим использовать для прогнозирования. Моделирование данных — это сложный процесс создания логического представления структуры данных. Правильно сконструированная модель данных должна быть адекватна предметной области, т.е. соответствовать всем пользовательским представлениям данных. Моделирование также включает в себя смешивание и агрегирование веб данных, данных из мобильных приложений, оффлайн данных и др. Для модели, рассматриваемой в данном конспекте, инженеры объединяют разнородные данные в цельный набор данных. Например, у них есть уже готовые данные по признакам, и они объединяют их в один набор данных.\\nКонструирование признаков\\nКонструирование признаков состоит из учета, статистической обработки и преобразования данных для выбора признаков, используемых в модели. Чтобы понять лежащие в основе модели механизмы, целесообразно оценить связь между компонентами и понять, как алгоритмы машинного обучения будут использовать эти компоненты. На данном этапе нужно творческое сочетание опыта и информации, полученной на этапе исследования данных. В конструирование признаков необходимо найти баланс. Важно найти и учесть информативные переменные, не создавая при этом лишние несвязанные признаки. Информативные признаки улучшают результат модели, а не информативные — добавляют в модель ненужный шум. При выборе признаков необходимо учитывать все новые данные, полученные во время обучения модели.\\nМоделирование\\nНа этом шаге происходит обучения модели. Обучение моделей машинного обучения происходит итерационно – пробуются различные модели, перебираются гиперпараметры, сравниваются значения выбранной метрики и выбирается лучшая комбинация.\\nВыбор алгоритма\\nВначале нужно понять, какие модели будут использоваться. Выбор модели зависит от решаемой задачи, используемых признаков и требований по сложности (например, если модель будет дальше внедряться в Excel, то Дерево решений или AdaBoost не подойдут). При выборе модели обязательно принять во внимание следующие факторы:\\n- Достаточность данных (обычно, сложные модели требуют большого количества данных).\\n- Обработка пропусков (некоторые алгоритмы не умеют обрабатывать пропуски).\\n- Формат данных (для части алгоритмов потребуется конвертация данных).\\nПланирование тестирования\\nДалее необходимо определить, на каких данных будет обучаться модель, а на каких тестироваться. Традиционный подход – это разделение набора данных на 3 части (обучение, валидация и тестирование) в пропорции 60/20/20. В данном случае обучающая выборка используется для обучения модели, а валидация и тестирование для получения значения метрики без эффекта переобучения. Более сложные стратегии обучения модели подразумевают использование различных вариантов кросс-валидации. Также на данном шаге требуется определить, как будет происходить оптимизация гиперпараметров моделей, сколько потребуется итераций для каждого алгоритма, будет ли использоваться grid-search или random-search.\\nОбучение модели\\nНа данном шаге начинается цикл обучения. После каждой итерации записывается результат модели. На выходе получаем результаты для каждой модели и использованных в ней гиперпараметров. Кроме того, для моделей, у которых значение выбранной метрики превышает минимально допустимое, нужно обратить внимание на следующие особенности:\\n- Необычные закономерности (Например, точность предсказания модели на 95% объясняется всего лишь одним признаком).\\n- Скорость обучения модели (Если модель долго обучается, то стоит использовать более эффективный алгоритм или уменьшить обучающую выборку).\\n- Проблемы с данными (Например, в тестовую выборку попали объекты с пропущенными значениями, и, как следствие, значение метрики было посчитано не полностью, и она не позволяет целиком оценить модель).\\nОценка результатов\\nПосле формирования списка из подходящих моделей, нужно еще раз их детально проанализировать и выбрать лучшие модели. На выходе необходимо иметь список моделей, отсортированный по объективному и/или субъективному критерию. Задачи шага: провести технический анализ качества модели (ROC, Gain, K-S и т.д.), оценить, готова ли модель к внедрению в корпоративное хранилище данных, достигаются ли заданные критерии качества, проанализировать результаты с точки зрения достижения бизнес-целей. Если критерий успешности (выбранная метрика) не достигнут, то необходимо или улучшить текущую модель, или использовать другую. Прежде чем переходить к внедрению нужно убедиться, что результат моделирования понятен и логичен. Например, прогнозируется отток клиентов и значение метрики GAIN равно 99%. Слишком хороший результат – повод проверить модель еще раз.\\nОценка решения\\nРезультатом предшествующего этапа является построенная модель машинного обучения и найденные закономерности. На данном этапе происходит оценивание результатов проекта.\\nЕсли на предыдущем этапе оценивались результаты моделирования с технической точки зрения, то здесь происходит оценка результатов с позиции достижения бизнес-целей. Например, насколько качественно полученная модель решает поставленные бизнес-задачи. Также, необходимо понять найдена ли в течении проекта какая-то новая полезная информация, которую стоит выделить отдельно. Далее необходимо проанализировать ход проекта и сформулировать его сильные и слабые стороны. Для этого нужно ответить на следующие вопросы:\\n- Какие этапы проекта можно было сделать эффективнее?\\n- Какие ошибки были сделаны? Возможно ли их избежать в будущем?\\n- Были ли не сработавшие гипотезы? Если да, стоит ли их повторять?\\n- Были ли неожиданности при реализации шагов? Как их предусмотреть в будущем?\\nЗатем, если модель устраивает заказчика, то необходимо или внедрить модель, или, если существует возможности для улучшения, улучшить модель. Если на данном этапе несколько подходящих моделей, то нужно выбрать модель, которая будет дальше внедряться.\\nВнедрение\\nВнедрение модели машинного обучения в производство означает доступность модели для других бизнес-систем. Внедряя модель, другие системы могут отправлять ей данные и получать от модели прогнозы, которые, в свою очередь, используются в системах компании. Благодаря внедрению модели машинного обучения, компания сможет в полной мере воспользоваться созданной моделью машинного обучения. Основная задача, решаемая на этом этапе - ввод модели в эксплуатацию. Необходимо развернуть модель и конвейер в рабочую или близкую к ней среду, чтобы приложения могли к ней обращаться. Создав эффективно работающую модель, требуется ввести ее в эксплуатацию для взаимодействия с другими системами компании. В зависимости от бизнес-требований, модель исполняет прогнозы в режиме реального времени или в стандартном режиме. Для развертывания модели, необходимо внедрять модель с помощью открытого API-интерфейса. Интерфейс упрощает использование модели различными приложениями, например:\\n- Веб-сайты.\\n- Электронные таблицы.\\n- Панели мониторинга бизнес-приложения.\\n- Серверные приложения.\\nТакже необходимо понять, собирается ли компания использовать Платформу как Сервис (англ. Platform as a Service, PaaS) или Инфраструктуру как Сервис (англ. Infrastructure as a Service, IaaS). PaaS может быть полезен для создания прототипов и компаний с меньшим трафиком. В конце концов, по мере роста бизнеса и / или увеличения трафика компании придется использовать IaaS с большей сложностью. Есть множество решений от больших компаний (AWS, Google, Microsoft). Если приложения контейнеризованы, развертывание на большинстве платформ / инфраструктур будет проще. Контейнезирование также дает возможность использовать платформу оркестровки контейнеров для быстрого масштабирования количества контейнеров по мере увеличения спроса. Далее, нужно убедиться, что развертывание происходит через платформу непрерывного развертывания(англ. Continuous Deployment platform).\\nТестирование и мониторинг\\nНа данном этапе осуществляется тестирование, мониторинг и контролирование модели. В основном тесты моделей машинного обучения делятся на следующие части:\\nДифференциальные тесты\\nПроисходит сравнение результатов, данных новой моделью, и результатов, данных старой моделью для стандартного набора тестовых данных. Необходимо настроить чувствительность этих тестов в зависимости от варианта использования модели. Эти тесты могут быть жизненно важны для обнаружения модели, которая выглядит работающей, но, на самом деле, таковой не является, например, когда устаревший набор данных использовался в обучении или модель обучилась не на всех признаках. Такие проблемы, присущие машинному обучения, не приведут к ошибке на стандартных тестах.\\nКонтрольные тесты\\nТесты сравнивают время, затрачиваемое либо на обучение, либо на предоставление прогнозов из модели от одной версии к другой. Они мешают вводить неэффективные добавления кода в модели машинного обучения. Опять же, это то, что трудно уловить с помощью традиционных тестов (хотя некоторые инструменты статического анализа кода могут помочь).\\nНагрузочные / стресс-тесты\\nЭто не совсем специфичные тесты для модели машинного обучения, но с учетом необычно больших требований к ЦП / памяти в некоторых моделях машинного обучения такие тесты особенно стоит использовать.\\nA/B-тестирование\\nЕще один популярный способ тестирования - A/B-тестирование. Этот метод также называется сплит-тестированием (англ. split testing ). A/B-тестирование позволяет оценивать количественные показатели работы двух вариантов модели, а также сравнивать их между собой. Чтобы получить статистически значимый результат, очень важно исключить влияние моделей друг на друга.\\nВсе вышеперечисленные тесты намного проще использовать с контейнеризованными приложениями, так как это делает раскрутку реалистичного производственного стека тривиальной.\\nМониторинг и оповещение могут быть особенно важны при развертывании моделей. По мере усложнения системы потребуются возможности мониторинга и оповещения, чтобы сообщать, когда прогнозы для конкретной системы выходят за пределы ожидаемого диапазона. Мониторинг и оповещение также могут быть связаны с косвенными проблемами, например, при обучении новой сверточной нейронной сети расходовать ежемесячный бюджет AWS за 30 минут. Также понадобятся панели управления, позволяющие быстро проверить развернутые версии моделей.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='3fe4a3d8-67b2-4bd6-bf2c-f955520230d9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bf1c6066658e57609216f2e89c72f6ad25235478dc3ec4233ad3e828729b65cd', text=\"Анализ временных рядов\\nВременные ряды — это актуальный инструмент, применимый во множестве решений, от предсказания цен на акции, прогнозов погоды, планирования бизнеса, до распределения ресурсов. Несмотря на то, что прогнозирование может быть сведено к построению контролируемой регрессии, существуют особенности, связанные с временным характером наблюдений, которые необходимо учитывать, используя специальные инструменты.\\nСодержание\\n- 1 Временной ряд\\n- 2 Валидирование и тестирование модели временного ряда\\n- 3 Краткое исследование данных\\n- 4 Модели прогнозирования временных рядов\\n- 5 Оценка\\n- 6 Заключительные замечания\\n- 7 См. Также\\n- 8 Примечания\\n- 9 Источники Информации\\nВременной ряд\\n|Определение:\\n|Временно́й ряд (или ряд динамики) — собранный в разные моменты времени статистический материал о значении каких-либо параметров (в простейшем случае одного) исследуемого процесса. Каждая единица статистического материала называется измерением или отсчётом. Во временном ряде для каждого отсчёта должно быть указано время измерения или номер измерения по порядку.\\nКак и большинство других видов анализа, анализ временных рядов предполагает, что данные содержат систематическую составляющую (обычно включающую несколько компонент) и случайный шум (ошибку), который затрудняет обнаружение регулярных компонент. Большинство методов исследования временных рядов включает различные способы фильтрации шума, позволяющие увидеть регулярную составляющую более отчетливо. Большинство регулярных составляющих временных рядов принадлежит к двум классам: они являются либо трендом, либо сезонной составляющей. Тренд представляет собой общую систематическую линейную или нелинейную компоненту, которая может изменяться во времени. Сезонная составляющая — это периодически повторяющаяся компонента. Оба эти вида регулярных компонент часто присутствуют в ряде одновременно.\\nВалидирование и тестирование модели временного ряда\\nДанные упорядочены относительно неслучайных моментов времени, и, значит, в отличие от случайных выборок, могут содержать в себе дополнительную информацию, поэтому нельзя пользоваться обычными способами валидации. Чтобы избежать смещения оценки необходимо удостовериться, что обучающие наборы данных содержат только наблюдения, которые произошли до событий из валидирующиx наборов.\\nВозможным способом преодоления данной проблемы будет использование скользящего окна, как описано здесь. Эта процедура называется кросс-валидацией временного ряда и может быть вкратце описана следующей картинкой (рис. 1), в которой синие точки обозначают тренировочный набор данных, а красные соответствующие валидационные наборы данных.\\nЕсли необходимо предсказать следующие $n$ шагов, то можно заранее кросс-валидировать $1,2,...,n$.\\nТаким образом можно также сравнить качество предсказаний для разных временных горизонтов.\\nОпределив лучшую модель, можно применить её ко всему обучающему набору и оценить его работу на следующем во времени наборе данных. Оценка работы может быть дана с использованием метода скользящего окна[1], который используем при кросс-валидации, но без переподсчёта параметра модели.\\nКраткое исследование данных\\nВ данной части используется несколько разных моделей для предсказания изменений в промышленном производстве,\\nкоторые для примера будем оценивать численно, как количество электрооборудования, произведённого в зоне Евро (рис. 2, 3).\\nНабор данных описывает ежемесячное производство электрооборудования (компьютеры электрические и оптические приборы) в зоне евро (17 стран) в период с января 1996 по март 2012 года (см. график ниже). Последние два года будем использовать при тестировании.\\nМодели прогнозирования временных рядов\\nСуществует 10 моделей прогнозирования, у каждой имеются свои достоинства и недостатки. Ниже, используя каждую модель, предскажем 12 месяцев, соответственно, значение $t+1, t+2, …, t + 12$.\\nИмеет смысл использовать среднюю абсолютную ошибку для работы оценки модели.\\nНаивное предсказание\\nПредсказания для каждого горизонта соотвествуют последнему наблюдаемому значению $Y(t + h|t) = Y(t)$.\\nТакие предскания предполагают, что стохастическая[2] модель генерирует случайное блуждание.\\nРасширение наивной модели сезонно-наивная модель (англ. Season Naive, SNAIVE) — сезонно-наивная модель предполагает, что временной ряд имеет сезонную компоненту, и что период сезонности $T$.\\nПрогнозы SNAIVE-модели описываются формулой $\\\\dot{Y}(t+h|t) = Y(t+h-T)$.\\nПолучаемые прогнозы следующие $T$ шагов совпадают с предыдущими $T$ шагами.\\nЭти модели часто используются как ориентировочные модели. Следующий графики показывают предсказания двух моделей для 2007 года (рис. 4, 5).\\nРазделение по сезонам + любая модель\\nЕсли данные показывают, что они восприимчивы к периодическим (сезонным) изменениям (ежедневно, еженедельно, ежеквартально, ежегодно), то будет полезным разложить исходный временной ряд на сумму трёх компонентов.\\n$Y(t) = S(t) + T(t) + R(t)$\\n$S(t)$ — сезонный компонент.\\n$T(t)$ — компонент трендового цикла.\\n$R(t)$ — остаток.\\nСуществуют несколько способов для такого разложения, но наиболее простой называется классическим разложением и заключается в том, чтобы оценить тренд $T(t)$ через скользящее среднее, посчитать $S(t)$, как среднее без тренда $Y(t) - T(t)$ для каждого сезона.\\nПосчитать остаток, как $R(t) = Y(t) - T(t)-S(t)$.\\nКлассическое разложение можно расширить несколькими способами.\\nРасширение позволяет использовать данный метод при:\\n- непостоянной величине сезона;\\n- посчитать начальные и конечные значения декомпозиции;\\n- избежать лишнего сглаживания;\\nОбзор методов разложений ряда можно увидеть по ссылке. Используется реализация из стандартной библиотеки (рис. 6).\\nОдним из способов использования декомпозиции для прогнозирования будет:\\n1) Разложить обучающий набор алгоритмом.\\n2) Посчитать сезонное отклонение ряда $Y(t) - S(t)$, используя любую модель для прогнозирования сезонно-чувствительного временного ряда.\\n3) Добавить прогнозам сезонность последнего временного периода во временном ряду (в нашем случае $S(t)$ для прошлого года).\\nНа следующем графике показаны сезонные индексы ряда с учётом сезонности (рис. 7).\\nСледующий график показывает расчёты для 2007 года с использованием декомпозиции и наивной модели (рис. 8) для сезонно-изменяемого временного ряда.\\nЭкспоненциальное сглаживание\\nЭкспоненциальное сглаживание[3] — один из наиболее успешных классических методов предсказаний. В своей базовой форме он называется простым экспоненциальный сглаживанием и его прогнозы описываются формулами:\\n$Ŷ(t+h|t) = ⍺y(t) + ⍺(1-⍺)y(t-1) + ⍺(1-⍺)²y(t-2) + …$\\nгде $0<⍺<1$ . Если $⍺ = 0$, то текущие наблюдения игнорируются, если же $⍺ = 1$, то полностью игнорируются предыдущие наблюдения.\\nЗаметно, что прогнозы равны взвешенному среднему от старых наблюдений, и что соответствующие веса убывают экспоненциально по мере хода времени.\\nНекоторые методы для расширения алгоритма позволяют добавить тренд, его затухание и сезонность. Экспоненциальное сглаживание состоит из 9 моделей, которые подробно описаны здесь.\\nСледующие графики (рис. 9, 10) описывают прогнозы данных полученные для 2007 года, с использованием модели экспоненциального сглаживания (выбраны автоматически), которые подходили исходному и сезонно-чувствительному временному ряду.\\nARIMA, SARIMA\\nТакже как и экспоненциальное сглаживание, интегрированная модель авторегрессии скользящего среднего (англ. autoregressive integrated moving average, ARIMA) также часто используются для прогноза временных рядов.\\n|Определение:\\n|Процесс авторегрессии — последовательная зависимость элементов временного ряда, выразается следующим уравнением:\\n$x(t) = \\\\psi + \\\\phi_1 * x_(t-1) + \\\\phi_2 * x_(t-2) + \\\\phi_3 * x_(t-3) + ... + \\\\epsilon$\\n|Определение:\\n|Скользящее среднее — общее название для семейства функций, значения которых в каждой точке определения равны некоторому среднему значению исходной функции за предыдущий период.\\n|Определение:\\n|Процесс скользящего среднего — в процессе скользящего среднего каждый элемент ряда подвержен суммарному воздействию предыдущих ошибок. В общем виде это можно записать следующим образом:\\n$x_t = \\\\mu + \\\\epsilon_t - \\\\theta_1 * \\\\epsilon_{t-1} - \\\\theta_2 * \\\\epsilon_{t-2} - ...$\\nARIMA — комбинация этих двух подходов. Так как эти подходы требуются стационарности временного ряда, может понадобится продифференциировать/проинтегрировать ряд. То есть рассматировать ряд разностей, а не исходный ряд.\\nСезонная интегрированная модель авторегрессии скользящего среднего (англ. season autoregressive integrated moving average, SARIMA) учитывает сезонность, добавляя линейную комбинацию прошлых сезонных значений и/или прошлых ошибок прогноза. Более подробную информацию про ARIMA, SARIMA читайте по ссылке.\\nДанные графики показывают предсказания полученные для 2007 года, с использованием модели SARIMA (рис. 11,12).\\nGarch\\nВ предыдущих моделях считалось, что слагаемое ошибки в стохастическом процессе генерации временного ряда имело одинаковую дисперсию.\\nВ GARСH-модели (англ. Generalized AutoRegressive Conditional Heteroscedasticity, GARCH) предполагается, что слагаемое ошибки следует авторегрессионному скользящему среднему (англ. AutoRegressive Moving Average, ARMA), соответственно слагаемое меняется по ходу времени. Это особенно полезно при моделировании финансовых временных рядов, так как диапазон изменений тоже постоянно меняется (рис. 13).\\nВ 1982 году была предложена ARCH — модель, описываемая формулой:\\n$\\\\sigma^2(t) = \\\\alpha + \\\\sum_{i = 1}^{\\\\alpha}b_ir^{2}_{t-1}$\\nгде $\\\\alpha$ — коэффициент задержки\\n$\\\\sigma^2(t)$ - волатильность\\n$\\\\sum_{i = 1}^{\\\\alpha}b_ir^{2}_{t-1}$ - линенйная комбинация абсолютных значений нескольких последних изменений значений.\\nПозднее была создана GARCH — обобщённая ARCH модель, которая также учитывает предыдущие оценки дисперсии. Формула может быть записана так:\\n$\\\\sigma^2(t) = \\\\alpha + \\\\sum_{i = 1}^{\\\\alpha}b_ir^{2}_{t-1} \\\\sum_{i = 1}^{p}c_i\\\\sigma^{2}_{t-1}$\\nгде p — количество предшествующих оценок, влияющих на текущее значение.\\nс — весовые коэффициенты предыдущих оценок.\\nОбычно ARMA используется и для учёта среднего, более подробное введение в Garsh и различные варианты можно найти здесь.\\nДинамические линейные модели\\nДинамические линейные модели представляют другой класс моделей предсказания временных рядов (рис. 14).\\nИдея заключается в том, что в каждый момент времени $t$ эти модели соответствуют линейной модели, но коэффициент регрессии постоянно меняется.\\nПример динамической линейной модели ниже:\\n$y(t) = ⍺(t) + tβ(t) + w(t)$,\\n$⍺(t) = ⍺(t-1) + m(t)$,\\n$β(t) = β(t-1) + r(t)$,\\n$w(t)$ ~ $N(0,W)$, $m(t)$ ~ $N(0,M)$, $r(t)$ ~ $N(0,R)$.\\nВ предыдущей модели коэффициенты $a(t)$ и $b(t)$ следуют случайному блужданию.\\nДинамические линейные модели могут быть построены в рамках Байесовской системы. Тем не менее и этот метод можно улучшить, подробности здесь.\\nTBATS\\nTBATS (англ. Trigonometric seasonality, Box-Cox transformation, ARMA errors, Trend and Seasonal components) — это модели, которые основаны на экспоненциальном сглаживании (рис. 15).\\nГлавной особенностью TBATS является возможность взаимодействия с несколькими сезонностями. Моделируя каждую функцию сезонности отдельным тригонометрическим отображением построенным на рядах Фурье.\\nКлассическим примером комплексной сезонности будет отображение ежедневных объемов продаж, которое имеет, как еженедельные колебания, так и ежегодные.\\nБольше информации можно прочиать тут.\\nProphet\\nЕщё одна модель, способная взаимодействовать с несколькими сезонностями (рис. 16). Это ПО с открытым исходным кодом от Фейсбука (ссылка).\\nProphet считает, что временной ряд может быть разложен следующим образом:\\n$y(t) = g(t) + s(t) + h(t) + ε(t)$,\\n$g(t)$ — тренд,\\n$s(t)$ — сезонность,\\n$h(t)$ — каникулы, т.е аномальные данные,\\n$ε(t)$ — ошибки.\\nПодгонка модели представляет собой упражнение по подгонке кривой, поэтому она явно не учитывает структуру временной зависимости в данных. Это также позволяет проводить наблюдения с нерегулярным интервалом.\\nЕсть два варианта временных рядов тренда: модель насыщающего роста и кусочно-линейная модель. Модель многопериодной сезонности основана на рядах Фурье[4]. Эффект известных и заказных выходных дней может быть легко включен в модель.\\nМодель Prophet вставлена в байесовскую структуру и позволяет сделать полный апостериорный вывод, чтобы включить неопределенность параметров модели в неопределенность прогноза.\\nNNETAR\\nМодель авторегрессии нейронной сети (англ. Neural NETwork AutoRegression, NNETAR) представляет собой полносвязную нейронную сеть. Модель NNETAR принимает на вход последние элементы последовательности до момента времени $t$ и выводит прогнозируемое значение в момент времени $t + 1$. Для выполнения многоэтапных прогнозов сеть применяется итеративно.\\nМодель можно описать уравнением\\n$y_t = f(y_{t-1}) + \\\\epsilon_t$\\nгде $y_{t-1} = (y_{t-1}, y_{t-2}, ...)'$ — вектор, содержащий запаздывающие значения,\\nf — нейронная сеть, с 4 скрытыми узлами в каждом слое,\\n$\\\\epsilon_t$ — считаем, что ряд ошибок гомокседастичен (и возможно имеет нормальное распределение).\\nМы можем моделировать будущие выборочные пути этой модели итеративно, случайным образом генерируя значение для $\\\\epsilon_t$ либо из нормального распределения, либо путем повторной выборки из исторических значений.\\nТак что если $\\\\epsilon^*_{T+1}$ — случайная выборка из распределения ошибок в момент времени $T+1$,\\nтогда $y^*_{T+1} = f(y_T) + \\\\epsilon^*_{T+1}$ — один из возможных вариантов распределения прогнозов для $y_{T+1}$\\nУстановив $y^*_{T+1} = (y^*_{T+1}, y_{T})'$, мы можем повторить процесс, чтобы получить $y^*_{T+2} = f(y_{T+1}) + \\\\epsilon_{T+2}$.\\nТаким образом, мы можем итеративно моделировать будущий путь выборки. Повторно моделируя выборочные пути, мы накапливаем знания о распределении всех будущих значений на основе подобранной нейронной сети.\\nLSTM\\nБлок cети долго-краткосрочной памяти (англ. Long short-term memory, LSTM) могут использоваться для прогнозирования временных рядов (а также других рекуррентных нейронных сетей).\\nСостояние сети LSTM представлено через вектор пространства состояний. Этот метод позволяет отслеживать зависимости новых наблюдений от прошлых (даже очень далеких).\\nВообще говоря, LSTM представляют собой сложные модели, и они редко используются для прогнозирования одного временного ряда, поскольку для их оценки требуется большой объем данных.\\nОднако они обычно используются, когда необходимы прогнозы для большого количества временных рядов (как показано здесь).\\nОценка\\nВыполнен выбор модели с помощью процедуры перекрестной проверки, описанной ранее. Не рассчитывая его для динамических линейных моделей и моделей LSTM из-за их высокой вычислительной стоимости и низкой производительности.\\nНа следующем рисунке показана средняя абсолютная ошибка (англ. Mean Absolute Error, MAE) с перекрестной проверкой для каждой модели и для каждого временного горизонта (рис. 17):\\nМодель NNETAR по сезонно скорректированным данным была лучшей моделью для данной задачи, поскольку она соответствовала самому низкому значению MAE, прошедшему перекрестную проверку.\\nЧтобы получить объективную оценку наилучшей производительности модели, вычислим MAE на тестовом наборе (рис. 18), получив оценку, равную 5,24. На следующем рисунке можно увидеть MAE, оцененную на тестовой выборке для каждого временного горизонта.\\nМетоды увеличения производительности\\n- Использование разных моделей для разных временных горизонтов,\\n- Объединение нескольких прогнозов (например, с учетом среднего прогноза),\\n- Агрегация начальных данных.\\nЗаключительные замечания\\nБольшинство ранее описанных моделей позволяют легко включать изменяющиеся во времени предикторы. Они могут быть извлечены из одного и того же временного ряда или могут соответствовать внешним предикторам (например, временному ряду другого индекса). В последнем случае необходимо обратить внимание на то, чтобы не использовать информацию из будущего, которая могла бы быть удовлетворена путем прогнозирования предикторов или использования версий c ошибками.\\nОбратите внимание, что в данном конспекте рассматривается случай, когда у нас есть один временной ряд для прогнозирования. Когда у нас много временных рядов, может быть предпочтительнее глобальный подход, поскольку он позволяет нам оценивать более сложную и потенциально более точную модель. Подробнее о глобальном подходе здесь.\\nСм. Также\\n- Кластеризация\\n- Уменьшение размерности\\n- Рекомендательные системы\\n- Анализ социальных сетей\\n- Графовые нейронные сети\\n- Компьютерное зрение\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='488f8252-67cc-4fe7-81ee-51c323adafc5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9987a796bd0073dbff789f668630f69e813635753f56ebbf67ba647392cab4bc', text='Метрический классификатор и метод ближайших соседей\\nМетрический классификатор (англ. similarity-based classifier) — алгоритм классификации, основанный на вычислении оценок сходства между объектами.\\nДля формализации понятия сходства вводится функция расстояния между объектами. Как правило, не требуется, чтобы были выполнены все три аксиомы метрики — неравенство треугольника может нарушаться.\\nМетод ближайших соседей — простейший метрический классификатор, основанный на оценивании сходства объектов. Классифицируемый объект относится к тому классу, которому принадлежат ближайшие к нему объекты обучающей выборки.\\nМетодближайших соседей (англ. kNN — Nearest Neighbours) — Для повышения надёжности классификации объект относится к тому классу, которому принадлежит большинство из его соседей — ближайших к нему объектов обучающей выборки . В задачах с двумя классами число соседей берут нечётным, чтобы не возникало ситуаций неоднозначности, когда одинаковое число соседей принадлежат разным классам.\\nМетод взвешенных ближайших соседей — в задачах с числом классов 3 и более нечётность уже не помогает и ситуации неоднозначности всё равно могут возникать. Тогда-му соседу приписывается вес , как правило, убывающий с ростом ранга соседа . Объект относится к тому классу, который набирает больший суммарный вес среди ближайших соседей.\\nСодержание\\n- 1 Описание алгоритма\\n- 2 Использование ядер сглаживания\\n- 3 Использование различных метрик расстояния\\n- 4 Пример использования (через scikit-learn)\\n- 5 Пример на языке Scala\\n- 6 Пример на языке Java\\n- 7 См. также\\n- 8 Примечания\\n- 9 Источники информации\\nОписание алгоритма\\nПусть задана обучающая выборка пар \"объект-ответ\"\\nПусть на множестве объектов задана функция расстояния. Эта функция должна быть достаточно адекватной моделью сходства объектов. Чем больше значение этой функции, тем менее схожими являются два объекта .\\nДля произвольного объектарасположим объекты обучающей выборки в порядке возрастания расстояний до :\\n, где через обозначается тот объект обучающей выборки, который является -м соседом объекта . Аналогичное обозначение введём и для ответа на -м соседе: . Таким образом, произвольный объект порождает свою перенумерацию выборки. В наиболее общем виде алгоритм ближайших соседей есть: ,\\nгде— заданная весовая функция, которая оценивает степень важности -го соседа для классификации объекта . Естественно полагать, что эта функция не отрицательна и не возрастает по (поскольку чем дальше объект, тем меньший вклад он должен вносить в пользу своего класса).\\nПо-разному задавая весовую функцию, можно получать различные варианты метода ближайших соседей.\\n— простейший метод ближайшего соседа;\\n— метод ближайших соседей;\\n— метод экспоненциально взвешенных ближайших соседей, где предполагается константа ;\\nИспользование ядер сглаживания\\nПри использовании линейной функции в качестве Ядра[на 28.01.18 не создан].возможно совпадение суммарного веса для нескольких классов. Это приводит к неоднозначности ответа при классификации. Чтобы такого не происходило, используют функцию\\nБудем обозначать функцию ядра.\\nПримеры ядер\\nTriangular:,\\nParabolic:,\\nTricube:.\\nМетод парзеновского окна\\nАлгоритмближайших соседей можно обобщить с помощью функции ядра. Рассмотрим два способа, которыми это можно сделать.\\n— метод парзеновского окна фиксированной ширины ;\\n— метод парзеновского окна переменной ширины;\\nСравним два этих метода. Сперва запишем классификаторы, полученные при использовании этих методов, в явном виде:\\nФиксированной ширины:,\\nПеременной ширины:.\\nне будет учитывать соседей на расстояние больше чем , а всех остальных учтет в соответствии с функций ядра . является аналогом метода ближайших соседей (т.к. для всех -ых соседей функция вернет 0), но при этом чем ближе -ый сосед, тем больший вклад в сторону своего класса он даст.\\nЧасто используют окно переменной ширины т.е. классификатор, по следующим причинам:\\n- Удобнее оптимизировать целочисленный параметр , чем вещественный параметр по некоторой сетке;\\n- Существует большое количество задач, где точки разбросаны неравномерно. В них могут существовать области, где достаточно брать небольшую и области, где в окно ширины попадает только одна точка. Тогда для классификатора будут существовать области в которых не будет ни одного объекта (кроме того, который нужно классифицировать). Для таких областей не понятно как классифицировать объекты.\\nИспользование различных метрик расстояния\\nОчень редко известна хорошая функция расстояния. В качестве нее обычно использую следующие функции:\\nПримеры метрик\\nПусть, — объекты, а , их признаковые описания.\\nЕвклидова метрика:,\\nРасстояние Чебышёва:,\\nМанхэттенское Расстояние:.\\nПри их использовании важно нормировать значения признаков, иначе один признак с максимальным значением может стать преобладающим, а признаки с маленькими значениями не будут учитываться при классификации. Чтобы отсеять лишние признаки (т.е. не влияющие на класс объекта) можно использовать feature selection.\\nПример использования (через scikit-learn)\\nРассмотрим использование алгоритма реального набора данных. Предположим, что мы загрузили и сохранили как с заголовком — описанием признаков.на примере\\n- Загружаем данные\\nimport pandas as pd from sklearn.preprocessing import StandardScaler\\ndef load_data(data_path): ds = pd.read_csv(data_path, names=[\"id\", \"diagnosis\", \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\", \"fractal_dimension_mean\", \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\", \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\", \"radius_worst\", \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\", \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\"]) y = ds[\\'diagnosis\\'] X = ds.drop(\\'diagnosis\\', axis=1) X = X.drop(\\'id\\', axis=1) i = len(X.columns) X = X.drop(X.columns[i - 1], axis=1) y.replace((\\'M\\', \\'B\\'), (1, 0), inplace=True) sc = StandardScaler() sc.fit(X) X_ans = sc.transform(X) return X_ans, y\\nX, y = load_data(\"tr.csv\")\\nТеперь , — нормированные значения признаков и соответствующие им классы.\\n- Делим данные на тренировочное и тестовое множество:\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\\n- Создаем классификатор:\\nfrom sklearn.neighbors import KNeighborsClassifier\\nbest_model = KNeighborsClassifier( n_neighbors=10, weights=’distance’, algorithm=’auto’, leaf_size=30, metric=’euclidean’, metric_params=None, n_jobs=4 )\\n- Обучаемся:\\nbest_model.fit(X_train, y_train)\\n- Используем скользящий контроль для поиска лучших параметров (англ. cross validation):\\nfrom sklearn.model_selection import GridSearchCV\\nmodel_params = best_model.get_params() tuned_params = {} for k, v in model_params.items(): tuned_params[k] = [v] tuned_params[\\'n_neighbors\\'] = range(1, 30) clf = GridSearchCV(KNeighborsClassifier(), tuned_params, cv=10, n_jobs=-1) clf.fit(X_train, y_train) best_params = clf.best_params_\\n- Оценка классификатора:\\nfrom sklearn import metrics\\nbest_model = KNeighborsClassifier(**best_params) best_model.fit(X_train, y_train) predicted = best_model.predict(X_test)\\n- Выводим результат:\\nprint(\\'Used params:\\', best_params) print(\\'Evaluation:\\\\n\\', metrics.classification_report(y_test, predicted))\\n> Used params: {\\'metric_params\\': None, \\'metric\\': \\'euclidean\\', \\'weights\\': \\'distance\\', \\'n_neighbors\\': 9, \\'leaf_size\\': 30, \\'n_jobs\\': 4, \\'p\\': 2, \\'algorithm\\': \\'auto\\'} Evaluation: precision recall f1-score support 0 0.90 1.00 0.95 69 1 1.00 0.82 0.90 45 micro avg 0.93 0.93 0.93 114 macro avg 0.95 0.91 0.92 114 weighted avg 0.94 0.93 0.93 114\\nПример на языке Scala\\nSBT зависимость:\\nlibraryDependencies += \"com.github.haifengl\" %% \"smile-scala\" % \"1.5.2\"\\nПример классификации датасета и вычисления F1 меры[1] используя smile.classification.knn[2]:\\nimport smile.classification._ import smile.data._ import smile.plot._ import smile.read import smile.validation.FMeasure\\nval toy: AttributeDataset = read.table(\"iris.csv\", delimiter = \",\", response = Some((new NumericAttribute(\"class\"), 2))) val x: Array[Array[Double]] = toy.x() val y: Array[Int] = toy.y().map(_.toInt) val KNN: KNN[Array[Double]] = knn(x, y, 3) val predictions: Array[Int] = x.map(KNN.predict) val f1Score = new FMeasure().measure(predictions, y) plot(x, y, KNN)\\nПример на языке Java\\nПример классификации датасета с применением\\nweka.classifiers.lazy.IBk[3]\\nMaven зависимость:\\n<dependency> <groupId>nz.ac.waikato.cms.weka</groupId> <artifactId>weka-stable</artifactId> <version>3.8.0</version> </dependency>\\nimport weka.classifiers.Evaluation; import weka.classifiers.lazy.IBk; import weka.core.converters.ConverterUtils;\\n// read dataset and build knn-classifier var source = new ConverterUtils.DataSource(\"iris.csv\"); var dataset = source.getDataSet(); var ibk = new IBk(); ibk.buildClassifier(dataset); // test the model var eTest = new Evaluation(dataset); eTest.evaluateModel(ibk, dataset); // print results summary var strSummary = eTest.toSummaryString(); System.out.println(strSummary);', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='7b4640ba-fae5-4c8d-ba28-1e20ac28e9c3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b525fe62fd1637d23b5788448f479bb40880b709f20bc5756bbd15b25e59dc50', text='Дерево решений и случайный лес\\nДерево решений — логический алгоритм классификации, решающий задачи классификации и регрессии. Представляет собой объединение логических условий в структуру дерева.\\nСодержание\\n- 1 Дерево решений\\n- 2 Редукция решающих деревьев\\n- 3 Алгоритмы построения деревьев решения\\n- 4 Случайный лес\\n- 5 Примеры кода\\n- 6 См. также\\n- 7 Источники информации\\nДерево решений\\n|Определение:\\n|Дерево решений (англ. decision tree, DT) — алгоритм классификации , задающийся деревом (связным ациклическим графом), где:\\n|Определение:\\n|Бинарное дерево решений — частный случай дерева решений, для которого.\\nfunction classify(x):if else return\\nИнформативность ветвления\\nДля того, чтобы оценивать качество разбиения объектов по предикату\\nСначала оценим распределение значений классов объектов внутри каждого множества из разбиения, введя понятие меры неопределенности распределения.\\n|Определение:\\n|Частотная оценка вероятности класса в вершине :\\n|Определение:\\n|Мера неопределенности (англ. impurity) распределения :\\nгде убывает и , например: , ,\\nПримерами мер неопределенности распределения являются:\\n- Энтропия: , определяется для каждого множества из разбиения, — количество возможных классов, и — вероятность объекта принадлежать -ому классу.\\n- Критерий Джини:\\nТеперь определим суммарную неопределенность распределения в разбиении.\\n|Определение:\\n|Неопределенность распределения после ветвления вершины по предикату и разбиения :\\nИнформационный выигрыш от разбиения определяется как изменение неопределенности в системе.\\n|Определение:\\n|Информационный выигрыш от разбиения по предикату\\nРекурсивный алгоритм построения бинарного дерева решений ID3\\nПокажем идею построения дерева решения на частном случае бинарного дерева. Алгоритм\\nПроще всего записать этот алгоритм в виде рекурсивной процедуры , которая строит дерево по заданной подвыборке и возвращает его корневую вершину.\\n1:function ID3(): 2: if : , // создать листовую вершину c меткой класса 3: v = createLeafVertex( ) 4: return v // найти предикат с максимальным информационным выигрышом Gain( , ) // разбить выборку на две части по предикату 5: 6: 7: if || // найти класс, в котором находится большинство объектов из 8: = majorClass( ) 9: v = createLeafVertex( ) else // создать внутреннюю вершину 10: v = createVertex() 11: 12: = ID3( ) 13: = ID3( ) 14: return\\nРедукция решающих деревьев\\nСуть редукции (англ. pruning) состоит в удалении поддеревьев, имеющих недостаточную статистическую надёжность. При этом дерево перестаёт безошибочно классифицировать обучающую выборку, зато качество классификации новых объектов, как правило, улучшается. Рассмотрим наиболее простые варианты редукции.\\nПредредукция\\nПредредукция (англ. pre-pruning) или критерий раннего останова досрочно прекращает дальнейшее ветвление в вершине дерева, если информативность\\nДля этого на шаге 8 алгоритма условие или заменяется условием . Порог является управляющим параметром метода.\\nПредредукция считается не самым эффективным способом избежать переобучения, так как жадное ветвление по-прежнему остаётся глобально неоптимальным. Более эффективной считается cтратегия постредукции.\\nПостредукция\\nПостредукция (англ. post-pruning) просматривает все внутренние вершины дерева и заменяет отдельные вершины либо одной из дочерних вершин (при этом вторая дочерняя удаляется), либо терминальной вершиной. Процесс замен продолжается до тех\\nпор, пока в дереве остаются вершины, удовлетворяющие критерию замены.\\nКритерием замены является сокращение числа ошибок на контрольной выборке, отобранной заранее, и не участвовавшей в обучении дерева. Стандартная рекомендация — оставлять в контроле около 30% объектов.\\nДля реализации постредукции контрольная выборка пропускается через построенное дерево. При этом в каждой внутренней вершине запоминается подмножество попавших в неё контрольных объектов. Если , то вершина считается ненадёжной и заменяется терминальной по мажоритарному правилу:\\nв качестве берётся тот класс, объектов которого больше всего в обучающей подвыборке , пришедшей в вершину .\\nЗатем для каждой внутренней вершины вычисляется число ошибок, полученных при классификации выборки следующими способами:\\n- — классификация поддеревом, растущим из вершины ;\\n- — классификация поддеревом левой дочерней вершины ;\\n- — классификация поддеревом правой дочерней вершины ;\\n-\\nЭти величины сравниваются, и в зависимости от того, какая из них оказалась\\nминимальной, принимается, соответственно, одно из четырёх решений:\\n- сохранить поддерево вершины ;\\n- заменить поддерево вершины поддеревом левой дочерней вершины ;\\n- заменить поддерево вершины поддеревом правой дочерней вершины ;\\n- заменить поддерево терминальной вершиной класса .\\nАлгоритмы построения деревьев решения\\nНедостатки рассмотренного алгоритма ID3:\\n- Применим только для дискретных значений признаков;\\n- Переобучение;\\n- На каждом шаге решение принимается по одному атрибуту.\\nАлгоритм CART (англ. Classification And Regression Trees)\\n- В отличие от ID3 работает и с непрерывными значениями признаков: на каждом шаге построения дерева последовательно сравнивает все возможные разбиения для всех атрибутов и выбирает наилучший атрибут и наилучшее разбиение для него. Разбивает объекты на две части;\\n- Использует редукцию для избежания переобучения;\\n- Обрабатывает пропущенные или аномальные значения признаков.\\nАлгоритм C4.5\\n- Также работает и с непрерывными значениями признаков: на каждом шаге построения дерева выбирает правило разбиения по одному из признаков. Разбивает объекты на несколько частей по этому правилу, рекурсивно запускается из полученных подмножеств;\\n- Использует редукцию для избежания переобучения;\\n- Обрабатывает пропущенные или аномальные значения признаков.\\nСлучайный лес\\nСлучайный лес — один из примеров объединения классификаторов в ансамбль.\\nАлгоритм построения случайного леса, состоящего из деревьев на основе обучающей выборки такой:\\nfor (n: 1,...,N): // сгенерировать выборку бутстрэпа = bootstrap( ) // построить решающее дерево по выборке = ID3( )c помощью\\nИтоговый классификатор —\\nТаким образом, случайный лес — бэггинг над решающими деревьями, при обучении которых для каждого разбиения признаки выбираются из некоторого случайного подмножества признаков.\\nПримеры кода\\nПримеры на языке Python\\n- Для решения задач классификации и регрессии используют DecisionTreeClassifier, DecisionTreeRegressor;\\n- В sklearn.ensemble также представлены методы классификации, основанные на ансамблях, в том числе: бэггинг и случайный лес, которые были описаны выше.\\nТак, в этом примере создается бэггинг ансамбль из классификаторов KNeighborsClassifier, каждый из которых обучен на случайных подмножествах из 50% объектов из обучающей выборки, и 50% случайно выбранных признаков.\\nfrom sklearn.ensemble import BaggingClassifier from sklearn.neighbors import KNeighborsClassifier bagging = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\\nПример использования классификатора на случайном лесе: Полную версию кода можно найти здесь\\nfrom sklearn import RandomForestClassifier from sklearn.datasets import make_classification // сгенерируем случайную обучающую выборку с классификацией по n_classes классам X, y = make_classification(n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1, n_classes=2) // разбиваем выборку на обучающую и тестовую X = StandardScaler().fit_transform(X) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42) // создадим классификатор на случайном лесе, состоящим из n_estimators деревьев RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1) clf.fit(X_train, y_train) score = clf.score(X_test, y_test)\\nРезультат классификации показан на рисунке.\\nПример на языке Scala\\nSBT зависимость:\\nlibraryDependencies += \"com.github.haifengl\" %% \"smile-scala\" % \"1.5.2\"\\nПример классификации датасета и вычисления F1 меры[1] используя smile.classification.cart[2]:\\nimport smile.classification._ import smile.data._ import smile.plot._ import smile.read import smile.validation.FMeasure\\nval iris: AttributeDataset = read.table(\"iris.csv\", delimiter = \",\", response = Some((new NumericAttribute(\"class\"), 2))) val x: Array[Array[Double]] = iris.x() val y: Array[Int] = iris.y().map(_.toInt) val dt: DecisionTree = cart(x, y, 1000) val predictions: Array[Int] = x.map(dt.predict) val f1Score = new FMeasure().measure(predictions, y) plot(x, y, dt)\\nПример на языке Java\\nПример классификации с применением\\nweka.classifiers.trees.RandomForest[3]\\nMaven зависимость:\\n<dependency> <groupId>nz.ac.waikato.cms.weka</groupId> <artifactId>weka-stable</artifactId> <version>3.8.0</version> </dependency>\\nimport weka.classifiers.evaluation.Evaluation; import weka.classifiers.trees.RandomForest;\\n// read dataset var trainingDataSet = getDataSet(...); var testingDataSet = getDataSet(...); // create random forest classifier var forest = new RandomForest(); forest.setMaxDepth(15); forest.setNumFeatures(2); forest.buildClassifier(trainingDataSet); // evaluate the model on test dataset and print summary var eval = new Evaluation(trainingDataSet); eval.evaluateModel(forest, testingDataSet); System.out.println(eval.toSummaryString());\\nПример на языке R\\nДеревья решений\\nДля создания деревьев решений используется функция\\nctree() из пакета\\nparty.\\n# importing package install.packages(\"party\") # reading data rdata <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # evaluating model output.tree <- ctree(target ~ x + y + z, data = rdata) # plotting results plot(output.tree)\\nСлучайный лес\\nДля создания случайного леса необходимо импортировать пакет\\nrandomForest\\n# importing packages install.packages(\"party\") install.packages(\"randomForest\") # reading data rdata <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # creating the forest output.forest <- randomForest(target ~ x + y + z, data = rdata) # getting results print(output.forest)\\nСм. также\\nИсточники информации\\n- Логические алгоритмы классификации — Лекция К. В. Воронцова\\n- Случайный лес — статья на Medium, Yury Kashnitskiy\\n- Деревья решений — scikit-learn.org\\n- Ансамбли классификаторов — scikit-learn.org.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='13313369-2ff4-4226-bf1b-dc6729e75b2e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f212059e832f93de18ba0674b8cac338cd8a46a751277d555c0bd807656e07cd', text='Вариации регрессии\\nРегрессия (англ. Regression) — метод моделирования зависимости между зависимой переменнойи одной или несколькими независимыми переменными . В случае нескольких независимых переменных регрессия называется множественной (англ. multivariate regression). Цель регрессионного анализа состоит в том, чтобы оценить значение непрерывной выходной переменной по значениям входных переменных.\\nСодержание\\n- 1 Линейная регрессия\\n- 2 Логистическая регрессия\\n- 3 Гребневая регрессия (ридж-регрессия)\\n- 4 Лассо-регрессия\\n- 5 Байесовская регрессия\\n- 6 Логическая регрессия\\n- 7 См. также\\n- 8 Источники информации\\nЛинейная регрессия\\nЛинейная регрессия (англ. linear regression) — разновидность регрессии для моделирования линейной зависимости между зависимой и независимой переменными.\\nЛогистическая регрессия\\nЛогистическая регрессия (англ. logistic regression) — разновидность регрессии для прогнозирования вероятности некоторого события по значениям независимых переменных. Зависимая переменнаяв этом случае принимает значения или (рассматриваемое событие не произошло или произошло соответственно).\\nГребневая регрессия (ридж-регрессия)\\nГребневая регрессия или ридж-регрессия (англ. ridge regression) — один из методов понижения размерности. Применяется для борьбы с избыточностью данных, когда независимые переменные коррелируют друг с другом, вследствие чего проявляется неустойчивость оценок коэффициентов многомерной линейной регрессии.\\nМотивация\\n|Определение:\\n|Мультиколлинеарность (англ. multicollinearity) — наличие линейной зависимости между независимыми переменными регрессионной модели. Различают полную коллинеарность и частичную или просто мультиколлинеарность — наличие сильной корреляции между независимыми переменными.\\nРассмотрим пример линейной модели:. Пусть имеет место зависимость . Добавим к первому коэффициенту произвольное число , а из двух других коэффициентов это же число вычтем. Получаем (без случайной ошибки):\\nНесмотря на относительно произвольное изменение коэффициентов модели мы получили исходную модель, то есть такая модель неидентифицируема.\\nНа практике чаще встречается проблема сильной корреляции между независимыми переменными. В этом случае оценки параметров модели получить можно, но они будут неустойчивыми.\\nОписание\\nНапомним задачу многомерной линейной регрессии:\\nРассматривается линейная зависимость.\\nНаходим вектор, при котором достигается минимум среднего квадрата ошибки:\\nМетодом наименьших квадратов находим решение:\\nВ условиях мультиколлинеарности матрицастановится плохо обусловленной.\\nДля решения этой проблемы наложим ограничение на величину коэффициентов: .\\nФункционалс учетом ограничения принимает вид:\\n- ,\\nгде— неотрицательный параметр.\\nРешением в этом случае будет\\nЭто изменение увеличивает собственные значения матрицы, но не изменяет ее собственные вектора. В результате имеем хорошо обусловленную матрицу.\\nДиагональная матрицаназывается гребнем.\\nПримеры кода\\nПример кода для Scikit-learn\\n# импорт библиотек from sklearn.datasets import make_regression from sklearn.linear_model import Ridge from sklearn.model_selection import train_test_split # генерируем данные для X и y X, y = make_regression(n_samples=10000, noise=100, random_state=0) # разделение данных на train и test train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=3) ridge_regression = Ridge(alpha=0.1) # alpha — величина регуляризации # обучение ridge_regression.fit(train_X, train_y) # предсказание результата print(ridge_regression.predict(test_X)) # вывод точности предсказания print(ridge_regression.score(test_X, test_y))\\nТочность предсказания для данного датасета и параметров:\\n>>> 0.8171822749108134\\nПример на языке Java\\nПример гребневой регрессии с применением\\nsmile.regression.RidgeRegression[1]\\nMaven зависимость:\\n<dependency> <groupId>com.github.haifengl</groupId> <artifactId>smile-core</artifactId> <version>1.5.2</version> </dependency>\\nimport smile.data.NominalAttribute; import smile.data.parser.DelimitedTextParser; import smile.regression.RidgeRegression;\\nvar parser = new DelimitedTextParser(); parser.setDelimiter(\", \"); parser.setResponseIndex(new NominalAttribute(\"class\"), 0); var dataset = parser.parse(\"dataset.csv\"); var lambda = 0.0057d; var ridgeClf = new RidgeRegression(dataset.x(), dataset.y(), lambda); ridgeClf.predict(testX);\\nЛассо-регрессия\\nМетод регрессии лассо (англ. LASSO, Least Absolute Shrinkage and Selection Operator) похож на гребневую регрессию, но он использует другое ограничение на коэффициенты:\\nФункционалпринимает следующий вид:\\nОсновное различие лассо- и ридж-регрессии заключается в том, что первая может приводить к обращению некоторых независимых переменных в ноль, тогда как вторая уменьшает их до значений, близких к нулю. Рассмотрим для простоты двумерное пространство независимых переменных. В случае лассо-регрессии органичение на коэффициенты представляет собой ромб (), в случае ридж-регрессии — круг ( ). Необходимо минимизировать функцию ошибки, но при этом соблюсти ограничения на коэффициенты. С геометрической точки зрения задача состоит в том, чтобы найти точку касания линии, отражающей функцию ошибки с фигурой, отражающей ограничения на . Из рисунка 1 интуитивно понятно, что в случае лассо-регрессии эта точка с большой вероятностью будет находиться на углах ромба, то есть лежать на оси, тогда как в случае ридж-регрессии такое происходит очень редко. Если точка пересечения лежит на оси, один из коэффициентов будет равен нулю, а значит, значение соответствующей независимой переменной не будет учитываться.\\nПримеры кода\\nПример кода для Scikit-learn\\n# импорт библиотек from sklearn.datasets import make_regression from sklearn.linear_model import Lasso from sklearn.model_selection import train_test_split # генерируем данные для X и y X, y = make_regression(n_samples=10000, noise=100, random_state=0) # разделение данных на train и test train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=3) lasso_regression = Lasso(alpha=0.1) # alpha — величина регуляризации # обучение lasso_regression.fit(train_X, train_y) # предсказание результата print(lasso_regression.predict(test_X)) # вывод точности предсказания print(lasso_regression.score(test_X, test_y))\\nТочность предсказания для данного датасета и параметров:\\n>>> 0.8173906804156383\\nПример на языке Java\\nПример Лассо-регрессии с применением\\nsmile.regression.LASSO[2]\\nMaven зависимость:\\n<dependency> <groupId>com.github.haifengl</groupId> <artifactId>smile-core</artifactId> <version>1.5.2</version> </dependency>\\nimport smile.data.NominalAttribute; import smile.data.parser.DelimitedTextParser; import smile.regression.LASSO;\\nvar parser = new DelimitedTextParser(); parser.setDelimiter(\", \"); parser.setResponseIndex(new NominalAttribute(\"class\"), 0); var dataset = parser.parse(\"dataset.csv\"); var lasso = new LASSO(dataset.x(), dataset.y(), 10); lasso.predict(testX);\\nБайесовская регрессия\\nОписанные выше методы никак не учитывали наличие в данных шума, тогда как в реальных данных он скорее всего будет присутствовать. Предположим, что в данных все же есть некоторый шум, и что он распределен нормально. Тогда задачу линейной регрессии можно записать в следующем виде:\\n- , где .\\nРешением этой задачи мы и будем заниматься в этом разделе.\\nБайесовская линейная регрессия (англ. Bayesian linear regression) — подход в линейной регрессии, в котором предполагается что шум распределен нормально.\\nНа рисунке 2 синяя точка показывает значения из датасета, красная — значение, предсказанное регрессией. Поскольку центр гауссианы находится в красной точке, маленькие отклонения синей точки от красной более вероятны, а большие менее вероятны.\\nДля решения поставленной задачи регрессии воспользуемся методом максимального правдоподобия.\\nЗапишем правдоподобие:\\n- ,\\nгде— плотность распределения значения из датасета, которая, как мы ранее предположили, соответствует нормальному распределению с центром в точке (значение для , предсказанное алгоритмом).\\nБудем также предполагать, что данные независимы:\\nПоскольку нас интересует только максимум, положим:\\nПрологарифмируем это выражение:\\nТаким образом, оказывается, что метод максимального правдоподобия с учетом шума в данных сводится к оценке по методу наименьших квадратов, которую мы уже видели в обычной линейной регрессии.\\nПример кода для Scikit-learn\\n# импорт библиотек from sklearn.datasets import make_regression from sklearn.linear_model import BayesianRidge from sklearn.model_selection import train_test_split # генерируем данные для X и y X, y = make_regression(n_samples=10000, noise=100, random_state=0) # разделение данных на train и test train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=3) bayesian_regression = BayesianRidge() # обучение bayesian_regression.fit(train_X, train_y) # предсказание результата print(bayesian_regression.predict(test_X)) # вывод точности предсказания print(bayesian_regression.score(test_X, test_y))\\nТочность предсказания для данного датасета и параметров:\\n>>> 0.8170548749907206\\nЛогическая регрессия\\nЛогическая регрессия (англ. logic regression) — обобщенный метод регрессии, применяемый в основном в случае, когда независимые переменные имеют двоичную природу (при этом зависимая переменная не обязательно двоичная). Задачей логической регрессии является определение независимых переменных, которые могут быть выражены как результат вычисления булевой функции от других независимых переменных.\\nОбычно в методах регрессии не учитывается связь между переменными. Предполагается, что влияние каждой переменной на результат не зависит от значений других переменных. Однако это предположение зачастую неверно.\\nПусть— двоичные независимые переменные, и пусть — зависимая переменная. Будем пытаться натренировать модели регрессии вида , где — булева функция от переменных (например ). Для каждого типа модели необходимо определить функцию, которая отражает качество рассматриваемой модели. Например, для линейной регрессии такой функцией может быть остаточная сумма квадратов. Целью метода логической регрессии является минимизация выбранной функции качества посредством настройки параметров одновременно с булевыми выражениями .\\nМожет показаться не совсем понятным, как же применить регрессию к булевым выражениям. Рассмотрим в общих чертах алгоритм логической регрессии. Логическая регрессия, как и другие методы регрессии, перебирает различные выражения в попытках минимизировать функцию потерь. Дляпеременных можно составить различных выражений. Нужно найти более эффективный метод для поиска наилучшего выражения, чем простой перебор всех вариантов.\\nЛюбое логическое выражение можно представить в виде дерева, где в узлах расположены операции, а листья представляют собой переменные. Будем называть такие деревья логическими деревьями (англ. logic trees). Будем называть соседями (англ. neighbours) логического дерева такие деревья, которые могут быть получены из него за один шаг. Допустимые шаги проиллюстрированы на рисунке 3.\\nРассмотрим самый простой алгоритм поиска наилучшего дерева — жадный поиск (англ. greedy search).\\n- В качестве стартового дерева выберем одну переменную, которая дает минимальное значение функции потерь среди всех остальных переменных.\\n- Перебираем соседей текущего дерева и выбираем такое, что оно уменьшает значение функции потерь по сравнению с текущим, а также дает наименьший результат среди остальных соседей.\\n- Если такого дерева не существует, алгоритм завершается. Если оно все же есть, выбираем его в качестве текущего и повторяем второй шаг.\\nЭтот алгоритм склонен к переобучению, а также в некоторых ситуациях может остановиться преждевременно, так и не дойдя до наилучшего дерева. Существует также алгоритм под названием имитация отжига (англ. simulated annealing) который показывает лучшие результаты, чем описанный жадный поиск.\\nСм. также\\n- Общие понятия\\n- Линейная регрессия\\n- Логистическая регрессия\\n- Обзор библиотек для машинного обучения на Python\\n- Байесовская классификация\\n- Уменьшение размерности\\nИсточники информации\\n- 10 типов регрессии — какой выбрать?\\n- machinelearning.ru — Линейная регрессия (пример)\\n- machinelearning.ru — Ридж-регрессия\\n- Лекции по алгоритмам восстановления регрессии К. В. Воронцов\\n- Ridge and Lasso Regression: A Complete Guide with Python Scikit-Learn\\n- Habr — Базовые принципы машинного обучения на примере линейной регрессии\\n- Documents on Logic Regression', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='31e082f5-b2e7-4edf-828f-6b6ac26a7ad6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='819dd0734f059e05b0bdc6635abbc97dd6978dee1746bc24f8ebdcc03694001c', text='Линейная регрессия\\nЛинейная регрессия (англ. linear regression) — метод восстановления зависимости одной (объясняемой, зависимой) переменнойот другой или нескольких других переменных (факторов, регрессоров, независимых переменных) с линейной функцией зависимости. Данный метод позволяет предсказывать значения зависимой переменной по значениям независимой переменной .\\nСодержание\\n- 1 Задача\\n- 2 Решение\\n- 3 Проблема мультиколлинеарности и переобучения\\n- 4 Примеры кода\\n- 5 Применение\\n- 6 См. также\\n- 7 Источники информации\\nЗадача\\nДано\\n- — числовые признаки;\\n- модель многомерной линейной регрессии:\\n,\\nгде ;\\n- обучающая выборка: множество из пар ;\\n- — объекты из множества ;\\n- — объекты из множества .\\nМатричные обозначения\\nПерейдем к матричным обозначениям:\\n,\\nгде\\n- — матрица объектов-признаков, где строки соответствуют объектам а столбцы — признакам;\\n- — вектор ответов, или целевой вектор;\\n- — вектор коэффициентов.\\nПостановка задачи\\nВ этих трех векторно-матричных обозначениях очень удобно расписать постановку задачи наименьших квадратов:\\n.\\nНеобходимо найти векторпри известной матрице и известном вектор-столбце .\\nРешение\\nНормальная система уравнений\\nЗапишем необходимые условия минимума в матричном виде:\\n.\\nОтсюда следует нормальная система задачи МНК:\\n,\\nгдематрица.\\nМы получили систему уравнений, откуда можем выразить искомый вектор.\\nРешение системы\\n,\\nгде — псевдо-обратная матрица.\\nЗначение функционала:\\nгде — проекционная матрица.\\nПроблемы\\nВ случае мультиколлинеарности (столбцы матрицылинейно-зависимы) нам не удастся найти обратную матрицу к (она будет вырождена).\\nЕсли же столбцы матрицыпочти линейно-зависимы, то у нас возникнет масса вычислительных проблем с обращением этой матрицы.\\nРешение МНК через сингулярное разложение\\nВоспользуемся понятием сингулярного разложения , которое позволяет произвольную прямоугольную матрицу представить в виде произведения трех матриц:\\n.\\nНайдем псевдо-обратную матрицу:\\n.\\nТеперь, зная псевдо-обратную матрицу, найдем решение задачи наименьших квадратов:\\n.\\nНайдем вектор, которым наша линейная модель аппроксимирует целевой вектор\\n.\\nКвадрат нормы вектора коэффициентов:\\n.\\nВ 3-х из 4-х формул сингулярные числа оказались в знаменателе. Если имеются сингулярные числа приближающиеся к 0, то мы получаем проблему мультиколлинеарности. Близкие к 0 собственные значения или сингулярные числа — показатель того, что среди признаков есть почти линейно-зависимый.\\nПроблема мультиколлинеарности и переобучения\\nЕсли имеются сингулярные числа близкие к 0, то:\\n- матрица плохо обусловлена;\\n- решение становится неустойчивым и неинтерпретируемым, слишком большие коэффициенты разных знаков;\\n- возникает переобучение:\\nна обучении мало;\\nна контроле велико.\\nСтратегии устранения мультиколлинеарности и переобучения:\\n- отбор признаков, то есть выкидываем те признаки, которые могут оказаться линейно-зависимыми:\\n;\\n- регуляризация (накладываем дополнительные ограничения на вектор коэффициентов):\\n;\\n- преобразование признаков, чтобы в новом признаковом пространстве признаков оказалось меньше, но они хорошо восстанавливали бы исходные:\\n.\\nПримеры кода\\nПример кода для Scikit-learn\\nimport matplotlib.pyplot as plt from sklearn import datasets, linear_model # generate dataset X, y = datasets.make_regression(n_samples=1_000, n_features=1, noise=8, shuffle=True) # test and train data sizes train_size = 700 test_size = 300 # split the data into training/testing sets X_train = X[:-train_size] X_test = X[-test_size:] # split the targets into training/testing sets y_train = y[:-train_size] y_test = y[-test_size:] # create linear regression object regr = linear_model.LinearRegression() # train the model using the training sets regr.fit(X_train, y_train) # make predictions using the testing set y_pred = regr.predict(X_test) # plot outputs plt.scatter(X_test, y_test, color=\\'red\\', s=5) plt.plot(X_test, y_pred, color=\\'blue\\', linewidth=2) plt.xticks(()) plt.yticks(()) plt.show()\\nВозможный результат исполнения программы:\\nПример на языке Java\\nПример линейной регресии с применением\\nweka.classifiers.functions.LinearRegression[1]\\nMaven зависимомсть:\\n<dependency> <groupId>nz.ac.waikato.cms.weka</groupId> <artifactId>weka-stable</artifactId> <version>3.8.0</version> </dependency>\\nimport weka.classifiers.functions.LinearRegression; import weka.core.Instance; import weka.core.Instances;\\n//Load Data set var data = new Instances(new BufferedReader(new FileReader(\"dataset/house.arff\"))); data.setClassIndex(data.numAttributes() - 1); //Build model var model = new LinearRegression(); try { model.buildClassifier(data); } catch (Exception e) { e.printStackTrace(); } //output model System.out.printf(\"model parameters: %s%n\", model); // Now Predicting the cost var myHouse = data.lastInstance(); var price = model.classifyInstance(myHouse); System.out.printf(\"predicted price = %s%n\", price)\\nПример на языке R\\n# reading data data <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # evaluating linear regression model model <- lm(data$x ~ data$y) # getting summary print(summary(model)) # visualizing data plot(data$y, data$x) lines(data$y, predict(fit), col = \\'red\\')\\nПрименение\\nПеречислим несколько примеров реального применения линейной регрессии:\\n- для предсказания скидки на продукты на основе поведения покупателей в прошлом;\\n- экономисты использую линейную регрессия для предсказания экономического роста страны или региона;\\n- застройщики при помощи данного метода могут предсказать, сколько домов он продаст в ближайшие месяцы и по какой цене;\\n- цены на нефть могут быть предсказаны с использованием линейной регрессии.\\nСм. также\\n- Общие понятия\\n- Вариации регрессии\\n- Логистическая регрессия\\n- Обзор библиотек для машинного обучения на Python\\n- Переобучение\\nИсточники информации\\n- machinelearning.ru — Многомерная линейная регрессия\\n- machinelearning.ru — Линейная регрессия (пример)\\n- Coursera — \"Введение в машинное обучение\", Неделя 4,\\n- Лекции по алгоритмам восстановления регрессии К. В. Воронцов\\n- Scikit-Learn — Linear Regression Example\\n- What are some real-world applications of \"simple\" linear regression?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='300be750-1c34-483e-a1d6-90a1fdffef5a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='408d6e06294986afcb47a487ef394065823e741a01d422ce9769f27e68182111', text='Логистическая регрессия\\nЛогистическая регрессия (англ. logistic regression) — метод построения линейного классификатора, позволяющий оценивать апостериорные вероятности принадлежности объектов классам.\\nСодержание\\nОписание\\nЛогистическая регрессия применяется для прогнозирования вероятности возникновения некоторого события по значениям множества признаков. Для этого вводится зависимая переменная $y$, принимающая значения $0$ и $1$ и множество независимых переменных на основе значений которых требуется вычислить вероятность принятия того или иного значения зависимой переменной.\\nИтак, пусть объекты задаются $n$ числовыми признаками $f_j : X \\\\to R, j = 1 ... n$ и пространство признаковых описаний в таком случае $X = R^n$. Пусть $Y$ — конечное множество меток классов и задана обучающая выборка пар «объект-ответ»\\nРассмотрим случай двух классов: $Y = \\\\{-1, +1\\\\}$. В логистической регрессии строится линейный алгоритм классификации $a: X \\\\to Y$ вида\\nгде $w_j$ $-$ вес $j$-го признака, $w_0$ $-$ порог принятия решения, $w=\\\\left(w_0, ..., w_n\\\\right)$ $-$ вектор весов, $\\\\left<x, w\\\\right>$ $-$ скалярное произведение признакового описания объекта на вектор весов. Предполагается, что искусственно введён нулевой признак: $f_{0}(x)=-1$.Задача обучения линейного классификатора заключается в том, чтобы по выборке $X^m$ настроить вектор весов $w$. В логистической регрессии для этого решается задача минимизации эмпирического риска с функцией потерь специального вида:\\nПосле того, как решение $w$ найдено, становится возможным не только вычислять классификацию $a(x) = \\\\mathrm{sign}\\\\langle x,w \\\\rangle$ для произвольного объекта $x$, но и оценивать апостериорные вероятности его принадлежности классам:\\nгде $\\\\sigma(z) = \\\\frac1{1+e^{-z}}$ — сигмоидная функция.\\nОбоснование\\nС точки зрения байесовского классификатора\\nНаиболее строгое обоснование логистической регрессии опирается на следующую теорему\\n|Теорема:\\nПусть\\nгде $\\\\mathrm{P}_y$ — априорные вероятности, $p_y(x)$ $-$ функции правдоподобия, принадлежащие экспонентному семейству плотностей (т.е. $p_y(x) = \\\\exp \\\\left( \\\\langle\\\\theta,x\\\\rangle \\\\cdot a(\\\\delta) + b(\\\\delta,\\\\theta) + d(x,\\\\delta) \\\\right)$, где $a, b, d$ $-$ произвольные функции);\\nТогда\\n|Доказательство:\\n|\\nНапомним, что оптимальный байесовский классификатор для двух классов выглядит следущим образом:\\nРассмотрим отношение апостериорных вероятностей классов\\nи распишем функции правдоподобия, используя экспонентную формулу с параметрами $\\\\theta_y$ и $\\\\delta$:\\nРассмотрим получившуюся под экспонентой сумму:\\nТаким образом,\\nРазделяющая поверхность в байесовском решающем правиле определяется уравнением\\nкоторое равносильно\\nСледовательно, разделяющая поверхность линейна и первый пункт теоремы доказан.\\nИспользуя формулу полной вероятности получаем следующее равенство\\nОткуда следует:\\nПримеры кода\\nscikit-learn\\nКлассификатор sklearn.linear_model.LogisticRegression имеет несколько параметров, например:\\n- solver $-$ алгоритм, использующийся для оптимизации;\\n- multi_class $-$ классификация на 2 или много классов.\\n- Импортируем нужные библиотеки:\\nfrom sklearn.linear_model import LogisticRegression from sklearn import datasets from sklearn.model_selection import train_test_split\\n- Выберем тренировочное и тестовое множества:\\niris = datasets.load_iris() X = iris.data y = iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\\n- Обучение:\\nclf = LogisticRegression(random_state=0, solver=\\'lbfgs\\', multi_class=\\'multinomial\\') model = clf.fit(X_train, y_train)\\n- Предсказание:\\ny_pred = model.predict(X_test) model.score(X_test, y_test)\\nПример кода на Scala\\nПример на языке Java\\nПример логистической регрессии с применением\\nsmile.classification.LogisticRegression[1]\\nMaven зависимость:\\n<dependency> <groupId>com.github.haifengl</groupId> <artifactId>smile-core</artifactId> <version>1.5.2</version> </dependency>\\nimport smile.data.AttributeDataset; import smile.data.NominalAttribute; import smile.classification.LogisticRegression; import smile.data.parser.ArffParser;\\nvar arffParser = new ArffParser(); arffParser.setResponseIndex(4); var iris = arffParser.parse(smile.data.parser.IOUtils.getTestDataFile(\"weka/iris.arff\")); var logClf = new LogisticRegression(iris.x(), iris.labels()); logClf.predict(testX);\\nПример на языке R\\n# reading data rdata <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # evaluating model model = glm(formula = target ~ x + y + z, data = rdata, family = binomial) # printing summary print(summary(model))\\nСм. также\\n- Байесовская классификация[на 28.01.19 не создан]\\n- Линейная регрессия[на 28.01.19 не создан]\\n- Вариации регрессии\\n- Обзор библиотек для машинного обучения на Python\\n- Общие понятия\\n- Уменьшение размерности', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='09fe35ed-1fcc-48f7-ad76-c14d0209e447', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ab1e5c80b60f3807bf7ca65b2f7cee78f00ddc681cdab03e7114b679b7830519', text='Метод опорных векторов (SVM)\\nМетод опорных векторов (англ. support vector machine, SVM) — один из наиболее популярных методов обучения, который применяется для решения задач классификации и регрессии. Основная идея метода заключается в построении гиперплоскости, разделяющей объекты выборки оптимальным способом. Алгоритм работает в предположении, что чем больше расстояние (зазор) между разделяющей гиперплоскостью и объектами разделяемых классов, тем меньше будет средняя ошибка классификатора.\\nСодержание\\n- 1 Метод опорных векторов в задаче классификации\\n- 2 Преимущества и недостатки SVM\\n- 3 Модификации\\n- 4 Примеры кода\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nМетод опорных векторов в задаче классификации\\nРассмотрим задачу бинарной классификации, в которой объектам из $X=\\\\mathbb{R}^n$ соответствует один из двух классов $Y = \\\\{-1, +1\\\\}$.\\nПусть задана обучающая выборка пар \"объект-ответ\": $T^\\\\ell = (\\\\vec{x}_i, y_i)_{i=1}^\\\\ell$. Необходимо построить алгоритм классификации $a(\\\\vec{x}) : X \\\\to Y$.\\nРазделяющая гиперплоскость\\nВ пространстве $\\\\mathbb{R}^n$ уравнение $\\\\langle \\\\vec{w}, \\\\vec{x} \\\\rangle - b = 0$ при заданных $\\\\vec{w}$ и $b$ определяет гиперплоскость — множество векторов $\\\\vec{x} = (x_1, \\\\ldots, x_n)$, принадлежащих пространству меньшей размерности $\\\\mathbb{R}^{n-1}$. Например, для $\\\\mathbb{R}^1$ гиперплоскостью является точка, для $\\\\mathbb{R}^2$ — прямая, для $\\\\mathbb{R}^3$ — плоскость и т.д. Параметр $\\\\vec{w}$ определяет вектор нормали к гиперплоскости, а через $\\\\frac{b}{\\\\lVert \\\\vec{w} \\\\rVert}$ выражается расстояние от гиперплоскости до начала координат.\\nГиперплоскость делит $\\\\mathbb{R}^n$ на два полупространства: $\\\\langle \\\\vec{w}, \\\\vec{x} \\\\rangle - b > 0$ и $\\\\langle \\\\vec{w}, \\\\vec{x} \\\\rangle - b < 0$.\\nГоворят, что гиперплоскость разделяет два класса $C_1$ и $C_2$, если объекты этих классов лежат по разные стороны от гиперплоскости, то есть выполнено либо\\n$\\\\begin{cases}\\\\langle \\\\vec{w}, \\\\vec{x} \\\\rangle - b > 0, && \\\\forall x \\\\in C_1 \\\\\\\\ \\\\langle \\\\vec{w}, \\\\vec{x} \\\\rangle - b < 0, && \\\\forall x \\\\in C_2\\\\end{cases}$\\nлибо\\n$\\\\begin{cases}\\\\langle \\\\vec{w}, \\\\vec{x} \\\\rangle - b < 0, && \\\\forall x \\\\in C_1 \\\\\\\\ \\\\langle \\\\vec{w}, \\\\vec{x} \\\\rangle - b > 0, && \\\\forall x \\\\in C_2\\\\end{cases}$\\nЛинейно разделимая выборка\\nПусть выборка линейно разделима, то есть существует некоторая гиперплоскость, разделяющая классы $-1$ и $+1$. Тогда в качестве алгоритма классификации можно использовать линейный пороговый классификатор:\\n$a(\\\\vec{x}) = sign(\\\\langle \\\\vec{w}, \\\\vec{x} \\\\rangle - b) = sign\\\\left(\\\\sum\\\\limits_{i=1}^\\\\ell w_i x_i - b\\\\right)$\\nгде $\\\\vec{x} = (x_1, \\\\ldots, x_n)$ — вектор значений признаков объекта, а $\\\\vec{w} = (w_1, \\\\ldots, w_n) \\\\in \\\\mathbb{R}^n$ и $b \\\\in \\\\mathbb{R}$ — параметры гиперплоскости.\\nНо для двух линейно разделимых классов возможны различные варианты построения разделяющих гиперплоскостей. Метод опорных векторов выбирает ту гиперплоскость, которая максимизирует отступ между классами:\\n|Определение:\\n|Отступ (англ. margin) — характеристика, оценивающая, насколько объект \"погружён\" в свой класс, насколько типичным представителем класса он является. Чем меньше значение отступа $M_i$, тем ближе объект $\\\\vec{x}_i$ подходит к границе классов и тем выше становится вероятность ошибки. Отступ $M_i$ отрицателен тогда и только тогда, когда алгоритм $a(x)$ допускает ошибку на объекте $\\\\vec{x}_i$.\\nДля линейного классификатора отступ определяется уравнением: $M_i(\\\\vec{w}, b) = y_i(\\\\langle \\\\vec{w}, \\\\vec{x}_i \\\\rangle - b)$\\nЕсли выборка линейно разделима, то существует такая гиперплоскость, отступ от которой до каждого объекта положителен:\\n$\\\\exists \\\\vec{w}, b : \\\\; M_i(\\\\vec{w}, b) = y_i(\\\\langle \\\\vec{w}, \\\\vec{x}_i \\\\rangle - b) > 0, \\\\; i = 1\\\\ldots\\\\ell$\\nМы хотим построить такую разделяющую гиперплоскость, чтобы объекты обучающей выборки находились на наибольшем расстоянии от неё.\\nЗаметим, что при умножении $\\\\vec{w}$ и $b$ на константу $c \\\\neq 0$ уравнение $\\\\langle c\\\\vec{w}, \\\\vec{x} \\\\rangle - cb = 0$ определяет ту же самую гиперплоскость, что и $\\\\langle \\\\vec{w}, \\\\vec{x} \\\\rangle - b = 0$. Для удобства проведём нормировку: выберем константу $c$ таким образом, чтобы $\\\\min M_i(\\\\vec{w}, b) = 1$. При этом в каждом из двух классов найдётся хотя бы один \"граничный\" объект обучающей выборки, отступ которого равен этому минимуму: иначе можно было бы сместить гиперплоскость в сторону класса с большим отступом, тем самым увеличив минимальное расстояние от гиперплоскости до объектов обучающей выборки.\\nОбозначим любой \"граничный\" объект из класса $+1$ как $\\\\vec{x}_+$, из класса $-1$ как $\\\\vec{x}_-$. Их отступ равен единице, то есть\\n$\\\\begin{cases} M_+(\\\\vec{w}, b) = (+1)(\\\\langle \\\\vec{w}, \\\\vec{x}_+ \\\\rangle - b) = 1 \\\\\\\\ M_-(\\\\vec{w}, b) = (-1)(\\\\langle \\\\vec{w}, \\\\vec{x}_- \\\\rangle - b) = 1 \\\\end{cases}$\\nНормировка позволяет ограничить разделяющую полосу между классами: $\\\\{x: -1 < \\\\langle \\\\vec{w}, \\\\vec{x}_i \\\\rangle - b < 1\\\\}$. Внутри неё не может лежать ни один объект обучающей выборки. Ширину разделяющей полосы можно выразить как проекцию вектора $\\\\vec{x}_+ - \\\\vec{x}_-$ на нормаль к гиперплоскости $\\\\vec{w}$. Чтобы разделяющая гиперплоскость находилась на наибольшем расстоянии от точек выборки, ширина полосы должна быть максимальной:\\n$\\\\frac{\\\\langle \\\\vec{x}_+ - \\\\vec{x}_-, \\\\vec{w} \\\\rangle}{\\\\lVert w \\\\rVert} = \\\\frac{\\\\langle \\\\vec{x}_+, \\\\vec{w} \\\\rangle - \\\\langle \\\\vec{x}_-, \\\\vec{w} \\\\rangle - b + b}{\\\\lVert w \\\\rVert} = \\\\frac{(+1)\\\\left(\\\\langle \\\\vec{x}_+, \\\\vec{w} \\\\rangle - b\\\\right) \\\\, + \\\\, (-1)\\\\left(\\\\langle \\\\vec{x}_-, \\\\vec{w} \\\\rangle - b\\\\right)}{\\\\lVert w \\\\rVert} = \\\\\\\\ = \\\\frac{M_+(\\\\vec{w}, b) \\\\, + \\\\, M_-(\\\\vec{w}, b)}{\\\\lVert w \\\\rVert} = \\\\frac{2}{\\\\lVert w \\\\rVert} \\\\to \\\\max \\\\; \\\\Rightarrow \\\\; \\\\lVert w \\\\rVert \\\\to \\\\min$\\nЭто приводит нас к постановке задачи оптимизации в терминах квадратичного программирования:\\n$\\\\begin{cases} \\\\lVert \\\\vec{w} \\\\rVert^2 \\\\to \\\\min\\\\limits_{w,b} \\\\\\\\ M_i(\\\\vec{w}, b) \\\\geq 1, \\\\quad i = 1, \\\\ldots, \\\\ell \\\\end{cases}$\\nЛинейно неразделимая выборка\\nНа практике линейно разделимые выборки практически не встречаются: в данных возможны выбросы и нечёткие границы между классами. В таком случае поставленная выше задача не имеет решений, и необходимо ослабить ограничения, позволив некоторым объектам попадать на \"территорию\" другого класса. Для каждого объекта отнимем от отступа некоторую положительную величину $\\\\xi_i$, но потребуем чтобы эти введённые поправки были минимальны. Это приведёт к следующей постановке задачи, называемой также SVM с мягким отступом (англ. soft-margin SVM):\\n$\\\\begin{cases} \\\\frac{1}{2} \\\\lVert \\\\vec{w} \\\\rVert^2 \\\\color{brown}{+ C \\\\sum\\\\limits_{i=1}^\\\\ell \\\\xi_i} \\\\to \\\\min\\\\limits_{w, b, \\\\color{brown}{\\\\xi}} \\\\\\\\ M_i(\\\\vec{w}, b) \\\\geq 1 \\\\color{brown}{- \\\\xi_i}, \\\\quad i = 1, \\\\ldots, \\\\ell \\\\\\\\ \\\\color{brown}{\\\\xi_i \\\\geq 0, \\\\quad i = 1, \\\\ldots, \\\\ell} \\\\\\\\ \\\\end{cases}$\\nМы не знаем, какой из функционалов $\\\\frac{1}{2} \\\\lVert \\\\vec{w} \\\\rVert^2$ и $\\\\sum\\\\limits_{i=1}^\\\\ell \\\\xi_i$ важнее, поэтому вводим коэффициент $C$, который будем оптимизировать с помощью кросс-валидации. В итоге мы получили задачу, у которой всегда есть единственное решение.\\nЗаметим, что мы можем упростить постановку задачи:\\n$\\\\begin{cases} \\\\xi_i \\\\geq 0 \\\\\\\\ \\\\xi_i \\\\geq 1 - M_i(\\\\vec{w}, b) \\\\\\\\ \\\\sum\\\\limits_{i=1}^\\\\ell \\\\xi_i \\\\to \\\\min \\\\end{cases} \\\\,\\\\Rightarrow\\\\, \\\\begin{cases} \\\\xi_i \\\\geq \\\\max(0, 1 - M_i(\\\\vec{w}, b)) \\\\\\\\ \\\\sum\\\\limits_{i=1}^\\\\ell \\\\xi_i \\\\to \\\\min \\\\end{cases} \\\\,\\\\Rightarrow\\\\, \\\\xi_i = (1- M_i(\\\\vec{w}, b))_+$\\nПолучим эквивалентную задачу безусловной минимизации:\\n$\\\\frac{1}{2} \\\\lVert \\\\vec{w} \\\\rVert^2 + C \\\\sum\\\\limits_{i=1}^\\\\ell \\\\left(1 - M_i(\\\\vec{w}, b)\\\\right)_+ \\\\to \\\\min\\\\limits_{w, b}$\\nТеперь научимся её решать.\\n|Теорема (Условия Каруша—Куна—Таккера):\\nПусть поставлена задача нелинейного программирования с ограничениями:\\n$$ \\\\begin{cases} f(x) \\\\to \\\\min\\\\limits_{x \\\\in X} \\\\\\\\ g_i(x) \\\\leq 0,\\\\;i=1\\\\ldots m \\\\\\\\ h_j(x) = 0,\\\\;j=1\\\\ldots k \\\\end{cases} $$\\nЕсли $x$ — точка локального минимума при наложенных ограничениях, то существуют такие множители $\\\\mu_i, i = 1\\\\ldots m$, $\\\\;\\\\lambda_j, j = 1\\\\ldots k$, что для функции Лагранжа $L(x; \\\\mu, \\\\lambda)$ выполняются условия:\\n$$\\\\begin{cases}\\\\frac{\\\\partial L}{\\\\partial x} = 0, \\\\quad L(x; \\\\mu, \\\\lambda) = f(x) + \\\\sum\\\\limits_{i=1}^m \\\\mu_i g_i(x) + \\\\sum\\\\limits_{j=1}^k \\\\lambda_j h_j(x) \\\\\\\\ g_i(x) \\\\leq 0,\\\\;h_j(x) = 0 \\\\quad \\\\text{(исходные ограничения)} \\\\\\\\ \\\\mu_i \\\\geq 0 \\\\quad \\\\text{(двойственные ограничения)} \\\\\\\\ \\\\mu_i g_i(x) = 0 \\\\quad \\\\text{(условие дополняющей нежёсткости)} \\\\end{cases}$$При этом искомая точка является седловой точкой функции Лагранжа: минимумом по $x$ и максимумом по двойственным переменным $\\\\mu$.\\nПо теореме Каруша—Куна—Таккера, поставленная нами задача минимизации эквивалентна двойственной задаче поиска седловой точки функции Лагранжа:\\n$\\\\mathscr{L}(\\\\vec{w},b,\\\\xi; \\\\lambda, \\\\eta) = \\\\frac{1}{2} \\\\lVert w \\\\rVert^2 - \\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i \\\\left(M_i(\\\\vec{w}, b) - 1\\\\right) - \\\\sum\\\\limits_{i=1}^\\\\ell \\\\xi_i \\\\left(\\\\lambda_i + \\\\eta_i - C\\\\right)$\\n$\\\\lambda_i$ — переменные, двойственные к ограничениям $M_i \\\\geq 1 - \\\\xi_i$\\n$\\\\eta_i$ — переменные, двойственные к ограничениям $\\\\xi_i \\\\geq 0$\\nЗапишем необходимые условия седловой точки функции Лагранжа:\\n$\\\\begin{cases} \\\\frac{\\\\partial \\\\mathscr{L}}{\\\\partial w} = 0, \\\\quad \\\\frac{\\\\partial \\\\mathscr{L}}{\\\\partial b} = 0, \\\\quad \\\\frac{\\\\partial \\\\mathscr{L}}{\\\\partial \\\\xi} = 0 \\\\\\\\ \\\\xi_i \\\\geq 0, \\\\quad \\\\lambda_i \\\\geq 0, \\\\quad \\\\eta_i \\\\geq 0, && i = 1, \\\\ldots, \\\\ell \\\\\\\\ \\\\lambda_i = 0 \\\\;\\\\text{либо}\\\\; M_i(\\\\vec{w},b) = 1 - \\\\xi_i, && i = 1, \\\\ldots, \\\\ell \\\\\\\\ \\\\eta_i = 0 \\\\;\\\\text{либо}\\\\; \\\\xi_i = 0, && i = 1, \\\\ldots, \\\\ell \\\\end{cases}$\\nПродифференцируем функцию Лагранжа и приравняем к нулю производные. Получим следующие ограничения:\\n$\\\\begin{array}{lcl} \\\\frac{\\\\partial \\\\mathscr{L}}{\\\\partial w} = \\\\vec{w} - \\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i y_i \\\\vec{x}_i = 0 & \\\\Rightarrow & \\\\vec{w} = \\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i y_i \\\\vec{x}_i \\\\\\\\ \\\\frac{\\\\partial \\\\mathscr{L}}{\\\\partial b} = -\\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i y_i = 0 & \\\\Rightarrow & \\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i y_i = 0 \\\\\\\\ \\\\frac{\\\\partial \\\\mathscr{L}}{\\\\partial \\\\xi_i} = -\\\\lambda_i - \\\\eta_i + C = 0 & \\\\Rightarrow & \\\\eta_i + \\\\lambda_i = C, \\\\quad i = 1, \\\\ldots, \\\\ell \\\\end{array}$\\nЗаметим, что $\\\\eta_i \\\\geq 0$, $\\\\lambda_i \\\\geq 0$, $C > 0$, поэтому из последнего ограничения получаем $0 \\\\leq \\\\eta_i \\\\leq C$, $0 \\\\leq \\\\lambda_i \\\\leq C$.\\nДиапазон значений $\\\\lambda_i$ (которые, как указано выше, соответствуют ограничениям на величину отступа) позволяет нам разделить объекты обучающей выборки на три типа:\\n- $\\\\lambda_i = 0 \\\\; \\\\Rightarrow \\\\; \\\\eta_i = C; \\\\; \\\\xi_i = 0; \\\\; M_i \\\\geq 1 \\\\;$ — периферийные (неинформативные) объекты\\nЭти объекты лежат в своём классе, классифицируются верно и не влияют на выбор разделяющей гиперплоскости (см. уравнение для $\\\\vec{w}$)\\n- $0 < \\\\lambda_i < C \\\\; \\\\Rightarrow \\\\; 0 < \\\\eta_i < C; \\\\; \\\\xi_i = 0; \\\\; M_i = 1 \\\\;$ — опорные граничные объекты\\nЭти объекты лежат ровно на границе разделяющей полосы на стороне своего класса\\n- $\\\\lambda_i = C \\\\; \\\\Rightarrow \\\\; \\\\eta_i = 0; \\\\; \\\\xi_i > 0; \\\\; M_i < 1 \\\\;$ — опорные объекты-нарушители\\nЭти объекты лежат внутри разделяющей полосы или на стороне чужого класса\\n|Определение:\\n|Опорный объект (опорный вектор, англ. support vector) — объект $\\\\vec{x}_i$, соответствующий которому множитель Лагранжа отличен от нуля: $\\\\lambda_i \\\\neq 0$.\\nТеперь подставим ограничения, которые мы получили при дифференцировании, в функцию Лагранжа. Получим следующую постановку двойственной задачи, которая зависит только от двойственных переменных $\\\\lambda$:\\n$\\\\begin{cases} -\\\\mathscr{L}(\\\\lambda) = -\\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i + \\\\frac{1}{2} \\\\sum\\\\limits_{i=1}^\\\\ell \\\\sum\\\\limits_{j=1}^\\\\ell \\\\lambda_i \\\\lambda_j y_i y_j \\\\langle \\\\vec{x}_i, \\\\vec{x}_j \\\\rangle \\\\to \\\\min\\\\limits_\\\\lambda \\\\\\\\ 0 \\\\leq \\\\lambda_i \\\\leq C, \\\\quad i = 1, \\\\ldots, \\\\ell \\\\\\\\ \\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i y_i = 0 \\\\end{cases}$\\nЭто также задача квадратичного программирования. Решение задачи лежит в пересечении $\\\\ell$-мерного куба с ребром $C$ и гиперплоскости $\\\\langle \\\\lambda, y \\\\rangle = 0$, что является выпуклым многогранником размерности $\\\\ell-1$. В этом многограннике нужно найти минимум выпуклого квадратичного функционала. Следовательно, данная задача имеет единственное решение.\\nСуществуют различные методы поиска решения: можно воспользоваться универсальным солвером задачи квадратичного программирования (CPLEX, Gurobi), либо алгоритмом, учитывающим специфические особенности SVM (SMO, INCAS).\\nПосле того, как мы получили вектор коэффициентов $\\\\vec{\\\\lambda}$, можем выразить решение прямой задачи через решение двойственной:\\n$\\\\begin{cases} \\\\vec{w} = \\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i y_i \\\\vec{x}_i \\\\\\\\ b = \\\\langle \\\\vec{w}, \\\\vec{x}_i \\\\rangle - y_i, \\\\quad \\\\forall i: \\\\lambda_i > 0, M_i = 1 \\\\end{cases}$\\nНа практике для повышения вычислительной устойчивости рекомендуется при расчёте $b$ брать медиану по опорным граничным объектам:\\n$b = med\\\\{ \\\\langle \\\\vec{w}, \\\\vec{x}_i \\\\rangle - y_i : \\\\lambda_i > 0, M_i = 1, i = 1, \\\\ldots, \\\\ell\\\\}$\\nТеперь можем переписать наш линейный классификатор, выразив $\\\\vec{w}$ через $\\\\vec{\\\\lambda}$:\\n$a(x) = sign \\\\left(\\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i y_i \\\\langle \\\\vec{x}_i, \\\\vec{x} \\\\rangle - b\\\\right)$\\nНелинейное обобщение, kernel trick\\nСуществует ещё один подход к решению проблемы линейной разделимости, известный как трюк с ядром (kernel trick). Если выборка объектов с признаковым описанием из $X = \\\\mathbb{R}^n$ не является линейно разделимой, мы можем предположить, что существует некоторое пространство $H$, вероятно, большей размерности, при переходе в которое выборка станет линейно разделимой. Пространство $H$ здесь называют спрямляющим, а функцию перехода $\\\\psi : X \\\\to H$ — спрямляющим отображением. Построение SVM в таком случае происходит так же, как и раньше, но в качестве векторов признаковых описаний используются векторы $\\\\psi(\\\\vec{x})$, а не $\\\\vec{x}$. Соответственно, скалярное произведение $\\\\langle \\\\vec{x}_1, \\\\vec{x}_2 \\\\rangle$ в пространстве $X$ везде заменяется скалярным произведением $\\\\langle \\\\psi(\\\\vec{x}_1), \\\\psi(\\\\vec{x}_2) \\\\rangle$ в пространстве $H$. Отсюда следует, что пространство $H$ должно быть гильбертовым, так как в нём должно быть определено скалярное произведение.\\nОбратим внимание на то, что постановка задачи и алгоритм классификации не используют в явном виде признаковое описание и оперируют только скалярными произведениями признаков объектов. Это даёт возможность заменить скалярное произведение в пространстве $X$ на ядро — функцию, являющуюся скалярным произведением в некотором $H$. При этом можно вообще не строить спрямляющее пространство в явном виде, и вместо подбора $\\\\psi$ подбирать непосредственно ядро.\\nПостановка задачи с применением ядер приобретает вид:\\n$\\\\begin{cases} -\\\\mathscr{L}(\\\\lambda) = -\\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i + \\\\frac{1}{2} \\\\sum\\\\limits_{i=1}^\\\\ell \\\\sum\\\\limits_{j=1}^\\\\ell \\\\lambda_i \\\\lambda_j y_i y_j \\\\color{brown}{K(\\\\vec{x}_i, \\\\vec{x}_j)} \\\\to \\\\min\\\\limits_\\\\lambda \\\\\\\\ 0 \\\\leq \\\\lambda_i \\\\leq C, \\\\quad i = 1, \\\\ldots, \\\\ell \\\\\\\\ \\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i y_i = 0 \\\\end{cases}$\\n$a(x) = sign \\\\left(\\\\sum\\\\limits_{i=1}^\\\\ell \\\\lambda_i y_i \\\\color{brown}{K(\\\\vec{x}_i, \\\\vec{x})} - b\\\\right)$\\nПреимущества и недостатки SVM\\nПреимущества SVM перед методом стохастического градиента и нейронными сетями:\\n- Задача выпуклого квадратичного программирования хорошо изучена и имеет единственное решение.\\n- Метод опорных векторов эквивалентен двухслойной нейронной сети, где число нейронов на скрытом слое определяется автоматически как число опорных векторов.\\n- Принцип оптимальной разделяющей гиперплоскости приводит к максимизации ширины разделяющей полосы, а следовательно, к более уверенной классификации.\\nНедостатки классического SVM:\\n- Неустойчивость к шуму: выбросы в исходных данных становятся опорными объектами-нарушителями и напрямую влияют на построение разделяющей гиперплоскости.\\n- Не описаны общие методы построения ядер и спрямляющих пространств, наиболее подходящих для конкретной задачи.\\n- Нет отбора признаков.\\n- Необходимо подбирать константу $C$ при помощи кросс-валидации.\\nМодификации\\nСуществуют различные дополнения и модификации метода опорных векторов, направленные на устранение описанных недостатков:\\n- Метод релевантных векторов (Relevance Vector Machine, RVM)\\n- 1-norm SVM (LASSO SVM)\\n- Doubly Regularized SVM (ElasticNet SVM)\\n- Support Features Machine (SFM)\\n- Relevance Features Machine (RFM)\\nПримеры кода\\nПример на языке Java\\nПример классификации с применением\\nsmile.classification.SVM[1]\\nMaven зависимость:\\n<dependency> <groupId>com.github.haifengl</groupId> <artifactId>smile-core</artifactId> <version>1.5.2</version> </dependency>\\nimport smile.classification.SVM; import smile.data.NominalAttribute; import smile.data.parser.DelimitedTextParser; import smile.math.kernel.GaussianKernel; import java.util.Arrays;\\n// read train & test dataset var parser = new DelimitedTextParser(); parser.setResponseIndex(new NominalAttribute(\"class\"), 0); var train = parser.parse(\"USPS Train\", this.getClass().getResourceAsStream(\"/smile/data/usps/zip.train\")); var test = parser.parse(\"USPS Test\", this.getClass().getResourceAsStream(\"/smile/data/usps/zip.test\")); var classes = Arrays.stream(test.labels()).max().orElse(0) + 1; // build SVM classifier var svm = new SVM<>(new GaussianKernel(8.0), 5.0, classes, SVM.Multiclass.ONE_VS_ONE); svm.learn(train.x(), train.labels()); svm.finish(); // calculate test error rate var error = 0; for (int i = 0; i < test.x().length; i++) { if (svm.predict(test.x()[i]) != test.labels()[i]) { error++; } } System.out.format(\"USPS error rate = %.2f%%\\\\n\", 100.0 * error / test.x().length);\\nПример на языке R\\n# importing package and its\\' dependencies library(caret) #reading data data <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # splitting data into train and test sets index <- createDataPartition(y = data$target, p = 0.8, list = FALSE) training <- data[index,] testing <- data[-index,] # evaluating model fit <- train(target ~ x + y + z, data = train_flats, method = \"svmRadial\", trControl = trainControl(method = \"repeatedcv\", number = 10, repeats = 3)) # printing parameters print(fit)\\nСм. также\\nПримечания\\nИсточники информации\\n- machinelearning.ru — Машина опорных векторов\\n- Лекция \"Линейные методы классификации: метод опорных векторов\" — К.В. Воронцов, курс \"Машинное обучение\" 2014\\n- Wikipedia — Метод опорных векторов\\n- Alexey Nefedov — Support Vector Machines: A Simple Tutorial\\n- John Platt — Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines\\n- Shai Fine, Katya Scheinberg — INCAS: An Incremental Active Set Method for SVM', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='2a3caa17-3fc8-45f1-b30f-c7f75480497a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1f100bab7aa0e1bdedc984bfc5783a50d5fa2f2580a6ade620b4dabad19b85e7', text='Ядра\\n|Определение:\\n|Ядро (англ. kernel) — функция $K: X \\\\times X \\\\to \\\\mathbb{R}$, которая является скалярным произведением в некотором спрямляющем пространстве: $K(\\\\vec{x}_1, \\\\vec{x}_2) = \\\\langle \\\\psi(\\\\vec{x}_1), \\\\psi(\\\\vec{x}_2) \\\\rangle$ при некотором $\\\\psi : X \\\\to H$, где $H$ — пространство со скалярным произведением.\\nСодержание\\nВыбор ядра\\nТеорема Мерсера определяет условия, при которых функция может являться ядром:\\n|Теорема (Мерсер):\\nФункция $K(\\\\vec{x}_1, \\\\vec{x}_2)$ является ядром тогда и только тогда, когда выполнены условия:\\n$\\\\begin{cases}K(\\\\vec{x}_1, \\\\vec{x}_2) = K(\\\\vec{x}_2, \\\\vec{x}_1) & \\\\text{(симметричность)} \\\\\\\\[1ex] \\\\forall g: X \\\\to \\\\mathbb{R} \\\\quad \\\\int\\\\limits_X \\\\int\\\\limits_X K(\\\\vec{x}_1, \\\\vec{x}_2) g(\\\\vec{x}_1) g(\\\\vec{x}_2) d \\\\vec{x}_1 d \\\\vec{x}_2 \\\\geq 0 & \\\\text{(неотрицательная определенность)}\\\\end{cases}$\\nПроверка неотрицательной определённости является довольно трудоёмкой, поэтому на практике теорема явно не используется. Проблема выбора лучшего ядра на сегодняшний день остаётся открытой, лучшие из известных на данный момент решений основываются на генетических алгоритмах[1]). Обычно в практических реализациях ограничиваются перебором нескольких функций, про которые известно, что они являются ядрами, и выбирают среди них лучшую при помощи кросс-валидации. Кроме того, существуют правила порождения ядер, которые также применяются для расширения пространства перебираемых функций.\\nКонструктивные методы синтеза ядер\\nВ целях достижения большей гибкости, и как следствие, более точных результатов, простые ядра могут быть объединены в более сложные функции, которые также будут являться ядром. Для этого используются следующие методы синтеза ядер:\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = \\\\langle \\\\vec{x}_1, \\\\vec{x}_2 \\\\rangle \\\\quad$ (скалярное произведение)\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = \\\\alpha \\\\quad$ (константа $\\\\alpha \\\\in \\\\mathbb{R}_+$)\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = K_1(\\\\vec{x}_1, \\\\vec{x}_2) + K_2(\\\\vec{x}_1, \\\\vec{x}_2) \\\\quad$ (сумма ядер)\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = K_1(\\\\vec{x}_1, \\\\vec{x}_2) * K_2(\\\\vec{x}_1, \\\\vec{x}_2) \\\\quad$ (произведение ядер)\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = \\\\psi(\\\\vec{x}_1) * \\\\psi(\\\\vec{x}_2) \\\\quad$ (произведение функций $\\\\psi : X \\\\to \\\\mathbb{R}$)\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = K_1(\\\\phi(\\\\vec{x}_1), \\\\phi(\\\\vec{x}_2)) \\\\quad$ (композиция ядра и функции $\\\\phi : X \\\\to X$)\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = \\\\int\\\\limits_X s(\\\\vec{x}_1, \\\\vec{z}) s(\\\\vec{x}_2, \\\\vec{z}) d \\\\vec{z} \\\\quad$ ($s : X \\\\times X \\\\to \\\\mathbb{R}$ — симметричная интегрируемая функция)\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = f(K_1(\\\\vec{x}_1, \\\\vec{x}_2)) \\\\quad$ ($f: \\\\mathbb{R} \\\\to \\\\mathbb{R}$ представима в виде сходящегося степенного ряда с неотрицательными коэффициентами)\\nСтандартные ядра\\nСуществует несколько \"стандартных\" ядер, которые соответствуют известным алгоритмам классификации:\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = (\\\\langle \\\\vec{x}_1, \\\\vec{x}_2 \\\\rangle + c)^d, \\\\quad c, d \\\\in \\\\mathbb{R}$ — полиномиальное ядро\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = \\\\sigma(\\\\langle \\\\vec{x}_1, \\\\vec{x}_2 \\\\rangle)$ — нейросеть с заданной функцией активации $\\\\sigma(z)$ (не при всех $\\\\sigma$ является ядром)\\n- $K(\\\\vec{x}_1, \\\\vec{x}_2) = \\\\exp(-\\\\beta \\\\lVert \\\\vec{x}_1 - \\\\vec{x}_2 \\\\rVert^2)$ — сеть радиальных базисных функций (англ. RBF)\\nСверточные ядра\\nСверточные ядра (англ. convolutional kernel) — матрицы небольших размеров, с помощью которых производится свертка. Используются для извлечения определенного признака, веса являются обучаемыми параметрами, например, с помощью градиентного спуска. Для разноцветных (с количеством каналов больше единицы) изображений используются фильтры, которые являются тензором ядер. Веса у таких ядер внутри тензора могут иметь разные значения. Например для пространства RGB, мы можем искать границы только в канале красного цвета и ядро будет применять оператор Собеля, а ядра для синего и зеленого каналов будут иметь вид нулевой матрицы.\\nПримеры сверточных ядер\\nСглаживающие фильтры\\nСредний фильтр (англ. mean filter) — это простой способ сглаживания и уменьшения шума в изображениях. Идея фильтра заключается в замене значения пикселя на среднюю сумму его соседей, включая сам пиксель. Обычно используется матрица размера $3 \\\\times 3$, но для получения большего размытия можно брать матрицы большей размерности:\\n$\\\\frac{1}{9}\\\\begin{bmatrix}1&1&1\\\\\\\\1&1&1\\\\\\\\1&1&1\\\\end{bmatrix}$ — средний фильтр размера $3 \\\\times 3$\\nОпределение границ\\nОператор Собеля (англ. Sobel operator) — ядро размерности $3 \\\\times 3$, которое вычисляет приближенное значение производной изображения.\\n- $G_x = \\\\begin{bmatrix}1&0&-1\\\\\\\\2&0&2\\\\\\\\1&0&-1\\\\end{bmatrix}$ — горизонтальная компонента\\n- $G_y = \\\\begin{bmatrix}1&2&1\\\\\\\\0&0&0\\\\\\\\-1&2&-1\\\\end{bmatrix}$ — вертикальная компонента\\nГоризонтальная и вертикальная компоненты могут быть скомбинированы для нахождения значения градиента в точке $G=\\\\sqrt{G^2_x + G^2_y}$\\nОпределение линий\\nОператор определения линий с помощью сверточных ядер состоит из 4 матриц $3 \\\\times 3$: горизонтальной, вертикальной, и двух наклонных ($+45^{\\\\circ}$ и $-45^{\\\\circ}$) соответственно:\\n$\\\\begin{bmatrix}-1&-1&-1\\\\\\\\2&2&2\\\\\\\\-1&-1&-1\\\\end{bmatrix}$, $\\\\begin{bmatrix}-1&2&-1\\\\\\\\-1&2&-1\\\\\\\\-1&2&-1\\\\end{bmatrix}$, $\\\\begin{bmatrix}-1&-1&2\\\\\\\\-1&2&-1\\\\\\\\2&-1&-1\\\\end{bmatrix}$, $\\\\begin{bmatrix}2&-1&-1\\\\\\\\-1&2&-1\\\\\\\\-1&-1&2\\\\end{bmatrix}$\\nСм. также\\nПримечания\\nИсточники информации\\n- machinelearning.ru — Машина опорных векторов\\n- Лекция \"Линейные методы классификации: метод опорных векторов\" — К.В. Воронцов, курс \"Машинное обучение\" 2014\\n- HIPR Sobel Edge Detector', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='e4ae736b-9cbf-48c9-8fc0-794c2a370245', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='416c7f4b7bf1c19cbad568e9811e731f90232219113408e5fb61b1a0455977d1', text='Оценка качества в задачах классификации и регрессии\\nВ машинном обучении различают оценки качества для задачи классификации и регрессии. Причем оценка задачи классификации часто значительно сложнее, чем оценка регрессии.\\nСодержание\\n- 1 Оценки качества классификации\\n- 2 Оценки качества регрессии\\n- 2.1 Средняя квадратичная ошибка (англ. Mean Squared Error, MSE)\\n- 2.2 Cредняя абсолютная ошибка (англ. Mean Absolute Error, MAE)\\n- 2.3 Коэффициент детерминации\\n- 2.4 Средняя абсолютная процентная ошибка (англ. Mean Absolute Percentage Error, MAPE)\\n- 2.5 Корень из средней квадратичной ошибки (англ. Root Mean Squared Error, RMSE)\\n- 2.6 Cимметричная MAPE (англ. Symmetric MAPE, SMAPE)\\n- 2.7 Средняя абсолютная масштабированная ошибка (англ. Mean absolute scaled error, MASE)\\n- 3 Кросс-валидация\\n- 4 Примечания\\n- 5 См. также\\n- 6 Источники информации\\nОценки качества классификации\\nМатрица ошибок (англ. Сonfusion matrix)\\nПеред переходом к самим метрикам необходимо ввести важную концепцию для описания этих метрик в терминах ошибок классификации — confusion matrix (матрица ошибок). Допустим, что у нас есть два классаи алгоритм, предсказывающий принадлежность каждого объекта одному из классов. Рассмотрим пример. Пусть банк использует систему классификации заёмщиков на кредитоспособных и некредитоспособных. При этом первым кредит выдаётся, а вторые получат отказ. Таким образом, обнаружение некредитоспособного заёмщика ( ) можно рассматривать как \"сигнал тревоги\", сообщающий о возможных рисках.\\nЛюбой реальный классификатор совершает ошибки. В нашем случае таких ошибок может быть две:\\n- Кредитоспособный заёмщик распознается моделью как некредитоспособный и ему отказывается в кредите. Данный случай можно трактовать как \"ложную тревогу\".\\n- Некредитоспособный заёмщик распознаётся как кредитоспособный и ему ошибочно выдаётся кредит. Данный случай можно рассматривать как \"пропуск цели\".\\nНесложно увидеть, что эти ошибки неравноценны по связанным с ними проблемам. В случае \"ложной тревоги\" потери банка составят только проценты по невыданному кредиту (только упущенная выгода). В случае \"пропуска цели\" можно потерять всю сумму выданного кредита. Поэтому системе важнее не допустить \"пропуск цели\", чем \"ложную тревогу\".\\nПоскольку с точки зрения логики задачи нам важнее правильно распознать некредитоспособного заёмщика с меткой, чем ошибиться в распознавании кредитоспособного, будем называть соответствующий исход классификации положительным (заёмщик некредитоспособен), а противоположный - отрицательным (заемщик кредитоспособен ). Тогда возможны следующие исходы классификации:\\n- Некредитоспособный заёмщик классифицирован как некредитоспособный, т.е. положительный класс распознан как положительный. Наблюдения, для которых это имеет место называются истинно-положительными (True Positive — TP).\\n- Кредитоспособный заёмщик классифицирован как кредитоспособный, т.е. отрицательный класс распознан как отрицательный. Наблюдения, которых это имеет место, называются истинно отрицательными (True Negative — TN).\\n- Кредитоспособный заёмщик классифицирован как некредитоспособный, т.е. имела место ошибка, в результате которой отрицательный класс был распознан как положительный. Наблюдения, для которых был получен такой исход классификации, называются ложно-положительными (False Positive — FP), а ошибка классификации называется ошибкой I рода.\\n- Некредитоспособный заёмщик распознан как кредитоспособный, т.е. имела место ошибка, в результате которой положительный класс был распознан как отрицательный. Наблюдения, для которых был получен такой исход классификации, называются ложно-отрицательными (False Negative — FN), а ошибка классификации называется ошибкой II рода.\\nТаким образом, ошибка I рода, или ложно-положительный исход классификации, имеет место, когда отрицательное наблюдение распознано моделью как положительное. Ошибкой II рода, или ложно-отрицательным исходом классификации, называют случай, когда положительное наблюдение распознано как отрицательное. Поясним это с помощью матрицы ошибок классификации:\\nИстинно-положительный (True Positive — TP) Ложно-положительный (False Positive — FP) Ложно-отрицательный (False Negative — FN) Истинно-отрицательный (True Negative — TN)\\nЗдесь— это ответ алгоритма на объекте, а — истинная метка класса на этом объекте. Таким образом, ошибки классификации бывают двух видов: False Negative (FN) и False Positive (FP). P означает что классификатор определяет класс объекта как положительный (N — отрицательный). T значит что класс предсказан правильно (соответственно F — неправильно). Каждая строка в матрице ошибок представляет спрогнозированный класс, а каждый столбец — фактический класс.\\n# код для матрицы ошибок # Пример классификатора, способного проводить различие между всего лишь двумя # классами, \"пятерка\" и \"не пятерка\" из набора рукописных цифр MNIST import numpy as np from sklearn.datasets import fetch_openml from sklearn.model_selection import cross_val_predict from sklearn.metrics import confusion_matrix from sklearn.linear_model import SGDClassifier mnist = fetch_openml(\\'mnist_784\\', version=1) X, y = mnist[\"data\"], mnist[\"target\"] y = y.astype(np.uint8) X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] y_train_5 = (y_train == 5) # True для всех пятерок, False для в сех остальных цифр. Задача опознать пятерки y_test_5 = (y_test == 5) sgd_clf = SGDClassifier(random_state=42) # классификатор на основе метода стохастического градиентного спуска (англ. Stochastic Gradient Descent SGD) sgd_clf.fit(X_train, y_train_5) # обучаем классификатор распозновать пятерки на целом обучающем наборе # Для расчета матрицы ошибок сначала понадобится иметь набор прогнозов, чтобы их можно было сравнивать с фактическими целями y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3) print(confusion_matrix(y_train_5, y_train_pred)) # array([[53892, 687], # [ 1891, 3530]])\\nБезупречный классификатор имел бы только истинно-положительные и истинно отрицательные классификации, так что его матрица ошибок содержала бы ненулевые значения только на своей главной диагонали (от левого верхнего до правого нижнего угла):\\nimport numpy as np from sklearn.datasets import fetch_openml from sklearn.metrics import confusion_matrix mnist = fetch_openml(\\'mnist_784\\', version=1) X, y = mnist[\"data\"], mnist[\"target\"] y = y.astype(np.uint8) X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] y_train_5 = (y_train == 5) # True для всех пятерок, False для в сех остальных цифр. Задача опознать пятерки y_test_5 = (y_test == 5) y_train_perfect_predictions = y_train_5 # притворись, что мы достигли совершенства print(confusion_matrix(y_train_5, y_train_perfect_predictions)) # array([[54579, 0], # [ 0, 5421]])\\nАккуратность (англ. Accuracy)\\nИнтуитивно понятной, очевидной и почти неиспользуемой метрикой является accuracy — доля правильных ответов алгоритма:\\nЭта метрика бесполезна в задачах с неравными классами, что как вариант можно исправить с помощью алгоритмов сэмплирования и это легко показать на примере.\\nДопустим, мы хотим оценить работу спам-фильтра почты. У нас есть 100 не-спам писем, 90 из которых наш классификатор определил верно (True Negative = 90, False Positive = 10), и 10 спам-писем, 5 из которых классификатор также определил верно (True Positive = 5, False Negative = 5). Тогда accuracy:\\nОднако если мы просто будем предсказывать все письма как не-спам, то получим более высокую аккуратность:\\nПри этом, наша модель совершенно не обладает никакой предсказательной силой, так как изначально мы хотели определять письма со спамом. Преодолеть это нам поможет переход с общей для всех классов метрики к отдельным показателям качества классов.\\n# код для для подсчета аккуратности: # Пример классификатора, способного проводить различие между всего лишь двумя # классами, \"пятерка\" и \"не пятерка\" из набора рукописных цифр MNIST import numpy as np from sklearn.datasets import fetch_openml from sklearn.model_selection import cross_val_predict from sklearn.metrics import accuracy_score from sklearn.linear_model import SGDClassifier mnist = fetch_openml(\\'mnist_784\\', version=1) X, y = mnist[\"data\"], mnist[\"target\"] y = y.astype(np.uint8) X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] y_train_5 = (y_train == 5) # True для всех пятерок, False для в сех остальных цифр. Задача опознать пятерки y_test_5 = (y_test == 5) sgd_clf = SGDClassifier(random_state=42) # классификатор на основе метода стохастического градиентного спуска (Stochastic Gradient Descent SGD) sgd_clf.fit(X_train, y_train_5) # обучаем классификатор распозновать пятерки на целом обучающем наборе y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3) # print(confusion_matrix(y_train_5, y_train_pred)) # array([[53892, 687] # [ 1891, 3530]]) print(accuracy_score(y_train_5, y_train_pred)) # == (53892 + 3530) / (53892 + 3530 + 1891 +687) # 0.9570333333333333\\nТочность (англ. Precision)\\nТочностью (precision) называется доля правильных ответов модели в пределах класса — это доля объектов действительно принадлежащих данному классу относительно всех объектов которые система отнесла к этому классу.\\nИменно введение precision не позволяет нам записывать все объекты в один класс, так как в этом случае мы получаем рост уровня False Positive.\\nПолнота (англ. Recall)\\nПолнота — это доля истинно положительных классификаций. Полнота показывает, какую долю объектов, реально относящихся к положительному классу, мы предсказали верно.\\nПолнота (recall) демонстрирует способность алгоритма обнаруживать данный класс вообще.\\nИмея матрицу ошибок, очень просто можно вычислить точность и полноту для каждого класса. Точность (precision) равняется отношению соответствующего диагонального элемента матрицы и суммы всей строки класса. Полнота (recall) — отношению диагонального элемента матрицы и суммы всего столбца класса. Формально:\\nРезультирующая точность классификатора рассчитывается как арифметическое среднее его точности по всем классам. То же самое с полнотой. Технически этот подход называется macro-averaging.\\n# код для для подсчета точности и полноты: # Пример классификатора, способного проводить различие между всего лишь двумя # классами, \"пятерка\" и \"не пятерка\" из набора рукописных цифр MNIST import numpy as np from sklearn.datasets import fetch_openml from sklearn.model_selection import cross_val_predict from sklearn.metrics import precision_score, recall_score from sklearn.linear_model import SGDClassifier mnist = fetch_openml(\\'mnist_784\\', version=1) X, y = mnist[\"data\"], mnist[\"target\"] y = y.astype(np.uint8) X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] y_train_5 = (y_train == 5) # True для всех пятерок, False для в сех остальных цифр. Задача опознать пятерки y_test_5 = (y_test == 5) sgd_clf = SGDClassifier(random_state=42) # классификатор на основе метода стохастического градиентного спуска (Stochastic Gradient Descent SGD) sgd_clf.fit(X_train, y_train_5) # обучаем классификатор распозновать пятерки на целом обучающем наборе y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3) # print(confusion_matrix(y_train_5, y_train_pred)) # array([[53892, 687] # [ 1891, 3530]]) print(precision_score(y_train_5, y_train_pred)) # == 3530 / (3530 + 687) print(recall_score(y_train_5, y_train_pred)) # == 3530 / (3530 + 1891) # 0.8370879772350012 # 0.6511713705958311\\nF-мера (англ. F-score)\\nPrecision и recall не зависят, в отличие от accuracy, от соотношения классов и потому применимы в условиях несбалансированных выборок. Часто в реальной практике стоит задача найти оптимальный (для заказчика) баланс между этими двумя метриками. Понятно что чем выше точность и полнота, тем лучше. Но в реальной жизни максимальная точность и полнота не достижимы одновременно и приходится искать некий баланс. Поэтому, хотелось бы иметь некую метрику которая объединяла бы в себе информацию о точности и полноте нашего алгоритма. В этом случае нам будет проще принимать решение о том какую реализацию запускать в производство (у кого больше тот и круче). Именно такой метрикой является F-мера.\\nF-мера представляет собой гармоническое среднее между точностью и полнотой. Она стремится к нулю, если точность или полнота стремится к нулю.\\nДанная формула придает одинаковый вес точности и полноте, поэтому F-мера будет падать одинаково при уменьшении и точности и полноты. Возможно рассчитать F-меру придав различный вес точности и полноте, если вы осознанно отдаете приоритет одной из этих метрик при разработке алгоритма:\\nгдепринимает значения в диапазоне если вы хотите отдать приоритет точности, а при приоритет отдается полноте. При формула сводится к предыдущей и вы получаете сбалансированную F-меру (также ее называют ).\\nF-мера достигает максимума при максимальной полноте и точности, и близка к нулю, если один из аргументов близок к нулю.\\nF-мера является хорошим кандидатом на формальную метрику оценки качества классификатора. Она сводит к одному числу две других основополагающих метрики: точность и полноту. Имея \"F-меру\" гораздо проще ответить на вопрос: \"поменялся алгоритм в лучшую сторону или нет?\"\\n# код для подсчета метрики F-mera: # Пример классификатора, способного проводить различие между всего лишь двумя # классами, \"пятерка\" и \"не пятерка\" из набора рукописных цифр MNIST import numpy as np from sklearn.datasets import fetch_openml from sklearn.model_selection import cross_val_predict from sklearn.linear_model import SGDClassifier from sklearn.metrics import f1_score mnist = fetch_openml(\\'mnist_784\\', version=1) X, y = mnist[\"data\"], mnist[\"target\"] y = y.astype(np.uint8) X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] y_train_5 = (y_train == 5) # True для всех пятерок, False для в сех остальных цифр. Задача опознать пятерки y_test_5 = (y_test == 5) sgd_clf = SGDClassifier(random_state=42) # классификатор на основе метода стохастического градиентного спуска (Stochastic Gradient Descent SGD) sgd_clf.fit(X_train, y_train_5) # обучаем классификатор распознавать пятерки на целом обучающем наборе y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3) print(f1_score(y_train_5, y_train_pred)) # 0.7325171197343846\\nROC-кривая\\nКривая рабочих характеристик (англ. Receiver Operating Characteristics curve). Используется для анализа поведения классификаторов при различных пороговых значениях. Позволяет рассмотреть все пороговые значения для данного классификатора. Показывает долю ложно положительных примеров (англ. false positive rate, FPR) в сравнении с долей истинно положительных примеров (англ. true positive rate, TPR).\\nДоля FPR — это пропорция отрицательных образцов, которые были некорректно классифицированы как положительные.\\n- ,\\nгде TNR — доля истинно отрицательных классификаций (англ. Тrие Negative Rate), представляющая собой пропорцию отрицательных образцов, которые были корректно классифицированы как отрицательные.\\nДоля TNR также называется специфичностью (англ. specificity). Следовательно, ROC-кривая изображает чувствительность (англ. seпsitivity), т.е. полноту, в сравнении с разностью 1 - specificity.\\nПрямая линия по диагонали представляет ROC-кривую чисто случайного классификатора. Хороший классификатор держится от указанной линии настолько далеко, насколько это возможно (стремясь к левому верхнему углу).\\nОдин из способов сравнения классификаторов предусматривает измерение площади под кривой (англ. Area Under the Curve — AUC). Безупречный классификатор будет иметь площадь под ROC-кривой (ROC-AUC), равную 1, тогда как чисто случайный классификатор - площадь 0.5.\\n# Код отрисовки ROC-кривой # На примере классификатора, способного проводить различие между всего лишь двумя классами # \"пятерка\" и \"не пятерка\" из набора рукописных цифр MNIST from sklearn.metrics import roc_curve import matplotlib.pyplot as plt import numpy as np from sklearn.datasets import fetch_openml from sklearn.model_selection import cross_val_predict from sklearn.linear_model import SGDClassifier mnist = fetch_openml(\\'mnist_784\\', version=1) X, y = mnist[\"data\"], mnist[\"target\"] y = y.astype(np.uint8) X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] y_train_5 = (y_train == 5) # True для всех пятерок, False для в сех остальных цифр. Задача опознать пятерки y_test_5 = (y_test == 5) sgd_clf = SGDClassifier(random_state=42) # классификатор на основе метода стохастического градиентного спуска (Stochastic Gradient Descent SGD) sgd_clf.fit(X_train, y_train_5) # обучаем классификатор распозновать пятерки на целом обучающем наборе y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3) y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\") fpr, tpr, thresholds = roc_curve(y_train_5, y_scores) def plot_roc_curve(fpr, tpr, label=None): plt.plot(fpr, tpr, linewidth=2, label=label) plt.plot([0, 1], [0, 1], \\'k--\\') # dashed diagonal plt.xlabel(\\'False Positive Rate, FPR (1 - specificity)\\') plt.ylabel(\\'True Positive Rate, TPR (Recall)\\') plt.title(\\'ROC curve\\') plt.savefig(\"ROC.png\") plot_roc_curve(fpr, tpr) plt.show()\\nPrecison-recall кривая\\nЧувствительность к соотношению классов. Рассмотрим задачу выделения математических статей из множества научных статей. Допустим, что всего имеется 1.000.100 статей, из которых лишь 100 относятся к математике. Если нам удастся построить алгоритм, идеально решающий задачу, то его TPR будет равен единице, а FPR — нулю. Рассмотрим теперь плохой алгоритм, дающий положительный ответ на 95 математических и 50.000 нематематических статьях. Такой алгоритм совершенно бесполезен, но при этом имеет TPR = 0.95 и FPR = 0.05, что крайне близко к показателям идеального алгоритма. Таким образом, если положительный класс существенно меньше по размеру, то AUC-ROC может давать неадекватную оценку качества работы алгоритма, поскольку измеряет долю неверно принятых объектов относительно общего числа отрицательных. Так, алгоритм , помещающий 100 релевантных документов на позиции с 50.001-й по 50.101-ю, будет иметь AUC-ROC 0.95.\\nPrecison-recall (PR) кривая. Избавиться от указанной проблемы с несбалансированными классами можно, перейдя от ROC-кривой к PR-кривой. Она определяется аналогично ROC-кривой, только по осям откладываются не FPR и TPR, а полнота (по оси абсцисс) и точность (по оси ординат). Критерием качества семейства алгоритмов выступает площадь под PR-кривой (англ. Area Under the Curve — AUC-PR)\\n# Код отрисовки Precison-recall кривой # На примере классификатора, способного проводить различие между всего лишь двумя классами # \"пятерка\" и \"не пятерка\" из набора рукописных цифр MNIST from sklearn.metrics import precision_recall_curve import matplotlib.pyplot as plt import numpy as np from sklearn.datasets import fetch_openml from sklearn.model_selection import cross_val_predict from sklearn.linear_model import SGDClassifier mnist = fetch_openml(\\'mnist_784\\', version=1) X, y = mnist[\"data\"], mnist[\"target\"] y = y.astype(np.uint8) X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] y_train_5 = (y_train == 5) # True для всех пятерок, False для в сех остальных цифр. Задача опознать пятерки y_test_5 = (y_test == 5) sgd_clf = SGDClassifier(random_state=42) # классификатор на основе метода стохастического градиентного спуска (Stochastic Gradient Descent SGD) sgd_clf.fit(X_train, y_train_5) # обучаем классификатор распозновать пятерки на целом обучающем наборе y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3) y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\") precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores) def plot_precision_recall_vs_threshold(precisions, recalls, thresholds): plt.plot(recalls, precisions, linewidth=2) plt.xlabel(\\'Recall\\') plt.ylabel(\\'Precision\\') plt.title(\\'Precision-Recall curve\\') plt.savefig(\"Precision_Recall_curve.png\") plot_precision_recall_vs_threshold(precisions, recalls, thresholds) plt.show()\\nОценки качества регрессии\\nНаиболее типичными мерами качества в задачах регрессии являются\\nСредняя квадратичная ошибка (англ. Mean Squared Error, MSE)\\nMSE применяется в ситуациях, когда нам надо подчеркнуть большие ошибки и выбрать модель, которая дает меньше больших ошибок прогноза. Грубые ошибки становятся заметнее за счет того, что ошибку прогноза мы возводим в квадрат. И модель, которая дает нам меньшее значение среднеквадратической ошибки, можно сказать, что что у этой модели меньше грубых ошибок.\\n- и\\nCредняя абсолютная ошибка (англ. Mean Absolute Error, MAE)\\nСреднеквадратичный функционал сильнее штрафует за большие отклонения по сравнению со среднеабсолютным, и поэтому более чувствителен к выбросам. При использовании любого из этих двух функционалов может быть полезно проанализировать, какие объекты вносят наибольший вклад в общую ошибку — не исключено, что на этих объектах была допущена ошибка при вычислении признаков или целевой величины.\\nСреднеквадратичная ошибка подходит для сравнения двух моделей или для контроля качества во время обучения, но не позволяет сделать выводов о том, на сколько хорошо данная модель решает задачу. Например, MSE = 10 является очень плохим показателем, если целевая переменная принимает значения от 0 до 1, и очень хорошим, если целевая переменная лежит в интервале (10000, 100000). В таких ситуациях вместо среднеквадратичной ошибки полезно использовать коэффициент детерминации —\\nКоэффициент детерминации\\nКоэффициент детерминации измеряет долю дисперсии, объясненную моделью, в общей дисперсии целевой переменной. Фактически, данная мера качества — это нормированная среднеквадратичная ошибка. Если она близка к единице, то модель хорошо объясняет данные, если же она близка к нулю, то прогнозы сопоставимы по качеству с константным предсказанием.\\nСредняя абсолютная процентная ошибка (англ. Mean Absolute Percentage Error, MAPE)\\nЭто коэффициент, не имеющий размерности, с очень простой интерпретацией. Его можно измерять в долях или процентах. Если у вас получилось, например, что MAPE=11.4%, то это говорит о том, что ошибка составила 11,4% от фактических значений. Основная проблема данной ошибки — нестабильность.\\nКорень из средней квадратичной ошибки (англ. Root Mean Squared Error, RMSE)\\nПримерно такая же проблема, как и в MAPE: так как каждое отклонение возводится в квадрат, любое небольшое отклонение может значительно повлиять на показатель ошибки. Стоит отметить, что существует также ошибка MSE, из которой RMSE как раз и получается путем извлечения корня.\\nCимметричная MAPE (англ. Symmetric MAPE, SMAPE)\\nСредняя абсолютная масштабированная ошибка (англ. Mean absolute scaled error, MASE)\\nMASE является очень хорошим вариантом для расчета точности, так как сама ошибка не зависит от масштабов данных и является симметричной: то есть положительные и отрицательные отклонения от факта рассматриваются в равной степени. Обратите внимание, что в MASE мы имеем дело с двумя суммами: та, что в числителе, соответствует тестовой выборке, та, что в знаменателе - обучающей. Вторая фактически представляет собой среднюю абсолютную ошибку прогноза. Она же соответствует среднему абсолютному отклонению ряда в первых разностях. Эта величина, по сути, показывает, насколько обучающая выборка предсказуема. Она может быть равна нулю только в том случае, когда все значения в обучающей выборке равны друг другу, что соответствует отсутствию каких-либо изменений в ряде данных, ситуации на практике почти невозможной. Кроме того, если ряд имеет тенденцию к росту либо снижению, его первые разности будут колебаться около некоторого фиксированного уровня. В результате этого по разным рядам с разной структурой, знаменатели будут более-менее сопоставимыми. Всё это, конечно же, является очевидными плюсами MASE, так как позволяет складывать разные значения по разным рядам и получать несмещённые оценки.\\nНедостаток MASE в том, что её тяжело интерпретировать. Например, MASE=1.21 ни о чём, по сути, не говорит. Это просто означает, что ошибка прогноза оказалась в 1.21 раза выше среднего абсолютного отклонения ряда в первых разностях, и ничего более.\\nКросс-валидация\\nХороший способ оценки модели предусматривает применение кросс-валидации (cкользящего контроля или перекрестной проверки).\\nВ этом случае фиксируется некоторое множество разбиений исходной выборки на две подвыборки: обучающую и контрольную. Для каждого разбиения выполняется настройка алгоритма по обучающей подвыборке, затем оценивается его средняя ошибка на объектах контрольной подвыборки. Оценкой скользящего контроля называется средняя по всем разбиениям величина ошибки на контрольных подвыборках.\\nПримечания\\n- [1] Лекция \"Оценивание качества\" на www.coursera.org\\n- [2] Лекция на www.stepik.org о кросвалидации\\n- [3] Лекция на www.stepik.org о метриках качества, Precison и Recall\\n- [4] Лекция на www.stepik.org о метриках качества, F-мера\\n- [5] Лекция на www.stepik.org о метриках качества, примеры\\nСм. также\\nИсточники информации\\n- [6] Соколов Е.А. Лекция линейная регрессия\\n- [7] - Дьяконов А. Функции ошибки / функционалы качества\\n- [8] - Оценка качества прогнозных моделей\\n- [9] - HeinzBr Ошибка прогнозирования: виды, формулы, примеры\\n- [10] - egor_labintcev Метрики в задачах машинного обучения\\n- [11] - grossu Методы оценки качества прогноза\\n- [12] - К.В.Воронцов, Классификация\\n- [13] - К.В.Воронцов, Скользящий контроль', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='0694f78d-2117-4249-9df9-c16d34457083', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b69e2a93d46e851e45fa0942b43c3dae5c5e747314d4d8711308ee29cb1e3b32', text='Байесовская классификация\\nСодержание\\nВероятностная постановка задачи классификации\\nПусть $X$ множество объектов, $Y$ конечное множество имён классов, множество $X \\\\times Y$ является вероятностным пространством с плотностью распределения $p(x,y)=P(y)p(x|y)$. Вероятности появления объектов каждого из классов $P_y=P(y)$ называются априорными вероятностями классов. Плотности распределения $p_y(x)=p(x|y)$ называются функциями правдоподобия классов.\\nВероятностная постановка задачи классификации разделяется на две независимые подзадачи:\\n- Имеется простая выборка $X^l=(x_i, y_i)^l_{i=1}$ из неизвестного распределения $p(x,y)=P_yp_y(x)$. Требуется построить эмпирические оценки априорных вероятностей $P\\'_y$ и функций правдоподобия $p\\'_y(x)$ для каждого из классов $y \\\\in Y$.\\n- По известным плотностям распределения $p_y(x)$ и априорным вероятностям $P_y$ всех классов $y \\\\in Y$ построить алгоритм $a(x)$, минимизирующий вероятность ошибочной классификации.\\nАприорные вероятности классов $P_y$ можно оценить согласно закону больших чисел, тогда частота появления объектов каждого из классов равна $P\\'_y=\\\\frac{l_y}{l}$ где $l_y=|X^l_y|, y \\\\in Y$ сходится по вероятности к $P_y$ при $l_y \\\\to \\\\infty$. Чем больше длина выборки, тем точнее выборочная оценка $P\\'_y$.\\nОптимальный байесовский классификатор\\nРассмотрим произвольный алгоритм $a:X \\\\to Y$. Он разбивает множество $X$ на не пересекающиеся области $A_y=\\\\{x \\\\in X | a(x) = y\\\\}, y \\\\in Y$. Вероятность того,что появится объект класса $y$ и алгоритм $a$ отнесёт его к классу $s$, равна $P_yP(A_s|y)$. Каждой паре $(y,s) \\\\in Y \\\\times Y$ поставим в соответствие величину потери $\\\\lambda_{ys}$ при отнесении объекта класса $y$ к классу $s$.\\n|Определение:\\n|Функционал среднего риска — ожидаемая величина потери при классификации объектов алгоритмом $a$:\\n|Теорема (об оптимальности байесовского классификатора):\\nЕсли известны априорные вероятности $P_y$ и функции правдоподобия $p_y(x)$,\\nто минимум среднего риска $R(a)$ достигается алгоритмом\\n|Доказательство:\\n|\\nДля произвольного $t \\\\in Y$ запишем функционал среднего риска:\\nПрименив формулу полной вероятности, $P(A_t \\\\mid y) = 1 −\\\\displaystyle\\\\sum_{ s \\\\in Y \\\\setminus \\\\{t\\\\} }P(A_s \\\\mid y)$, получим:\\nВведём для сокращения записи обозначение $g_s(x) = \\\\displaystyle\\\\sum_{y \\\\in Y}\\\\lambda_{ys}P_yp_y(x)$, тогда $R(a) = const(a) + \\\\displaystyle\\\\sum_{ s \\\\in Y \\\\setminus \\\\{t\\\\} }\\\\int_{A_s}(g_s(x)−g_t(x))dx$.\\nМинимум интеграла достигается, когда $A_s$ совпадает с областью неположительности подынтегрального выражения.\\nС другой стороны, $A_s=\\\\{x \\\\in X \\\\mid a(x) = s\\\\}$. Значит, $a(x) = s$ тогда и только тогда, когда\\nНаивный байесовский классификатор\\nДопустим, что объекты $x \\\\in X$ описываются $n$ числовыми признаками $f_j:X→R,j= 1,...,n$. Обозначим через $x = (\\\\xi_1,...,\\\\xi_n)$ произвольный элемент пространства объектов $X=R^n$, где $\\\\xi_j=f_j(x)$.\\nПредположим, что признаки $f_1(x),...,f_n(x)$ являются независимыми случайными величинами. Следовательно, функции правдоподобия классов представимы в виде:\\nгде $p_{yj}(\\\\xi_j)$ плотность распределения значений $j$-го признака для класса $y$. Алгоритмы классификации исходящие из этого предположения, называются наивными байесовскими.\\nПодставим эмпирические оценки одномерных плотностей в байесовский классификатор. Получим алгоритм:\\nОсновные его преимущества — простота реализации и низкие вычислительные затраты при обучении и классификации. В тех редких случаях, когда признаки почти независимы, наивный байесовский классификатор близок к оптимальному. Достаточно малое количество данных необходимо для обучения, оценки параметров и классификации.\\nОсновной его недостаток — низкое качество классификации в общем случае.\\nПрименение\\nИз-за своего низкого качества классификации наивный байесовскими классификатор в основном он используется либо как эталон при экспериментальном сравнении алгоритмов, либо как элементарный строительный блок в алгоритмических композициях.\\nРассмотрим частое применение байесовского классификатора к задаче классификации документов по их содержимому, а именно к классификации электронных писем на два класса — спам ($S$) и не-спам ($\\\\displaystyle \\\\neg S$), предполагая что вероятность слов в тексте не зависит друг от друга:\\nПрограммные спам-фильтры, построенные на принципах наивного байесовского классификатора, делают «наивное» предположение о том, что события, соответствующие наличию того или иного слова в электронном письме или сообщении, являются независимыми по отношению друг к другу. Это упрощение в общем случае является неверным для естественных языков:\\nИсходя из такого предположения, для решения задачи классификации сообщений лишь на 2 класса: $S$ (спам) и $H = \\\\neg S$ («хэм», то есть не спам) из теоремы Байеса можно вывести следующую формулу оценки вероятности «спамовости» всего сообщения $D$, содержащего слова $W_1, W_2, ... W_N$:\\n- [так как $W_i$ предполагаются независимыми]\\nРезультат $p$ обычно сравнивают с некоторым порогом (например, $0.5$), чтобы решить, является ли сообщение спамом или нет. Если $p$ ниже, чем порог, сообщение рассматривают как вероятный «ham», иначе его рассматривают как вероятный спам.\\n- .\\nПримеры кода\\nПример кода scikit-learn\\nКлассификатор GaussianNB реализует наивный байесовский классификатор в предположении что изначальное распределение было гауссовым:\\nfrom sklearn import datasets from sklearn.metrics import f1_score, accuracy_score from sklearn.naive_bayes import GaussianNB iris = datasets.load_iris() gnb = GaussianNB() pred = gnb.fit(iris.data, iris.target).predict(iris.data) accuracy = accuracy_score(iris.target, pred) f1 = f1_score(iris.target, pred, average=\"micro\") print(\"accruracy:\", accuracy, \"f1:\", f1)\\nВывод:\\naccruracy: 0.96 f1: 0.96\\nПример на языке Java\\nПример классификации с применением\\nweka.classifiers.bayes.NaiveBayes[1]\\nMaven зависимость:\\n<dependency> <groupId>nz.ac.waikato.cms.weka</groupId> <artifactId>weka-stable</artifactId> <version>3.8.0</version> </dependency>\\nimport weka.classifiers.bayes.NaiveBayes; import weka.classifiers.evaluation.Evaluation; import weka.core.converters.ConverterUtils; import java.util.Random;\\n// load dataset var source = new DataSource(\"/iris.arff\"); var dataset = source.getDataSet(); // set class index to the last attribute dataset.setClassIndex(dataset.numAttributes() - 1); // create and build the classifier var nb = new NaiveBayes(); nb.buildClassifier(dataset); // cross validate model var eval = new Evaluation(dataset); eval.crossValidateModel(nb, dataset, 10, new Random(41)); System.out.println(\"Estimated Accuracy: \"+ Double.toString(eval.pctCorrect()));\\nПример на языке R\\n# importing package and it\\'s dependencies library(e1071) # reading data data <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # splitting data into training and test data sets index <- createDataPartition(y = data$target, p = 0.8, list = FALSE) training <- data[index,] testing <- data[-index,] # create objects x and y for predictor and response variables x <- training[, -9] y <- training$target # training model model <- train(x, y, \\'nb\\', trControl = trainControl(method = \\'cv\\', number = 10)) # predicting results predictions <- predict(model, newdata = testing)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='429119de-7965-40ac-86d2-c008160a0b88', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8b27794ad874e514184e4dd17e1af75cbbf70e48102739b5f0176cd457e1f955', text='Байесовские сети\\n|Определение:\\n|Байесовская сеть (англ. Bayesian network) — это направленный ациклический граф, в котором каждой вершине поставлена в соответствие случайная величина и каждое ребро представляет прямую зависимость от . Пусть , тогда в Байесовской сети каждой вершине графа должно быть сопоставлено распределение условных вероятностей от вершин из .\\nЦепное правило для Байесовских сетей: Цепное правило позволяет разложить (факторизовать) совместное распределение в произведение условных распределений.\\nСодержание\\nПример\\nБайесовская сеть, представленная на рисунке 1, отображает следующие зависимости. Оценка студента зависит от его интеллекта и сложности курса. Студент просит у преподавателя рекомендацию, предположим, что преподаватель может написать плохую или хорошую рекомендацию в зависимости от оценки студента. Также студент сдаёт госэкзамен, результаты экзамена не зависят от рекомендации преподавателя, оценки за его курс и сложности курса. Представление этой модели в Байесовской сети представлено на рисунке ниже.\\nС помощью цепного правила рассчитаем вероятность того, что умный студент получает B по лёгкому курсу, высокий балл за госэкзамен и плохую рекомендацию:\\nБайесовская сеть представляет корректное вероятностное распределение:\\n- Вероятность исхода в Байесовской сети неотрицательна, так как вычисляется как произведение условных вероятностей событий, которые неотрицательны.\\n- Сумма вероятностей исходов в Байесовской сети равна единице:\\nВиды вероятностного вывода (англ. Reasoning Patterns)\\nПрямой вывод, или прогнозирование (англ. Causal Reasoning)\\nПрямой вывод — определение вероятности события при наблюдаемых причинах.\\nПример к рисунку 1: вероятность получения хорошей рекомендации, если известно, что студент обладает низким интеллектом,, если известно, что курс был лёгким, вероятность повысится, .\\nОбратный вывод, или диагностирование (англ. Evidential Reasoning)\\nОбратный вывод — определение вероятности причины при наблюдаемых следствиях.\\nПример к рисунку 1: вероятность того, что курс сложный, если студент получил оценку С,, вероятность того, что студент умный, если он получил оценку С, .\\nМежпричинный (смешанный) вывод (англ. Intercausal Reasoning)\\nМежпричинный вывод — определение вероятности одной из причин наступившего события при условии наступления одной или нескольких других причин этого события.\\nРассмотрим вероятность из прошлого примера,, вероятность того, что студент умный, слегка увеличивается, если также известно, что курс сложный, , сложность курса (D) и интеллект студента (I) не связаны ребром, рассмотрим, как получается, что они влияют друг на друга, на более простом примере.\\nПредположим, у пациента температура, это сильно повышает вероятность как простуды, так и отравления, хотя они не влияют друг на друга, но если станет известно, что пациент отравился, вероятность простуды сильно уменьшится, симптом уже объяснён одной из возможных причин, и вторая становится менее вероятной. Таким образом, если общее следствие получает означивание, причины становятся зависимыми. По-английски этот феномен называется «explaining away».\\nПропагация вывода (англ. Flow of Probabilistic Influence)\\nОбобщим наблюдения из прошлой секции.\\nСвидетельства — утверждения вида «событие в узле x произошло».\\nвлияет на , когда свидетельство может изменить распределение вероятностей .\\nРассмотрим случаи, когдавлияет на при имеющихся свидетельствах :\\n- : всегда влияет на .\\n- : всегда влияет на .\\n- : влияет на , если не принадлежит .\\n- : влияет на , если не принадлежит .\\n- : влияет на , если не принадлежит .\\n- ( -образная структура): влияет на , если или кто-либо из потомков принадлежит , и, соответственно, не влияет на , если или хотя бы кто-либо из потомков не принадлежит .\\n|Определение:\\n|Активные пути (англ. Active Trails) — путь активен при свидетельствах , если:\\nУсловная независимость\\n|Определение:\\n|Маргинальная вероятность — это безусловная вероятностьсобытия ; то есть, вероятность события , независимо от того, наступает ли какое-то другое событие или нет.\\nЕсли о можно думать как о некоторой случайной величине, принявшей данное значение, маргинальная вероятность может быть получена суммированием (или более широко интегрированием) совместных вероятностей по всем значениям этой случайной величины. Эту процедуру иногда называют маргинализацией вероятности. На рисунке 1 вероятность того, что студент умный ( ), является маргинальной, так как у вершины нет родителей, с помощью маргинализации эту же вероятность можно получить, сложив вероятности того, что студент умный и он получит высокий балл за госэкзамен, и того, что студент умный и получит низкий балл за госэкзамен.\\n|Определение:\\n|и являются -разделёнными (англ. -separated), если в графе при означивании не существует активного пути между и . Обозначение: .\\n|Определение:\\n|факторизуется над , если\\nЗнак следует читать как \"удовлетворяет\", — \"пропорционально\".\\n|Определение:\\n|— в вероятностном пространстве переменная не зависима от переменной при условии означивания переменной .\\n|Утверждение:\\n, если , где — факторы.\\n|Теорема:\\nЕслифакторизуется над и , то .\\nПроверим утверждение теоремы:\\n,\\n— цепное правило, факторизуется над ,\\nЗначит,.\\n|Утверждение:\\nЕслифакторизуется над , то в каждая переменная -отделена (независима) от вершин, не являющихся её потомками, при означивании родителей.\\nРассмотрим пример на рисунке 2: вершина-отделена от всех вершин, не являющихся её потомками: в вершину можно попасть из вершин или , все пути к ней от вершин, не являющихся её потомками, проходящие через , неактивны, так как получила означивание, а пути, проходящие через , также не являются активными, так как не получила означивания и образует -образную структуру с и и и .\\n|Определение:\\n|, если , является картой независимостей (англ. Independency map (I-map)) для . — множество независимостей.\\n|Теорема:\\nЕслифакторизуется над , то является картой независимостей для .\\n|Теорема:\\nЕслиявляется картой независимостей для , то факторизуется над .\\n|Доказательство:\\n|\\nЗначит — цепное правило для вероятностей, воспользуемся тем, что переменные независимы от вершин, не являющихся их потомками, при означивании родителей, получим: — цепное правило для байесовской сети. факторизуется над .\\nПрименение\\nБайесовские сети используются в медицине, классификации документов, обработке изображений, обработке данных, системах поддержки принятия решений, моделирования в биоинформатике, для анализа текстов и сегментации.\\nПримечания\\n- https://www.coursera.org/lecture/probabilistic-graphical-models/semantics-factorization-trtai\\n- https://www.coursera.org/lecture/probabilistic-graphical-models/reasoning-patterns-KMjHs\\n- https://www.coursera.org/lecture/probabilistic-graphical-models/flow-of-probabilistic-influence-1eCp1\\n- https://www.coursera.org/lecture/probabilistic-graphical-models/conditional-independence-PTXfn\\n- https://www.coursera.org/lecture/probabilistic-graphical-models/independencies-in-bayesian-networks-JRkCU\\nСм. также\\nИсточники информации\\n- Andrew D. Gordon, Thomas A. Henzinger, Aditya V. Nori, and Sriram K. Rajamani. 2014. Probabilistic programming. In Proceedings of the on Future of Software Engineering (FOSE 2014). ACM, New York, NY, USA, 167-181. DOI=10.1145/2593882.2593900 doi.acm.org/10.1145/2593882.2593900', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='f3dbce53-4e19-4c6c-b389-8f505fb1db10', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ee3927261b8dbc3efcac59c37ff576d2c194fbeab23f4d70e71b68472fff35e0', text=\"Поиск ближайших соседей с помощью иерархического маленького мира\\nИерархический маленький мир (англ. Hierarchical Navigable Small World) — структура данных, позволяющая эффективно искать классификации и кластеризации.почти что ближайших соседей на больших множествах вершин. Поиск ближайших соседей нужен в задачах\\nПо своей концепции напоминает список с пропусками.\\nСодержание\\nПрименение\\nПредставим себе ситуацию:\\n- У социальной сети есть пользовательских фотографий с отмеченными лицами на них.\\n- По новой фотографии требуется быстро узнать кто на ней и предложить пользователю отметить этого человека.\\nВозможный процесс:\\n- Обучаем FaceNet выдавать -мерные вектора по изображению лица, такие, что у фотографий одного человека похожие значения векторов.\\n- Добавляем векторов в иерархический маленький мир.\\n- При добавлении новой фотографии, вычисляем соответствующий лицу вектор.\\n- Ищем его ближайших соседей.\\n- Классифицируем лицо с использованием ядер сглаживания.\\n- Если пользователь подтвердил нашу догадку, добавляем этот вектор в иерархический маленький мир.\\nМаленький мир\\nМаленький мир (англ. Small World) — граф, в котором мат. ожидание кратчайшего пути между двумя случайно выбранными вершинами растёт пропорционально. Но при этом средняя степень вершины мала.\\nДля маленького мира на точках в Евклидовом пространстве жадный поискближайших соседей будет выглядеть так:\\nknn(V, E, request, m, k): W =// Ближайшие к q вершины. C = // Вершины, которые предстоит посетить. V = // Посещённые вершины. for i = 1 to m C = С v G TN = // Ближайшие вершины в этом проходе. while true u = {q1 | q2 C, |q - q1| <= |q - q2|} // Ближайшая к q вершина из C. C = C u if u дальше чем k-й элемент W break for e: (u, e) in G if e V C = C e V = V e TN = TN e W = W TN return k ближайших к q вершин из W\\nРасстояние между вершинами графа может измеряться различными метриками.\\nОчевидный недостаток этого алгоритма — опасность свалиться в локальный минимум, остановившись в каком-то кластере. С увеличением числа , вероятность такого застревания экспоненциально падает.\\nОписание структуры\\nИерархический Маленький мир — слоистая структура графов. На нулевом слое представлены всевершин из исходной выборки. Вершина, присутствующая на уровне так же присутствует на уровне с вероятностью . Т.е. кол-во слоёв растет как . Количество соседей каждой вершины на каждом уровне ограниченно константой, что позволяет делать запросы на добавление и удаление вершины за .\\nОперации над структурой\\nПоиск ближайших соседей в слое\\nЖадно идём по уровню в сторону запроса.\\nsearchLayer(q, ep, ef, layer): // Входные данные: иерархия графов hnsw, запрос q, входные точки ep, искомое количество ближайших соседей ef, номер слоя layer. // Возвращает: ef ближайших соседей q в слое layer. W = {ep} // Ближайшие к q вершины. C = {ep} // Вершины, которые предстоит посетить. V = {ep} // Посещённые вершины. while C !=u = {q1 | q2 C, |q - q1| <= |q - q2|} // Ближайшая к q вершина из C. f = {q1 | q2 W, |q - q1| >= |q - q2|} // Самая дальняя от q вершина из W. if |u - q| > |f - q| break // Мы в локальном минимуме. for e : (u, e) in G if e V V = V e f = {q1 | q2 W, |q - q1| >= |q - q2|} // Самая дальняя от q вершина из W. if |e - q| < |f - q| or |W| < ef C = C e W = W e if |W| > ef W = W \\\\ f return W\\nПоиск ближайших соседей во всей структуре\\n- Идём с верхнего уровня до первого:\\n- Жадно ищем ближайшую к вершину на текущем уровне.\\n- Спускаемся в соответствующую соседу вершине на уровень ниже.\\n- На нулевом уровне жадно ищем ближайших соседей.\\nknn(hnsw, q, k, ef): // Входные данные: иерархия графов hnsw, запрос q, искомое количество ближайших соседей k, количество кандидатов при поиске ef. // Возвращает: k ближайших соседей q. W =// Ближайшие к q вершины. mL = |hnsw| - 1 ep = v hnsw[mL] for level = mL to 1 W = searchLayer(hnsw, q, ep, ef=1, level) // На каждом уровне, кроме нижнего мы ищем всего одну ближайшую вершину. ep = W W = searchLayer(hnsw, q, ep, ef, lc=0) return k ближайших к q вершин из W\\nВставка элемента\\n- Случайным образом выбираем максимальный слой, на котором будет представлена .\\n- На каждом уровне, где будет представлена\\n, сверху вниз:\\n- Жадно ищем ближайших к вершин.\\n- Добавляем связи с ними.\\n- Удаляем лишние связи у новообразовавшихся соседей.\\ninsert(hnsw, q, m, mMax, ef, mL): // Входные данные: иерархия графов hnsw, запрос на добавление q, желаемое количество связей m, максимальное количество связей вершины // на одном слое mMax, количество кандидатов при поиске ef, коэффициент выбора высоты mL. // Возвращает: hnsw с вставленным элементом q. W =// Ближайшие к q вершины. mL = |hnsw| - 1 ep = v hnsw[mL] qL = -ln(rand(eps, 1.0)) * mL // Верхний слой для вершины q. for level = mL to qL + 1 W = searchLayer(q, ep, ef=1, level) ep = W for level = min(mL, qL) to 0 W = searchLayer(q, ep, ef, level) neighbours = M ближайших к q вершин из W for n neighbours: // Добавляем двусторонние связи между n и q. hnsw[level] = hnsw[level] (n, q) hnsw[level] = hnsw[level] (q, n) nNeighbours = {v| (v, n) in hnsw[level]} // Ищем всех соседей n на уровне level. // Убираем лишние связи, если требуется. if nNeighbours.Count() > mMax // Самая дальняя от n вершина, смежняя с ней. v = {q1 | (q2, n) nNeighbours & q2 hnsw[level], |q - q1| >= |q - q2|} hnsw[level] = hnsw[level] (n, v) hnsw[level] = hnsw[level] (v, n) ep = W if qL > mL for level = mL to qL hnsw.append({q, {}})\\nПрактическое использование\\nВ библиотеке Hnswlib есть реализация иерархического маленького мира. Эта библиотека написана на C++, с биндингами на python. Пример использования:\\nimport hnswlib import numpy as np dim = 128 num_elements = 10000 # Создаём тестовые данные. data = np.float32(np.random.random((num_elements, dim))) data_labels = np.arange(num_elements) # Создаём иерархический маленький мир в L2. # Возможные метрики — l2, cosine, ip (L2, косинус угла между векторами, скалярное произведение). p = hnswlib.Index(space = 'l2', dim = dim) # Инициализируем структуру. p.init_index(max_elements = num_elements, ef_construction = 200, M = 16) # Добавляем данные (можно вызывать много раз). p.add_items(data, data_labels) # Настраиваем качество, выставляя ef: p.set_ef(50) # ef должно быть > k # Делаем запрос. # k - количество ближайших вершин labels, distances = p.knn_query(data, k = 1)\\nСм. также\\nИсточники информации\\n- Yu. A. Malkov, D. A. Yashunin — Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs\\n- Википедия — Мир тесен (граф)\\n- Wikipedia — Small-world network\\n- Поиск знаменитостей на фотографии с помощью иерархического маленького мира\\n- Статья от Mail.ru об использовании иерархического маленького мира\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='2cfcfe36-40be-4b0d-9912-911c95246b13', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a4819d4711592247840da94a316f756a1e4886aafe34faf54851a56f1354c88b', text='Кластеризация\\nКластеризация (англ. cluster analysis) — задача группировки множества объектов на подмножества (кластеры) таким образом, чтобы объекты из одного кластера были более похожи друг на друга, чем на объекты из других кластеров по какому-либо критерию.\\nЗадача кластеризации относится к классу задач обучения без учителя.\\nСодержание\\n- 1 Постановка задачи кластеризации\\n- 2 Теорема невозможности Клейнберга\\n- 3 Типология задач кластеризации\\n- 4 Меры качества кластеризации\\n- 5 Применение\\n- 6 Псевдокод некоторых алгоритмов кластеризации\\n- 7 Пример кода\\n- 8 См. также\\n- 9 Примечания\\n- 10 Источники информации\\nПостановка задачи кластеризации\\nПусть— множество объектов, — множество идентификаторов (меток) кластеров. На множестве задана функция расстояния между объектами . Дана конечная обучающая выборка объектов . Необходимо разбить выборку на подмножества (кластеры), то есть каждому объекту сопоставить метку , таким образом чтобы объекты внутри каждого кластера были близки относительно метрики , а объекты из разных кластеров значительно различались.\\n|Определение:\\n|Алгоритм кластеризации — функция, которая любому объекту ставит в соответствие идентификатор кластера .\\nМножествов некоторых случаях известно заранее, однако чаще ставится задача определить оптимальное число кластеров, с точки зрения того или иного критерия качества кластеризации.\\nКластеризация (обучение без учителя) отличается от классификации (обучения с учителем) тем, что метки объектов из обучающей выборкиизначально не заданы, и даже может быть неизвестно само множество .\\nРешение задачи кластеризации объективно неоднозначно по ряду причин:\\n- Не существует однозначного критерия качества кластеризации. Известен ряд алгоритмов, осуществляющих разумную кластеризацию \"по построению\", однако все они могут давать разные результаты. Следовательно, для определения качества кластеризации и оценки выделенных кластеров необходим эксперт предметной области;\\n- Число кластеров, как правило, заранее не известно и выбирается по субъективным критериям. Даже если алгоритм не требует изначального знания о числе классов, конкретные реализации зачастую требуют указать этот параметр[1];\\n- Результат кластеризации существенно зависит от метрики. Однако существует ряд рекомендаций по выбору метрик для определенных классов задач.[2].\\nЧисло кластеров фактически является гиперпараметром для алгоритмов кластеризации. Подробнее про другие гиперпараметры и их настройку можно прочитать в статье[3].\\nТеорема невозможности Клейнберга\\nДля формализации алгоритмов кластеризации была использована аксиоматическая теория. Клейнберг постулировал три простых свойства в качестве аксиом кластеризации и доказал теорему, связывающую эти свойства.\\n|Определение:\\n|Алгоритм кластеризацииявляется масштабно инвариантным (англ. scale-invariant), если для любой функции расстояния и любой константы результаты кластеризации с использованием расстояний и совпадают.\\nПервая аксиома интуитивно понятна. Она требует, чтобы функция кластеризации не зависела от системы счисления функции расстояния и была нечувствительна к линейному растяжению и сжатию метрического пространства обучающей выборки.\\n|Определение:\\n|Полнота (англ. Richness). Множество результатов кластеризации алгоритмав зависимости от изменения функции расстояния должно совпадать со множеством всех возможных разбиений множества объектов .\\nВторая аксиома утверждает, что алгоритм кластеризации должен уметь кластеризовать обучающую выборку на любое фиксированное разбиение для какой-то функции расстояния.\\n|Определение:\\n|Функция расстояния является допустимым преобразованием функции расстояния , если\\n|Определение:\\n|Алгоритм кластеризации является согласованным (англ. consistent), если результат кластеризации не изменяется после допустимого преобразования функции расстояния.\\nТретья аксиома требует сохранения кластеров при уменьшении внутрикластерного расстояния и увеличении межкластерного расстояния.\\nИсходя из этих аксиом Клейнберг сформулировал и доказал теорему:\\n|Теорема (Клейнберга, о невозможности):\\nДля множества объектов, состоящего из двух и более элементов, не существует алгоритма кластеризации, который был бы одновременно масштабно-инвариантным, согласованным и полным.\\nНесмотря на эту теорему Клейнберг показал[4], что иерархическая кластеризация по методу одиночной связи с различными критериями останова удовлетворяет любым двум из трех аксиом.\\nТипология задач кластеризации\\nТипы входных данных\\n- Признаковое описание объектов. Каждый объект описывается набором своих характеристик, называемых признаками (англ. features). Признаки могут быть как числовыми, так и категориальными;\\n- Матрица расстояний между объектами. Каждый объект описывается расстоянием до всех объектов из обучающей выборки.\\nВычисление матрицы расстояний по признаковому описанию объектов может быть выполнено бесконечным числом способов в зависимости от определения метрики между объектами. Выбор метрики зависит от обучающей выборки и поставленной задачи.\\nЦели кластеризации\\n- Классификация объектов. Попытка понять зависимости между объектами путем выявления их кластерной структуры. Разбиение выборки на группы схожих объектов упрощает дальнейшую обработку данных и принятие решений, позволяет применить к каждому кластеру свой метод анализа (стратегия «разделяй и властвуй»). В данном случае стремятся уменьшить число кластеров для выявления наиболее общих закономерностей;\\n- Сжатие данных. Можно сократить размер исходной выборки, взяв один или несколько наиболее типичных представителей каждого кластера. Здесь важно наиболее точно очертить границы каждого кластера, их количество не является важным критерием;\\n- Обнаружение новизны (обнаружение шума). Выделение объектов, которые не подходят по критериям ни в один кластер. Обнаруженные объекты в дальнейшем обрабатывают отдельно.\\nМетоды кластеризации\\n- Графовые алгоритмы кластеризации. Наиболее примитивный класс алгоритмов. В настоящее время практически не применяется на практике;\\n- Вероятностные алгоритмы кластеризации. Каждый объект из обучающей выборки относится к каждому из кластеров с определенной степенью вероятности:\\n- Иерархические алгоритмы кластеризации. Упорядочивание данных путем создания иерархии вложенных кластеров;\\n- Алгоритм [на 28.01.19 не создан] (англ. -средних -means). Итеративный алгоритм, основанный на минимизации суммарного квадратичного отклонения точек кластеров от центров этих кластеров;\\n- Распространение похожести (англ. affinity propagation). Распространяет сообщения о похожести между парами объектов для выбора типичных представителей каждого кластера;\\n- Сдвиг среднего значения (англ. mean shift). Выбирает центроиды кластеров в областях с наибольшей плотностью;\\n- Спектральная кластеризация (англ. spectral clustering). Использует собственные значения матрицы расстояний для понижения размерности перед использованием других методов кластеризации;\\n- Основанная на плотности пространственная кластеризация для приложений с шумами (англ. Density-based spatial clustering of applications with noise, DBSCAN). Алгоритм группирует в один кластер точки в области с высокой плотностью. Одиноко расположенные точки помечает как шум.\\nМеры качества кластеризации\\nДля оценки качества кластеризации задачу можно переформулировать в терминах задачи дискретной оптимизации. Необходимо так сопоставить объектам из множестваметки кластеров, чтобы значение выбранного функционала качества приняло наилучшее значение. В качестве примера, стремятся достичь минимума среднего внутрикластерного расстояния или максимума среднего межкластерного расстояния .\\nПодробнее про меры качества можно прочитать в статье оценка качества в задаче кластеризации.\\nПрименение\\nБиология и биоинформатика\\n- В области экологии кластеризация используется для выделения пространственных и временных сообществ организмов в однородных условиях;\\n- Кластерный анализ используется для группировки схожих геномных последовательностей в семейство генов, которые являются консервативными структурами для многих организмов и могут выполнять схожие функции;\\n- Кластеризация помогает автоматически определять генотипы по различным частям хромосом;\\n- Алгоритмы применяются для выделения небольшого числа групп генетических вариации человеческого генома.\\nМедицина\\n- Используется в позитронно-эмиссионной томографии для автоматического выделения различных типов тканей на трехмерном изображении;\\n- Применяется для выявления шаблонов устойчивости к антибиотикам; для классификации антибиотиков по типу антибактериальной активности.\\nМаркетинг\\nКластеризация широко используется при изучении рынка для обработки данных, полученных из различных опросов. Может применяться для выделения типичных групп покупателей, разделения рынка для создания персонализированных предложений, разработки новых линий продукции.\\nИнтернет\\n- Выделение групп людей на основе графа связей в социальных сетях;\\n- Повышение релевантности ответов на поисковые запросы путем группировки веб-сайтов по смысловым значениям поискового запроса.\\nКомпьютерные науки\\n- Кластеризация используется в сегментации изображений для определения границ и распознавания объектов;\\n- Кластерный анализ применяется для определения образовавшихся популяционных ниш в ходе работы эволюционных алгоритмов для улучшения параметров эволюции;\\n- Подбор рекомендаций для пользователя на основе предпочтений других пользователей в данном кластере;\\n- Определение аномалий путем построения кластеров и выявления неклассифицированных объектов.\\nПсевдокод некоторых алгоритмов кластеризации\\nМетод K-средних (Алгоритм Ллойда)\\nОсновная идея заключается в том, что на каждой итерации перевычисляется центр масс для каждого кластера, полученного на предыдущем шаге, затем объекты снова разбиваются на кластеры в соответствии с тем, какой из новых центров оказался ближе по выбранной метрике. Алгоритм завершается, когда на какой-то итерации не происходит изменения внутрикластерного расстояния.\\nАлгоритм минимизирует сумму квадратов внутрикластерных расстояний:\\nНа вход алгоритму подаётся выборкаи количество кластеров .\\nНа выходе получаем центры кластеровдля кластеров .\\n# Инициализируем произвольно начальное приближение для центров кластеров . (Можно наиболее удалённые друг от друга объекты выборки) # Инициализируем массив отображений из объектов выборки в их кластеры : # Повторяем пока изменяются : # Относим каждый к ближайшему центру : : # Вычисляем новые положения центров # Возвращаем центры кластеров и распределение по ним объектов выборки\\nDBSCAN\\nОсновная идея метода заключается в том, что алгоритм разделит заданный набор точек в некотором пространстве на группы точек, которые лежат друг от друга на большом расстоянии. Объекты, которые лежат отдельно от скоплений с большой плотностью, будут помечены как шумовые.\\nНа вход алгоритму подаётся набор точек, параметры(радиус окружности) и (минимальное число точек в окрестности). Для выполнения кластеризации потребуется поделить точки на четыре вида: основные точки, прямо достижимые, достижимые и шумовые.\\n- Точка является основной, если в окружности с центром в этой точке и радиусом находится как минимум точек.\\n- Точка является прямо достижимой из основной точки , если находится на расстоянии, не большем от точки .\\n- Точка является достижимой из , если существует путь с и , где каждая точка прямо достижима из точки .\\n- Все остальные точки, которые не достижимы из основных точек, считаются шумовыми.\\nОсновная точка вместе со всеми достижимыми из нее точками формирует кластер. В кластер будут входить как основные, так и неосновные точки. Таким образом, каждый кластер содержит по меньшей мере одну основную точку.\\nАлгоритм начинается с произвольной точки из набора, которая еще не просматривалась. Для точки ищется-окрестность. Если она не содержит как минимум точек, то помечается как шумовая, иначе образуется кластер , который включает все точки из окрестности. Если точка из окрестности уже является частью другого кластера , то все точки данного кластера добавляются в кластер . Затем выбирается и обрабатывается новая, не посещённая ранее точка, что ведёт к обнаружению следующего кластера или шума.\\nНа выходе получаем разбиение на кластеры и шумовые объекты. Каждый из полученных кластеровявляется непустым множеством точек и удовлетворяет двум условиям:\\n- Любые две точки в кластере попарно связаны (то есть найдется такая точка в кластере, из которой достижимы обе этих точки).\\n- Если точка достижима из какой-либо точки кластера, то она принадлежит кластеру.\\nРассмотрим код:\\nПусть для каждогоимеем посчитанной его -окрестность .\\n# Непомеченные объекты # Инициализируем массив отображений из объектов выборки в их кластеры # Количество кластеров : # Пока в выборке есть непомеченные объекты # Берём случайную непомеченную точку : \" \" # Пометим как, возможно, шумовой : # Создадим новый кластер K : || \" \": # Если не помечен или помечен как шумовой : \" \" # Пометим как внутренний кластера # Добавим вместе с всю его окрестность : \" \" # Пометим как граничный кластера : # Возвращаем количество кластеров, распределение по кластерам и метки объектов (внутренние, граничные или шумовые)\\nDBSCAN находит практическое применение во многих реальных задачах, например, в маркетинге: необходимо предложить покупателю релевантный товар, который подойдет под его заказ. Выбрать такой товар можно, если посмотреть на похожие заказы других покупателей — в таком случае похожие заказы образуют кластер вещей, которые часто берут вместе. Похожим образом с помощью DBSCAN можно исследовать и находить общие интересы людей, делить их на социальные группы, моделировать поведение посетителей сайта. Алгоритм также может использоваться для сегментации изображений.\\nПример кода\\nПример на языке R\\nДля реализации алгоритма k-средних используется пакет\\nClusterR. В нем реализовано 2 функции:\\nKMeans_arma() и\\nKMeans_rcpp(). В примере далее рассмотрена реализация с использованием функции\\nKMeans_arma().\\n# importing package and its\\' dependencies library(ClusterR) # reading data data <- read.csv(\"data.csv\") # evaluating model model <- KMeans_arma(data, clusters = 2, n_iter = 10, seed_mode = \"random_subset\", verbose = T, CENTROIDS = NULL) # predicting results predictions <- predict_KMeans(test_data, model)\\nСм. также\\n- Оценка качества в задаче кластеризации\\n- EM-алгоритм\\n- Иерархическая кластеризация\\n- [на 28.01.18 не создан] -средних\\nПримечания\\n- ↑ scikit-learn — Clustering\\n- ↑ Cornwell, B. (2015). Linkage Criteria for Agglomerative Hierarchical Clustering. Social Sequence Analysis, 270–274\\n- ↑ Shalamov Viacheslav, Valeria Efimova, Sergey Muravyov, and Andrey Filchenkov. \"Reinforcement-based Method for Simultaneous Clustering Algorithm Selection and its Hyperparameters Optimization.\" Procedia Computer Science 136 (2018): 144-153.\\n- ↑ Kleinberg J. An Impossibility Theorem for Clustering\\n- ↑ scikit-learn — Comparing different clustering algorithms on toy datasets', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='12259ee2-d3e2-44ba-bd88-be242e52ea44', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f2670fbc6afdc60404427ad474cc4c573f59159e07d8585fcecf12dbca339a12', text='EM-алгоритм\\nСодержание\\n- 1 Определение\\n- 2 Основной алгоритм\\n- 3 Модификации\\n- 4 Пример. Разделение смеси Гауссиана\\n- 5 Использование в задаче кластеризации\\n- 6 Реализация на python\\n- 7 См. также\\n- 8 Примечания\\n- 9 Источники информации\\nОпределение\\nАлгоритм EM (англ. expectation-maximization) — итеративный алгоритм поиска оценок максимума правдоподобия модели, в ситуации, когда она зависит от скрытых (ненаблюдаемых) переменных.\\nАлгоритм ищет параметры модели итеративно, каждая итерация состоит из двух шагов:\\nE (Expectation) шаг — поиск наиболее вероятных значений скрытых переменных.\\nM (Maximization) шаг — поиск наиболее вероятных значений параметров, для полученных на шаге E значений скрытых переменных.\\nEM алгоритм подходит для решения задач двух типов:\\n- Задачи с неполными данными.\\n- Задачи, в которых удобно вводить скрытые переменные для упрощения подсчета функции правдоподобия. Примером такой задачи может служить кластеризация.\\nОсновной алгоритм\\nПостановка задачи\\nПлотность распределения смеси имеет вид:\\n.\\nГде — функция правдоподобия -ой компонеты смеси, — априорная вероятность -ой компоненты смеси.\\nПеред нами стоит две задачи:\\n- По заданной выборке случайных и независимых наблюдений полученных из смеси , числу и функции , оценить вектор параметров .\\n- Найти .\\nПроблема\\nЗадачи подобного рода мы умеем решать, максимизируя логармиф правдоподобия:\\n.\\nНо проблeма в том, что мы не знаем как аналитически посчитать логарифм суммы. Тут нам и поможет алгоритм EM.\\nРешение\\nОсновная идея алгоритма EM заключается в том, что мы добавляем скрытые переменные такие, что:\\n- Они могут быть выражены через .\\n- Они помогают разбить сумму так: , где — матрица скрытых переменных.\\nТогда алгоритм EM сводится к повторению шагов, указанных в Определении.\\nE-шаг\\n.\\nСкрытые переменные представляют из себя матрицу\\nгде — вероятность того, что пренадлежит -ой компоненте.\\nПо формуле Байеса справедливо равенство:\\n.\\nТакже\\nТаким образом, зная значения вектора параметров\\nM-шаг\\n|Теорема:\\nЕсли известны скрытые переменные, то задача минимизациисводится к независимым подзадачам:\\nОптимальные же веса считаются как:\\n|Доказательство:\\n|\\nПосчитаем логарифм правдоподобия:\\n.\\nПриравняв к нулю производную Лагранжиана по\\nКритерий остановки\\nАлгоритм EM выполняется до сходимости, но как нам определить, что сходимость наступила? Мы можем останавливаться, когда либо, либо перестают сильно меняться. Но, обычно, удобней контролировать изменения значений скрытых переменных, так как они имеют смысл вероятностей и принимают значения из отрезка . Поэтому один из возможных критериев остановки будет выглядеть так: .\\nПсевдокод\\nInput:Repeat E-step: for all i = 1..m; j = 1..k: M-step: for all j = 1..k: Until a stopping criterion is satisfied Return\\nПлюсы и минусы\\nПлюсы:\\n- Сходится в большинтсве случаев.\\n- Наиболее гибкое решение.\\n- Существуют простые модификации, позволяющие уменьшить чуствительность алгоритма к шуму в данных.\\nМинусы:\\n- Чуствителен к начальному приближению. Могут быть ситуации, когда сойдемся к локальному экстремуму.\\n- Число компонент гиперпараметром. является\\nМодификации\\nБазовый алгоритм EM является очень гибким для модификаций, позволяющих улучшить его работу. В этом разделе мы приведем краткое описание некоторых из них.\\nGeneralized EM-algorithm\\nОсоновная идея этой модификации заключается в том, что на шаге M мы не будем пытаться найти наилучшее решение. Это применимо в случаях, когда максимизацияявляется сликшом дорогой, поэтому нам достаточно сделать лишь несколько итераций, для того, чтобы сместиться в сторону максимума значения . Эта модификация имеет неплохую сходимость.\\nStochastic EM-algorithm\\nКак уже было отмечено в Плюсы и минусы, базовый алгоритм чувствителен к начальному приближению и могут быть ситуации, когда алгоритм \"застрянет\" в локальном экстремуме. Для того, чтобы предотвратить это, будем на каждой итерации алгоритма случайно \"встряхивать\" выборку. В этой модификации у нас добавляется шаг S, на котором мы и будем \"встряхивать\" выборку. И на шаге M мы будем решать уже задачу максимуму невзвешенного правдоподобия. Эта модификация хороша тем, что нечуствиетльная к начальном приблежению.\\nПример. Разделение смеси Гауссиана\\nКаноническим примером использования EM алгоритма является задача разделения смеси гауссиана. Данные у нас получены из нормального распределения. В этом случае параметрами функций ялвяются матожидание и дисперсия.\\n— вектор параметров,\\n— плотность распределения.\\nПосчитаем значения для каждого шага.\\nE-шаг:\\nM-шаг:\\nИспользование в задаче кластеризации\\nКак уже упоминалось в Определении, алгоритм EM подходит для решения задачи кластеризации. И одной из его имплементаций для этой задачи является алгоритм . В этом алгоритме в качестве скрытых переменных выступают метки классов объектов. Параметрами же являются центроиды искомых классов. Тогда на шаге E мы относим объекты к какому-то одному классу на основе расстояний до центроид. А на шаге M мы пересчитываем центроиды кластеров, исходя из полученной на шаге E разметке. -Means\\nТакже стоит упомянуть алгоритм [1]. В нем качестве скрытых переменных выступают вероятности принадлежности объекта к классам. На шаге E мы пересчитывем вероятности принадлежности объектов, иходя из расстояния до центроид. Шаг M, идейно, остается без изменений.-means\\nРеализация на python\\nВ пакете sklearn алгоритм EM представлен объектом GaussianMixture. Проиллюстрируем его работу на примере задачи кластеризации и сравним его с алгоритмом-means:\\nimport numpy as np import matplotlib.pyplot as plt from sklearn import cluster, datasets, mixture from sklearn.preprocessing import StandardScaler from itertools import cycle, islice np.random.seed(12) # Создаем datasets с использованием стандартных sklearn.datasets n_samples = 2000 random_state = 170 noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5, noise=.05) noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05) blobs = datasets.make_blobs(n_samples=n_samples, random_state=8) varied = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state) # Создаем анизатропно разделенные данные X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state) transformation = [[0.6, -0.6], [-0.4, 0.8]] X_aniso = np.dot(X, transformation) aniso = (X_aniso, y) # Выставляем параметры для matplotlib.pyplot plt.figure(figsize=(9 * 2 + 3, 12.5)) plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05, hspace=.01) plot_num = 1 defaul_n = 3 # Варьируем значение количества классов в зависимости от данных, ведь для нас это гиперпараметр datasets = [ (varied, defaul_n), (aniso, defaul_n), (blobs, defaul_n), (noisy_circles, 2)] for i_dataset, (dataset, n_cluster) in enumerate(datasets): X, y = dataset # Нормализация данных X = StandardScaler().fit_transform(X) # Непосредственно наш алгоритм - Gaussian Mixture gmm = mixture.GaussianMixture(n_components=n_cluster, covariance_type=\\'full\\') # Для сравнения берем алгоритм - k-means two_means = cluster.KMeans(n_clusters=n_cluster) clustering_algorithms = { \\'Real distribution\\': None, \\'Gaussian Mixture\\': gmm, \\'k-Means\\': two_means } for name, algorithm in clustering_algorithms: # Этап обучения if algorithm is not None: algorithm.fit(X) # Применяем алгоритм y_pred = y if algorithm is None else algorithm.predict(X) # Рисуем результаты plt.subplot(len(datasets), len(clustering_algorithms), plot_num) if i_dataset == 0: plt.title(name, size=18) colors = np.array(list(islice(cycle([\\'#377eb8\\', \\'#ff7f00\\', \\'#4daf4a\\']), int(max(y_pred) + 1)))) plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred]) plt.xlim(-2.5, 2.5) plt.ylim(-2.5, 2.5) plt.xticks(()) plt.yticks(()) plot_num += 1 plt.show()\\nКак и следовало ожидать, алгоритм EM работает на некоторых данных лучше чем k-means, однако есть данные, с которыми он не справляется без дополнительных преобразований.\\nСм. также\\nПримечания\\nИсточники информации\\n- Материалы лекции про кластеризацию курса \"Машинное обучение\" университета ИТМО, 2019 год\\n- Математические методы обучения по прецедентам К. В. Воронцов\\n- Статья про EM-алгоритм на machinelearning.ru\\n- A Gentle Introduction to Expectation-Maximization\\n- k-means', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='cbd76180-376f-41f3-89ae-288c6d1fb9e2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='604fd128dd436098e8eae61a04b9f90b33b60fbc43be436e12848e92254c3938', text='Иерархическая кластеризация\\n|Определение:\\n|Иерархическая кластеризация (англ. hierarchical clustering) — множество алгоритмов кластеризации, направленных на создание иерархии вложенных разбиений исходного множества объектов.\\nИерархические алгоритмы кластеризации часто называют алгоритмами таксономии. Для визуального представления результатов кластеризации используется дендрограмма — дерево, построенное по матрице мер близости между кластерами. В узлах дерева находятся подмножества объектов из обучающей выборки. При этом на каждом ярусе дерева множество объектов из всех узлов составляет исходное множество объектов. Объединение узлов между ярусами соответствует слиянию двух кластеров. При этом длина ребра соответствует расстоянию между кластерами.\\nСодержание\\nАлгоритм иерархической кластеризации\\nДерево строится от листьев к корню. В начальный момент времени каждый объект содержится в собственном кластере. Далее происходит итеративный процесс слияния двух ближайших кластеров до тех пор, пока все кластеры не объединятся в один или не будет найдено необходимое число кластеров. На каждом шаге необходимо уметь вычислять расстояние между кластерами и пересчитывать расстояние между новыми кластерами. Расстояние между одноэлементными кластерами определяется через расстояние между объектами:. Для вычисления расстояния между кластерами и на практике используются различные функции в зависимости от специфики задачи.\\nФункции расстояния между кластерами\\n- Метод одиночной связи (англ. single linkage)\\n- Метод полной связи (англ. complete linkage)\\n- Метод средней связи (англ. UPGMA (Unweighted Pair Group Method with Arithmetic mean))\\n- Центроидный метод (англ. UPGMC (Unweighted Pair Group Method with Centroid average))\\n- Метод Уорда (англ. Ward\\'s method)\\nФормула Ланса-Уильямса\\nНа каждом шаге необходимо уметь быстро подсчитывать расстояние от образовавшегося кластерадо любого другого кластера , используя известные расстояния с предыдущих шагов. Это легко выполняется при использовании формулы, предложенной Лансом и Уильямсом в 1967 году:\\n, где— числовые параметры.\\nКаждая из указанных выше функций расстояния удовлетворяет формуле Ланса-Уильямса со следующими коэффициентами:\\n- Метод одиночной связи (англ. single linkage)\\n- Метод полной связи (англ. complete linkage)\\n- Метод средней связи (англ. UPGMA (Unweighted Pair Group Method with Arithmetic mean))\\n- Центроидный метод (англ. UPGMC (Unweighted Pair Group Method with Centroid average))\\n- Метод Уорда (англ. Ward\\'s method)\\nСвойство монотонности\\nВведем обозначение— расстояние между кластерами, выбранными на шаге для объединения.\\nДендрограмма позволяет представлять зависимости между множеством объектов с любым числом заданных характеристик на двумерном графике, где по одной из осей откладываются все объекты, а по другой — расстояние. Если не накладывать на это расстояние никаких ограничений, то дендрограмма будет иметь большое число самопересечений и изображение перестанет быть наглядным. Чтобы любой кластер мог быть представлен в виде непрерывного отрезка на оси объектов и ребра не пересекались, необходимо наложить ограничение монотонности на .\\n|Определение:\\n|Функция расстоянияявляется монотонной, если на каждом следующем шаге расстояние между кластерами не уменьшается:\\nРасстояние является монотонным, если для коэффициентов в формул Ланса-Уильямса верна теорема Миллигана.\\n|Теорема (Миллиган, 1979):\\nЕсли выполняются следующие три условия, то кластеризация является монотонной:\\nИз перечисленных выше расстояний теореме удовлетворяют все, кроме центроидного.\\nОпределение числа кластеров\\nДля определения числа кластеров находится интервал максимальной длины. В качестве итоговых кластеров выдаются кластеры, полученные на шаге . При этом число кластеров равно .\\nОднако, когда число кластеров заранее неизвестно и объектов в выборке не очень много, бывает полезно изучить дендрограмму целиком.\\nПсевдокод\\n// алгоритм принимает множество объектов и возвращает множество кластеров для каждого шага function hierarchy(X: Set<Object>): Set<Set<Object>> t = 1for i = 2 to m for in return\\nПример\\n# Подключение библиотек from scipy.cluster.hierarchy import linkage, dendrogram from sklearn import datasets import matplotlib.pyplot as plt# Создание полотна для рисования fig = plt.figure(figsize=(15, 30)) fig.patch.set_facecolor(\\'white\\') # Загрузка набора данных \"Ирисы Фишера\" iris = datasets.load_iris() # Реализация иерархической кластеризации при помощи функции linkage mergings = linkage(iris.data, method=\\'ward\\') # Построение дендрограммы. Разными цветами выделены автоматически определенные кластеры R = dendrogram(mergings, labels=[iris.target_names[i] for i in iris.target], orientation = \\'left\\', leaf_font_size = 12) # Отображение дендрограммы plt.show()\\n|Дендрограммы кластеризации ирисов Фишера[1] в зависимости от функции расстояния между кластерами\\n|Метод одиночной связи\\n|Метод полной связи\\n|Метод средней связи\\n|Метод Уорда\\nЛучше всего с задачей справился алгоритм с использованием расстояния Уорда. Он точно выделил класс Iris setosa и заметно отделил вид Iris virginica от Iris versicolor.\\nСм. также\\n- Кластеризация\\n- Оценка качества в задаче кластеризации\\n- EM-алгоритм\\n- [на 28.01.18 не создан] -средних\\nПримечания\\nИсточники информации\\n- Википедия — Иерархическая кластеризация\\n- Scipy Documentation — Hierarchical clustering (scipy.cluster.hierarchy)\\n- К.В.Воронцов Лекции по алгоритмам кластеризации и многомерного шкалирования\\n- G. N. Lance, W. T. Williams; A General Theory of Classificatory Sorting Strategies: 1. Hierarchical Systems, The Computer Journal, Volume 9, Issue 4, 1 February 1967, Pages 373–380', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='c899a39b-a684-48ad-9c7e-260e17065237', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0afe5aa71174c7dc4093a106ccd066215df9e7db3eff5628647e5074deeb56d8', text='Оценка качества в задаче кластеризации\\nПроблема оценки качества в задаче кластеризации трудноразрешима, как минимум, по двум причинам:\\n- Теорема невозможности Клейнберга — не существует оптимального алгоритма кластеризации.\\n- Многие алгоритмы кластеризации не способны определить настоящее количество кластеров в данных. Чаще всего количество кластеров подается на вход алгоритма и подбирается несколькими запусками алгоритма.\\nСодержание\\n- 1 Методы оценки качества кластеризации\\n- 2 Внешние меры оценки качества\\n- 2.1 Обозначения\\n- 2.2 Индекс Rand\\n- 2.3 Индекс Adjusted Rand\\n- 2.4 Индекс Жаккара (англ. Jaccard Index)\\n- 2.5 Индекс Фоулкса – Мэллова (англ. Fowlkes-Mallows Index)\\n- 2.6 Hubert Г statistic\\n- 2.7 Индекс Phi\\n- 2.8 Minkowski Score\\n- 2.9 Индекс Гудмэна-Крускала (англ. Goodman-Kruskal Index)\\n- 2.10 Entropy\\n- 2.11 Purity\\n- 2.12 F-мера\\n- 2.13 Variation of Information\\n- 3 Внутренние меры оценки качества\\n- 3.1 Компактность кластеров (англ. Cluster Cohesion)\\n- 3.2 Отделимость кластеров (англ. Cluster Separation)\\n- 3.3 Индекс Данна (англ. Dunn Index)\\n- 3.4 Обобщенный Индекс Данна (gD31, gD41, gD51, gD33, gD43, gD53)\\n- 3.5 Индекс S_Dbw\\n- 3.6 Силуэт (англ. Silhouette)\\n- 3.7 Индекс Calinski–Harabasz\\n- 3.8 Индекс C\\n- 3.9 Индекс Дэвиcа-Болдуина (англ. Davies–Bouldin Index)\\n- 3.10 Score function\\n- 3.11 Индекс Gamma\\n- 3.12 Индекс COP\\n- 3.13 Индекс CS\\n- 3.14 Индекс Sym\\n- 3.15 Индексы SymDB, SymD, Sym33\\n- 3.16 Negentropy increment\\n- 3.17 Индекс SV\\n- 3.18 Индекс OS\\n- 4 Сравнение\\n- 5 См. также\\n- 6 Источники информации\\n- 7 Примечания\\nМетоды оценки качества кластеризации\\nМетод оценки качества кластеризации — инструментарий для количественной оценки результатов кластеризации.\\nПринято выделять две группы методов оценки качества кластеризации:\\n- Внешние (англ. External) меры основаны на сравнении результата кластеризации с априори известным разделением на классы.\\n- Внутренние (англ. Internal) меры отображают качество кластеризации только по информации в данных.\\nВнешние меры оценки качества\\nДанные меры используют дополнительные знания о кластеризуемом множестве: распределение по кластерам, количество кластеров и т.д.\\nОбозначения\\nДано множествоиз элементов, разделение на классы , и полученное разделение на кластеры , совпадения между и могут быть отражены в таблице сопряженности , где каждое обозначает число объектов, входящих как в , так и в : .\\nПусть.\\nТакже рассмотрим парыиз элементов кластеризуемого множества . Подсчитаем количество пар, в которых:\\n- Элементы принадлежат одному кластеру и одному классу —\\n- Элементы принадлежат одному кластеру, но разным классам —\\n- Элементы принадлежат разным кластерам, но одному классу —\\n- Элементы принадлежат разным кластерам и разным классам —\\nИндекс Rand\\nИндекс Rand оценивает, насколько много из тех пар элементов, которые находились в одном классе, и тех пар элементов, которые находились в разных классах, сохранили это состояние после кластеризации алгоритмом.\\nИмеет область определения от 0 до 1, где 1 — полное совпадение кластеров с заданными классами, а 0 — отсутствие совпадений.\\nИндекс Adjusted Rand\\nгде— значения из таблицы сопряженности.\\nВ отличие от обычного индекса Rand, индекс Adjusted Rand может принимать отрицательные значения, если .\\nИндекс Жаккара (англ. Jaccard Index)\\nИндекс Жаккара похож на Индекс Rand, только не учитывает пары элементов находящиеся в разные классах и разных кластерах ( ).\\nИмеет область определения от 0 до 1, где 1 — полное совпадение кластеров с заданными классами, а 0 — отсутствие совпадений.\\nИндекс Фоулкса – Мэллова (англ. Fowlkes-Mallows Index)\\nИндекс Фоулкса – Мэллова используется для определения сходства между двумя кластерами.\\nБолее высокое значение индекса означает большее сходство между кластерами. Этот индекс также хорошо работает на зашумленных данных.\\nHubert Г statistic\\nДанная мера отражает среднее расстояние между объектами разных кластеров:\\nгде, — матрица близости, а\\nМожно заметить, что два объекта влияют на, только если они находятся в разных кластерах.\\nЧем больше значение меры — тем лучше.\\nИндекс Phi\\nКлассическая мера корреляции между двумя переменными:\\nMinkowski Score\\nИндекс Гудмэна-Крускала (англ. Goodman-Kruskal Index)\\nEntropy\\nЭнтропия измеряет \"чистоту\" меток классов:\\nСтоит отметить, что если все кластера состоят из объектов одного класса, то энтропия равна 0.\\nPurity\\nЧистота ставит в соответствие кластеру самый многочисленный в этом кластере класс.\\nЧистота находится в интервале [0, 1], причём значение = 1 отвечает оптимальной кластеризации.\\nF-мера\\nF-мера представляет собой гармоническое среднее между точностью (precision) и полнотой (recall).\\nVariation of Information\\nДанная мера измеряет количество информации, потерянной и полученной при переходе из одного кластера в другой.\\nВнутренние меры оценки качества\\nДанные меры оценивают качество структуры кластеров опираясь только непосредственно на нее, не используя внешней информации.\\nКомпактность кластеров (англ. Cluster Cohesion)\\nИдея данного метода в том, что чем ближе друг к другу находятся объекты внутри кластеров, тем лучше разделение.\\nТаким образом, необходимо минимизировать внутриклассовое расстояние, например, сумму квадратов отклонений:\\n- , где — количество кластеров.\\nОтделимость кластеров (англ. Cluster Separation)\\nВ данном случае идея противоположная — чем дальше друг от друга находятся объекты разных кластеров, тем лучше.\\nПоэтому здесь стоит задача максимизации суммы квадратов отклонений:\\n- , где — количество кластеров.\\nИндекс Данна (англ. Dunn Index)\\nИндекс Данна имеет множество вариаций, оригинальная версия выглядит следующим образом:\\n- ,\\nгде:\\n- — межкластерное расстояние (оценка разделения), ,\\n- — диаметр кластера (оценка сплоченности), .\\nОбобщенный Индекс Данна (gD31, gD41, gD51, gD33, gD43, gD53)\\nВсе эти вариации являются комбинациями 3 вариантов вычисления оценки разделенияи оценки компактности\\nОценки разделения:\\n- ,\\n- ,\\n- .\\nОценки компактности:\\n- ,\\n- .\\nОбобщенный индекс Данна, как и обычный, должен возрастать вместе с улучшением качества кластеризации.\\nИндекс S_Dbw\\nОснован на вычислении Евклидовой нормы\\nи стандартных отклонений\\n- ,\\n- .\\nСам индекс определяется формулой:\\n- .\\nЗдесь\\n- ,\\n- ,\\n- , если и в ином случае.\\nДолжен снижаться с улучшением кластеризации.\\nСилуэт (англ. Silhouette)\\nЗначение силуэта показывает, насколько объект похож на свой кластер по сравнению с другими кластерами.\\nОценка для всей кластерной структуры:\\n- ,\\nгде:\\n- — среднее расстояние от до других объектов из кластера (компактность),\\n- — среднее расстояние от до объектов из другого кластера (отделимость).\\nМожно заметить, что\\n- .\\nЧем ближе данная оценка к 1, тем лучше.\\nЕсть также упрощенная вариация силуэта:и вычисляются через центры кластеров.\\nИндекс Calinski–Harabasz\\nКомпактность основана на расстоянии от точек кластера до их центроидов, а разделимость - на расстоянии от центроид кластеров до глобального центроида. Должен возрастать.\\nИндекс C\\nИндекс C представляет собой нормализованную оценку компактности:\\n- ,\\nгде:\\n- ,\\n- - сумма минимальных (максимальных) расстояний между парами всех объектов во всем датасете.\\nИндекс Дэвиcа-Болдуина (англ. Davies–Bouldin Index)\\nЭто, возможно, одна из самых используемых мер оценки качества кластеризации.\\nОна вычисляет компактность как расстояние от объектов кластера до их центроидов, а отделимость - как расстояние между центроидами.\\n- ,\\nгде:\\nСуществует еще одна вариация данной меры, которая была предложена автором вместе с основной версией:\\nC-индекс и индекс Дэвиcа-Болдуина должны минимизироваться для роста кластеризации.\\nScore function\\nИндекс, основанный на суммировании. Здесь оценка компактности выражается в дистанции от точек кластера до его центроида, а оценка разделимости — в дистанции от центроидов кластеров до глобального центроида.\\n- ,\\nгде:\\n- ,\\n-\\nЧтобы функция оценки была эффективной, она должна максимизировать bcd, минимизировать wcd и быть ограниченной. Чем больше данный индекс, тем выше качество.\\nИндекс Gamma\\nгде:\\n- — число пар таких, что (1) и принадлежат разным кластерам, и (2) ,\\n- .\\nИндекс COP\\nВ данной мере компактность вычисляется как расстояние от точек кластера до его центроиды, а разделимость основана на расстоянии до самого отдаленного соседа.\\n- .\\nИндекс CS\\nБыл предложен в области сжатия изображений, но может быть успешно адаптирован для любого другого окружения. Он оценивает компактность по диаметру кластера, а отделимость — как дистанцию между ближайшими элементами двух кластеров.\\n- .\\nЧем меньше значение данного индекса, тем выше качество кластеризации.\\nИндекс Sym\\n- .\\nЗдесь— дистанция симметрии для точки из кластера .\\nЧем выше данное значение, тем лучше.\\nИндексы SymDB, SymD, Sym33\\nМодифицируют оценку компактности для индексов Дэвиса-Боулдина, Данна и gD33 соответственно.\\nSymDB вычисляется аналогично DB с изменением вычисленияна:\\n- .\\nДанная оценка должна уменьшаться для улучшения качества кластеризации.\\nВ SymD переопределена функция:\\n- .\\nв Sym33 аналогично SymD переопределена:\\n- .\\nПоследние две оценки должны расти для улучшения качества кластеризации.\\nNegentropy increment\\nВ отличие от подавляющего большинства других оценок, не основывается на сравнении компактности и разделимости. Определяется следующим образом:\\n- .\\nЗдесь, - определитель ковариационной матрицы кластера , - определитель ковариационной матрицы всего датасета.\\nДанная оценка должна уменьшаться пропорционально росту качества кластеризации.\\nИндекс SV\\nОдна из самых новых из рассматриваемых в данном разделе оценок. Измеряет разделимость по дистанции между ближайшими точка кластеров, а компактность — по расстоянию от пограничных точек кластера до его центроида.\\n- .\\nДанная оценка должна увеличиваться.\\nИндекс OS\\nОтличается от предыдущей оценки усложненным способом вычисления оценки разделимости.\\n- .\\nГде\\n- .\\nпри, и в ином случае.\\nФункциии определены следующим образом:\\n- .\\n- .\\nДанная оценка, как и предыдущая, должна возрастать.\\nСравнение\\nНе существует лучшего метода оценки качества кластеризации. Однако, в рамках исследования[1] была предпринята попытка сравнить существующие меры на различных данных. Полученные результаты показали, что на искусственных датасетах наилучшим образом себя проявили индексы , и . На реальных датасетах лучше всех показал себя .\\nВ Таблице 1 приведены оценки сложности мер качества кластеризации (— число объектов в рассматриваемом наборе данных):\\nИз всех рассмотренных мер, меры [2]., , и наиболее полно соответствуют когнитивному представлению асессоров о качестве кластеризации\\nСм. также\\n- Кластеризация\\n- Оценка качества в задачах классификации и регрессии[на 28.01.19 не создан]\\nИсточники информации\\n- Wikipedia — Category:Clustering criteria\\n- Сивоголовко Е. В. Методы оценки качества четкой кластеризации\\n- Cluster Validation\\n- Halkidi, M., Batistakis, Y., Vazirgiannis, M., 2001. On clustering validation techniques. Journal of intelligent information systems, 17(2-3), pp.107-145.\\n- Pal, N.R., Biswas, J., 1997. Cluster validation using graph theoretic concepts. Pattern Recognition, 30(6), pp.847-857.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='7dd3f4e8-19f4-4902-ade3-f84cc0cdb180', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4e1772d18c45cb394a3a2e37574bc8d00089659894396e43dc65650f68c3703f', text='Эволюционные алгоритмы кластеризации\\nФормулировка задачи кластеризации в общем случае не задаёт условие близости относительно метрики (см. теорему Клейнберга); в связи с этим, многие разработанные методы и алгоритмы решения задачи кластеризации предполагают применимость конкретной меры близости объектов для анализа рассматриваемой выборки.\\nАльтернативный подход заключается в задании индекса кластеризации как меры близости объектов внутри кластеров и использовании универсального метода для оптимизации этого индекса; эволюционные алгоритмы являются одним из семейств таких универсальных методов.\\nСодержание\\nОписание метода\\nДля решения задачи кластеризации эволюционный алгоритм использует:\\n- разбиения выборки в качестве особей;\\n- индекс кластеризации в качестве целевой функции;\\n- операции видоизменения разбиений в качестве мутаций;\\n- операции комбинирования (\"скрещивания\") разбиений в качестве кроссовера;\\n- и т.д.\\nПараметры эволюционного алгоритма\\nИз описания выше следует, что эволюционный алгоритм кластеризации задаётся рядом гиперпараметров — таких как способ инициализации, применяемые мутации, схема самого алгоритма и т.п. Некоторые исследованные элементы конфигурации эволюционного алгоритма кластеризации приведены ниже.\\nПредставление особи\\nРазличные мутации, кроссоверы и способы инициализации особи предполагают некоторое её представление в памяти. Например:\\n- целочисленное кодирование по меткам кластеров (англ. label-based integer encoding) — для каждого объекта в выборке его кластер задаётся непосредственно. Таким образом, вся особь — это массив из $N$ чисел, соответствующих кластерам элементов выборки размера $N$.\\n- решётчатое кодирование — для каждого вещественного признака объектов одного кластера задаются верхняя и нижняя граница. Таким образом, область одного кластера $d$-мерной выборки ограничивается $d$-мерным гиперкубом.\\n- вещественное кодирование (англ. real encoding) — для каждого кластера $d$-мерной выборки задаётся его центроид — синтезированный объект, определяемый его координатами в пространстве выборки. Принадлежность объекта к кластеру определяется центроидом, который ближе всего к объекту согласно используемой метрике. Вся особь определяется вещественным вектором размера $k \\\\cdot d$.\\n- бинарное кодирование (англ. binary encoding) — то же самое, что и вещественное кодирование, но в качестве центроида используется элемент выборки, называемый прототипом (англ. prototype). Таким образом, одна особь может быть представлена вектором из $N$ булевых значений, из которых $k$ истинных определяют прототипы соответствующих $k$ кластеров.\\n- бинарное кодирование по остовному дереву (англ. tree-based binary encoding) — по выборке строится минимальное остовное дерево; особь кодируется вектором из $N-1$ булевых значений, среди которых $k-1$ истинное соответвует рёбрам остовного дерева, разделяющим кластеры.\\nМутации\\nВ качестве мутации можно либо использовать одну из операций, приведённых ниже, либо случайно (н-р, равновероятно) выбирать одну из нескольких таких операций.\\nРазбиения, слияния и переназначения\\nВ этом разделе приведён ряд мутаций, предполагающих целочисленное кодирование особи. Общим свойством этих операций является необходимость выбрать один, два или более кластеров, над которыми операции производятся. Делать это можно либо случайно (англ. unguided), либо выборочно (англ. guided) на основе той или иной характеристики кластера (англ. interestingness) — например, расстояний объектов до центроида, плотности объектов в кластере и т.п. [1][2]\\n- разбиение кластера (англ. split-gene) — выбранный кластер делится вдоль $N-1$-мерной поверхности (н-р, гиперплоскости; для двухмерного случая это прямая) на два новых. Гиперплоскость можно задать:\\n- случайно на основе выпуклой оболочки кластера;\\n- случайно по направлению, а по положению — выборочно на основе индуцированной функции распределения (или гистограммы) положения объектов кластера вдоль оси, перпендикулярной гиперплоскости;\\n- детерминированно как медиану между центроидом кластера и самой отдалённым от центроида объектом.\\n- слияние двух кластеров (англ. merge-gene) — выбранные два кластера объединяются в один.\\n- удаление кластера — все объекты выбранного кластера переназначаются в другие кластеры на основе расстояния до них.\\n- переназначение элементов кластера (англ. remove-and-reclassify) — небольшой набор объектов выбранного кластера переназначается в другие кластеры. Вместе с объектом можно также переместить случайное число (от 0 до $N/k$) ближайших к нему объектов. Набор объектов и целевой кластер можно задать случайно или выборочно на основе расстояний до соседних кластеров.\\nСледует заметить, что если алгоритм использует хотя бы одну операцию разбиения, то должна быть включена в рассмотрение какая-нибудь операция слияния, и наоборот. Иначе количество кластеров либо уменьшится до двух, либо возрастёт до $N$.\\nМодификация прототипа\\nНад прототипами (как вещественно, так и бинарно закодированными) можно проводить операции удаления и добавления; также у вещественного прототипа (центроида) можно поменять координаты. Помимо этого, можно получить гибрид эволюционного алгоритма и K-Means, совершая в качестве одной из возможных мутирующих операций шаг алгоритма $k$ средних значений [3]. Аналогично можно внедрить EM-шаг из Gaussian mixture, но для этого нужно при кодировании особи задавать дисперсию распределения при каждом центроиде [4].\\nКроссовер\\nВ качестве операций кроссовера различными авторами были опробованы:\\n- k-точечный кроссовер (англ. k-point crossover) на целочисленном и вещественном кодировании;\\n- однородный кроссовер (англ. uniform crossover) на бинарном кодированиии по остовному дереву;\\n- скрещивание кластеров — из выбранного кластера первой особи удаляется часть объектов, после чего в него добавляются случайно выбранные объекты из кластера второй особи. Удалённые объекты переназначаются в другие кластеры первой особи. На всех стадиях этой операции, требующих выбор объектов или кластеров, можно использовать как выборочную (англ. guided), так и полностью случайную (англ. unguided) стратегии, аналогично описанию мутаций разбиения и слияния [2].\\nИнициализация\\nЗадание особей первого поколения алгоритма может производиться с помощью различных эвристик:\\n- случайная инициализация — объекты назначаются в кластеры полностью случайным образом. Качество у полученной особи наихудшее, но можно использовать этот способ для тестирования.\\n- случайный выбор прототипов — прототипы бинарно закодированной особи задаются случайно.\\n- пространственная инициализация — например, объекты назначаются в кластеры на основе их координаты вдоль случайной оси.\\n- запуск другого алгоритма кластеризации — особь можно инициализировать с помощью K-Means, иерархической кластеризации и проч.\\nВиды алгоритмов\\nНа момент написания конспекта автору было известно о попытках использования эволюционных алгоритмов Roulette wheel selection, $(\\\\mu + \\\\lambda)$[5], tabu search[6], алгоритма многокритериальной оптимизации PESA-II[7].\\nСм. также\\nПримечания\\n- Кластерный анализ - Википедия\\n- Эволюционные алгоритмы - Википедия\\n- Crossover (genetic algorithm) - Wikipedia\\nИсточники информации\\n- Hruschka, E.R. A Survey of Evolutionary Algorithms for Clustering / E.R. Hruschka, R.J.G.B. Campello, A.A.Freitas, A.C.P.L.F. de Carvalho // IEEE Transactions on Systems, Man, and Cybernetics — Part C: Applications and Reviews, Vol. 39 — 2009 — С.133-155\\n- ↑ R. M. Cole. Clustering with genetic algorithms: дис. магистра, University of Western Australia, Perth, W.A., 1998\\n- ↑ 2,0 2,1 Ma, P.C.H. An Evolutionary Clustering Algorithm for Gene Expression Microarray Data Analysis / P.C.H. Ma, K.C.C. Chan, X. Yao, D.K.Y. Chiu // IEEE Transactions on Evolutionary Computation, Vol. 10 — 2006 — С.296-314\\n- ↑ Marghny, M.H. An Effective Evolutionary Clustering Algorithm: Hepatitis C case study / M.H. Marghny, Rasha M. Abd El-Aziz, Ahmed I. Taloba // International Journal of Computer Applications, Vol. 34 — No.6 — 2011\\n- ↑ Lu, W. A novel evolutionary clustering algorithm based on Gaussian mixture model / W. Lu, I. Traore // ICCOMP\\'06 Proceedings of the 10th WSEAS international conference on Computers — 2006 — C. 686-691\\n- ↑ Alves, V.S. Towards a fast evolutionary algorithm for clustering / V. S. Alves, R. J. G. B. Campello, E. R. Hruschka, // Proceedings IEEE Congress on Evolutionary Computation — 2006 — С. 6240–6247\\n- ↑ Pan, S. Evolution-based tabu search approach to automatic clustering / S. Pan, K. Cheng // IEEE Transactions on Systems, Man, and Cybernetics — Part C, Applications and Reviews, Vol. 37, No. 5 — 2007 — С. 827–838\\n- ↑ Handl, J. An evolutionary approach to multiobjective clustering / J. Handl, J. Knowles, // IEEE Transactions on Evolutionary Computation, vol. 11, no. 1, — 2007 — С. 56–76', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='cbdaacf5-3093-4446-bfe5-cc9ef87fe7cb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0e841ee65bf8485f97210ab54ad0ca7875e7e5656c629cb551c82c88ae8bbc72', text='Виды ансамблей\\nСодержание\\nАнсамбль\\nАнсамбль алгоритмов (методов) — метод, который использует несколько обучающих алгоритмов с целью получения лучшей эффективности прогнозирования, чем можно было бы получить от каждого обучающего алгоритма по отдельности.\\nРассмотрим задачу классификации на\\nПусть имеется классификаторов (\"экспертов\"): .\\n.\\nТогда давайте посмотрим новый классификатор на основе данных:\\nПростое голосование:\\nВзвешенное голосование: .\\nГде\\nТеорема Кондорсе о присяжных\\n|Теорема:\\nЕсли каждый член жюри присяжных имеет независимое мнение, и если вероятность правильного решения члена жюри больше 0.5, то тогда вероятность правильного решения присяжных в целом возрастает с увеличением количества членов жюри, и стремится к единице.\\nЕсли же вероятность быть правым у каждого из членов жюри меньше 0.5, то вероятность принятия правильного решения присяжными в целом монотонно уменьшается и стремится к нулю с увеличением количества присяжных.\\nПусть— количество присяжных, — вероятность правильного решения одного эксперта, — вероятность правильного решения всего жюри, — минимальное большинство членов жюри .\\nТогда\\nБэггинг\\nПусть имеется выборкаразмера . Количество классификаторов .\\nАлгоритм использует метод бутстрэпа (англ. bootstrap):\\nИз всего множества объектов равновероятно выберем N объектов с возвращением. Это значит, что после выбора каждого из объектов мы будем возращать его в множество для выбора. Отметим, что из-за возвращения некоторые объекты могут повторяться в выбранном множестве.\\nОбозначим новую выборку через . Повторяя процедуру раз, сгенерируем подвыборок . Теперь мы имеем достаточно большое число выборок и можем оценивать различные статистики исходного распределения.\\nШаги алгоритма бэггинг:\\n- Генерируется с помощью бутстрэпа M выборок размера N для каждого классификатора.\\n- Производится независимое обучения каждого элементарного классификатора (каждого алгоритма, определенного на своем подпространстве).\\n- Производится классификация основной выборки на каждом из подпространств (также независимо).\\n- Принимается окончательное решение о принадлежности объекта одному из классов. Это можно сделать несколькими разными способами, подробнее описано ниже.\\nОкончательное решение о принадлежности объекта классу может приниматься, например, одним из следующих методов:\\n- Консенсус: если все элементарные классификаторы присвоили объекту одну и ту же метку, то относим объект к выбранному классу.\\n- Простое большинство: консенсус достижим очень редко, поэтому чаще всего используют метод простого большинства. Здесь объекту присваивается метка того класса, который определило для него большинство элементарных классификаторов.\\n- Взвешивание классификаторов: если классификаторов четное количество, то голосов может получиться поровну, еще возможно, что для экспертов одна из групп параметров важна в большей степени, тогда прибегают к взвешиванию классификаторов. То есть при голосовании голос классификатора умножается на его вес.\\nРассмотрим задачу регрессии с базовыми алгоритмами . Предположим, что существует истинная функция ответа для всех объектов y(x), а также задано распределение p(x) на объектах. В этом случае мы можем записать ошибку каждой функции регрессии:\\nи записать матожидание среднеквадратичной ошибки:\\nСредняя ошибка построенных функций регрессии имеет вид:\\nПредположим, что ошибки несмещены и некоррелированы:\\nПостроим теперь новую функцию регрессии, усредняющую ответы уже построенных:\\nНайдем ее среднеквадратичную ошибку:\\nТаким образом, усреднение ответов позволило уменьшить средний квадрат ошибки враз.\\nБустинг\\nБустинг (англ. boosting — улучшение) — это процедура последовательного построения композиции алгоритмов машинного обучения, когда каждый следующий алгоритм стремится компенсировать недостатки композиции всех предыдущих алгоритмов. Бустинг представляет собой жадный алгоритм построения композиции алгоритмов.\\nПусть— базовый классификатор, где — вектор параметров.\\nЗадача состоит в том, чтоб найти такой алгоритмгде — коэффиценты, такие, чтобы минимизировать эмпирический риск , где — функция потерь.\\nОчевидно, что сложно найти сразуОсновная идея в том, чтоб найти решение пошагово . Таким образом мы сможем постепенно оценивать изменение эмпирического риска .\\nАлгоритмы бустинга:\\n- AdaBoost — адаптивный алгоритм бустинга, усиливающий классификаторы, объединяя их в «комитет». Чувствителен к шуму.\\n- BrownBoost — алгоритм бустинга, эффективный на зашумленных наборах данных\\n- GradientBoost — алгоритм бустинга, использующий идеи линейной регресии\\n- LogitBoost — алгоритм бустинга, использующий идеи логистической регресси\\nРеализации и применения бустинга\\nРеализации бустинга:\\n- XGBoost — одна из самых популярных и эффективных реализаций алгоритма градиентного бустинга на деревьях на 2019-й год.\\n- CatBoost — открытая программная библиотека, разработанная компанией Яндекс.\\n- LightGBM — библиотека для метода машинного обучения, основанная на градиентном бустинге (англ. gradient boosting).\\nПрименение бустинга:\\n- поисковые системы\\n- ранжирования ленты рекомендаций\\n- прогноз погоды\\n- оптимизации расхода сырья\\n- предсказания дефектов при производстве.\\n- исследованиях на Большом адронном коллайдере (БАК) для объединения информации с различных частей детектора LHCb в максимально точное, агрегированное знание о частице.\\nРазличия между алгоритмами\\n- Оба алгоритма используют N базовых классификаторов\\n- Бустинг использует последовательное обучение\\n- Бэггинг использует параллельное обучение\\n- Оба генерируют несколько наборов данных для обучения путем случайной выборки\\n- Бустинг определяет вес данных, чтоб утяжелить тяжелые случаи\\n- Бэггинг имеет невзвешенные данные\\n- Оба принимают окончательное решение, усредняя N классификаторов\\n- В бустинге определяются веса для них\\n- В бэггинге они равнозначны\\n- Оба уменьшают дисперсию и обеспечивают более высокую стабильность\\n- Бэггинг может решить проблему переобучения\\n- Бустинг пытается уменьшить смещение, но может увеличить проблему переобучения\\nПримеры кода\\nИнициализация\\nfrom pydataset import data #Считаем данные The Boston Housing Dataset[1] df = data(\\'Housing\\')\\n#Проверим данные df.head().values array([[42000.0, 5850, 3, 1, 2, \\'yes\\', \\'no\\', \\'yes\\', \\'no\\', \\'no\\', 1, \\'no\\'], [38500.0, 4000, 2, 1, 1, \\'yes\\', \\'no\\', \\'no\\', \\'no\\', \\'no\\', 0, \\'no\\'], [49500.0, 3060, 3, 1, 1, \\'yes\\', \\'no\\', \\'no\\', \\'no\\', \\'no\\', 0, \\'no\\'], ...\\n# Создадим словарь для слов \\'no\\', \\'yes\\' d = dict(zip([\\'no\\', \\'yes\\'], range(0,2))) for i in zip(df.dtypes.index, df.dtypes): if str(i[1]) == \\'object\\': df[i[0]] = df[i[0]].map(d) df[‘price’] = pd.qcut(df[‘price’], 3, labels=[‘0’, ‘1’, ‘2’]).cat.codes # Разделим множество на два y = df[\\'price\\'] X = df.drop(\\'price\\', 1)\\nБэггинг\\n# Импорты классификаторов from sklearn.model_selection import cross_val_score from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.linear_model import RidgeClassifier from sklearn.svm import SVC seed = 1075 np.random.seed(seed) # Инициализуруем классификаторы rf = RandomForestClassifier() et = ExtraTreesClassifier() knn = KNeighborsClassifier() svc = SVC() rg = RidgeClassifier() clf_array = [rf, et, knn, svc, rg] for clf in clf_array: vanilla_scores = cross_val_score(clf, X, y, cv=10, n_jobs=-1) bagging_clf = BaggingClassifier(clf, max_samples=0.4, max_features=10, random_state=seed) bagging_scores = cross_val_score(bagging_clf, X, y, cv=10, n_jobs=-1) print \"Mean of: {1:.3f}, std: (+/-) {2:.3f [{0}]\" .format(clf.__class__.__name__, vanilla_scores.mean(), vanilla_scores.std()) print \"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\\\n\" .format(clf.__class__.__name__, bagging_scores.mean(), bagging_scores.std())\\n#Результат Mean of: 0.632, std: (+/-) 0.081 [RandomForestClassifier] Mean of: 0.639, std: (+/-) 0.069 [Bagging RandomForestClassifier] Mean of: 0.636, std: (+/-) 0.080 [ExtraTreesClassifier] Mean of: 0.654, std: (+/-) 0.073 [Bagging ExtraTreesClassifier] Mean of: 0.500, std: (+/-) 0.086 [KNeighborsClassifier] Mean of: 0.535, std: (+/-) 0.111 [Bagging KNeighborsClassifier] Mean of: 0.465, std: (+/-) 0.085 [SVC] Mean of: 0.535, std: (+/-) 0.083 [Bagging SVC] Mean of: 0.639, std: (+/-) 0.050 [RidgeClassifier] Mean of: 0.597, std: (+/-) 0.045 [Bagging RidgeClassifier]\\nБустинг\\nada_boost = AdaBoostClassifier() grad_boost = GradientBoostingClassifier() xgb_boost = XGBClassifier() boost_array = [ada_boost, grad_boost, xgb_boost] eclf = EnsembleVoteClassifier(clfs=[ada_boost, grad_boost, xgb_boost], voting=\\'hard\\') labels = [\\'Ada Boost\\', \\'Grad Boost\\', \\'XG Boost\\', \\'Ensemble\\'] for clf, label in zip([ada_boost, grad_boost, xgb_boost, eclf], labels): scores = cross_val_score(clf, X, y, cv=10, scoring=\\'accuracy\\') print(\"Mean: {0:.3f}, std: (+/-) {1:.3f} [{2}]\".format(scores.mean(), scores.std(), label))\\n# Результат Mean: 0.641, std: (+/-) 0.082 [Ada Boost] Mean: 0.654, std: (+/-) 0.113 [Grad Boost] Mean: 0.663, std: (+/-) 0.101 [XG Boost] Mean: 0.667, std: (+/-) 0.105 [Ensemble]', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='2da3b159-1d84-4532-bed9-67b9ae820371', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='aa1c585c82252ceb6e2cfd6997286a0c05c1fbd51122414fe508256bfbb3089c', text='Бустинг, AdaBoost\\nСодержание\\n- 1 Описание\\n- 2 Алгоритмы бустинга\\n- 3 Прикладное использование алгоритмов бустинга\\n- 4 AdaBoost\\n- 5 Пример кода\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nОписание\\nБустинг (англ. boosting) — мета-алгоритм машинного обучения. Основной идеей бустинга является комбинирование слабых функций, которые строятся в ходе итеративного процесса, где на каждом шаге новая модель обучается с использованием данных об ошибках предыдущих. Сильный обучающий алгоритм является классификатором, хорошо коррелирующим с верной классификацией, в отличие от слабого. Наравне с бустингом в мета-обучении также рассматривают такие понятия, как бэггинг (англ. bagging) и стэкинг[1] (англ. stacking). Бэггинг, в отличии от бустинга, использует параллельное обучение базовых классификаторов. Стэкинг же комбинирует результаты различных алгоритмов, получая тем самым более точный ответ.\\nОдним из недостатков бустинга является то, что он может приводить к построению громоздких композиций, состоящих из сотен алгоритмов. Такие композиции исключают возможность содержательной интерпретации, требуют больших объёмов памяти для хранения базовых алгоритмов и существенных затрат времени на вычисление классификаций.\\nАлгоритмы бустинга\\n|Определение:\\n|Композицией $T$ алгоритмов суперпозиция алгоритмических операторов , корректирующей операции и решающего правила , где — пространство оценок, называется\\n, Алгоритмы $a_t$ называют базовыми алгоритмами.\\nБустинг представляет собой композицию алгоритмов, в которых ошибки отдельных алгоритмов взаимно компенсируются. Например, в задаче классификации на два класса $Y = {-1, +1}$ в качестве пространства оценок принимают $R = \\\\mathbb{R}$ и. Тогда базовые алгоритмы возвращают ответы $−1, 0, +1$. Ответ $b_t(x) = 0$ означает, что базовый алгоритм $b_t$ отказывается от классификации объекта $x$, и ответ $b_t(x)$ не учитывается в композиции. Получаем искомую композицию:\\nБольшая часть алгоритмов бустинга основывается на итеративном обучении слабых классификаторов с дальнейшей сборкой их в сильный классификатор. Когда они добавляются, им обычно приписываются веса, обычно связанные с точностью обучения. После добавления слабого классификатора, веса пересчитываются («пересчёт весовых коэффициентов»). Неверно классифицированные входные данные получают больший вес, а правильно классифицированные экземпляры теряют вес. Таким образом, дальнейшее слабое обучение фокусируется на примерах, где предыдущие слабые обучения дали ошибочную классификацию.\\nОсновное расхождение между многими алгоритмами бустинга заключается в методах определения весовых коэффициентов точек тренировочных данных и гипотез. Первым алгоритмом, который смог адаптироваться к слабому обучению был AdaBoost[2] (сокр. Adaptive Boosting), предложенный Шапире и Фройндом.\\nАлгоритмы бустинга могут использовать выпуклую или невыпуклую функцию потерь. Алгоритмы с выпуклой функцией, такие как AdaBoost и LogitBoost[3], могут некорректно классифицировать из-за случайного шума, так как не могут обучить базовым и поддающимся научению комбинациям слабых гипотез. Алгоритмы бустинга, основанные на невыпуклой функции потерь, такие как BrownBoost[4], позволяют избежать переобучения на данных с большим количеством \"шума\", откидывая зашумленные элементы.\\nПрикладное использование алгоритмов бустинга\\nЗадача классификации объектов\\nЕсли даны изображения, содержащие различные известные в мире объекты, классификатор может быть обучен на основе них для автоматической классификации объектов в будущих неизвестных изображениях. Простые классификаторы, построенные на основе некоторых признаков изображения объекта, обычно оказываются малоэффективными в классификации. Использование методов бустинга для классификации объектов — путь объединения слабых классификаторов специальным образом для улучшения общей возможности классификации.\\nКлассификация признаков является типичной задачей компьютерного зрения, где определяется, содержит ли изображение некоторую категорию объектов или нет. Идея тесно связана с распознаванием, идентификацией и обнаружением. Классификация по обнаружению объекта обычно содержит выделение признаков, обучение классификатора и применение классификатора к новым данным. Есть много способов представления категории объектов, например по анализу формы, с помощью модели «мешок слов», с помощью локальных описателей, таких как SIFT[5], и так далее. Примерами классификаторов с учителем служат наивные байесовские классификаторы[на 28.01.19 не создан], методы опорных векторов[на 28.01.19 не создан], смесь гауссиан и нейронные сети. Однако исследования показали, что категории объектов и их положение в изображениях могут быть обнаружены также с помощью обучения без учителя.\\nЗадача ранжирования выдачи поисковых систем\\nБлагодаря AdaBoost в мире появился градиентный бустинг (англ. gradient boosting) или GBM. Задачу ранжирования выдачи поисковых запросов рассмотрели с точки зрения функции потерь, которая штрафует за ошибки в порядке выдачи, поэтому было удобно внедрить GBM в ранжирование.\\nAdaBoost\\nОписание\\nАлгоритм может использоваться в сочетании с несколькими алгоритмами классификации для улучшения их эффективности. Алгоритм усиливает классификаторы, объединяя их в «комитет». AdaBoost является адаптивным в том смысле, что каждый следующий комитет классификаторов строится по объектам, неверно классифицированным предыдущими комитетами. AdaBoost чувствителен к шуму в данных и выбросам. Однако он менее подвержен переобучению по сравнению с другими алгоритмами машинного обучения.\\nAdaBoost вызывает слабые классификаторыв цикле . После каждого вызова обновляется распределение весов , которые отвечают важности каждого из объектов обучающего множества для классификации. На каждой итерации веса каждого неверно классифицированного объекта возрастают, таким образом новый комитет классификаторов «фокусирует своё внимание» на этих объектах.\\nОписание алгоритма\\n//function AdaBoost($X$, $Y$, $m$): //Инициализируем for i = 1..m do: end for for t = 1..T do: //$\\\\epsilon$ — Взвешенная ошибка классификации, классификатор for i = 1..m do: // — нормализующий параметр, выбранный так, чтобы являлось распределением вероятностей, то есть , для end for end for //$H(x)$ — результирующий классификатор return $H$\\nВыражение для обновления распределениядолжно быть сконструировано таким образом, чтобы выполнялось условие:\\nТаким образом, после выбора оптимального классификаторадля распределения , объекты , которые классификатор идентифицирует корректно, имеют веса меньшие, чем те, которые идентифицируются некорректно. Следовательно, когда алгоритм тестирует классификаторы на распределении , он будет выбирать классификатор, который лучше идентифицирует объекты неверно распознаваемые предыдущим классификатором.\\nПример работы\\nРассмотрим набор данных, которые пометим как $-$ и $+$.\\nДля всех ошибочно классифицированных объектов увеличим веса, а для верно классифицированных уменьшим\\nРассмотрим результат после $2$-х итераций:\\nКак видно из последнего изображения, все, что находиться в \"цветной\" зоне, мы можем однозначно классифицировать, но тогда у нас появляются ошибки и \"белые\" зоны, которые мы не можем однозначно классифицировать. Рассмотрим алгоритм после $30$-ти итераций:\\nТеперь у нас все объекты классифицируются верно и число ошибок на выборке равно нулю.\\nДостоинства и недостатки\\nДостоинства:\\n- Простота реализации;\\n- Хорошая обобщающая способность. В реальных задачах удаётся строить композиции, превосходящие по качеству базовые алгоритмы. Обобщающая способность может улучшаться по мере увеличения числа базовых алгоритмов;\\n- Время построения композиции практически полностью определяется временем обучения базовых алгоритмов;\\n- Возможность идентифицировать выбросы. Это наиболее «трудные» объекты $x_i$, для которых в процессе наращивания композиции веса $w_i$ принимают наибольшие значения.\\nНедостатки:\\n- Склонен к переобучению при наличии значительного уровня шума в данных;\\n- Требует достаточно длинных обучающих выборок. Другие методы линейной коррекции, в частности, бэггинг, способны строить алгоритмы сопоставимого качества по меньшим выборкам данных.\\nПример кода\\nПример кода на python для scikit-learn\\nКлассификатор sklearn.ensemble.AdaBoostClassifier[6] имеет 5 параметров: base_estimator, n_estimators, learning_rate, algorithm, random_state. Наиболее важными являются:\\n- base_estimator — базовый алгоритм. По умолчанию используется DecisionTreeClassifier(max_depth=1);\\n- n_estimators — максимальное количество оценок, после которого бустинг прекращается. Если произойдет полное совпадение, то закончится раньше;\\n- learning_rate — вклад каждой модели в весовые коэффициенты и значение по умолчанию равно $1$. Снижение этого параметра будет означать, что весовые коэффициенты буду увеличиваться или уменьшаться в небольшой степени, вынуждая модель дольше обучаться (но иногда повышается производительность).\\nfrom sklearn.ensemble import AdaBoostClassifier from sklearn import datasets from sklearn.model_selection import train_test_split from sklearn import metrics iris = datasets.load_iris() X = iris.data y = iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\\nabc = AdaBoostClassifier(n_estimators=50, learning_rate=1) model = abc.fit(X_train, y_train) y_pred = model.predict(X_test) print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\\nAccuracy: 0.8888888888888888\\nТеперь рассмотрим алгоритм с SVC в качестве базы:\\nfrom sklearn.svm import SVC svc=SVC(probability=True, kernel=\\'linear\\') abc = AdaBoostClassifier(base_estimator=svc, n_estimators=50, learning_rate=1) model = abc.fit(X_train, y_train) y_pred = model.predict(X_test) print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\\nAccuracy: 0.9555555555555556\\nПример на языке Scala\\nSBT зависимость:\\nlibraryDependencies += \"com.github.haifengl\" %% \"smile-scala\" % \"1.5.2\"\\nПример классификации датасета и вычисления F1 меры[7] используя smile.classification.adaboost[8]:\\nimport smile.classification._ import smile.data._ import smile.plot._ import smile.read import smile.validation.FMeasure\\nval iris: AttributeDataset = read.table(\"iris.csv\", delimiter = \",\", response = Some((new NumericAttribute(\"class\"), 2))) val x: Array[Array[Double]] = iris.x() val y: Array[Int] = iris.y().map(_.toInt) val ada: AdaBoost = adaboost(x, y, ntrees = 500, maxNodes = 2) val predictions: Array[Int] = x.map(ada.predict) val f1Score = new FMeasure().measure(predictions, y) plot(x, y, ada)\\nПример на языке Java\\nПример классификации с применением\\nsmile.classification.AdaBoost[9]\\nMaven зависимость:\\n<dependency> <groupId>com.github.haifengl</groupId> <artifactId>smile-core</artifactId> <version>1.5.2</version> </dependency>\\nimport smile.classification.AdaBoost; import smile.data.parser.ArffParser; import smile.validation.Accuracy; import smile.validation.ClassificationMeasure; import smile.validation.FMeasure; import java.util.Arrays;\\n// load train and test datasets var arffParser = new ArffParser(); arffParser.setResponseIndex(0); var train = arffParser.parse(this.getClass().getResourceAsStream(\"train.arff\")); var test = arffParser.parse(this.getClass().getResouceAsStream(\"test.arff\")); // create adaboost classifier var forest = new AdaBoost(train.attributes(), train.x(), train.labels(), 200, 4); // measure accuracy and F1-measure on test dataset var measures = new ClassificationMeasure[]{new FMeasure(), new Accuracy()}; var results = forest.test(test.x(), test.labels(), measures); System.out.println(Arrays.deepToString(results));\\nПример на языке R\\n# loading libraries install.packages(\"mlr\") library(mlr) # loading data train <- read.csv(\"input.csv\") test <- read.csv(\"testInput.csv\") # loading GBM getParamSet(\"classif.gbm\") baseLearner <- makeLearner(\"classif.gbm\", predict.type = \"response\") # specifying parameters controlFunction <- makeTuneControlRandom(maxit = 50000) # specifying tuning method cvFunction <- makeResampleDesc(\"CV\", iters = 100000) # definig cross-validation function gbmParameters<- makeParamSet( makeDiscreteParam(\"distribution\", values = \"bernoulli\"), makeIntegerParam(\"n.trees\", lower = 100, upper = 1000), # number of trees makeIntegerParam(\"interaction.depth\", lower = 2, upper = 10), # depth of tree makeIntegerParam(\"n.minobsinnode\", lower = 10, upper = 80), makeNumericParam(\"shrinkage\", lower = 0.01, upper = 1) ) # tunning parameters gbmTuningParameters <- tuneParams(learner = baseLearner, task = trainTask, resampling = cvFunction, measures = acc, par.set = gbmParameters, control = controlFunction) # creating model parameters model <- setHyperPars(learner = baseLearner, par.vals = gbmTuningParameters) # evaluating model fit <- train(model, train) predictions <- predict(fit, test)\\nСм. также\\n- Метод опорных векторов[на 28.01.19 не создан]\\n- Байесовская классификация[на 28.01.19 не создан]\\n- Мета-обучение\\n- Нейронные сети\\n- Оценка качества в задаче кластеризации\\n- CatBoost\\nПримечания\\nИсточники информации\\n- AdaBoost — статья на machinelearning.ru\\n- AdaBoost — презентация по AdaBoost\\n- Example of AdaBoost in action — презентация на coursera.org\\n- Курс лекций по машинному обучению — Воронцов К.В.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='481ae215-7be1-435e-a656-8aa7182f543f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='adec19ab19b543ac67d8f120e72e44e86e49bd4aad72a4a56225e868debda09e', text='XGBoost\\nXGBoost[1] — одна из самых популярных и эффективных реализаций алгоритма градиентного бустинга на деревьях на 2019-й год.\\nСодержание\\nИстория\\nXGBoost изначально стартовал как исследовательский проект Тяньцзи Чена (Tianqi Chen) как часть сообщества распределенного глубинного машинного обучения. Первоначально он начинался как терминальное приложение, которое можно было настроить с помощью файла конфигурации libsvm. После победы в Higgs Machine Learning Challenge, он стал хорошо известен в соревновательный кругах по машинному обеспечению. Вскоре после этого были созданы пакеты для Python и R, и теперь у него есть пакеты для многих других языков, таких как Julia, Scala, Java и т. д. Это принесло библиотеке больше разработчиков и сделало ее популярной среди сообщества Kaggle[2], где она использовалось для большого количества соревнований. Программное обеспечение разработано по методологии SCRUM.\\nОна вскоре стала использоваться с несколькими другими пакетами, что облегчает ее использование в соответствующих сообществах. Теперь у нее есть интеграция с scikit-learn для пользователей Python, а также с пакетом caret для пользователей R. Она также может быть интегрирована в рамах потока данных, таких как Apache Spark[3], Apache Hadoop[4], и Apache Flink[5] с использованием абстрактных Rabit[6] и XGBoost4J[7]. Принцип работы XGBoost также был опубликован Тяньцзи Ченом (Tianqi Chen) и Карлосом Гастрин (Carlos Guestrin).\\nОписание алгоритма\\nВ основе XGBoost лежит алгоритм градиентного бустинга деревьев решений. Градиентный бустинг — это техника машинного обучения для задач классификации и регрессии, которая строит модель предсказания в форме ансамбля слабых предсказывающих моделей, обычно деревьев решений. Обучение ансамбля проводится последовательно в отличие, например от бэггинга. На каждой итерации вычисляются отклонения предсказаний уже обученного ансамбля на обучающей выборке. Следующая модель, которая будет добавлена в ансамбль будет предсказывать эти отклонения. Таким образом, добавив предсказания нового дерева к предсказаниям обученного ансамбля мы можем уменьшить среднее отклонение модели, которое является таргетом оптимизационной задачи. Новые деревья добавляются в ансамбль до тех пор, пока ошибка уменьшается, либо пока не выполняется одно из правил \"ранней остановки\".\\nРассмотрим иллюстрацию бустинга. На ней рассматривается поведение модели на одной точке абстрактной задачи линейной регрессии. Предположим, что первая модель ансамблявсегда выдает выборочное среднее предсказываемой величины . Такое предсказание довольно грубое, поэтому среднеквадратичное отклонение на выбранной нами точке будет довольно большим. Мы попробуем это исправить обучив модель , которая будет \"корректировать\" предсказание предыдущего ансамбля . Таким образом мы получим ансамбль , предсказание которого будет суммироваться из предсказаний моделей и . Продолжая такую последовательность мы приходим к ансамблю предсказание которого суммируется из предсказаний , , , , и предсказывает в точности значение заданного таргета.\\nМатематика за алгоритмом\\n— функция для оптимизации градиентного бустинга, где:\\n— значение i-го элемента обучающей выборки и сумма предсказаний первых t деревьев соответственно.\\n— набор признаков i-го элемента обучающей выборки.\\n— функция (в нашем случае дерево), которую мы хотим обучить на шаге t. — предсказание на i-ом элементе обучающей выборки.\\n— регуляризация функции . , где T — количество вершин в дереве, — значения в листьях, а и — параметры регуляризации.\\nДальше с помощью разложения Тейлора до второго члена можем приблизить оптимизируемую функциюследующим выражением:\\n, где\\n,\\nПоскольку мы хотим минимизировать ошибку модели на обучающей выборке, нам нужно найти минимумдля каждого t.\\nМинимум этого выражения относительнонаходится в точке .\\nКаждое отдельное дерево ансамбля Дерево решений и случайный лес.обучается стандартным алгоритмом. Для более полного описания см.\\nВозможности XGBoost\\nОсобенности модели\\nXGBoost поддерживает все возможности таких библиотек как scikit-learn с возможностью добавлять регуляризацию. Поддержаны три главные формы градиетного бустинга:\\n- Стандартный градиентный бустинг с возможностью изменения скорости обучения(learning rate).\\n- Стохастический градиентный бустинг[8] с возможностью семплирования по строкам и колонкам датасета.\\n- Регуляризованный градиентный бустинг[9] с L1 и L2 регуляризацией.\\nСистемные функции\\nБиблиотека предоставляет систему для использования в различных вычислительных средах:\\n- Параллелизация построения дерева с использованием всех ваших ядер процессора во время обучения.\\n- Распределенные вычисления для обучения очень крупных моделей с использованием кластера машин.\\n- Вычисления для очень больших наборов данных, которые не вписываются в память.\\n- Кэш Оптимизация структуры данных и алгоритма для наилучшего использования аппаратного обеспечения.\\nОсобенности алгоритма\\nРеализация алгоритма была разработана для эффективности вычислительных ресурсов времени и памяти. Цель проекта заключалась в том, чтобы наилучшим образом использовать имеющиеся ресурсы для обучения модели. Некоторые ключевые функции реализации алгоритма включают:\\n- Различные стратегии обработки пропущенных данных.\\n- Блочная структура для поддержки распараллеливания обучения деревьев.\\n- Продолжение обучения для дообучения на новых данных.\\nОсновные параметры\\n- n_estimators — число деревьев.\\n- eta — размер шага. Предотвращает переобучение.\\n- gamma — минимальное изменение значения loss функции для разделения листа на поддеревья.\\n- max_depth — максимальная глубина дерева.\\n- lambda/alpha — L2/L1 регуляризация.\\nДля более полного описания параметров модели см. документацию[10].\\nПоддерживаемые интерфейсы\\n- Интерфейс командной строки (CLI).\\n- C++ (язык, на котором написана библиотека).\\n- Интерфейс Python, а также модель в Scikit-Learn.\\n- R интерфейс, а также модель в пакете карета.\\n- Julia.\\n- JVM языки, такие как Java, Scala, и платформы, такие как Hadoop.\\nПример использования с помощью библиотеки xgboost\\nЗагрузка датасета.\\nfrom sklearn import datasets iris = datasets.load_iris() X = iris.data y = iris.target\\nРазделение датасета на обучающую/тестовую выборку.\\nfrom sklearn.cross_validation import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\nИмпорт XGBoost и создание необходимых объектов.\\nimport xgboost as xgb dtrain = xgb.DMatrix(X_train, label=y_train) dtest = xgb.DMatrix(X_test, label=y_test)\\nЗадание параметров модели.\\nparam = { \\'max_depth\\': 3, \\'eta\\': 0.3, \\'silent\\': 1, \\'objective\\': \\'multi:softprob\\', \\'num_class\\': 3} num_round = 20\\nОбучение.\\nbst = xgb.train(param, dtrain, num_round) preds = bst.predict(dtest)\\nОпределение качества модели на тестовой выборке.\\nimport numpy as np from sklearn.metrics import precision_score best_preds = np.asarray([np.argmax(line) for line in preds]) print precision_score(y_test, best_preds, average=\\'macro\\')', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='eb881782-d294-4a5d-9876-2a6caa547654', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='74b71344a41d33233ddd6d809b3c8d5d2975eb38b051979f0b97be62e3ece08f', text=\"CatBoost\\nБиблиотека CatBoost — метод машинного обучения, основанный на градиентном бустинге (англ. gradient boosting).\\nПрактически любой современный метод на основе градиентного бустинга работает с числовыми признаками. Если у нас в наборе данных присутствуют не только числовые, но и категориальные признаки (англ. categorical features), то необходимо переводить категориальные признаки в числовые. Это приводит к искажению их сути и потенциальному снижению точности работы модели. Именно поэтому было важно разработать алгоритм, который умеет работать не только с числовыми признаками, но и с категориальными напрямую, закономерности между которыми этот алгоритм будет выявлять самостоятельно, без ручной «помощи». CatBoost — библиотека для градиентного бустинга, главным преимуществом которой является то, что она одинаково хорошо работает «из коробки» как с числовыми признаками, так и с категориальными. Программное обеспечение разработано по методологии SCRUM.\\nДокументацию по CatBoost можно найти на сайте[1].\\nСодержание\\n- 1 Общий принцип работы\\n- 2 Особенности CatBoost\\n- 3 Обучение\\n- 4 Работа с датасетом\\n- 5 Подбор параметров\\n- 6 Полезная функциональность\\n- 7 Бенчмарки\\n- 8 Пример использования\\n- 9 См. также\\n- 10 Примечания\\n- 11 Источники информации\\nОбщий принцип работы\\nДерево решений\\nАлгоритм работы следующий: для каждого документа имеется набор значений признаков, имеется дерево, в вершинах дерева — условия. Если условие выполнено, осуществляется переход в правого ребенка вершины, иначе в левого. Нужно пройти до листа по дереву в соответствии со значениями признаков для документа. На выходе каждому документу соответствует значение листа. Это и есть ответ.\\nБустинг\\nИдея бустинг-подхода заключается в комбинации слабых (с невысокой обобщающей способностью) функций, которые строятся в ходе итеративного процесса, где на каждом шаге новая модель обучается с использованием данных об ошибках предыдущих. Результирующая функция представляет собой линейную комбинацию базовых, слабых моделей. Более подробно можно посмотреть в статье про градиентный бустинг[2].\\nДалее будет рассматриваться бустинг деревьев решений. Будем строить несколько деревьев, чтобы добавление новых деревьев уменьшало ошибку. Итого при достаточно большом количестве деревьев мы сможем сильно уменьшить ошибку, однако не стоит забывать, что чем больше деревьев, тем дольше обучается модель и в какой-то момент прирост качества становится незначительным.\\nГрадиентный бустинг\\n- В основе CatBoost лежит градиентный бустинг.\\n- Градиент функции ошибки — все производные по всем значениям функции\\nГрадиентный бустинг — метод машинного обучения, который создает решающую модель прогнозирования в виде ансамбля слабых моделей прогнозирования, обычно деревьев решений. Он строит модель поэтапно, позволяя оптимизировать произвольную дифференцируемую функцию потерь.\\nОсобенности CatBoost\\nРежимы работы\\n- Регрессия (англ. regression);\\n- Классификация (англ. classification);\\nФункция потерь (англ. loss function) — максимизируем вероятность того, что все объекты в обучающей выборке классифицированы правильно, вероятность - это сигмоида над значением формулы. Функция predict_proba — на выходе получаем готовые вероятности. Нужно отметить, что складывать их уже нельзя. Функция predict — выдает необработанный результат. Такой результат можно складывать, например, с результатами других моделей.\\n- Мультиклассификация (англ. multiclass classification);\\n- Ранжирование (англ. ranking).\\nОбъекты с попарной классификацией (??)\\nМетрики\\nПоддерживает множество метрик[на 28.01.19 не создан] (англ. metrics), таких как:\\n- Регрессия: MAE, MAPE, RMSE, SMAPE etc.;\\n- Классификация: Logloss , Precision, Recall, F1, CrossEntropy, BalancedAccuracy etc.;\\n- Мультиклассификация: MultiClass, MultiClassOneVsAll, HammingLoss, F1 etc.;\\n- Ранжирование: NDCG, PrecisionAt, RecallAt, PFound, PairLogit etc.\\nОбучение\\nШаги обучения\\n- Строим дерево;\\n- Считаем значение в листьях.\\nПостроение дерева\\nПроцесс построения происходит жадно.\\n- Выбираем первую вершину;\\n- Выбираем лучшее дерево с одной вершиной;\\n- Считаем метрику и по ней выбираем лучшее дерево.\\nДерево строится по слоям. Гарантировано на каждом слое один и тот же сплит (условие по которому мы делим).\\nВычисление значений в листьях\\nВо время вычисления значений в листьях можем позволить себе сделать больше операций, так как у нас уже зафиксирована структура дерева и значения в листьях будут вычислены единожды. Поэтому можем себе позволить даже сделать несколько шагов по градиенту или применить метод Ньютона.\\nКак выбрать лучшее дерево?\\nСмотрим, на сколько меняется функция ошибки, выбираем такое дерево, чтобы оно как можно лучше приближало вектор градиентов.\\nКак работает градиентный бустинг?\\nОтметим, что существует идеальный шаг по градиенту, однако листьев в дереве меньше, чем документов в датасете. Поэтому мы можем пытаться приближать тот самый идеальный шаг. Чтобы найти лучший сплит, проверяем похожесть после одного шага алгоритма по градиенту.\\nРандомизация\\nЕсть рандомизация метрики, по которой выбирается лучшее дерево.\\nScore += random_strength * Rand (0, lenofgrad * q)\\nq — множитель, уменьшающийся при увеличении итерации. Таким образом, рандом уменьшается ближе к концу.\\nРабота с датасетом\\nРежимов выборки данных\\nCatBoost поддерживает несколько режимов выборки данных\\n- Бутстрап (англ. bootstrap) Бернулли — выбираем документ с вероятностью p. Регулируется параметром sample_rate;\\n- Байесовский бутстрап — байесовское распределение. Регулируется параметром bagging_temp.\\nОтметим, что бутстрап используется только для выбора структуры дерева, для подсчета значения в листьях используем всю выборку. Это сделано, так как выбор структуры дерева происходит долго, нужно несколько раз пересчитывать значения, поэтому использовать всю выборку слишком дорого. Однако значения в листьях с уже готовой структурой дерева считаются один раз, и для большей точности можно позволить использовать весь датасет.\\nБинаризация признаков\\nПробовать все — долго. Поэтому выбираем сетку заранее и ходим по ней.\\nЕсть несколько способов выбора:\\n- Uniform. Равномерно разбиваем отрезок от минимума значения для данного признака до максимума;\\n- Медианная сетка. Задаем количество разбиений над множеством значений, далее идем по объектам в порядке сортировки и разбиваем на группы по k объектов, где k — количество объектов в одном слоте разбиения;\\n- UniformAndQuantiles. Комбинация 1 и 2 пунктов;\\n- MaxSumLog — в основе лежит динамика, работает долго;\\n- GreedyLogSum — аналог MaxSumLog, используется жадный алгоритм, поэтому работает не точно, однако быстрее чем MaxSumLog.\\nРабота с категориальными признаками\\n- LabelEncoding — на реальных примерах точность работы низкая, так как появляется отношения порядка между объектами;\\n- One-hot encoding — дает неплохую точность, если различных значений признаков не много. Иначе один признак размножится на множество признаков и будет влиять на модель заведомо сильнее остальных признаков.\\nЛучше не делать препроцессинг самим из-за проблем, описанных выше. В CatBoost можно задать параметр cat_features, передав туда индексы категориальных признаков. Также можно отрегулировать параметр one_hot_max_size — максимальное количество различных значений у категориального признака, чтобы он мог в последствии быть подвержен one-hot encoding.\\nПодбор параметров\\nНиже описаны гиперпараметры (англ. hyperparameters), на которые стоит обратить внимание при использовании библиотеки.\\n- cat_features;\\n- Overfitting detector;\\n- Число итераций и learning rate;\\n- L2_reg;\\n- Random_srength;\\n- Bagging_temp;\\n- Глубина дерева (стоит попробовать 10 и 6).\\nПолезная функциональность\\n- Snapshots;\\n- Overfitting detector;\\n- CV;\\n- eval_metrics.\\nБенчмарки\\nСравнение библиотеки CatBoost с открытыми аналогами XGBoost, LightGBM и H20 на наборе публичных датасетов[3].\\nПример использования\\n- Делим данные на тренировочное и тестовое множество\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.5, random_state=1234) print(X_train.shape, X_validation.shape)\\n- Создаем классификатор\\nfrom catboost import CatBoostClassifier\\nbest_model = CatBoostClassifier( bagging_temperature=1, random_strength=1, thread_count=3, iterations=500, l2_leaf_reg = 4.0, learning_rate = 0.07521709965938336, save_snapshot=True, snapshot_file='snapshot_best.bkp', random_seed=63, od_type='Iter', od_wait=20, custom_loss=['AUC', 'Accuracy'], use_best_model=True )\\n- Обучаемся\\nbest_model.fit( X_train, y_train, cat_features=cat_features, eval_set=(X_validation, y_validation), logging_level='Silent', plot=True )\\n- Вывод числа деревьев в модели\\nprint('Resulting tree count:', best_model.tree_count_)\\n> Resulting tree count: 217\\n- Используем скользящий контроль (англ. cross validation)\\nfrom catboost import cv\\nparams = best_model.get_params() params['iterations'] = 10 params['custom_loss'] = 'AUC' del params['use_best_model'] pool1 = Pool(X, label=y, cat_features=cat_features)\\ncv_data = cv( params = params, pool = pool1, fold_count=2, inverted=False, shuffle=True, stratified=False, partition_random_seed=0 )\\n- Выводим результат\\nbest_value = np.max(cv_data['AUC_test_avg']) best_iter = np.argmax(cv_data['AUC_test_avg']) print('Best validation AUC score: {:.2f}±{:.2f} on step {}'.format( best_value, cv_data['AUC_test_stddev'][best_iter], best_iter ))\\n> Best validation AUC score: 0.91±0.00 on step 9\\nБольше примеров[4] можно найти на сайте библиотеки.\\nСм. также\\n- Дерево решений и случайный леc[на 28.01.19 не создан]\\n- Бустинг, AdaBoost\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='19298810-fa21-4375-9769-41e3d27b569a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='db05d9a905e79cf0fe750dd82f038803463e0cbb56354cba967a4b609ec0ba47', text='Нейронные сети, перцептрон\\nИскусственная нейронная сеть (ИНС) (англ. Artificial neural network (ANN)) — упрощенная модель биологической нейронной сети, представляющая собой совокупность искусственных нейронов, взаимодействующих между собой.\\nОсновные принципы работы нейронных сетей были описаны еще в 1943 году Уорреном Мак-Каллоком и Уолтером Питтсом[1]. В 1957 году нейрофизиолог Фрэнк Розенблатт разработал первую нейронную сеть[2], а в 2010 году большие объемы данных для обучения открыли возможность использовать нейронные сети для машинного обучения.\\nНа данный момент нейронные сети используются в многочисленных областях машинного обучения и решают проблемы различной сложности.\\nСодержание\\n- 1 Структура нейронной сети\\n- 2 Виды нейронных сетей\\n- 3 Обучение нейронной сети\\n- 4 Перцептрон\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nСтруктура нейронной сети\\nХорошим примером биологической нейронной сети является человеческий мозг. Наш мозг — сложнейшая биологическая нейронная сеть, которая принимает информацию от органов чувств и каким-то образом ее обрабатывает (узнавание лиц, возникновение ощущений и т.д.). Мозг же, в свою очередь, состоит из нейронов, взаимодействующих между собой.\\nДля построения искусственной нейронной сети будем использовать ту же структуру. Как и биологическая нейронная сеть, искусственная состоит из нейронов, взаимодействующих между собой, однако представляет собой упрощенную модель. Так, например, искусственный нейрон, из которых состоит ИНС, имеет намного более простую структуру: у него есть несколько входов, на которых он принимает различные сигналы, преобразует их и передает другим нейронам. Другими словами, искусственный нейрон — это такая функция, которая преобразует несколько входных параметров в один выходной.\\nКак видно на рисунке справа, у нейрона естьвходов , у каждого из которого есть вес , на который умножается сигнал, проходящий по связи. После этого взвешенные сигналы направляются в сумматор, который аггрегирует все сигналы во взвешенную сумму. Эту сумму также называют . Таким образом, .\\nПросто так передавать взвешенную сумму функцию активации, которая преобразует взвешенную сумму в какое-то число, которое и будет являться выходом нейрона. Функция активации обозначается . Таким образом, выходов искусственного нейрона является .на выход достаточно бессмысленно — нейрон должен ее как-то обработать и сформировать адекватный выходной сигнал. Для этих целей используют\\nДля разных типов нейронов используют самые разные функции активации, но одними из самых популярных являются:\\n- Функция единичного скачка. Если , , а иначе ;\\n- Сигмоидальная функция. , где параметр характеризует степень крутизны функции;\\n- Гиперболический тангенс. , где параметр также определяет степень крутизны графика функции;\\n- Rectified linear units (ReLU). .\\nВиды нейронных сетей\\nРазобравшись с тем, как устроен нейрон в нейронной сети, осталось понять, как их в этой сети располагать и соединять.\\nКак правило, в большинстве нейронных сетей есть так называемый входной слой, который выполняет только одну задачу — распределение входных сигналов остальным нейронам. Нейроны этого слоя не производят никаких вычислений. В остальном нейронные сети делятся на основные категории, представленные ниже.\\nОднослойные нейронные сети\\nОднослойная нейронная сеть (англ. Single-layer neural network) — сеть, в которой сигналы от входного слоя сразу подаются на выходной слой, который и преобразует сигнал и сразу же выдает ответ.\\nКак видно из схемы однослойной нейронной сети, представленной справа, сигналыпоступают на входной слой (который не считается за слой нейронной сети), а затем сигналы распределяются на выходной слой обычных нейронов. На каждом ребре от нейрона входного слоя к нейрону выходного слоя написано число — вес соответствующей связи.\\nМногослойные нейронные сети\\nМногослойная нейронная сеть (англ. Multilayer neural network) — нейронная сеть, состоящая из входного, выходного и расположенного(ых) между ними одного (нескольких) скрытых слоев нейронов.\\nПомимо входного и выходного слоев эти нейронные сети содержат промежуточные, скрытые слои. Такие сети обладают гораздо большими возможностями, чем однослойные нейронные сети, однако методы обучения нейронов скрытого слоя были разработаны относительно недавно.\\nРаботу скрытых слоев нейронов можно сравнить с работой большого завода. Продукт (выходной сигнал) на заводе собирается по стадиям на станках. После каждого станка получается какой-то промежуточный результат. Скрытые слои тоже преобразуют входные сигналы в некоторые промежуточные результаты.\\nСети прямого распространения\\nСети прямого распространения (англ. Feedforward neural network) (feedforward сети) — искусственные нейронные сети, в которых сигнал распространяется строго от входного слоя к выходному. В обратном направлении сигнал не распространяется.\\nВсе сети, описанные выше, являлись сетями прямого распространения, как следует из определения. Такие сети широко используются и вполне успешно решают определенный класс задач: прогнозирование, кластеризация и распознавание.\\nОднако сигнал в нейронных сетях может идти и в обратную сторону.\\nСети с обратными связями\\nСети с обратными связями (англ. Recurrent neural network) — искусственные нейронные сети, в которых выход нейрона может вновь подаваться на его вход. В более общем случае это означает возможность распространения сигнала от выходов к входам.\\nВ сетях прямого распространения выход сети определяется входным сигналом и весовыми коэффициентами при искусственных нейронах. В сетях с обратными связями выходы нейронов могут возвращаться на входы. Это означает, что выход какого-нибудь нейрона определяется не только его весами и входным сигналом, но еще и предыдущими выходами (так как они снова вернулись на входы).\\nОбучение нейронной сети\\nОбучение нейронной сети — поиск такого набора весовых коэффициентов, при котором входной сигнал после прохода по сети преобразуется в нужный нам выходной.\\nЭто определение «обучения нейронной сети» соответствует и биологическим нейросетям. Наш мозг состоит из огромного количества связанных друг с другом нейросетей, каждая из которых в отдельности состоит из нейронов одного типа (с одинаковой функцией активации). Наш мозг обучается благодаря изменению синапсов — элементов, которые усиливают или ослабляют входной сигнал.\\nЕсли обучать сеть, используя только один входной сигнал, то сеть просто «запомнит правильный ответ», а как только мы подадим немного измененный сигнал, вместо правильного ответа получим бессмыслицу. Мы ждем от сети способности обобщать какие-то признаки и решать задачу на различных входных данных. Именно с этой целью и создаются обучающие выборки.\\nОбучающая выборка — конечный набор входных сигналов (иногда вместе с правильными выходными сигналами), по которым происходит обучение сети.\\nПосле обучения сети, то есть когда сеть выдает корректные результаты для всех входных сигналов из обучающей выборки, ее можно использовать на практике. Однако прежде чем сразу использовать нейронную сеть, обычно производят оценку качества ее работы на так называемой тестовой выборке.\\nТестовая выборка — конечный набор входных сигналов (иногда вместе с правильными выходными сигналами), по которым происходит оценка качества работы сети.\\nСамо обучение нейронной сети можно разделить на два подхода: обучение с учителем[на 28.01.19 не создан] и обучение без учителя[на 28.01.19 не создан]. В первом случае веса меняются так, чтобы ответы сети минимально отличались от уже готовых правильных ответов, а во втором случае сеть самостоятельно классифицирует входные сигналы.\\nПерцептрон\\nПерцептрон (англ. Perceptron) — простейший вид нейронных сетей. В основе лежит математическая модель восприятия информации мозгом, состоящая из сенсоров, ассоциативных и реагирующих элементов.\\nИстория\\nИдею перцептрона предложил нейрофизиолог Фрэнк Розенблатт. Он предложил схему устройства, моделирующего процесс человеческого восприятия, и назвал его «перцептроном» (от латинского perceptio — восприятие). В 1960 году Розенблатт представил первый нейрокомпьютер — «Марк-1», который был способен распознавать некоторые буквы английского алфавита.\\nТаким образом перцептрон является одной из первых моделей нейросетей, а «Марк-1» — первым в мире нейрокомпьютером.\\nОписание\\nВ основе перцептрона лежит математическая модель восприятия информации мозгом. Разные исследователи по-разному его определяют. В самом общем своем виде (как его описывал Розенблатт) он представляет систему из элементов трех разных типов: сенсоров, ассоциативных элементов и реагирующих элементов.\\nПринцип работы перцептрона следующий:\\n- Первыми в работу включаются S-элементы. Они могут находиться либо в состоянии покоя (сигнал равен 0), либо в состоянии возбуждения (сигнал равен 1);\\n- Далее сигналы от S-элементов передаются A-элементам по так называемым S-A связям. Эти связи могут иметь веса, равные только -1, 0 или 1;\\n- Затем сигналы от сенсорных элементов, прошедших по S-A связям, попадают в A-элементы, которые еще называют ассоциативными элементами;\\n- Одному A-элементу может соответствовать несколько S-элементов;\\n- Если сигналы, поступившие на A-элемент, в совокупности превышают некоторый его порог , то этот A-элемент возбуждается и выдает сигнал, равный 1;\\n- В противном случае (сигнал от S-элементов не превысил порога A-элемента), генерируется нулевой сигнал;\\n- Далее сигналы, которые произвели возбужденные A-элементы, направляются к сумматору (R-элемент), действие которого нам уже известно. Однако, чтобы добраться до R-элемента, они проходят по A-R связям, у которых тоже есть веса (которые уже могут принимать любые значения, в отличие от S-A связей);\\n- R-элемент складывает друг с другом взвешенные сигналы от A-элементов, а затем\\n- если превышен определенный порог, генерирует выходной сигнал, равный 1;\\n- eсли порог не превышен, то выход перцептрона равен -1.\\nДля элементов перцептрона используют следующие названия:\\n- S-элементы называют сенсорами;\\n- A-элементы называют ассоциативными;\\n- R-элементы называют реагирующими.\\nКлассификация перцептронов\\nПерцептрон с одним скрытым слоем (элементарный перцептрон, англ. elementary perceptron) — перцептрон, у которого имеется только по одному слою S, A и R элементов.\\nОднослойный персептрон (англ. Single-layer perceptron) — перцептрон, каждый S-элемент которого однозначно соответствует одному А-элементу, S-A связи всегда имеют вес 1, а порог любого А-элемента равен 1. Часть однослойного персептрона соответствует модели искусственного нейрона.\\nЕго ключевая особенность состоит в том, что каждый S-элемент однозначно соответствует одному A-элементу, все S-A связи имеют вес, равный +1, а порог A элементов равен 1. Часть однослойного перцептрона, не содержащая входы, соответствует искусственному нейрону, как показано на картинке. Таким образом, однослойный перцептрон — это искусственный нейрон, который на вход принимает только 0 и 1.\\nОднослойный персептрон также может быть и элементарным персептроном, у которого только по одному слою S,A,R-элементов.\\nМногослойный перцептрон по Розенблатту (англ. Rosenblatt multilayer perceptron) — перцептрон, который содержит более 1 слоя А-элементов.\\nМногослойный перцептрон по Румельхарту (англ. Rumelhart multilater perceptron) — частный случай многослойного персептрона по Розенблатту, с двумя особенностями:\\n- S-A связи могут иметь произвольные веса и обучаться наравне с A-R связями;\\n- Обучение производится по специальному алгоритму, который называется обучением по методу обратного распространения ошибки.\\nОбучение перцептрона\\nЗадача обучения перцептрона — подобрать такие, чтобы как можно чаще совпадал с — значением в обучающей выборке (здесь — функция активации). Для удобства, чтобы не тащить за собой свободный член , добавим в вектор $x$ лишнюю «виртуальную размерность» и будем считать, что . Тогда можно заменить на .\\nЧтобы обучать эту функцию, сначала надо выбрать функцию ошибки, которую потом можно оптимизировать градиентным спуском. Число неверно классифицированных примеров не подходит на эту кандидатуру, потому что эта функция кусочно-гладкая, с массой разрывов: она будет принимать только целые значения и резко меняться при переходе от одного числа неверно классифицированных примеров к другому. Поэтому использовать будем другую функцию, так называемый критерий перцептрона: , где — множество примеров, которые перцептрон с весами классифицирует неправильно.\\nИначе говоря, мы минимизируем суммарное отклонение наших ответов от правильных, но только в неправильную сторону; верный ответ ничего не вносит в функцию ошибки. Умножение наздесь нужно для того, чтобы знак произведения всегда получался отрицательным: если правильный ответ −1, значит, перцептрон выдал положительное число (иначе бы ответ был верным), и наоборот. В результате у нас получилась кусочно-линейная функция, дифференцируемая почти везде, а этого вполне достаточно.\\nТеперьможно оптимизировать градиентным спуском. На очередном шаге получаем: .\\nАлгоритм такой — мы последовательно проходим примерыиз обучающего множества, и для каждого :\\n- если он классифицирован правильно, не меняем ничего;\\n- а если неправильно, прибавляем .\\nОшибка на примерепри этом, очевидно, уменьшается, но, конечно, совершенно никто не гарантирует, что вместе с тем не увеличится ошибка от других примеров. Это правило обновления весов так и называется — правило обучения перцептрона, и это было основной математической идеей работы Розенблатта.\\nПрименение\\n- Решение задач классификации, если объекты классификации обладают свойством линейной разделимости;\\n- Прогнозирование и распознавание образов;\\n- Управление агентами[3].\\nПримеры кода\\nПример использования с помощью scikit-learn[4]\\nБудем классифицировать с помощью перцептрона датасет MNIST[5].\\n# Load required libraries from sklearn import datasets from sklearn.preprocessing import StandardScaler from sklearn.linear_model import Perceptron #Single-layer perceptron from sklearn.neural_network import MLPClassifier #Multilayer perceptron from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score import numpy as np\\n# Load the mnist dataset mnist = datasets.load_digits()\\n# Create our X and y data n_samples = len(mnist.images) X = mnist.images.reshape((n_samples, -1)) y = mnist.target\\n# Split the data into 70% training data and 30% test data X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\\n# Train the scaler, which standarizes all the features to have mean=0 and unit variance sc = StandardScaler() sc.fit(X_train)\\n# Apply the scaler to the X training data X_train_std = sc.transform(X_train)\\n# Apply the SAME scaler to the X test data X_test_std = sc.transform(X_test)\\n# Create a single-layer perceptron object with the parameters: 40 iterations (epochs) over the data, and a learning rate of 0.1 ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0) # Create a multilayer perceptron object mppn = MLPClassifier(solver=\\'lbfgs\\', alpha=1e-5, hidden_layer_sizes=(256, 512, 128), random_state=1)\\n# Train the perceptrons ppn.fit(X_train_std, y_train) mppn.fit(X_train_std, y_train)\\n# Apply the trained perceptrons on the X data to make predicts for the y test data y_pred = ppn.predict(X_test_std) multi_y_pred = mppn.predict(X_test_std)\\n# View the accuracies of the model, which is: 1 - (observations predicted wrong / total observations) print(\\'Single-layer perceptron accuracy: %.4f\\' % accuracy_score(y_test, y_pred)) print(\\'Multilayer perceptron accuracy: %.4f\\' % accuracy_score(y_test, multi_y_pred))\\nВывод:\\nSingle-layer perceptron accuracy: 0.9574 Multilayer perceptron accuracy: 0.9759\\nПример использования с помощью tensorflow[6]\\nБудем классифицировать цифры из того же датасета MNIST.\\n# Load required libraries import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data\\n#Load MNIST dataset mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\\n#placeholder for test data x = tf.placeholder(tf.float32, [None, 784]) #placeholder for weights and bias W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) #tensorflow model y = tf.nn.softmax(tf.matmul(x, W) + b) #loss function y_ = tf.placeholder(tf.float32, [None, 10]) cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\\n#gradient descent step train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\\ninit = tf.initialize_all_variables() sess = tf.Session() sess.run(init) for i in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) print(\"Accuracy: %s\" % sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\\nВывод:\\nAccuracy: 0.9164\\nНа рисунке справа показаны четыре типичных изображения, на которых классификаторы ошибаются. Согласитесь, случаи действительно тяжелые.\\nПример на языке Java\\nПример классификации с применением\\nweka.classifiers.functions.MultilayerPerceptron[7]\\nMaven зависимость:\\n<dependency> <groupId>nz.ac.waikato.cms.weka</groupId> <artifactId>weka-stable</artifactId> <version>3.8.0</version> </dependency>\\nimport weka.classifiers.functions.MultilayerPerceptron; import weka.core.converters.CSVLoader; import java.io.File;\\n// read train & test datasets and build MLP classifier var trainds = new DataSource(\"etc/train.csv\"); var train = trainds.getDataSet(); train.setClassIndex(train.numAttributes() - 1); var testds = new DataSource(\"etc/test.csv\"); var test = testds.getDataSet(); test.setClassIndex(test.numAttributes() - 1); var mlp = new MultilayerPerceptron(); mlp.buildClassifier(train); // Test the model var eTest = new Evaluation(train); eTest.evaluateModel(mlp, test); // Print the result à la Weka explorer: var strSummary = eTest.toSummaryString(); System.out.println(strSummary);\\nСм. также\\n- Сверточные нейронные сети\\n- Рекуррентные нейронные сети\\n- Рекурсивные нейронные сети[на 28.01.19 не создан]\\nПримечания\\nИсточники информации\\n- Сергей Николенко, Артур Кадурин, Екатерина Архангельская. Глубокое обучение. Погружение в мир нейронных сетей. — «Питер», 2018. — С. 93-123.\\n- Нейронные сети — учебник', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='d1ebecc4-7bc8-4fcb-bcea-7d5475fa752f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f4abc6ec2e3939838ee45a43964b4f3be2a2abc6c7761da4cf7e085c0e221252', text='Обратное распространение ошибки\\nМетод обратного распространения ошибок (англ. backpropagation) — метод вычисления градиента, который используется при обновлении весов в нейронной сети.\\nСодержание\\nОбучение как задача оптимизацииРассмотрим простую нейронную сеть без скрытых слоев, с двумя входными вершинами и одной выходной, в которых каждый нейрон использует линейную функцию активации, (обычно, многослойные нейронные сети используют нелинейные функции активации, линейные функции используются для упрощения понимания) которая является взвешенной суммой входных данных.\\nИзначально веса задаются случайно. Затем, нейрон обучается с помощью тренировочного множества, которое в этом случае состоит из множества троекгде и — это входные данные сети и — правильный ответ. Начальная сеть, приняв на вход и , вычислит ответ , который вероятно отличается от . Общепринятый метод вычисления несоответствия между ожидаемым и получившимся ответом — квадратичная функция потерь:\\n- где ошибка.\\nВ таком случае, выходное значение нейрона — взвешенная сумма всех его входных значений:\\nгдеи — веса на ребрах, соединяющих входные вершины с выходной. Следовательно, ошибка зависит от весов ребер, входящих в нейрон. И именно это нужно менять в процессе обучения. Распространенный алгоритм для поиска набора весов, минимизирующего ошибку — градиентный спуск. Метод обратного распространения ошибки используется для вычисления самого \"крутого\" направления для спуска.\\nДифференцирование для однослойной сети\\nМетод градиентного спуска включает в себя вычисление дифференциала квадратичной функции ошибки относительно весов сети. Обычно это делается с помощью метода обратного распространения ошибки. Предположим, что выходной нейрон один, (их может быть несколько, тогда ошибка — это квадратичная норма вектора разницы) тогда квадратичная функция ошибки:\\n- где — квадратичная ошибка, — требуемый ответ для обучающего образца, — действительный ответ сети.\\nМножительдобавлен чтобы предотвратить возникновение экспоненты во время дифференцирования. На результат это не повлияет, потому что позже выражение будет умножено на произвольную величину скорости обучения (англ. learning rate).\\nДля каждого нейрона, его выходное значение определено как\\nВходные значениянейрона — это взвешенная сумма выходных значений предыдущих нейронов. Если нейрон в первом слое после входного, то входного слоя — это просто входные значения сети. Количество входных значений нейрона . Переменная обозначает вес на ребре между нейроном предыдущего слоя и нейроном текущего слоя.\\nФункция активациинелинейна и дифференцируема. Одна из распространенных функций активации — сигмоида:\\nу нее удобная производная:\\nНаходим производную ошибки\\nВычисление частной производной ошибки по весамвыполняется с помощью цепного правила:\\nТолько одно слагаемое взависит от , так что\\nЕсли нейрон в первом слое после входного, то— это просто .\\nПроизводная выходного значения нейронапо его входному значению — это просто частная производная функции активации (предполагается что в качестве функции активации используется сигмоида):\\nПо этой причине данный метод требует дифференцируемой функции активации. (Тем не менее, функция ReLU стала достаточно популярной в последнее время, хоть и не дифференцируема в 0)\\nПервый множитель легко вычислим, если нейрон находится в выходном слое, ведь в таком случаеи\\nТем не менее, еслипроизвольный внутренний слой сети, нахождение производной по менее очевидно.\\nЕсли рассмотретькак функцию, берущую на вход все нейроны получающие на вход значение нейрона ,\\nи взять полную производную по, то получим рекурсивное выражение для производной:\\nСледовательно, производная поможет быть вычислена если все производные по выходным значениям следующего слоя известны.\\nЕсли собрать все месте:\\nи\\nЧтобы обновить весиспользуя градиентный спуск, нужно выбрать скорость обучения, . Изменение в весах должно отражать влияние на увеличение или уменьшение в . Если , увеличение увеличивает ; наоборот, если , увеличение уменьшает . Новый добавлен к старым весам, и произведение скорости обучения на градиент, умноженный на , гарантирует, что изменения будут всегда уменьшать . Другими словами, в следующем уравнении, всегда изменяет в такую сторону, что уменьшается:\\nАлгоритм\\n- - скорость обучения\\n- - коэффициент инерциальности для сглаживания резких скачков при перемещении по поверхности целевой функции\\n- — обучающее множество\\n- — количество повторений\\n- — функция, подающая x на вход сети и возвращающая выходные значения всех ее узлов\\n- — количество слоев в сети\\n- — множество нейронов в слое i\\n- — множество нейронов в выходном слое\\nfun BackPropagation: init repeat : for = to : = for : = for = to : for : = for : = = return\\nНедостатки алгоритма\\nНесмотря на многочисленные успешные применения обратного распространения, оно не является универсальным решением. Больше всего неприятностей приносит неопределённо долгий процесс обучения. В сложных задачах для обучения сети могут потребоваться дни или даже недели, она может и вообще не обучиться. Причиной может быть одна из описанных ниже.\\nПаралич сети\\nВ процессе обучения сети значения весов могут в результате коррекции стать очень большими величинами. Это может привести к тому, что все или большинство нейронов будут функционировать при очень больших выходных значениях, а производная активирующей функции будет очень мала. Так как посылаемая обратно в процессе обучения ошибка пропорциональна этой производной, то процесс обучения может практически замереть.\\nЛокальные минимумы\\nГрадиентный спуск с обратным распространением ошибок гарантирует нахождение только локального минимума функции; также, возникают проблемы с пересечением плато на поверхности функции ошибки.\\nПримечания\\n- Алгоритм обучения многослойной нейронной сети методом обратного распространения ошибки\\n- Neural Nets\\n- Understanding backpropagation\\nСм. также\\n- Нейронные сети, перцептрон\\n- Стохастический градиентный спуск\\n- Настройка глубокой сети\\n- Практики реализации нейронных сетей', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='262f168f-3946-4238-b9ea-529549af14bb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='18cef655e66420ffa7fc8ecdfe81473743428ed1f19a6ee9f2b4e4244a9c24ed', text='Практики реализации нейронных сетей\\nСодержание\\nАугментация данных\\nПри глубоком обучении иногда можно столкнуться с ситуацией, когда набор данных имеет ограниченный размер. Но чтобы получить лучшие результаты обобщение модели, необходимо иметь больше данных, в том числе и различные их вариации. То есть необходимо увеличить размер исходного набора искусственным образом, и это можно сделать с помощью аугментации данных.\\n|Определение:\\n|Аугментация данных (англ. data augmentation) — это методика создания дополнительных данных из имеющихся данных.\\nЧаще всего, проблема ограниченного набора данных возникает при решении задач, связанных с обработкой изображений. Следующие способы аугментации изображений являются самыми популярными:\\n- Отображение по вертикали или горизонтали (англ. flipping).\\n- Поворот изображения на определенный угол (англ. rotation).\\n- Создание отступа (англ. padding).\\n- Вырезание части изображения (англ. cropping).\\n- Добавление шума (англ. adding noise).\\n- Манипуляции с цветом (англ. color jittering).\\nТакже, можно применять различные комбинации, к примеру, вырезать часть изображения, повернуть его и изменить цвет фона.\\nПродвинутыми способами аугментации данных является семейство порождающих состязательных сетей.\\nДропаут\\nОдной из проблем глубокого обучения нейронных сетей является переобучение. И метод дропаут — популярный способ решения этой проблемы, благодаря простому алгоритму и хорошим практическим результатам.\\n|Определение:\\n|Дропаут (англ. dropout) — метод регуляризации нейронной сети для предотвращения переобучения.\\nВ обычной нейронной сети явление переобучения появляется из-за так называемой совместной адаптации (англ. co-adaptation), то есть при обновлении весов нейрона, во время обучения методом обратного распространения ошибки, учитывается деятельность остальных нейронов с целью минимизировать функцию потерь. Поэтому веса нейронов могут меняться, исправляя при этом ошибки других нейронов. Метод дропаута как раз предотвращает эту адаптацию.\\nАлгоритм дропаут\\nРассмотрим слой нейронной сети состоящий изнейронов. Метод дропаут выключает нейрон с вероятностью , соответственно, оставляет включенным с вероятностью , причем вероятность выключения любого нейрона сети одинакова.\\nПусть— функция активации, тогда применение дропаута для -ого нейрона выглядит так: ,\\nгде вероятность.\\nДанная формула применяется на этапе обучения модели. Но так как на этом этапе нейрон остается в сети с вероятностью, на этапе тестирования необходимо эмулировать поведение нейронной сети, использованного при обучении. Для этого результат выходного значения функции активации умножается на коэффициент , то есть на этапе тестирования: .\\nОбратный дропаут\\nОбратный дропаут (англ. inverted dropout) отличается от обычного тем, что умножение на коэффициент происходит на этапе обучения, причем этот коэффициент равен обратной вероятности того, что нейрон останется в сети:. А на этапе тестирования выходное значение нейрона остается таким же, как и в методе обратного распространения ошибки.\\nТаким образом, выходное значение-ого нейрона на этапе обучения: , на этапе тестирования: .\\nОбратная модификация дропаута на практике используется чаще обычной, потому что в ней не нужно менять каждый раз модель для проведения этапа тестирования.\\nФункции активации\\nОдним из важнейших аспектов глубокой нейронной сети являются функции активации.\\n|Определение:\\n|Функция активации (англ. activation function)определяет выходное значение нейрона в зависимости от результата взвешенной суммы входов и порогового значения.\\nРассмотрим нейрон, у которого взвешенная сумма входов:, где и — вес и входное значение -ого входа, а — смещение. Полученный результат передается в функцию активации, которая решает рассматривать этот нейрон как активированный, или его можно игнорировать.\\nСтупенчатая функция\\nСтупенчатая функция (англ. binary step function) является пороговой функцией активации. То есть еслибольше или меньше некоторого значения, то нейрон становится активированным. Такая функция отлично работает для бинарной классификации. Но она не работает, когда для классификации требуется большее число нейронов и количество возможных классов больше двух.\\nЛинейная функция\\nЛинейная функция (англ. linear function) представляет собой прямую линию, то есть, а это значит, что результат этой функции активации пропорционален переданному аргументу. В отличии от предыдущей функции, она позволяет получить диапазон значений на выходе, а не только бинарные 0 и 1, что решает проблему классификации с большим количеством классов. Но у линейной функции есть две основных проблемы:\\n- Невозможность использования метода обратного распространения ошибки. Так как в основе этого метода обучения лежит градиентный спуск, а для того чтобы его найти, нужно взять производную, которая для данной функции активации — константа и не зависит от входных значений. То есть при обновлении весов нельзя сказать улучшается ли эмпирический риск на текущем шаге или нет.\\n- Рассмотрим нейронную сеть с несколькими слоями с данной функцией активации. Так как для каждого слоя выходное значение линейно, то они образуют линейную комбинацию, результатом которой является линейная функция. То есть финальная функция активации на последнем слое зависит только от входных значений на первом слое. А это значит, что любое количество слоев может быть заменено всего одним слоем, и, следовательно, нет смысла создавать многослойную сеть.\\nГлавное отличие линейной функции от остальных в том, что ее область значений не ограничена:. Следовательно, ее нужно использовать, когда выходное значение нейрона должно , а не ограниченному интервалу.\\nСигмоидная функция\\nСигмоидная функция (англ. sigmoid function), которую также называет логистической (англ. logistic function), является гладкой монотонно возрастающей нелинейной функцией:. И так как эта функция нелинейна, то ее можно использовать в нейронных сетях с множеством слоев, а также обучать эти сети методом обратного распространения ошибки. Сигмоида ограничена двумя горизонтальными асимптотами и , что дает нормализацию выходного значения каждого нейрона. Кроме того, для сигмоидной функции характерен гладкий градиент, который предотвращает \"прыжки\" при подсчете выходного значения. Помимо всего этого, у этой функции есть еще одно преимущество, для значений и , \"прижимается\" к одной из асимптот, что позволяет делать четкие предсказания классов.\\nНесмотря на множество сильных сторон сигмоидной функции, у нее есть значительный недостаток. Производная такой функции крайне мала во всех точках, кроме сравнительно небольшого промежутка. Это сильно усложняет процесс улучшения весов с помощью градиентного спуска. Более того, эта проблема усугубляется в случае, если модель содержит много слоев. Данная проблема называется проблемой исчезающего градиента.[1]\\nЧто касается использования сигмоидной функции, то ее преимущество над другими — в нормализации выходного значения. Иногда, это бывает крайне необходимо. К примеру, когда итоговое значение слоя должно представлять вероятность случайной величины. Кроме того, эту функцию удобно применять при решении задачи классификации, благодаря свойству \"прижимания\" к асимптотам.\\nФункция гиперболического тангенса\\nФункция гиперболического тангенса (англ. hyperbolic tangent) имеет вид:. Эта функция является скорректированной сигмоидной функцей , то есть она сохраняет те же преимущества и недостатки, но уже для диапазона значений .\\nОбычно,является предпочтительнее сигмоиды в случаях, когда нет необходимости в нормализации. Это происходит из-за того, что область определения данной функции активации центрирована относительно нуля, что снимает ограничение при подсчете градиента для перемещения в определенном направлении. Кроме того, производная гиперболического тангенса значительно выше вблизи нуля, давая большую амплитуду градиентному спуску, а следовательно и более быструю сходимость.\\nФункция ReLU\\nRectified Linear Unit — это наиболее часто используемая функция активации при глубоком обучении. Данная функция возвращает 0, если принимает отрицательный аргумент, в случае же положительного аргумента, функция возвращает само число. То есть она может быть записана как. На первый взгляд может показаться, что она линейна и имеет те же проблемы что и линейная функция, но это не так и ее можно использовать в нейронных сетях с множеством слоев. Функция ReLU обладает несколькими преимущества перед сигмоидой и гиперболическим тангенсом:\\n- Очень быстро и просто считается производная. Для отрицательных значений — 0, для положительных — 1.\\n- Разреженность активации. В сетях с очень большим количеством нейронов использование сигмоидной функции или гиперболического тангенса в качестве активационный функции влечет активацию почти всех нейронов, что может сказаться на производительности обучения модели. Если же использовать ReLU, то количество включаемых нейронов станет меньше, в силу характеристик функции, и сама сеть станет легче.\\nУ данной функции есть один недостаток, называющийся проблемой умирающего ReLU[2]. Так как часть производной функции равна нулю, то и градиент для нее будет нулевым, а то это значит, что веса не будут изменяться во время спуска и нейронная сеть перестанет обучаться.\\nФункцию активации ReLU следует использовать, если нет особых требований для выходного значения нейрона, вроде неограниченной области определения. Но если после обучения модели результаты получились не оптимальные, то стоит перейти к другим функциям, которые могут дать лучший результат.\\nФункция Leaky ReLU\\nОдной из проблем стандартного ReLU является затухающий, а именно нулевой, градиент при отрицательных значениях. При использовании обычного ReLU некоторые нейроны умирают, а отследить умирание нейронов не просто. Чтобы решить эту проблему иногда используется подход ReLU с «утечкой» (leak) — график функции активации на отрицательных значениях образует не горизонтальную прямую, а наклонную, с маленьким угловым коэффициентом (порядка 0,01). То есть она может быть записана как. Такое небольшое отрицательное значение помогает добиться ненулевого градиента при отрицательных значениях. Однако, функция Leaky ReLU имеет некоторые недостатки:\\n- Сложнее считать производную, по сравнению со стандартным подходом (так как значения уже не равны нулю), что замедляет работу каждой эпохи.\\n- Угловой коэффициент прямой также является гиперпараметром, который надо настраивать.\\n- На практике, результат не всегда сильно улучшается относительно ReLU.\\nСтоит отметить, что помимо проблемы умирающих нейронов, у ReLU есть и другая — проблема затухающего градиента[на 03.01.20 не создан]. При слишком большом количестве слоев градиент будет принимать очень маленькое значение, постепенно уменьшаясь до нуля. Из-за этого нейронная сеть работает нестабильно и неправильно. Leaky ReLU (LReLU) решает первую проблему, но в по-настоящему глубоких сетях проблема затухания градиента все еще встречается и при использовании этого подхода.\\nНа практике LReLU используется не так часто. Практический результат использования LReLU вместо ReLU отличается не слишком сильно. Однако в случае использования Leaky требуется дополнительно настраивать гиперпараметр (уровень наклона при отрицательных значениях), что требует определенных усилий. Еще одной проблемой является то, что результат LReLU не всегда лучше чем при использовании обычного ReLU, поэтому чаще всего такой подход используют как альтернатива. Довольно часто на практике используется PReLU (Parametric ReLU), который позволяет добиться более значительных улучшений по сравнению с ReLU и LReLU. Также, в случае параметрической модификации ReLU, угол наклона не является гиперпараметром и настраивается нейросетью.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='f96831a2-3c6c-4812-b0df-01f7ef0e79a7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4ac7f3481a50ac790724834e9d1ad472e8424ebb1055e395db552b098334705e', text='Графовые нейронные сети\\nГрафовая нейронная сеть (англ. Graph Neural Network, GNN) — тип нейронной сети, которая напрямую работает со структурой графа. Типичным применением GNN является классификация узлов. Концепция графовой нейронной сети была впервые предложена в 2009 году в работе [1], которая расширила существующие нейронные сети для обработки данных, представленных в графовых областях.\\nСодержание\\nИдея\\nПри работе с естественными языками, обработке и анализе изображений, построении моделей веб-сетей и еще широком спектре прикладных задач, бывает удобно представлять данные в виде графов:\\nОднако для традиционных методов машинного обучения необходимо предварительно преобразовывать графово структурированные данные в другие структуры данных, к примеру числовой вектор. Такой подход может привести к потере части информации, заключающейся во взаиморасположении узлов сети.\\n|Определение:\\n|Граф — это структура данных, состоящая из двух компонентов: вершин и ребер. Графописывается множеством вершин (узлов) и ребер , которые он содержит .\\nИспользование GNN позволяет работать с данными графов, без предварительной обработки. Такой подход позволяет сохранить топологические отношения между узлами графа.\\nВ основе GNN заложен механизм распространения информации. Граф обрабатывается набором модулей, которые связаны между собой в соответствии со связями графа. Также каждый из модулей связан с узлами графа. В процессе обучения, модули обновляют свои состояния и обмениваются информацией. Это продолжается до тех пор, пока модули не достигнут устойчивого равновесия (для того, чтобы была гарантия того, что такое устойчивое состояние существует, этот механизм распространения ограничен). Выходные данные GNN вычисляются на основе состояния модуля на каждом узле.\\nОписание\\nВ графе каждый узел определяется его признаками и связанными узлами. Целью GNN является изучение состояния встраивания, которое содержит информацию об окрестностях для каждого узла. Состояние встраивания — это s-мерный вектор из вершины , который может быть использован для получения выхода (метки узла).\\nПусть— это параметрическая функция, называемая локальной переходной функцией, которая является общей для всех узлов и обновляет состояние узла в соответствии с входной окрестностью. Также пусть — локальная выходная функция, которая описывает, как выход был производен. Тогда и определяются следующим образом:\\nгдеявляются признаками , признаками его ребер, состояний, и признаками узлов в окрестностях соответственно.\\nПустьи — это векторы, построенные путем укладки всех состояний, всех выходных данных, всех признаков и всех признаков узлов соответственно. Тогда мы можем представить уравнения в более компактной форме:\\nгде— это глобальная функция перехода, а — глобальная выходная функция, которая является сложенной версией и для всех узлов в графе соответственно. Значение является фиксированным и однозначно определяется в предположением о том, что — это карта сжатия.\\nС учетом теоремы Банаха о неподвижной точке GNN использует следующую классическую итерационную схему для вычисления состояния:, где обозначает -ую итерацию . Динамическая система из этого уравнения сходится экспоненциально быстро к решению уравнения для любого начального значения . Стоит отметить, что вычисления описанные в и , могут быть интерпретированы как нейронные сети с прямой связью.\\nСледующие задачей становится поиск параметрови . С помощью целевой информации ( для конкретного узла) для контроля, функция потерь может быть вычислена следующим образом:\\nгде— это число контролируемых узлов. Алгоритм обучения основан на стратегии градиентного спуска и состоит из следующих шагов:\\n- Состояния итеративно обновляются до времени . Они стремятся к фиксированному значению .\\n- Градиент весов вычисляется из функции потерь.\\n- Веса обновляются в соответствии с градиентом, вычисленным на последнем шаге.\\nРазвитие\\nВ последние годы системы, основанные на вариантах графовых нейронных сетей, таких как GCN (Graph Convolutional Network)[2], GAT (Graph Attention Network)[3], GGNN (Gated Graph Neural Network)[4], продемонстрировали высокую производительность при решении многих задач.\\nДля тестирования алгоритмов часто используются датасеты наборов данных сети цитирования, такие как Citeseer, Cora and Pubmed. В них узлы — это документы, а ребра — это ссылки на цитаты. GCN на этих данных удается добиться точности в районе 70.3%, 81.5%, 79.0% соответственно, а результаты GAC составляют 83.0%, 72.5%, 79.0%.\\nПри решении же реальных задач, данные алгоритмы применяются в следующих областях:\\n- GCN применяют в задачах классификации текстовых данных, изображений, болезней и прогнозировании побочных эффектов;\\n- GAT используют для классификации текста, обнаружения объектов на изображениях, задач комбинаторной оптимизации;\\n- GGNN применяют для нейронного машинного перевода, для анализа социальных отношений.\\nОграничения\\nНесмотря на то, что экспериментальные результаты показали, что GNN является мощной архитектурой для моделирования структурных данных, существует еще несколько ограничений для обычного GNN.\\nВо-первых, итеративно обновлять скрытые состояния узлов для фиксированной точки неэффективно. Если ослабить предположение о неподвижной точке, мы можем спроектировать многослойную GNN, чтобы получить стабильное представление узла и его окрестности.\\nВо-вторых, GNN использует одни и те же параметры в итерации, в то время как большинство популярных нейронных сетей используют разные параметры в разных слоях, которые служат в качестве метода извлечения иерархических признаков.\\nВ-третьих, есть также некоторые информативные признаки на краях, которые не могут быть эффективно смоделированы обычной GNN. Например, ребра в графе знаний имеют тип отношений, и распространение сообщения через разные ребра должно быть различным в зависимости от их типов. Кроме того, поиск скрытых состояния ребер, также является важной проблемой.\\nНаконец, нецелесообразно использовать фиксированные точки, если мы сосредоточимся на представлении узлов вместо графиков, поскольку распределение представления в фиксированной точке будет гораздо более гладким по значению и менее информативным для различения каждого узла.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='d974d67e-d05b-4003-9f92-7cbce5d5c6c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='dfe77244251ea9be6cd61a0c7e67ab8729c958a1a05efcaf7b16b0664b4116af', text=\"Рекурсивные нейронные сети\\nРекурсивная нейронная сеть — тип глубокой нейронной сети, сформированный при применении одних и тех же наборов весов рекурсивно через структуру в виде дерева, чтобы сделать скалярное или структурированное предсказание над входными данными переменного размера через обход дерева в топологическом порядке.[1]\\nСодержание\\nПрименение\\nМодели рекурсивных сетей используют иерархические структуры образцов при обучении, поэтому они преуспели в следующих областях:\\n- Обработка естественного языка. Модели используются для предсказания тональности предложения [2]:\\n- Обработка изображений с природными ландшафтами[3].\\nОписание\\nПри обучении последовательных структур и деревьев в задачах обработки естественного языка, фразы и предложения моделируются через векторное представление слов.\\nБазовая структура сети является бинарным деревом, состоящим из родительского компонента (корня), и дочерних компонентов (листьев). Каждый компонент - набор нейронов, размер которого зависит от сложности входных данных. Входная последовательность данных подаётся на листья, а корень использует классификатор для определения класса и меры (score)\\nРекурсивная нейронная сеть использует следующую формулу для вычисления родительского вектора:\\n- — дочерние векторы\\n- — обученная матрица весов,\\n- — нелинейную функция активации типа гиперболического тангенса\\n- - cмещение, оно может быть добавлено в качестве дополнительного столбца к , если к конкатенации входных векторов добавляется 1.\\nРодительские векторы должны иметь одинаковую размерность, чтобы быть рекурсивно совместимыми и использоваться в качестве входных данных для следующей композиции.\\nПоследующие шаги получают на вход меру предыдущего корня и следующее слово последовательности, таким образом пока в сети не будет сформировано дерево со всеми словами в последовательности.\\nДеревья могут иметь разную структуру, выбор лучшей подструктуры дерева для сети основывается на их мере. Мера дерева - сумма мер на каждом узле:\\nПосле выбора структуры, сеть классифицирует части последовательности. Вероятность принадлежности к классу вектора p вычисляется классификатором с помощью функции Softmax:\\nЗдесь— матрица классификаций. Основной задачей и разницей между моделями будет вычисление скрытых векторов снизу вверх.\\nАлгоритм обратного распространения ошибки\\nВ рекурсивных нейронных сетях используется алгоритм обратного распространения ошибки (backpropagation) с некоторыми отличиями, вытекающими из древовидной структуры и рекурсии:\\n- Сумма производных матрицы W от всех узлов. Можно предположить, что она разная на каждом узле, однако если взять отдельные производные от каждого вхождения, то получится то же самое.\\n- Разделение производных в каждом узле. Во время прямого распространения, родительский вектор считается через дочерние узлы по формуле выше. Следовательно, ошибки должны быть вычислены относительно каждого из них, причём ошибка каждого дочернего узла является n-мерной\\nРекурсивные и рекуррентные нейронные сети\\nРекуррентная нейронная сеть представляет собой рекурсивную сеть со специфической структурой - в виде линейной цепочки. Рекурсивные сети работают на структурах общего типа, включающих иерархию, рекуррентные сети работают исключительно на линейной прогрессии во времени, связывая предыдущий момент времени со следующим через скрытый нейронный слой.[4]\\nПримеры кода\\nОпишем здесь пример построения сети, опустив построение дерева. Полный листинг кода для анализа тональности текста на PyTorch (из статьи Socher et al.(2013c))\\nclass RNTN(nn.Module): def __init__(self, word2index, hidden_size, output_size): super(RNTN,self).__init__() # Для рекурсивной нейронной сети обязательно нужно для векторное представление слов self.word2index = word2index self.embed = nn.Embedding(len(word2index), hidden_size) self.V = nn.ParameterList([nn.Parameter(torch.randn(hidden_size * 2, hidden_size * 2)) for _ in range(hidden_size)]) # Тензор self.W = nn.Parameter(torch.randn(hidden_size * 2, hidden_size)) self.b = nn.Parameter(torch.randn(1, hidden_size)) # bias self.W_out = nn.Linear(hidden_size, output_size) # инициализация весов def init_weight(self): nn.init.xavier_uniform(self.embed.state_dict()['weight']) nn.init.xavier_uniform(self.W_out.state_dict()['weight']) for param in self.V.parameters(): nn.init.xavier_uniform(param) nn.init.xavier_uniform(self.W) self.b.data.fill_(0) # прямое распространение def tree_propagation(self, node): recursive_tensor = OrderedDict() current = None if node.isLeaf: tensor = Variable(LongTensor([self.word2index[node.word]])) if node.word in self.word2index.keys() \\\\ else Variable(LongTensor([self.word2index['<UNK>']])) current = self.embed(tensor) # 1xD else: recursive_tensor.update(self.tree_propagation(node.left)) recursive_tensor.update(self.tree_propagation(node.right)) concated = torch.cat([recursive_tensor[node.left], recursive_tensor[node.right]], 1) # 1x2D xVx = [] for i, v in enumerate(self.V): xVx.append(torch.matmul(torch.matmul(concated, v), concated.transpose(0, 1))) xVx = torch.cat(xVx, 1) # 1xD Wx = torch.matmul(concated, self.W) # 1xD current = F.tanh(xVx + Wx + self.b) # 1xD recursive_tensor[node] = current return recursive_tensor\\ndef forward(self, Trees, root_only=False): propagated = [] if not isinstance(Trees, list): Trees = [Trees] for Tree in Trees: recursive_tensor = self.tree_propagation(Tree.root) if root_only: recursive_tensor = recursive_tensor[Tree.root] propagated.append(recursive_tensor) else: recursive_tensor = [tensor for node,tensor in recursive_tensor.items()] propagated.extend(recursive_tensor) propagated = torch.cat(propagated) # (num_of_node in batch, D) return F.log_softmax(self.W_out(propagated),1)\\nОбучение\\nHIDDEN_SIZE = 30 BATCH_SIZE = 20 EPOCH = 20 LR = 0.01 LAMBDA = 1e-5 RESCHEDULED = False for epoch in range(EPOCH): losses = [] # learning rate annealing if RESCHEDULED == False and epoch == EPOCH // 2: LR *= 0.1 optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=LAMBDA) # L2 нормализация RESCHEDULED = True for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)): if ROOT_ONLY: labels = [tree.labels[-1] for tree in batch] labels = Variable(LongTensor(labels)) else: labels = [tree.labels for tree in batch] labels = Variable(LongTensor(flatten(labels))) model.zero_grad() preds = model(batch, ROOT_ONLY) loss = loss_function(preds, labels) losses.append(loss.data.tolist()[0]) loss.backward() optimizer.step() if i % 100 == 0: print('[%d/%d] mean_loss : %.2f' % (epoch, EPOCH, np.mean(losses))) losses = []\\nПримеры кода на TensorFlow:\\n- https://github.com/bogatyy/cs224d/tree/master/assignment3\\n- https://gist.github.com/anj1/504768e05fda49a6e3338e798ae1cddd\\nCм. также\\nПримечания\\n- ↑ 7 архитектур нейронных сетей для решения задач NLP\\n- ↑ Richard Socher, Cliff Chiung-Yu Lin, Andrew Y. Ng, Christopher D. Manning. Parsing Natural Scenes and Natural Language with Recursive Neural Networks\\n- ↑ Richard Socher, Cliff Chiung-Yu Lin, Andrew Y. Ng, Christopher D. Manning. Parsing Natural Scenes and Natural Language with Recursive Neural Networks\\n- ↑ Рекурсивные нейронные сети. Википедия\\nИсточники\\n- [1] - Richard Socher, Alex Perelygin, Jean Y. Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, Christopher Potts. Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank. Stanford University, Stanford\\n- [2] - Richard Socher. Wrap up: LSTMs and Recursive Neural Networks\\n- [3] - Рекурсивные нейронные сети. Википедия\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='2044aefd-3ff2-416b-b3fa-b772996c9cbf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9bd54610fe580b17d5277f2739c0b0b03cdbb3e8f7edf664a7f7a4d9e1f714d0', text='Глубокое обучение\\nГлубокое обучение (англ. deep learning) — совокупность широкого семейства методов машинного обучения, основанных на имитации работы человеческого мозга в процессе обработки данных и создания паттернов, используемых для принятия решений[1]. Как правило, глубокое обучение предназначено для работы с большими объемами данных и использует сложные алгоритмы для обучения модели[2]. На больших датасетах глубокое обучение показывает более высокую точность результатов в сравнении с традиционным машинным обучением. Зависимость производительности (качества результатов) от объема данных представлена на рисунке ниже.\\nНесмотря на то, что данный раздел машинного обучения появился еще в 1980-х, до недавнего времени его применение было сильно ограничено из-за недостатка вычислительных мощностей существовавших компьютеров. Ситуация изменилась только в середине 2000-х.\\nНа создание моделей глубокого обучения оказали влияние некоторые процессы и паттерны, происходящие в биологических нейронных системах. Несмотря на это, данные модели во многом отличаются от биологического мозга (и в структуре и в функциях), что делает невозможным использование теорем и доказательств, применяющихся в нейробиологии.\\nСодержание\\nИстория\\n- 1943 — Искусственный нейрон Маккаллока — Питтса[3] — узел искусственной нейронной сети, являющийся упрощённой моделью естественного нейрона;\\n- 1949 — Принцип обучения нейронов Хебба[4] — изначально наблюдаемая причинно-следственная связь между активациями пре- и постсинаптического нейрона имеет тенденцию к усилению;\\n- 1957 — Модель перцептрона предложена Фрэнком Розенблаттом[5] — математическая или компьютерная модель восприятия информации мозгом;\\n- 1960 — Дельта-правило обучения перцептрона[6] — метод обучения перцептрона по принципу градиентного спуска по поверхности ошибки;\\n- 1969 — Выход книги Марвина Минска и Сеймура Паперта \"Перцептроны\"[7]. В данной книге математически показаны ограничения перцептронов;\\n- 1974 — Метод обратного распространения ошибки впервые предложен А. И. Галушкиным и Дж. Вербосом[8] — метод вычисления градиента, который используется при обновлении весов многослойного перцептрона;\\n- 1980 — Первая свёрточная нейронная сеть предложена Кунихико Фукусимой[9] — специальная архитектура искусственных нейронных сетей использующая некоторые особенности зрительной коры;\\n- 1982 — Рекуррентные нейронные сети предложены Д. Хопфилдом — вид нейронных сетей, где связи между элементами образуют направленную последовательность;\\n- 1991 — Проблема \"исчезающего\" градиента была сформулирована С. Хочрейтом. Проблема \"исчезающего\" градиента заключается в быстрой потере информации с течением времени;\\n- 1997 — Долгая краткосрочная память предложена С. Хочрейтом и Ю. Шмидхубером[10]. В отличие от традиционных рекуррентных нейронных сетей, LSTM-сеть хорошо приспособлена к обучению на задачах классификации, обработки и прогнозирования временных рядов в случаях, когда важные события разделены временными промежутками с неопределённой продолжительностью и границами;\\n- 1998 — Градиентный спуск для сверточных нейронных сетей предложен Я. Лекуном;\\n- 2006 — Публикации Г. Хинтона, С. Осиндера и Я. Теха об обучении сетей глубокого доверия. Данные публикации, а также их активное освещение в средствах массовой информации смогли привлечь внимание ученых и разработчиков со всего мира к глубоким сетям;\\n- 2012 — Предложение дропаута Г. Хинтоном, А. Крижевски и И. Шутковичем[11]. Дропаут (от англ. dropout) — метод регуляризации искусственных нейронных сетей, предназначен для предотвращения переобучения сети;\\n- 2012 — Нейронные сети побеждают в ImageNet Challenge[12]. Данное событие ознаменовало начало эры нейронных сетей и глубокого обучения;\\n- 2014 — Группа исследователей под руководством Зеппа Хохрейтера использовала глубокое обучение для определения токсичного воздействия лекарств и бытовых средств на окружающую среду. Данна работа была отмечена первым местом на соревновании \"Tox21 Data Challenge\"[13];\\n- 2016 — Программа для игры в го Google AlphaGo выиграла со счётом 4:1 у Ли Седоля, лучшего международного игрока в эту игру. AlphaGo, разработанная DeepMind, использует глубокое обучение с помощью многоуровневых нейронных сетей;\\n- 2018 — Глубокое обучение впервые используется для планирования лучевой терапии[14].\\nВ настоящее время глубокое обучение используется во многих сферах.\\nОпределение\\nГлубокое обучение — это класс алгоритмов машинного обучения, который:\\n- Использует многослойную систему нелинейных фильтров для извлечения признаков с преобразованиями. Каждый последующий слой получает на входе выходные данные предыдущего слоя;\\n- Может сочетать алгоритмы обучения с учителем[на 28.01.19 не создан] (пример — классификация) и без учителя [на 28.01.19 не создан] (пример — анализ образца);\\n- Формирует в процессе обучения слои выявления признаков на нескольких уровнях представлений, которые соответствуют различным уровням абстракции; при этом признаки организованы иерархически — признаки более высокого уровня являются производными от признаков более низкого уровня;\\nПрименения\\n- Распознавание речи[15]. Все основные коммерческие системы распознавания речи (например, Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu и iFlyTek) основаны на глубоком обучении;\\n- Компьютерное зрение[на 28.01.19 не создан]. На сегодняшний день системы распознавания образов основанные на глубоком обучении уже умеют давать более точные результаты, чем человеческий глаз[16];\\n- Обработка естественного языка[17]. Нейронные сети использовались для реализации языковых моделей еще с начала 2000-х годов. Изобретение LSTM помогло улучшить машинный перевод и языковое моделирование[18];\\n- Обнаружение новых лекарственных препаратов. К примеру, нейронная сеть AtomNet использовалась для прогнозирования новых биомолекул — кандидатов для лечения таких заболевания, как вирус Эбола и рассеянный склероз;\\n- Рекомендательные системы[19]. На сегодняшний день глубокое обучение применяется для изучения пользовательских предпочтений во многих доменах;\\n- Предсказание генномных онтологий в биоинформатике[20].\\nПолный список возможных применений глубокого обучения[21].\\nTransfer learning\\nTransfer learning — это применение к решению задачи знаний, извлеченных нейронной сетью при решении другой задачи.\\nГлубокие нейронные сети требуют больших объемов данных для сходимости обучения. Поэтому часто встречается ситуация, когда для решаемой задачи недостаточно данных для того, чтобы хорошо натренировать все слои нейросети. Для решения этой проблемы и используется transfer learning[22].\\nЧаще всего transfer learning выглядит следующим образом: к натренированной на определенную задачу нейросети добавляется еще несколько скрытый слоев, которые позволяют использовать уже полученные знания для решения более конкретной задачи. Например, знания, полученные при обучении распознаванию различных предметов, могут применяться при решении задачи распознавания еды.\\nФреймворки для глубокого обучения\\n- TensorFlow[23];\\n- Microsoft Cognitive Toolkit[24];\\n- Wolfram Mathematica[25];\\n- Keras[26];\\n- Deeplearning4j[27];\\n- Caffe[28];\\n- Torch/PyTorch[29];\\n- MXNet[30];\\n- Chainer[31].\\nСопоставление фреймворков, библиотек и отдельных программ для глубокого обучения[32].\\nСм. также\\n- Нейронные сети, перцептрон\\n- Сверточные нейронные сети\\n- Рекуррентные нейронные сети\\n- Обучение с подкреплением\\nПримечания\\n- ↑ Deep Learning, Investopedia\\n- ↑ The difference between neural networks and deep learning\\n- ↑ Artificial neuron, Wikipedia\\n- ↑ Hebbian theory, Wikipedia\\n- ↑ Perceptron, Wikipedia\\n- ↑ Delta rule, Wikipedia\\n- ↑ Perceptrons book, WIkipedia\\n- ↑ Backpropagation, Wikipedia\\n- ↑ Convolutional_neural_network, Wikipedia\\n- ↑ Long short-term memory, Wikipedia\\n- ↑ Dropout, Wikipedia\\n- ↑ ImageNet Challenge, Wikipedia\\n- ↑ Tox21 Data Challenge Winners\\n- ↑ Automatic treatment planning based on three‐dimensional dose distribution predicted from deep learning technique\\n- ↑ Speech recognition, Wikipedia\\n- ↑ Multi-column deep neural network for traffic sign classification\\n- ↑ Natural language processing, Wikipedia\\n- ↑ Sequence to Sequence Learning with Neural Networks\\n- ↑ Recommender system, Wikipedia\\n- ↑ Deep learning in bioinformatics, Wikipedia\\n- ↑ Applications of deep learning, Wikipedia\\n- ↑ Transfer Learning: как быстро обучить нейросеть на своих данных, habr.com\\n- ↑ TensorFlow, Wikipedia\\n- ↑ Microsoft Cognitive Toolkit, Wikipedia\\n- ↑ Wolfram Mathematica, Wikipedia\\n- ↑ Keras, Wikipedia\\n- ↑ Deeplearning4j, Wikipedia\\n- ↑ Caffe, Wikipedia\\n- ↑ PyTorch — ваш новый фреймворк глубокого обучения, habr\\n- ↑ MXNet, official site\\n- ↑ Chainer, official site\\n- ↑ Comparison of deep learning software, Wikipedia', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='3932dbff-dc96-4a7b-ad81-6a2d756f9480', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a9d00a45745177c6c9c56cbd91e90d359a53047765fab6ac68c1a7f98f92a34e', text='Настройка глубокой сети\\nГлубокая сеть состоит из нескольких слоев, где каждый слой организован таким образом, что каждый нейрон в одном слое получает свою копию всех выходных данных предыдущего слоя. Эта модель идеально подходит для определенных типов задач, например, обучение на ограниченном количестве более или менее неструктурированных параметров. Существует множество способов изменения параметров (весов) в такой модели, когда ей на вход поступают необработанные данные.\\nСодержание\\nИнициализация сети\\nПринцип выбора начальных значений параметров для слоев, составляющих модель очень важен: установка всех параметров в 0 будет серьезным препятствием для обучения, так как ни один из параметров изначально не будет активен. Присваивать параметрам значения из интервала инициализации сети может зависеть, достигнет она высочайшей производительности или вообще не будет сходиться. Даже если задача не предполагает такой крайности, удачно выбранный способ инициализации начальных параметров может значительно влиять на способность модели к обучению, так как он предустанавливает параметры модели с учетом функции потерь[1].— тоже обычно не лучший вариант — на самом деле, иногда (в зависимости от задачи и сложности модели) от правильной\\nВсегда можно выбрать случайно начальное приближение, но лучше выбирать определённым образом, ниже приведены самые распространённые из них:\\n- Метод инициализации Завьера (Xavier) (иногда — метод Glorot’а)[2]. Основная идея этого метода — упростить прохождение сигнала через слой во время как прямого, так и обратного распространения ошибки для линейной функции активации (этот метод также хорошо работает для сигмоидной функции, так как участок, где она ненасыщена, также имеет линейный характер). При вычислении параметров этот метод опирается на вероятностное распределение (равномерное или нормальное) с дисперсией, равной , где и — количества нейронов в предыдущем и последующем слоях соответственно;\\n- Метод инициализации Ге (He) — вариация метода Завьера, больше подходящая функции активации ReLU, компенсирующая тот факт, что эта функция возвращает нуль для половины области определения. А именно, в этом случае [3].\\nГраф вычислений\\nГлубокие сети являются особенной формой графа вычислений.\\nГраф вычислений — ориентированный граф, узлы которого соответствуют операциям или переменным. Переменные могут передавать свое значение в операции, а операции могут передавать свои результаты в другие операции. Таким образом, каждый узел в графе определяет функцию переменных.\\nЗначения, которые вводятся в узлы и выходят из узлов, называются тензорами (т.е. многомерными массивами). На рисунке 1 представлен граф вычислений для функции. В нейронах сетях функций имеют больше аргументов и сложнее, но смысл операций остаётся прежним.\\nПроцесс передачи значений от входных нейронов к выходным называется прямым распространением (от англ. Forward pass). После чего мы вычисляем ошибку обработанных сетью данных на выходном нейроне и, основываясь на её значении, делаем обратную передачу ошибки (Back propagation). Обратное распространение ошибки заключается в том, чтобы последовательно менять параметры нейронной сети, начиная с параметров выходного нейрона. Значения параметров будут меняться в сторону уменьшения ошибки.\\nПреимуществом такого представления функции является простота вычисления производных. Используя следующие правила вычисления частных производных:\\n- ;\\n- ;\\n- .\\nРассмотрим граф вычислений на рисунке 2 с поданными на вход значениями. Подсчёт производных по графу вычислений производим от значения функции к значениям независимых переменных-входов.\\n- ;\\n- , ;\\n- , .\\nГраф вычислений является частью нейронной сети, у которой — входные значения, — выходные с сети значения, — матрица параметров, приводящая значения предыдущего слоя к выходным значениям.\\nЗная производные, можно искать матрицы параметров градиентного спуска сдвигаемся в сторону градиента (при максимизации) или обратную ему (при минимизации) , где — функция потерь, а — параметры после -ой итерации, или его модификаций[4].(числа, на которые умножаются входные для этого слоя значения) с помощью\\nСпособы настройки параметров\\nНиже представлены различные вариации градиентного спуска (более подробное сравнение, применительно к данной задаче [7]). Градиентный спуск — итеративный алгоритм поиска минимума или максимума функции, метриками качества алгоритма этого семейства методов являются скорость сходимости и сходимость в глобальный оптимум. Методы имеют различные преимущества на различных функциях. Так например на рисунке 3 из локального минимума метод adam и метод Нестерова не могут достигнуть глобального, а в случае \"шаткого\" ландшафта (рисунок 4) эти методы сходятся быстрее.\\n- Метод стохастического градиентного спуска заключается в том, что алгоритм делает шаг постоянной величины в направлении, указанном градиентом в текущей точке: ;\\n- Модификация Momentum [8] запоминает скорость на предыдущем шаге и добавляет в раз меньшую величину на следующем шаге: , ;\\n- Метод Нестерова (англ. Nesterov accelerated gradient, NAG)[9] добавляет к методу Momentum идею \"заглядывания вперёд\", используя производную не в текущей точке, а в следующей (если бы мы продолжали двигаться в этом же направлении без измений): ;\\n- Adagrad имеет преимущество в плане обучения нейронных сетей в предположении, что процесс обучения должен сходится (т.е. не нужно сильно менять параметры сети, когда мы уже немного научились). В процессе обучения после каждого прецендента алгоритм будет уменьшать шаг за счёт суммы квадратов координат градиента предыдущих итераций[10]: , где — диагональная матрица, элементы которой, суммы квадратов координат градиента к -ой итерации алгоритма: ;\\n- RMSProp[11] основан на идее Adagrad\\'a, но с учётом того элементы матрицы могут быть большими величинами и начать препятствовать обучению. Для этого RMSProp делит шаг не на полную сумму градиентов, а на скользящую, т.е. , обновление параметров осталось таким же как в Adagrad : ;\\n- Adadelta[12] устраняет \"нефизичность\" методов Adagrad и RMSProp, добавка с градиентом в которых не имеет размерности параметров(точнее вообще безразмерна). Умножение этого слагаемого на любую величину правильной размерности — не самая хорошая идея. Используем разложение ряда Тейлора в точке с большим числом членов, тогда появится матрица вторых производных функции потерь: , расчёт которой повлечёт за собой дополнительные затраты на её расчёт (сами градиенты мы получаем сразу при обратном распространении ошибки), поэтому вместо неё можно брать приближение (из сложных выводов получаем необходимый множитель ), однако в данном случае знание предыдущей скорости не добавляет алгоритму \"инерции\" методов Momentum и NAG): , где ;\\n- Adam[13] сочетает в себе преимущества NAG и Adadelta над обычным градиентным спуском: , где и .\\nСравнение способов настройки параметров\\nРассмотрим график седловой функции с \"седлом\" в точке. Предположим, что в качестве начальной точки выбрана точка , где . На рисунке координата варьируется в пределах от до , координата , а координата . Рассмотрим работу описанных выше методов, примененных к данной оптимизируемой функции с данной начальной точкой:\\n- SGD (Стандартный градиентный спуск без оптимизаций) никак не учитывает тот факт, что по координате производная в данной точке пренебрежимо мала по сравнению с производной по . Поэтому через малое число итераций алгоритм сойдется в окрестности седловой точки и остановится, потому что производная в данной точке нулевая.\\n- Momentum. Так как добавится инерция, то спуск в сторону седловой точки будет значительно быстрее, чем в случае со стандартным градиентным спуском. Однако, оптимизируемая переменная будет еще долго колебаться в плоскости , накапливая градиенты. При этом колебания будут затухать из-за того, что параметр , но т.к. оптимизируемая переменная несколько раз отдалится от точки на достаточное расстояние, успеет накопиться значение производной по координате , достаточное для того чтобы выйти из локального минимума. Однако для этого потребуется большое число итераций, необходимое для того, чтобы производная по перестала преобладать над производной по .\\n- NAG. Эффект будет схожим с алгоритмом Momentum, однако спуск в плоскости будет происходить быстрее благодаря заглядыванию вперед.\\n- Adagrad. Изначально спуск будет происходить медленнее, чем при использовании SGD из-за нормирования градиента по всем координатам, однако метод сойдется в глобальном минимуме выбранной области графика.\\n- RMSProp. Изначально процесс оптимизации почти совпадает с Adagrad, но в области, где функция начинает сильно убывать, благодаря использованию скользящей суммы градиентов (то есть благодаря тому, что мы забываем старые изменения и больше учитываем новые) алгоритм RMSProp оптимизирует переменную быстрее, чем Adagrad.\\n- Adadelta. Использует все преимущества RMSProp, но при этом в данном случае сходится быстрее в раз.\\nСм.также\\n- Глубокое обучение\\n- Инициализация параметров глубокой сети\\n- Стохастический градиентный спуск\\n- Обратное распространение ошибки\\nПримечания\\n- ↑ Тонкая настройка нейронной сети, Habr\\n- ↑ Understanding the difficulty of training deep feedforward neural networks\\n- ↑ Delving Deep into Rectifiers\\n- ↑ Метод градиентного спуска\\n- ↑ Методы оптимизации нейронных сетей, Habr\\n- ↑ Методы оптимизации нейронных сетей, Habr\\n- ↑ Методы оптимизации нейронных сетей, Habr\\n- ↑ Momentum, Wikipedia\\n- ↑ Nesterov accelerated gradient\\n- ↑ AdaGrad\\n- ↑ RMSProp\\n- ↑ Adadelta\\n- ↑ Adam\\nИсточники информации\\n- Курс лекций по машинному обучению — Воронцов К.В.\\n- Riedmiller, M., & Braun, H. (1993). A direct adaptive method for faster backpropagation learning: The RPROP algorithm. In Neural Networks, 1993., IEEE International Conference on (pp. 586-591). IEEE.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='6476e954-1c32-4672-b000-0a34e7634ccc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8ff334fbfbf48105d2d4dc2ea95a2846ba48a15f96e4fcd9521ab167132407eb', text='Batch-normalization\\nПакетная нормализация (англ. batch-normalization) — метод, который позволяет повысить производительность и стабилизировать работу искусственных нейронных сетей. Суть данного метода заключается в том, что некоторым слоям нейронной сети на вход подаются данные, предварительно обработанные и имеющие нулевое математическое ожидание и единичную дисперсию. Впервые данный метод был представлен в [1].\\nСодержание\\n- 1 Идея\\n- 2 Описание метода\\n- 3 Обучение нейронных сетей с пакетной нормализацией\\n- 4 Пакетная нормализация в свёрточных сетях\\n- 5 Индивидуальная нормализация\\n- 6 Условная пакетная нормализация\\n- 7 Пример\\n- 8 Реализации\\n- 9 Модификации\\n- 10 См. также\\n- 11 Примечания\\n- 12 Источники информации\\nИдея\\nНормализация входного слоя нейронной сети обычно выполняется путем масштабирования данных, подаваемых в функции активации. Например, когда есть признаки со значениями отдо и некоторые признаки со значениями от до , то их необходимо нормализовать, чтобы ускорить обучение. Нормализацию данных можно выполнить и в скрытых слоях нейронных сетей, что и делает метод пакетной нормализации.\\nПакет\\nПредварительно, напомним, что такое пакет (англ. batch). Возможны два подхода к реализации алгоритма градиентного спуска для обучения нейросетевых моделей: стохастический и пакетный[2].\\n- Стохастический градиентный спуск (англ. stochastic gradient descent) — реализация, в которой на каждой итерации алгоритма из обучающей выборки каким-то (случайным) образом выбирается только один объект;\\n- Пакетный (батч) (англ. batch gradient descent) — реализация градиентного спуска, когда на каждой итерации обучающая выборка просматривается целиком, и только после этого изменяются веса модели.\\nТакже существует \"золотая середина\" между стохастическим градиентным спуском и пакетным градиентным спуском — когда просматривается только некоторое подмножество обучающей выборки фиксированного размера (англ. batch-size). В таком случае такие подмножества принято называть мини-пакетом (англ. mini-batch). Здесь и далее, мини-пакеты будем также называть пакетом.\\nКовариантный сдвиг\\nПакетная нормализация уменьшает величину, на которую смещаются значения узлов в скрытых слоях (т.н. ковариантный сдвиг (англ. covariance shift)).\\nКовариантный сдвиг — это ситуация, когда распределения значений признаков в обучающей и тестовой выборке имеют разные параметры (математическое ожидание, дисперсия и т.д.). Ковариантность в данном случае относится к значениям признаков.\\nПроиллюстрируем ковариантный сдвиг примером. Пусть есть глубокая нейронная сеть, которая обучена определять находится ли на изображении роза. И нейронная сеть была обучена на изображениях только красных роз. Теперь, если попытаться использовать обученную модель для обнаружения роз различных цветов, то, очевидно, точность работы модели будет неудовлетворительной. Это происходит из-за того, что обучающая и тестовая выборки содержат изображения красных роз и роз различных цветов в разных пропорциях. Другими словами, если модель обучена отображению из множества в множество и если пропорция элементов в изменяется, то появляется необходимость обучить модель заново, чтобы \"выровнять\" пропорции элементов в и . Когда пакеты содержат изображения разных классов, распределенные в одинаковой пропорции на всем множестве, то ковариантный сдвиг незначителен. Однако, когда пакеты выбираются только из одного или двух подмножеств (в данном случае, красные розы и розы различных цветов), то ковариантный сдвиг возрастает. Это довольно сильно замедляет процесс обучения модели. На Рисунке изображена разница в пропорциях.\\nПростой способ решить проблему ковариантного сдвига для входного слоя — это случайным образом перемешать данные перед созданием пакетов. Но для скрытых слоев нейронной сети такой метод не подходит, так как распределение входных данных для каждого узла скрытых слоев изменяется каждый раз, когда происходит обновление параметров в предыдущем слое. Эта проблема называется внутренним ковариантным сдвигом (англ. internal covariate shift). Для решения данной проблемы часто приходится использовать низкий темп обучения (англ. learning rate) и методы регуляризации при обучении модели. Другим способом устранения внутреннего ковариантного сдвига является метод пакетной нормализации.\\nСвойства пакетной нормализации\\nКроме того, использование пакетной нормализации обладает еще несколькими дополнительными полезными свойствами:\\n- достигается более быстрая сходимость моделей, несмотря на выполнение дополнительных вычислений;\\n- пакетная нормализация позволяет каждому слою сети обучаться более независимо от других слоев;\\n- становится возможным использование более высокого темпа обучения, так как пакетная нормализация гарантирует, что выходы узлов нейронной сети не будут иметь слишком больших или малых значений;\\n- пакетная нормализация в каком-то смысле также является механизмом регуляризации: данный метод привносит в выходы узлов скрытых слоев некоторый шум, аналогично методу dropout;\\n- модели становятся менее чувствительны к начальной инициализации весов.\\nОписание метода\\nОпишем устройство метода пакетной нормализации. Пусть на вход некоторому слою нейронной сети поступает вектор размерности: . Нормализуем данный вектор по каждой размерности :\\n,\\nгде математическое ожидание и дисперсия считаются по всей обучающей выборке. Такая нормализация входа слоя нейронной сети может изменить представление данных в слое. Чтобы избежать данной проблемы, вводятся два параметра сжатия и сдвига нормализованной величины для каждого: , — которые действуют следующим образом:\\n.\\nДанные параметры настраиваются в процессе обучения вместе с остальными параметрами модели.\\nПусть обучение модели производится с помощью пакетовразмера : . Здесь нормализация применяется к каждому элементу входа с номером отдельно, поэтому в индекс опускается для ясности изложения. Пусть были получены нормализованные значения пакета . После применения операций сжатия и сдвига были получены . Обозначим данную функцию пакетной нормализации следующим образом:\\nТогда алгоритм пакетной нормализации можно представить так:\\nВход: значенияиз пакета ; настраиваемые параметры ; константа для вычислительной устойчивости. Выход: // математическое ожидание пакета // дисперсия пакета // нормализация // сжатие и сдвиг\\nЗаметим, что еслии , то равен , то есть является тождественным отображением. Таким образом, использование пакетной нормализации не может привести к снижению точности, поскольку оптимизатор просто может использовать нормализацию как тождественное отображение.\\nОбучение нейронных сетей с пакетной нормализацией\\nДля обучения нейронных сетей необходимо вычислять градиент функции потерь . В случае использования метода пакетной нормализации градиент вычисляется следующим образом:\\nНа Рисунке граф вычислений слоя пакетной нормализации алгоритмом обратного распространения ошибки.изображен\\nВ прямом направлении, как и описано в алгоритме метода, из входавычисляется среднее значение по каждой размерности признакового пространства. Затем полученный вектор средних значение вычитается из каждого элемента обучающей выборки. Далее вычисляется дисперсия, и с помощью нее вычисляется знаменатель для нормализации. Затем полученное значение инвертируется и умножается на разницу входа и средних значений. В конце применяются параметры и .\\nВ обратном направлении вычисляются производные необходимых функций. В следующей таблице подробнее изображены шаги вычисления градиента функции потерь (иллюстрации из статьи, здесь и ):\\nПакетная нормализация в свёрточных сетях\\nПакетная нормализация может быть применена к любой функции активации. Рассмотрим подробнее случай аффинного преобразования с некоторой нелинейной функцией:\\n,\\nгде cигмоида или ReLU. Данной функцией можно описать как обычные, так и сверточные слои нейронных сетей. Пакетная нормализация применяется сразу перед функцией к . Параметр может быть опущен, так как в дальнейших вычислениях его роль будет играть параметр . Поэтому может быть записано так:и — настраиваемые параметры модели, а — некоторая нелинейная функция, например\\n,\\nгдеприменяется отдельно к каждой размерности с отдельной парой параметров и для каждой размерности.\\nВ случае свёрточных сетей, дополнительно необходима нормализация, чтобы удовлетворить свойство свёрточных сетей, что различные элементы в разных местах одной карты признаков (образ операции свёртки, англ. feature map) должны быть нормализованы одинаково. Чтобы этого добиться, нормализация выполняется совместно над всеми значениями в пакете. Пусть— множество всех значений в карте признаков по всему пакету и всем точкам в карте признаков. Тогда для пакета размера и карты признаков размера размер равен . Тогда параметры и настраиваются для каждой карты признаков отдельно.\\nИндивидуальная нормализация\\nПри пакетной нормализации происходит усреднение параметров по всему пакету. Например, в случае задачи переноса стилей картин, это вносит много шума. При усреднении теряются индивидуальные характеристики объектов. Поэтому используется более тонкая нормализация — индивидуальная нормализация (англ. instance normalization). Разница заключается в том, что нормализация происходит по каждому отдельному объекту, а не по всему пакету. Для примера, усреднение происходит по пикселям картины, но не по всем картинам в пакете, как видно на Рисунке.\\nУсловная пакетная нормализация\\nУсловная пакетная нормализация (англ. conditional batch normalization, CBN) — метод, который позволяет \"выбирать\" параметры пакетной нормализации ([3]. Позднее он был использован для пакетной нормализации в Modulating early visual processing by language[4].и ) в зависимости от какого-то состояния сети, например метки класса. Впервые данный метод был представлен для индивидуальной нормализации в A Learned Representation for Artistic Style\\nЗачем нужно делать параметры нормализации зависимостью? На практике было выяснено [3], что иногда нейронные сети, натренированные решать разные задачи из одного класса, имеют схожие веса и достаточно лишь слегка поменять параметры сжатия и сдвига после каждого слоя. Таким образом, добавив условную нормализацию, мы научимся решать сразу несколько задач используя одну сеть.\\nОписание метода\\nСамая важная часть метода — выбрать для входа описанием метода пакетной нормализации:параметры и . Возможные способы сделать это описаны ниже. Единожды параметры выбраны, формула не отличается от приведённой в параграфе c\\n.\\nВыбор параметров нормализации\\nЕсть несколько способов выбрать параметры. Самой простой из них — разделить предметную область начастей. Для каждого слоя надо добавить соответствующие параметры и настраивать их вместе с остальными параметрами модели. Когда мы тренируем на данных из -ой части, мы явно указываем, что в формуле . Когда мы хотим осуществить предсказание, мы снова явно указываем желаемый и в вычислениях используются соответствующие параметры.\\nЕсть другой способ: можно вместе с настройкой сети обучать алгоритм выбора параметров Modulating early visual processing by language в качестве используется многослойный перцептрон по Румельхарту с одним скрытым слоем. Таким образом, характеристики могут изменить выход целого слоя. Это бывает полезно, если верна гипотеза, что структура входных векторов связана с желаемым результатом работы.сжатия и сдвига по заданному входу: . К примеру, в работе\\nВ применении к переносу стиля\\nПопулярной задачей является отрисовка данного изображения в стиле какой-то заданной картины, как на Рисунке \"перенос стиля\". Одно из популярных и достаточно быстрых решений этой задачи использует простые нейронные сети прямого распространения. Это решение имеет недостаток: каждая сеть может переносить лишь один стиль. Если мы хотим научиться переносить стилей, то надо обучать различных сетей. Однако лишь небольшое количество параметров этих сетей отвечает за индивидуальные особенности стиля. Хотелось бы уметь переиспользовать остальные параметры.. Эта задача называется\\nДобавление условности\\nВ статье A Learned Representation for Artistic Style был получен удивительный результат: для моделирования какого-то стиля, достаточно специализировать параметры сжатия и сдвига нормализации для каждого конкретного стиля. Таким образом, давайте для каждого изображения стиля будем учитывать свои и . Получается, у нас будет лишь два вектора параметров, специфичных для каждого стиля, а все остальные — общие.\\nТакой подход имеет много преимуществ по сравнению с наивным:\\n- Это быстрее.\\n- Это требует меньше памяти.\\n- Легче добавить новый стиль: достаточно взять текущие веса, добавить новые параметры сжатия и сдвига и дообучить. Веса, скорее всего, уже были близки к оптимальным и дообучение не будет долгим.\\n- Можно комбинировать новые стили за счёт выпуклой комбинации существующих коэффициентов сжатия и сдвига.\\nКогда использовать условную нормализацию?\\nВо-первых, на условную нормализацию стоит обратить внимание, если вы настраиваете много сетей, решающих похожие задачи. Возможно, в этом случае вы можете использовать одну сеть с условными параметрами нормализации, зависящими от конкретной задачи. Например, при переносе стилей вместосетей вы настраиваете одну сеть с наборами параметров нормализации.\\nВо-вторых, если вы подозреваете, что информация о структуре входных векторов имеет значение для выхода. Например, имеет смысл \"слить\" лингвистическую информацию и характеристики изображения для задачи ответа на визуальные вопросы (англ. Visual Question Answering, VQA).\\nОднако во всех случаях надо помнить, что полученные алгоритмы для разных задач будут различаться лишь параметрами свёртки и сжатия. Иначе говоря, если ваши задачи нельзя выразить аффинной комбинацией параметров сети после нормализации, условная нормализация не поможет.\\nПример\\nПриведем пример демонстрирующий работу пакетной нормализации. Рассмотрим задачу распознавания рукописных цифр на известном датасете MNIST [5]. Для решения задачи будет использоваться обычная нейронная сеть с скрытыми полносвязными слоями по узлов в каждом. Функция активации — ReLU. Выходной слой содержит узлов. Размер пакета равен . Сравниваются две одинаковые модели, но в первой перед каждым скрытым слоем используется пакетная нормализация, а во второй — нет. Темп обучения равен . Веса инициализированы значениями с малой дисперсией.\\nНа Рисункеизображены два графика, показывающие разницу между моделями. Как видно, обе модели достигли высокой точности, но модель с использованием пакетной нормализации достигла точности более быстрее, почти сразу, и достигла максимума, примерно, уже на итераций. Однако, модель без пакетной нормализации достигла скорости обучения примерно пакетов в секунду, а модель с использованием пакетной нормализации — . Однако, как можно видеть, пакетная нормализация позволяет выполнить меньшее количество итераций и, в итоге, сойтись за меньшее время.\\nНа Рисункеизображен график, сравнивающий точно такие же модели, но с использованием сигмоиды в качестве функции активации. Такая конфигурация моделей требует большего времени, чтобы начать обучение. В итоге, модель обучается, но на это потребовалось более итераций, чтобы получить точность более . При использовании пакетной нормализации получилось достичь точность более примерно за итераций.\\nРеализации\\nМеханизм пакетной нормализации реализован практически во всех современных инструментариях для машинного обучения, таких как: TensorFlow [6], Keras [7], CNTK [8], Theano [9], PyTorch [10] и т.д.\\nПриведем пример[11] применения пакетной нормализации с использованием библиотеки TensorFlow на языке программирования Python [12]:\\nimport tensorflow as tf # ... is_train = tf.placeholder(tf.bool, name=\"is_train\"); # ... x_norm = tf.layers.batch_normalization(x, training=is_train) # ... update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) with tf.control_dependencies(update_ops): train_op = optimizer.minimize(loss)\\nМодификации\\nСуществует несколько модификаций и вариаций метода пакетной нормализации:\\n- Тим Койманс[13] в 2016 г. предложил способ применения пакетной нормализации к рекуррентным нейронным сетям;\\n- Расширение метода пакетной нормализации было предложено Ликси Хуангом[14] в 2018 г. Метод получил название декоррелированная пакетная нормализация (англ. Decorrelated Batch Normalization). В данном методе кроме операций масштабирования и сдвига была предложено использование специальной функции затирания данных;\\n- Джимми Лей Ба[15] в 2016 г. предложил метод нормализации слоев (англ. Layer Normalization), который решает проблему выбора размера пакета;\\n- В работе Сергея Иоффе[16] в 2017 г. было представлено расширение метода пакетной нормализации: пакетная ренормализация (англ. Batch Renormalization). Данный метод улучшает пакетную нормализацию, когда размер пакетов мал и не состоит из независимых данных;\\n- Метод потоковой нормализации (англ. Streaming Normalization) был предложен Кифэном Ляо[17] в 2016 г. Данный метод убирает два ограничения пакетной нормализации: использование при online-обучении и использование в рекуррентных нейронных сетях.\\nСм. также\\nПримечания\\n- ↑ Ioffe S., Szegedy C. — Batch normalization: Accelerating deep network training by reducing internal covariate shift, 2016\\n- ↑ Метод стохастического градиента\\n- ↑ 3,0 3,1 3,2 A Learned Representation for Artistic Style\\n- ↑ Modulating early visual processing by language\\n- ↑ Датасет MNIST\\n- ↑ TensorFlow\\n- ↑ Keras\\n- ↑ CNTK\\n- ↑ Theano\\n- ↑ PyTorch\\n- ↑ Batch normalization: theory and how to use it with Tensorflow\\n- ↑ Язык программирования Python\\n- ↑ Cooijmans T. — Recurrent batch normalization, 2016\\n- ↑ Huang L. — Decorrelated Batch Normalization, 2018\\n- ↑ Ba J. L., Kiros J. R., Hinton G. E. — Layer normalization, 2016\\n- ↑ Ioffe S. — Batch renormalization: Towards reducing minibatch dependence in batch-normalized models, 2017\\n- ↑ Liao Q., Kawaguchi K., Poggio T. — Streaming normalization: Towards simpler and more biologically-plausible normalizations for online and recurrent learning, 2016\\nИсточники информации\\n- Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\\n- Glossary of Deep Learning: Batch Normalisation\\n- Understanding the backward pass through Batch Normalization Layer\\n- Deeper Understanding of Batch Normalization with Interactive Code in Tensorflow\\n- Batch Normalization in Deep Networks\\n- Batch Normalization — Lesson\\n- A Learned Representation for Artistic Style', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='bd10ca83-731e-43ca-abe4-9bc0bfcc1697', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ea994ee10bfa5a6c7e245984736935472cf75ad812fea1c6252a654fd07e4378', text=\"Проблемы нейронных сетей\\nНейронные сети считаются универсальными моделями в машинном обучении, поскольку позволяют решать широкий класс задач. Однако, при их использовании могут возникать различные проблемы.\\nСодержание\\n- 1 Взрывающийся и затухающий градиент\\n- 1.1 Определение\\n- 1.2 Причины\\n- 1.3 Способы определения\\n- 1.4 Способы устранения\\n- 2 См. также\\n- 3 Примечания\\n- 4 Источники\\nВзрывающийся и затухающий градиент\\nОпределение\\nНапомним, что градиентом в нейронных сетях называется вектор частных производных функции потерь по весам нейронной сети. Таким образом, он указывает на направление наибольшего роста этой функции для всех весов по совокупности. Градиент считается в процессе тренировки нейронной сети и используется в оптимизаторе весов для улучшения качества модели.\\nВ процессе обратного распространения ошибки при прохождении через слои нейронной сети в элементах градиента могут накапливаться большие значения, что будет приводить к сильным изменениям весов. Это в свою очередь может сделать нестабильным алгоритм обучения нейронной сети. В таком случае элементы градиента могут переполнить тип данных, в котором они хранятся. Такое явление называется взрывающимся градиентом (англ. exploding gradient).\\nСуществует аналогичная обратная проблема, когда в процессе обучения при обратном распространении ошибки через слои нейронной сети градиент становится все меньше. Это приводит к тому, что веса при обновлении изменяются на слишком малые значения, и обучение проходит неэффективно или останавливается, то есть алгоритм обучения не сходится. Это явление называется затухающим градиентом (англ. vanishing gradient).\\nТаким образом, увеличение числа слоев нейронной сети с одной стороны увеличивает ее способности к обучению и расширяет ее возможности, но с другой стороны может порождать данную проблему. Поэтому для решения сложных задач с помощью нейронных сетей необходимо уметь определять и устранять ее.\\nПричины\\nТакая проблема может возникнуть при использовании нейронных сетях классической функцией активации (англ. activation function) сигмоиды (англ. sigmoid):\\n$\\\\sigma(x) = \\\\frac{1}{1 + e^{-x}}.$\\nЭта функция часто используется, поскольку множество ее возможных значений — отрезок $[0, 1]$ — совпадает с возможными значениями вероятностной меры, что делает более удобным ее предсказание. Также график сигмоиды соответствует многим естественным процессам, показывающим рост с малых значений, который ускоряется с течением времени, и достигающим своего предела[2] (например, рост популяции).\\nПусть сеть состоит из подряд идущих нейронов с функцией активации $\\\\sigma(x)$; функция потерть (англ. loss function) $L(y) = MSE(y, \\\\hat{y}) = (y - \\\\hat{y})^2$ (англ. MSE — Mean Square Error); $u_d$ — значение, поступающее на вход нейрону на слое $d$; $w_d$ — вес нейрона на слое $d$; $y$ — выход из последнего слоя. Оценим частные производные по весам такой нейронной сети на каждом слое. Оценка для производной сигмоиды видна из рисунка 1.\\n$\\\\frac{\\\\partial(L(y))}{\\\\partial(w_d)} = \\\\frac{\\\\partial(L(y))}{\\\\partial(y)} \\\\cdot \\\\frac{\\\\partial(y)}{\\\\partial(w_d)} = 2 (y - \\\\hat{y}) \\\\cdot \\\\sigma'(w_d u_d) u_d \\\\leq 2 (y - \\\\hat{y}) \\\\cdot \\\\frac{1}{4} u_d$\\n$\\\\frac{\\\\partial(L(y))}{\\\\partial(w_{d - 1})} = \\\\frac{\\\\partial(L(y))}{\\\\partial(w_d)} \\\\cdot \\\\frac{\\\\partial(w_d)}{\\\\partial(w_{d - 1})} \\\\leq 2 (y - \\\\hat{y}) \\\\cdot (\\\\frac{1}{4})^2 u_d u_{d-1}$\\n$\\\\ldots$\\nОткуда видно, что оценка элементов градиента растет экспоненциально при рассмотрении частных производных по весам слоев в направлении входа в нейронную сеть (уменьшения номера слоя). Это в свою очередь может приводить либо к экспоненциальному росту градиента от слоя к слою, когда входные значения нейронов — числа, по модулю большие $1$, либо к затуханию, когда эти значения — числа, по модулю меньшие $1$.\\nОднако, входные значения скрытых слоев есть выходные значения функций активаций предшествующих им слоев. В частности, сигмоида насыщается (англ. saturates) при стремлении аргумента к $+\\\\infty$ или $-\\\\infty$, то есть имеет там конечный предел. Это приводит к тому, что более отдаленные слои обучаются медленнее, так как увеличение или уменьшение аргумента насыщенной функции вносит малые изменения, и градиент становится все меньше. Это и есть проблема затухающего градиента.\\nСпособы определения\\nВзрывающийся градиент\\nВозникновение проблемы взрывающегося градиента можно определить по следующим признакам:\\n- Модель плохо обучается на данных, что отражается в высоком значении функции потерь.\\n- Модель нестабильна, что отражается в значительных скачках значения функции потерь.\\n- Значение функции потерь принимает значение\\nNaN.\\nБолее непрозрачные признаки, которые могут подтвердить возникновение проблемы:\\n- Веса модели растут экспоненциально.\\n- Веса модели принимают значение\\nNaN.\\nЗатухающий градиент\\nПризнаки проблемы затухающего градиента:\\n- Точность модели растет медленно, при этом возможно раннее срабатывание критерия останова, так как алгоритм может решить, что дальнейшее обучение не будет оказывать существенного влияния.\\n- Градиент ближе к концу показывает более сильные изменения, в то время как градиент ближе к началу почти не показывает никакие изменения.\\n- Веса модели уменьшаются экспоненциально во время обучения.\\n- Веса модели стремятся к $0$ во время обучения.\\nСпособы устранения\\nИспользование другой функции активации\\nКак уже упоминалось выше, подверженность нейронной сети проблемам взрывающегося или затухающего градиента во многом зависит от свойств используемых функций активации. Поэтому правильный их подбор важен для предотвращения описываемых проблем.\\nTanh\\n$\\\\tanh(x) = \\\\frac{e^x - e^{-x}}{e^x + e^{-x}}$\\nФункция аналогична сигмоиде, но множество возможных значений: $[-1, 1]$. Градиенты при этом сосредоточены около $0$,. Однако, эта функция также насыщается в обоих направлениях, поэтому также может приводить к проблеме затухающего градиента.\\nReLU\\n$h(x) = \\\\max(0, x)$\\nФункция проста для вычисления и имеет производную, равную либо $1$, либо $0$. Также есть мнение, что именно эта функция используется в биологических нейронных сетях. При этом функция не насыщается на любых положительных значениях, что делает градиент более чувствительным к отдаленным слоям.\\nНедостатком функции является отсутствие производной в нуле, что можно устранить доопределением производной в нуле слева или справа. Также эту проблему устраняет использование гладкой аппроксимации, Softplus.\\nСуществуют модификации ReLU:\\n- Noisy ReLU: $h(x) = \\\\max(0, x + \\\\varepsilon), \\\\varepsilon \\\\sim N(0, \\\\sigma(x))$.\\n- Parametric ReLU: $h(x) = \\\\begin{cases} x & x > 0 \\\\\\\\ \\\\beta x & \\\\text{otherwise} \\\\end{cases}$.\\n- Leaky ReLU: Paramtetric ReLU со значением $\\\\beta = 0.01$.\\nSoftplus\\n$h(x) = \\\\ln(1 + e^x)$\\nГладкий, везде дифференцируемый аналог функции ReLU, следовательно, наследует все ее преимущества. Однако, эта функция более сложна для вычисления. Эмпирически было выявлено, что по качеству не превосходит ReLU.\\nГрафики всех функций активации приведены на рисунок 2.\\nИзменение модели\\nДля решения проблемы может оказаться достаточным сокращение числа слоев. Это связано с тем, что частные производные по весам растут экспоненциально в зависимости от глубины слоя.\\nВ рекуррентных нейронных сетях можно воспользоваться техникой обрезания обратного распространения ошибки по времени, которая заключается в обновлении весов с определенной периодичностью.\\nИспользование Residual blocks\\nВ данной конструкции вывод нейрона подается как следующему нейрону, так и нейрону на расстоянии 2-3 слоев впереди, который суммирует его с выходом предшествующего нейрона, а функция активации в нем — ReLU (см. рисунок 3). Такая связка называется shortcut. Это позволяет при обратном распространении ошибки значениям градиента в слоях быть более чувствительным к градиенту в слоях, с которыми связаны с помощью shortcut, то есть расположенными несколько дальше следующего слоя.\\nРегуляризация весов\\nРегуляризация заключается в том, что слишком большие значения весов будут увеличивать функцию потерь. Таким образом, в процессе обучения нейронная сеть помимо оптимизации ответа будет также минимизировать веса, не позволяя им становиться слишком большими.\\nОбрезание градиента\\nОбразание заключается в ограничении нормы градиента. То есть если норма градиента превышает заранее выбранную величину $T$, то следует масштабировать его так, чтобы его норма равнялась этой величине:\\n$\\\\nabla_{clipped} = \\\\begin{cases} \\\\nabla & || \\\\nabla || \\\\leq T \\\\\\\\ \\\\frac{T}{|| \\\\nabla ||} \\\\cdot \\\\nabla & \\\\text{otherwise} \\\\end{cases}.$\\nСм. также\\n- Нейронные сети, перцептрон\\n- Обратное распространение ошибки\\n- Регуляризация\\n- Глубокое обучение\\n- Сверточные нейронные сети\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='e95e47c6-a116-4105-b73a-aeb5dfc2937f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9a1cd1ec4f72b694e2998333018c1176940c93c225d6b72b329fbcd5a3d9fc83', text=\"Рекуррентные нейронные сети\\nРекуррентная нейронная сеть (англ. recurrent neural network, RNN) — вид нейронных сетей, где связи между элементами образуют направленную последовательность.\\nСодержание\\n- 1 Описание\\n- 2 Области и примеры применения\\n- 3 Виды RNN\\n- 4 Архитектуры\\n- 4.1 Полностью рекуррентная сеть\\n- 4.2 Рекурсивная сеть\\n- 4.3 Нейронная сеть Хопфилда\\n- 4.4 Двунаправленная ассоциативная память (BAM)\\n- 4.5 Сеть Элмана\\n- 4.6 Сеть Джордана\\n- 4.7 Эхо-сети\\n- 4.8 Нейронный компрессор истории\\n- 4.9 Сети долго-краткосрочной памяти\\n- 4.10 Управляемые рекуррентные блоки\\n- 4.11 Двунаправленные рекуррентные сети\\n- 4.12 Seq-2-seq сети\\n- 5 Пример кода\\n- 6 См. также\\n- 7 Примечания\\nОписание\\nРекуррентные нейронные сети — сети с циклами, которые хорошо подходят для обработки последовательностей (рис. 1).\\nОбучение RNN аналогично обучению обычной нейронной сети. Мы также используем алгоритм обратного распространения ошибки (англ. Backpropagation), но с небольшим изменением. Поскольку одни и те же параметры используются на всех временных этапах в сети, градиент на каждом выходе зависит не только от расчетов текущего шага, но и от предыдущих временных шагов (рис. 4). Например, чтобы вычислить градиент для четвертого элемента последовательности, нам нужно было бы «распространить ошибку» на 3 шага и суммировать градиенты. Этот алгоритм называется «алгоритмом обратного распространения ошибки сквозь время» (англ. Backpropagation Through Time, BPTT).[3][4]\\nАлгоритм обратного распространения ошибки сквозь время:\\nОбласти и примеры применения\\nИспользуются, когда важно соблюдать последовательность, когда важен порядок поступающих объектов.\\n- Обработка текста на естественном языке:\\n- Анализ текста;\\n- Автоматический перевод;\\n- Обработка аудио:\\n- Автоматическое распознавание речи;\\n- Обработка видео:\\n- Прогнозирование следующего кадра на основе предыдущих;\\n- Распознавание эмоций;\\n- Обработка изображений:\\n- Прогнозирование следующего пикселя на основе окружения;\\n- Генерация описания изображений.\\nВиды RNN\\nОдин к одному\\n|Архитектура по сути является обычной нейронной сетью.\\nОдин ко многим\\n|Один вход ко многим выходам может применяться, например, для генерации аудиозаписи. На вход подаем жанр музыки, который хотим получить, на выходе получаем последовательность аудиозаписи.\\nМногие к одному\\n|Много входов и один выход может применяться, если мы хотим оценить тональность рецензии. На вход подаем слова рецензии, на выходе получаем оценку ее тональности: позитивная рецензия или негативная.\\nМногие ко многим\\n|Данную архитектуру можно использовать для перевода текста с одного языка на другой.\\n|Такой вариант подойдет для определения для классификации каждого слова в предложении в зависимости от контекста.\\nАрхитектуры\\nПолностью рекуррентная сеть\\nЭто базовая архитектура, разработанная в 1980-х. Сеть строится из узлов, каждый из которых соединён со всеми другими узлами. У каждого нейрона порог активации меняется со временем и является вещественным числом. Каждое соединение имеет переменный вещественный вес. Узлы разделяются на входные, выходные и скрытые.\\nРекурсивная сеть\\nРекурсивные нейронные сети (англ. Recurrent neural networks) представляют собой более общий случай рекуррентных сетей, когда сигнал в сети проходит через структуру в виде дерева (обычно бинарные деревья). Те же самые матрицы весов используются рекурсивно по всему графу в соответствии с его топологией.\\nНейронная сеть Хопфилда\\nТип рекуррентной сети, когда все соединения симметричны. Изобретена Джоном Хопфилдом в 1982 году и гарантируется, что динамика такой сети сходится к одному из положений равновесия.\\nДвунаправленная ассоциативная память (BAM)\\nВариацией сети Хопфилда является двунаправленная ассоциативная память (BAM). BAM имеет два слоя, каждый из которых может выступать в качестве входного, находить (вспоминать) ассоциацию и генерировать результат для другого слоя.\\nСеть Элмана\\nНейронная сеть Элмана состоит из трёх слоев:, , . Дополнительно к сети добавлен набор «контекстных блоков»: (рис. 5). Средний (скрытый) слой соединён с контекстными блоками с фиксированным весом, равным единице. С каждым шагом времени на вход поступает информация, которая проходит прямой ход к выходному слою в соответствии с правилами обучения. Фиксированные обратные связи сохраняют предыдущие значения скрытого слоя в контекстных блоках (до того как скрытый слой поменяет значение в процессе обучения). Таким способом сеть сохраняет своё состояние, что может использоваться в предсказании последовательностей, выходя за пределы мощности многослойного перцептрона.\\n,\\n,\\nОбозначения переменных и функций:\\n- : вектор входного слоя;\\n- : вектор скрытого слоя;\\n- : вектор выходного слоя;\\n- : матрица и вектор параметров;\\n- : функция активации.\\nСеть Джордана\\nНейронная сеть Джордана подобна сети Элмана, но контекстные блоки связаны не со скрытым слоем, а с выходным слоем. Контекстные блоки таким образом сохраняют своё состояние. Они обладают рекуррентной связью с собой.\\n,\\n,\\nЭхо-сети\\nЭхо-сеть (англ. Echo State Network, ESN) характеризуется одним скрытым слоем (который называется резервуаром) со случайными редкими связями между нейронами. При этом связи внутри резервуара фиксированы, но связи с выходным слоем подлежат обучению. Состояние резервуара (state) вычисляется через предыдущие состояния резервуара, а также предыдущие состояния входного и выходного сигналов. Так как эхо-сети обладают только одним скрытым слоем, они обладают достаточно низкой вычислительной сложностью.\\nНейронный компрессор истории\\nНейронный компрессор исторических данных — это блок, позволяющий в сжатом виде хранить существенные исторические особенности процесса, который является своего рода стеком рекуррентной нейронной сети, формируемым в процессе самообучения.\\nСети долго-краткосрочной памяти\\nСеть долго-краткосрочной памяти (англ. Long short-term memory, LSTM) является самой популярной архитектурой рекуррентной нейронной сети на текущий момент, такая архитектура способна запоминать данные на долгое время (рис. 6).[6]\\nУправляемые рекуррентные блоки\\nУправляемые рекуррентные блоки (англ. Gated Recurrent Units, GRU) — обладает меньшим количеством параметров, чем у LSTM, и в ней отсутствует выходное управление. При этом производительность в моделях речевого сигнала или полифонической музыки оказалась сопоставимой с LSTM.\\nДвунаправленные рекуррентные сети\\nДвунаправленная рекуррентная сеть (англ. Bidirectional Recurrent Neural Network, biRNN) представляет собой две однонаправленные рекуррентные сети, одна из которых обрабатывает входную последовательность в прямом порядке, а другая — в обратном (рис. 7). Таким образом, для каждого элемента входной последовательности считается два вектора скрытых состояний, на основе которых вычисляется выход сети. Благодаря данной архитектуре сети доступна информация о контексте как из прошлого, так и из будущего, что решает проблему однонаправленных рекуррентных сетей. Для обучения biRNN используются те же алгоритмы, что и для RNN.\\n,\\n,\\n,\\nгде, , , , , — матрицы весов, , , , — байесы, , , — функции активаций, и — выходы однонаправленных рекуррентных сетей, — их конкатенированный вектор, а — выход сети на шаге .\\nSeq-2-seq сети\\nSeq-2-seq (Sequence to sequence, Seq2seq) сеть является базовой архитектурой many-to-many RNN и используется для трансляции одной последовательности в другую (рис. 8). Она состоит из двух рекуррентных сетей: кодировщика и декодировщика. Кодировщик вычисляет вектор, кодирующий входную последовательность. Далее данный вектор передается декодировщику, который в свою очередь по полученному скрытому представлению восстанавливает целевую последовательность. При этом каждый посчитанный выход используется для обновления скрытого представления.\\nПример кода\\nПример кода на Python с использованием библиотеки Keras.[9]\\n# Импорты import numpy as np from keras.preprocessing import sequence from keras.models import Sequential from keras.layers import Dense, Activation, Embedding from keras.layers import LSTM from keras.datasets import imdb # Устанавливаем seed для обеспечения повторяемости результатов np.random.seed(42) # Указываем количество слов из частотного словаря, которое будет использоваться (отсортированы по частоте использования) max_features = 5000 # Загружаем данные (датасет IMDB содержит 25000 рецензий на фильмы с правильным ответом для обучения и 25000 рецензий на фильмы с правильным ответом для тестирования) (X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words = max_features) # Устанавливаем максимальную длину рецензий в словах, чтобы они все были одной длины maxlen = 80 # Заполняем короткие рецензии пробелами, а длинные обрезаем X_train = sequence.pad_sequences(X_train, maxlen = maxlen) X_test = sequence.pad_sequences(X_test, maxlen = maxlen) # Создаем модель последовательной сети model = Sequential() # Добавляем слой для векторного представления слов (5000 слов, каждое представлено вектором из 32 чисел, отключаем входной сигнал с вероятностью 20% для предотвращения переобучения) model.add(Embedding(max_features, 32, dropout = 0.2)) # Добавляем слой долго-краткосрочной памяти (100 элементов для долговременного хранения информации, отключаем входной сигнал с вероятностью 20%, отключаем рекуррентный сигнал с вероятностью 20%) model.add(LSTM(100, dropout_W = 0.2, dropout_U = 0.2)) # Добавляем полносвязный слой из 1 элемента для классификации, в качестве функции активации будем использовать сигмоидальную функцию model.add(Dense(1, activation = 'sigmoid')) # Компилируем модель нейронной сети model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) # Обучаем нейронную сеть (данные для обучения, ответы к данным для обучения, количество рецензий после анализа которого будут изменены веса, число эпох обучения, тестовые данные, показывать progress bar или нет) model.fit(X_train, y_train, batch_size = 64, nb_epoch = 7, validation_data = (X_test, y_test), verbose = 1) # Проверяем качество обучения на тестовых данных (если есть данные, которые не участвовали в обучении, лучше использовать их, но в нашем случае таковых нет) scores = model.evaluate(X_test, y_test, batch_size = 64) print('Точность на тестовых данных: %.2f%%' % (scores[1] * 100))\\nПример на языке Java\\nПример простой рекуррентной нейронной сети, способной генерировать заданную строку по первому символу, с применением библиотеки\\ndeeplearning4j.\\nСм. также\\nПримечания\\n- ↑ Understanding LSTM Networks\\n- ↑ Understanding LSTM Networks\\n- ↑ Backpropagation Through Time\\n- ↑ Backpropagation Through Time\\n- ↑ Understanding LSTM Networks\\n- ↑ Sepp Hochreiter, Jurgen Schmidhuber. Long short-term memory (1997). Neural Computation.\\n- ↑ Understanding Bidirectional RNN in PyTorch\\n- ↑ Implementation of seq2seq model\\n- ↑ Keras RNN\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='5c8a161f-a0c3-48a5-a64d-206bc4157cfa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='717f48b79c19d076aa60451d347f9f40bb1d382501e57a310276d175362aa98f', text='Сиамская нейронная сеть\\nСиамская нейронная сеть (англ. Siamese neural network) — это разновидность искусственной нейронной сети (англ. artificial neural network), которая состоит из двух идентичных нейронных подсетей с одинаковыми наборами весов. Данный вид сетей позволяет сравнить вектора признаков двух объектов с целью выделить их семантическое сходство или различие. Сиамская нейронная сеть представляет собой нелинейное отображение данных с целью приблизить друг к другу схожие объекты и разнести различные объекты на максимально возможное расстояние. Сиамские сети получили свое название от сиамских близнецов, физически приросших друг к другу, из-за использования сразу двух подсетей, разделяющих один набор весов. Эти подсети могут быть представлены многослойными перцептронами (англ. multilayer perceptron), сверточными нейронными сетями (англ. convolutional neural network) и другими.\\nСодержание\\nМотивация\\nРассмотрим следующую ситуацию: некоторая компания хочет создать систему, которая, основываясь на фотографии лица человека, могла бы установить, является ли он ее сотрудником. В этом случае она, например, разрешает ему доступ на территорию предприятия. Пусть в компании работаетчеловек. Тогда может быть выделено классов ( классов сотрудников и один класс не сотрудника). Каждый из этих классов может быть записан в форме вектора длины с помощью one-hot кодирования. Для решения задачи классификации фотографии в один из выделенных классов может быть использована сверточная нейронная сеть, возвращающая класс сотрудника в векторной форме. Однако число сотрудников компании может меняться, старые работники могут увольняться, а на их место приходить новые. Каждое такое изменение потребовало бы переобучения всей сети, что может быть накладно для крупных компаний. Более того, не все сотрудники имеют большое количество своих фотографий (необходимое для обучения сверточной нейронной сети), или не желают делиться большей их частью.\\nРешением данной проблемы может быть обучение сети не распознавать каждого отдельного сотрудника, а находить сходство между фотографиями двух людей. В качестве таких фотографий могут быть использованы фотография человека, который пытается попасть на территорию предприятия, и фотография одного из сотрудников компании. Например, мы можем выбрать некоторый предели обучить сеть так, чтобы она возвращала значение , если фотографии похожи, и , если они разные. В таком случае нам будет достаточно попарно сравнить с помощью нашей сети фотографию посетителя с фотографиями сотрудников компании, и, если выходное значение для одной из пар будет меньше , мы можем с высокой уверенностью сказать, что наш посетитель является сотрудником компании. Такое решение может быть реализовано с помощью сиамских нейронных сетей, которые рассмотрены ниже.\\nСиамская нейронная сеть\\nЗададимся набором данных, состоящим из векторов признаков размера с метками , где — число классов. Создадим обучающий набор данных , состоящих из пар с бинарными метками . Если оба вектора признаков и принадлежат к одному и тому же классу, то , иначе . Разделим обучающий набор данных на два подмножества: одно — со схожими парами (или с ), другое — с различающимися парами (или с ). Будем подавать наши пары векторов на вход сиамской сети.\\nВ общем случае сиамская сеть состоит из двух подсетей, выходы которых подаются на вход другого модуля, который генерирует конечный выход. Рассмотрим Рис. 1, на котороми — это входы, — общие веса/параметры, а и — выходы обеих подсетей. Сиамская сеть представляет собой отображение , для которого Евклидово расстояние максимально мало́ при и максимально велико при . Сеть возвращает оценку того, насколько различны и .\\nСуществует три главных вида структуры сиамских нейронных сетей (см. Рис. 2):\\n- Входы и подаются на две параллельные подсети, представляющие собой две отдельные сети с одними и теми же весами и смещениями. Для выходов и этих сетей подсчитывается метрика расстояния , которая подается на выходной слой, оценивающий схожесть между входами подсетей.\\n- Несколько последних слоев подсетей объединены, за ними следуют несколько дополнительных слоев. На последнем слое применяется softmax-преобразование. Данная архитектура известна под названием In-network stacking.\\n- Оба входа и конкатенируются и подаются на вход единой сети, завершающейся слоем с softmax-преобразованием.\\nТретья архитектура полезна для детального сравнения двух объектов, необходимого, например, при отслеживании пешеходов[1]. Первые две архитектуры показывают хорошие результаты при классификации.\\nСуществует много различных функций потерь (англ. loss function) для обучения сиамских нейронных сетей. Рассмотрим две наиболее популярные из них. Первая — contrastive loss function — использует пары объектов , которые могут принадлежать как одному, так и разным классам:\\n,\\nгде— это заранее заданный предел. Вторая функция потерь — triplet loss function — использует объект рассматриваемого класса (или якорь, англ. anchor) , с которым будет проводиться сравнение, а также два других объекта: один принадлежащий к тому же классу (англ. neighbor) , и один не принадлежащий к этому классу (англ. distant) :\\n,\\nгде [2]. Тогда эмпирический риск (англ. error function) равен— это заранее заданный предел. Обе функции стремятся приблизить похожие объекты и увеличить расстояние между разными объектами. В некоторых случаях возможно их совместное применение для достижения наилучшего результата\\n,\\nгде градиентный спуск (англ. gradient descent).— это результат суммирования значений функции потерь по всему обучающему набору данных, — это член, регуляризующий обобщающую способность сети, — это матрица параметров нейронных подсетей, а — это гиперпараметр, отвечающий за степень регуляризации. Для минимизации этой функции обычно применяется\\nСеть триплетов\\nСеть триплетов (англ. Triplet network) (см. Рис. 3) представляет собой модификацию сиамской сети с тремя сверточными нейронными подсетями с общими параметрами. В центральную подсеть подается объект [3].рассматриваемого класса . В одну из двух оставшихся подсетей подается объект того же класса (положительный пример), а в другую — объект , не принадлежащий к классу (негативный пример). Сочетание центральной подсети с каждой из двух других подсетей образует сиамскую сеть. Выходы и обеих сиамских сетей подаются на последний слой-компаратор. Было отмечено, что при обучении сети триплетов в качестве функции потерь удобнее использовать среднеквадратическую ошибку\\nКак сиамская сеть, так и сеть триплетов показывают хорошие результаты при сравнении изображений. Однако, в отличие от сиамской сети, сеть триплетов не требует нормализации данных.\\nПрименение\\nСиамские нейронные сети нашли широкое применение в области компьютерного зрения, распознавания речи и обработки естественных языков. Были предложены модели для распознавания манеры ходьбы[4], поведения пользователя в интернете[5], множественного трекинга пешеходов[1], и т.д.[6][7][8] Данный вид сетей также может быть использован для снижения размерности.\\nОднако наиболее популярное применение сиамских сетей — это распознавание лиц. Первые автоматизированные решения в этой области появились еще в 1960-е годы. Однако свою популярность распознание лиц приобрело после публикации метода eigenface[9], использующего алгоритмы снижения размерности (например, PCA) для компактного представления признаков. Позже, данное решение было улучшено с помощью применения сверточных нейронных сетей. Сиамские нейронные сети являются усовершенствованием над нейронными сетями и часто используются в задачах, когда фактическое число классов велико или не известно во время обучения, а количество объектов в классах мало.\\nСм. также\\nПримечания\\n- ↑ 1,0 1,1 L. Leal-Taixé, C. Canton-Ferrer and K. Schindler, \"Learning by Tracking: Siamese CNN for Robust Target Association,\" 2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Las Vegas, NV, 2016, pp. 418-425, doi: 10.1109/CVPRW.2016.59.\\n- ↑ X. Di and V. M. Patel. Deep tattoo recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 51–58, 2016.\\n- ↑ Elad Hoffer, Nir Ailon, \"Deep metric learning using Triplet network\", 2018.[1]\\n- ↑ C. Zhang, W. Liu, H. Ma and H. Fu, \"Siamese neural network based gait recognition for human identification,\" 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Shanghai, 2016, pp. 2832-2836, doi: 10.1109/ICASSP.2016.7472194.\\n- ↑ Y. Qiao, Y. Wu, F. Duo, W. Lin and J. Yang, \"Siamese Neural Networks for User Identity Linkage Through Web Browsing,\" in IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 8, pp. 2741-2751, Aug. 2020, doi: 10.1109/TNNLS.2019.2929575.\\n- ↑ M. E. Hossain, A. Islam and M. S. Islam, \"A Proficient Model to Classify Bangladeshi Bank Notes for Automatic Vending Machine Using a Tıny Dataset with One-Shot Learning & Siamese Networks,\" 2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT), Kharagpur, India, 2020, pp. 1-4, doi: 10.1109/ICCCNT49239.2020.9225405.\\n- ↑ S. Bhati, L. M. Velazquez, J. Villalba and N. Dehak, \"LSTM Siamese Network for Parkinson’s Disease Detection from Speech,\" 2019 IEEE Global Conference on Signal and Information Processing (GlobalSIP), Ottawa, ON, Canada, 2019, pp. 1-5, doi: 10.1109/GlobalSIP45357.2019.8969430.\\n- ↑ I. O. de Oliveira, K. V. O. Fonseca and R. Minetto, \"A Two-Stream Siamese Neural Network for Vehicle Re-Identification by Using Non-Overlapping Cameras,\" 2019 IEEE International Conference on Image Processing (ICIP), Taipei, Taiwan, 2019, pp. 669-673, doi: 10.1109/ICIP.2019.8803810.\\n- ↑ M. Turk and A. Pentland, “Eigenfaces for recognition,” Journal of cognitive neuroscience, vol. 3, no. 1, pp. 71–86, 1991.\\nИсточники информации\\n- Lev V. Utkin, Maxim S. Kovalev, Ernest M. Kasimov, \"An explanation method for Siamese neural networks\", 2019. [2]\\n- A. Nandy, S. Haldar, S. Banerjee and S. Mitra, \"A Survey on Applications of Siamese Neural Networks in Computer Vision,\" 2020 International Conference for Emerging Technology (INCET), Belgaum, India, 2020, pp. 1-5, doi: 10.1109/INCET49848.2020.9153977.\\n- H. Wu, Z. Xu, J. Zhang, W. Yan and X. Ma, \"Face recognition based on convolution siamese networks,\" 2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI), Shanghai, 2017, pp. 1-5, doi: 10.1109/CISP-BMEI.2017.8302003.\\n- Coursera. Convolutional Neural Networks [3].', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='94e1462d-6dd1-4b91-a746-d5495ecf01dd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='dcbe4152eb50cddc6fbc0747cfd3f7c30b95848fb6cdd6ef1b87dd74122c959e', text='Автокодировщик\\nАвтокодировщик (англ. autoencoder) — специальная архитектура искусственных нейронных сетей, позволяющая применять обучение без учителя при использовании метода с обратного распространения ошибки. Простейшая архитектура автокодировщика — сеть прямого распространения, без обратных связей, наиболее схожая с перцептроном и содержащая входной слой, промежуточный слой и выходной слой. В отличие от перцептрона , выходной слой автокодировщика должен содержать столько же нейронов, сколько и входной слой.\\nАвтокодировщик состоит из двух частей: энкодераи декодера . Энкодер переводит входной сигнал в его представление (код): , а декодер восстанавливает сигнал по его коду: .\\nАвтокодировщик, изменяяи , стремится выучить тождественную функцию , минимизируя какой-то функционал ошибки.\\nПри этом семейства функций энкодераи декодера как-то ограничены, чтобы автоэнкодер был вынужден отбирать наиболее важные свойства сигнала.\\nАвтокодировщик можно использовать для предобучения, например, когда стоит задача классификации, а размеченных пар слишком мало. Или для понижения размерности в данных для последующей визуализации. Либо когда просто надо научиться различать полезные свойства входного сигнала.\\nСодержание\\n- 1 Пример\\n- 2 Использование\\n- 3 Виды автокодировщиков\\n- 4 Пример реализации\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nПример\\nДля примера возьмем набор данных для продуктов, купленных клиентами\\n- Шаг 1: Возьмем первую строку из данных по клиенту для всех продуктов в качестве входа. означает, что клиент купил продукт. означает, что клиент не купил.\\n- Шаг 2: Закодируем ввод в другой вектор меньшего размера, чем входной. Можно использовать функцию активации сигмоида для , так как она ее область значения от до . - вес, примененный к входу, — член смещения.\\n- Шаг 3: Декодируем вектор , чтобы воссоздать ввод. Выход будет того же размера, что и вход\\n- Шаг 4: Рассчитать ошибку . Ошибка — это разница между входным и выходным вектором. Наша цель — минимизировать ошибку, чтобы выходной вектор был похож на входной вектор.\\n- Шаг 5: С помощью алгоритма обратного распространения ошибки нужно обновить веса. Скорость обучения определяется тем, насколько обновляются веса.\\n- Шаг 6: Повторите шаги с по для каждого клиента в наборе данных. Веса обновляются каждый раз (стохастический градиентный спуск)\\n- Шаг 7: Повторите для большего количества эпох. Эпоха - это когда все строки в наборе данных прошли через нейронную сеть.\\nИспользование\\n- Нелинейное уменьшения размерности. Кодирует ввод в скрытом слое с меньшей размерностью по сравнению с входным измерением. Скрытый слой позже декодируется как выходной. Автоэнкодер уменьшает размерность линейных и нелинейных данных, следовательно, он более мощный, чем метод главных компонент[на 3.04.19 не создан].\\n- Рекомендации пользователям. При этом используются глубокие кодеры, чтобы понять пользовательские предпочтения, порекомендовать фильмы, книги или предметы\\n- Извлечения зависимостей в данных: автоэнкодеры пытаются минимизировать ошибку восстановления. В процессе уменьшения ошибки он изучает некоторые важные зависимости, присутствующие во входных данных. Он восстанавливает входные данные из кодированного состояния. Кодирование генерирует новый набор функций, который представляет собой комбинацию оригинальных зависимостей. Кодирование в автоэнкодерах помогает идентифицировать скрытые зависимости, присутствующие во входных данных.\\n- Распознавание изображений: для распознавания изображений используется сложный автоэнкодер. Можно использовать несколько совмещенных кодировщиков, что помогает изучить различные функции изображения.\\nВиды автокодировщиков\\nUndercomplete Autoencoders\\nИмеют меньший размер скрытого слоя по сравнению с входным слоем. Это помогает выделить зависимости из данных. Undercomplete Autoencoders минимизируют функцию потерь, штрафуяза отличия от входных данных x. Так же не нуждаются в регуляризации, поскольку максимизируют вероятность данных, а не копируют входные данные в выходные.\\nSparse Autoencoders[1]\\nРазмерность скрытого слоя больше, чем входного. Они все еще могут обнаружить важные особенности из данных. На скрытый слой накладывается штраф за разреженность,, значение, близкое к нулю, в дополнение к ошибке восстановления. Это предотвращает переобучение.\\nDenoising Autoencoders(DAE)[2]\\nСоздаем поврежденную копию ввода, внося некоторый шум. Это помогает обучить убирать шум из данных. DAE минимизирует функцию потерь между выходным узлом и поврежденным вводом.\\nContractive Autoencoders(CAE)[3]\\nЦелью CAE является получение надежного представления данных, которое менее чувствительно к небольшим изменениям. Надежность представления данных достигается путем регуляризации. Наказание в CAE это норма Фробениуса матрицы Якоби, которая вычисляется для скрытого слоя относительно входных данных. Фробениусовой нормой матрицы Якоби является сумма квадратов всех элементов.\\nStacked Denoising Autoencoders[4]\\nStacked Autoencoders — это нейронная сеть с несколькими слоями Sparse Autoencoders. Когда мы добавляем в автоэнкодер больше скрытых слоев, это помогает уменьшить объемные код, получаемый кодировщиком. Restricted Boltzmann Machine (RBM) является основной частью сети глубокого убеждения.\\nDeep Autoencoders[5]\\nСостоит из двух идентичных глубоких сетей. Одна сеть для кодирования и другая для декодирования. Обычно имеют от 4 до 5 уровней для кодирования и следующие от 4 до 5 уровней для декодирования.\\nВариационный автокодировщик\\nАвтокодировщик, основанный на вариационном выводе.\\nПример реализации\\nНиже приведена реализация частного случая автокодировщика на языке Python с использованием библиотеки Keras. Эта реализация работает с датасетом рукописных цифр MNIST.\\ndef create_dense_ae(): # Размерность кодированного представления encoding_dim = 49 # Энкодер # Входной плейсхолдер input_img = Input(shape=(28, 28, 1)) # 28, 28, 1 — размерности строк, столбцов, фильтров одной картинки, без батч-размерности # Вспомогательный слой решейпинга flat_img = Flatten()(input_img) # Кодированное полносвязным слоем представление encoded = Dense(encoding_dim, activation=\\'relu\\')(flat_img) # Декодер # Раскодированное другим полносвязным слоем изображение input_encoded = Input(shape=(encoding_dim,)) flat_decoded = Dense(28*28, activation=\\'sigmoid\\')(input_encoded) decoded = Reshape((28, 28, 1))(flat_decoded) # Модели, в конструктор первым аргументом передаются входные слои, а вторым выходные слои # Другие модели можно так же использовать как и слои encoder = Model(input_img, encoded, name=\"encoder\") decoder = Model(input_encoded, decoded, name=\"decoder\") autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\") return encoder, decoder, autoencoder\\n# Создание модели encoder, decoder, autoencoder = create_dense_ae() autoencoder.compile(optimizer=\\'adam\\', loss=\\'binary_crossentropy\\')', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='92ac7a3c-ba57-4902-9ebc-5c1f9cac1d1b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='de881d5ff282a1b6cf17f27a598c50186f41b952594034f9befa7dec496566dc', text='Сети глубокого доверия\\nСети глубокого доверия — это вероятностные генеративные модели, которые состоят из нескольких слоев стохастических скрытых переменных. Скрытые переменные обычно имеют двоичные значения и часто называются скрытыми узлами или детекторами признаков. Два верхних слоя имеют ненаправленные, симметричные связи между ними и образуют ассоциативную память. Между оставшимися парами соседних слоёв есть только направленные связи от верхнего к нижнему. Состояния узлов в нижнем слое представляют вектор данных.\\nДва наиболее значимых свойства сетей глубокого доверия:\\n- Существует эффективная послойная процедура для обучения нисходящих весов, которая определяет, как переменные в одном слое зависят от переменных в слое выше.\\n- После обучения скрытых переменных в каждом слое могут быть выведены значения за один проход снизу вверх, который начинается с наблюдаемого вектора данных в нижнем слое и использует веса в обратном направлении.\\nСети глубокого доверия обучаются по одному слою за раз, обрабатывая значения скрытых переменных в одном слое в тот момент, когда они выводятся из данных для обучения следующего слоя. Это эффективное, жадное обучение может сопровождаться или сочетаться с другими процедурами обучения, которые точно настраивают все веса для улучшения генеративных или дискриминационных характеристик всей сети.\\nДискриминирующая тонкая настройка может быть выполнена путем добавления последнего слоя переменных, которые представляют желаемые выходные данные и производные ошибок обратного распространения. Когда сети со многими скрытыми слоями применяются к высокоструктурированным входным данным, таким как изображения, обратное распространение работает намного лучше, если детекторы признаков в скрытых слоях инициализируются путем обучения глубокой сети доверия, которая моделирует структуру во входных данных.\\nСодержание\\nКак развивались сети глубокого доверия\\nВ нейронных сетях первого поколения использовались перцептроны, которые идентифицировали конкретный объект или что-либо еще, принимая во внимание «вес» или предварительные свойства. Однако перцептроны могут быть эффективны только на базовом уровне и бесполезны для передовых технологий. Для решения этих проблем во втором поколении нейронных сетей была введена концепция обратного распространения, при которой полученный вывод сравнивается с желаемым выводом, а значение ошибки было снижено до нуля. Метод опорных векторов позволил создать больше контрольных примеров, ссылаясь на ранее введенные контрольные примеры. Затем последовали циклические графы, называемые сетями доверия, которые помогли в решении проблем, связанных с выводом и проблемами обучения. За этим последовали сети глубокого доверия, которые помогли создать непредвзятые значения для хранения в конечных узлах.\\nКомпозиция простых обучающих модулей\\nГлубокая сеть доверия может рассматриваться как набор простых обучающих модулей, каждый из которых представляет собой ограниченную машину Больцмана[1], которая содержит слой видимых узлов, представляющий данные, и слой скрытых узлов, которые обучаются представлению особенностей, которые захватывают более высокие порядки корреляции в данных. Ограниченные машины Больцмана могут быть сложены и обучены жадным алгоритмом, чтобы сформировать так называемые глубокие сети доверия, которые моделируют совместное распределение между наблюдаемым вектором и скрытыми слоями следующим образом:\\nгде $x=h^0$, $P(h^{k-1}|h^{k})$ — условное распределение для видимых узлов, обусловленных скрытыми узлами RBM на уровне, и $P(h^{l - 1}|h^l)$ — это видимое-скрытое совместное распределение в RBM верхнего уровня. Это показано на рисунке 1.\\nОграниченная машина Больцмана (RBM)\\nЕсли вы знаете, что такое факторный анализ, то RBM можно рассматривать как двоичную версию факторного анализа. Таким образом, вместо множества факторов, определяющих вывод, мы можем иметь двоичную переменную в форме 0 или 1.\\nНапример: если вы читаете книгу, а затем судите эту книгу по двухзначной шкале: это либо вам нравится книга, либо вам не нравится книга. В таких сценариях мы можем использовать RBM, которые помогут нам определить причину, по которой мы делаем такой выбор.\\nRBM используют вероятностный подход для нейронных сетей, и поэтому их также называют стохастическими нейронными сетями. Если мы разложим RBM, то становится ясно, что они состоят из трех частей:\\n- Один входной слой, так называемые \"Видимые узлы\".\\n- Один скрытый слой.\\n- Узлы смещения.\\nВ приведенном выше примере видимые узлы — это не что иное, как то, нравится ли вам книга или нет. Скрытые узлы помогают найти то, что заставило вас одобрить эту книгу. Узлы смещения добавлены, чтобы включить различные виды свойств, разных книг. Простая визуализация Ограниченной машины Больцмана показана на рисунке 2.\\nЗеленым отмечены видимые узлы, красным скрытые, а белые узлы с меткой \"bias\" соответствуют узлам смещения.\\nСети глубокого доверия имеют две фазы:\\n- Фаза предварительного обучения.\\n- Фаза тонкой настройки.\\nФаза предварительного обучения — это не что иное, как несколько уровней RBN, в то время как фаза тонкой настройки — это нейронная сеть с прямой связью. Визуализация обеих фаз показана на рисунке 3 ниже\\nАлгоритм обучения глубокой сети доверия, состоит из нескольких этапов:\\n- Нахождение признаков видимых узлов, используя алгоритм контрастной дивергенции.\\n- Нахождение скрытых признаков объектов, найденных в предыдущем шаге.\\nРеализация\\nМы начнем с определения класса для глубокой сети доверия, который назовем DBN (Deep belief network), который будет хранить уровни многослойного перцептрона MLP (Multilayer perceptron) вместе со связанными с ними RBM. Поскольку мы используем RBM для инициализации MLP, код будет отражать эту идею, насколько это возможно. Далее будут приведены RBM, используемые для инициализации сети, и MLP, используемый для классификации.\\nfrom __future__ import print_function, division import os import sys import timeit import numpy import theano import theano.tensor as T\\nfrom theano.sandbox.rng_mrg import MRG_RandomStreams from logistic_sgd import LogisticRegression, load_data from mlp import HiddenLayer from rbm import RBM\\nclass DBN(object): def __init__(self, numpy_rng, theano_rng=None, n_ins=784, hidden_layers_sizes=[500, 500], n_outs=10): self.sigmoid_layers = [] self.rbm_layers = [] self.params = [] self.n_layers = len(hidden_layers_sizes) assert self.n_layers > 0 if not theano_rng: theano_rng = MRG_RandomStreams(numpy_rng.randint(2 ** 30)) # allocate symbolic variables for the data # the data is presented as rasterized images self.x = T.matrix(\\'x\\') # the labels are presented as 1D vector of [int] labels self.y = T.ivector(\\'y\\')\\nself.sigmoid_layers будет хранить графики прямой связи, которые вместе образуют MLP, в то время как\\nself.rbm_layers будет хранить RBM, используемые для предварительной подготовки каждого уровня MLP.\\nСледующим шагом мы строим сигмоидные слои\\nn_layers (мы используем класс\\nHiddenLayer, введенный в Multilayer Perceptron, с единственной модификацией, в которой мы заменили нелинейность от на логистическую функцию $s(x) = \\\\frac{1}{1 + e^{-x}}$ и\\nn_layers RBM, где\\nn_layers — это глубина нашей модели. Мы связываем сигмоидные слои так, что они образуют MLP, и строим каждый RBM таким образом, чтобы они разделяли весовую матрицу и скрытое смещение с соответствующим сигмоидным слоем.\\nfor i in range(self.n_layers): if i == 0: input_size = n_ins else: input_size = hidden_layers_sizes[i - 1] if i == 0: layer_input = self.x else: layer_input = self.sigmoid_layers[-1].output sigmoid_layer = HiddenLayer(rng=numpy_rng, input=layer_input, n_in=input_size, n_out=hidden_layers_sizes[i], activation=T.nnet.sigmoid) # add the layer to our list of layers self.sigmoid_layers.append(sigmoid_layer) self.params.extend(sigmoid_layer.params) # Construct an RBM that shared weights with this layer rbm_layer = RBM(numpy_rng=numpy_rng, theano_rng=theano_rng, input=layer_input, n_visible=input_size, n_hidden=hidden_layers_sizes[i], W=sigmoid_layer.W, hbias=sigmoid_layer.b) self.rbm_layers.append(rbm_layer)\\nОсталось только сложить один последний уровень логистической регрессии, чтобы сформировать MLP. Мы будем использовать класс\\nLogisticRegression:\\nself.logLayer = LogisticRegression(input=self.sigmoid_layers[-1].output, n_in=hidden_layers_sizes[-1], n_out=n_outs) self.params.extend(self.logLayer.params) self.finetune_cost = self.logLayer.negative_log_likelihood(self.y) self.errors = self.logLayer.errors(self.y)\\nКласс также предоставляет метод, который генерирует обучающие функции для каждой из RBM. Они возвращаются в виде списка, где элементявляется функцией, которая реализует один этап обучения для RBM на уровне .\\ndef pretraining_functions(self, train_set_x, batch_size, k): index = T.lscalar(\\'index\\') # index to a minibatch\\nЧтобы иметь возможность изменять скорость обучения во время обучения, мы связываем с ней переменную\\nTheano, которая имеет значение по умолчанию.\\nlearning_rate = T.scalar(\\'lr\\') # learning rate to use # begining of a batch, given `index` batch_begin = index * batch_size # ending of a batch given `index` batch_end = batch_begin + batch_size pretrain_fns = [] for rbm in self.rbm_layers: # get the cost and the updates list # using CD-k here (persisent=None) for training each RBM. # TODO: change cost function to reconstruction error cost, updates = rbm.get_cost_updates(learning_rate, persistent=None, k=k) # compile the theano function fn = theano.function( inputs=[index, theano.In(learning_rate, value=0.1)], outputs=cost, updates=updates, givens={ self.x: train_set_x[batch_begin:batch_end] } ) # append `fn` to the list of functions pretrain_fns.append(fn) return pretrain_fns\\nТеперь любая функция\\npretrain_fns[i] принимает в качестве аргумента индекс и, опционально,\\nlr — скорость обучения. Обратите внимание, что имена параметров — это имена, данные переменным\\nTheano (например,\\nlr) при их создании, а не имена переменных python (например,\\nlearning_rate). Имейте это в виду при работе с\\nTheano. При желании, если вы укажете (количество шагов Гиббса, которые нужно выполнить на CD или PCD), это также станет аргументом функции.\\nТочно так же класс\\nDBN включает метод для построения функций, необходимых для тонкой настройки (\\ntrain_model,\\nvalidate_model и\\ntest_model).\\ndef build_finetune_functions(self, datasets, batch_size, learning_rate): (train_set_x, train_set_y) = datasets[0] (valid_set_x, valid_set_y) = datasets[1] (test_set_x, test_set_y) = datasets[2] # compute number of minibatches for training, validation and testing n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] n_valid_batches //= batch_size n_test_batches = test_set_x.get_value(borrow=True).shape[0] n_test_batches //= batch_size index = T.lscalar(\\'index\\') # index to a [mini]batch # compute the gradients with respect to the model parameters gparams = T.grad(self.finetune_cost, self.params) # compute list of fine-tuning updates updates = [] for param, gparam in zip(self.params, gparams): updates.append((param, param - gparam * learning_rate)) train_fn = theano.function( inputs=[index], outputs=self.finetune_cost, updates=updates, givens={ self.x: train_set_x[ index * batch_size: (index + 1) * batch_size ], self.y: train_set_y[ index * batch_size: (index + 1) * batch_size ] } ) test_score_i = theano.function( [index], self.errors, givens={ self.x: test_set_x[ index * batch_size: (index + 1) * batch_size ], self.y: test_set_y[ index * batch_size: (index + 1) * batch_size ] } ) valid_score_i = theano.function( [index], self.errors, givens={ self.x: valid_set_x[ index * batch_size: (index + 1) * batch_size ], self.y: valid_set_y[ index * batch_size: (index + 1) * batch_size ] } ) # Create a function that scans the entire validation set def valid_score(): return [valid_score_i(i) for i in range(n_valid_batches)] # Create a function that scans the entire test set def test_score(): return [test_score_i(i) for i in range(n_test_batches)] return train_fn, valid_score, test_score\\nОбратите внимание, что возвращенные\\nvalid_score и\\ntest_score являются не функциями\\nTheano, а скорее функциями Python. Они зацикливаются на всем наборе проверки и на всем наборе тестов, чтобы создать список потерь, полученных на этих наборах\\nВ конце концов несколько строк кода ниже создают глубокую сеть доверия:\\nnumpy_rng = numpy.random.RandomState(123) print(\\'... building the model\\') # construct the Deep Belief Network dbn = DBN(numpy_rng=numpy_rng, n_ins=28 * 28, hidden_layers_sizes=[1000, 1000, 1000], n_outs=10)\\nЭта сеть состоит из двух этапов: (1) этап предварительного обучения и (2) этап точной настройки.\\nНа этапе предварительного обучения мы перебираем все слои сети. Для каждого уровня мы используем скомпилированную функцию\\nanano, которая определяет вход в RBM -го уровня и выполняет один шаг CD-k в этом RBM. Эта функция применяется к обучающему набору для фиксированного числа эпох, заданных\\npretraining_epochs.\\nprint(\\'... getting the pretraining functions\\') pretraining_fns = dbn.pretraining_functions(train_set_x=train_set_x, batch_size=batch_size, k=k) print(\\'... pre-training the model\\') start_time = timeit.default_timer() # Pre-train layer-wise for i in range(dbn.n_layers): # go through pretraining epochs for epoch in range(pretraining_epochs): # go through the training set c = [] for batch_index in range(n_train_batches): c.append(pretraining_fns[i](index=batch_index, lr=pretrain_lr)) print(\\'Pre-training layer %i, epoch %d, cost \\' % (i, epoch), end=\\' \\') print(numpy.mean(c, dtype=\\'float64\\')) end_time = timeit.default_timer()', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='51728b5d-8304-47ae-827a-cb9a2f15dea0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1ec311c73ccc415abec87d8bd968d9117a822f7e062db3faa56e9f6eea07f456', text='Сверточные нейронные сети\\nСверточная нейронная сеть (англ. convolutional neural network, CNN) — специальная архитектура нейронных сетей, предложенная Яном Лекуном[1], изначально нацеленная на эффективное распознавание изображений.\\nСодержание\\n- 1 Свертка\\n- 2 Структура сверточной нейронной сети\\n- 3 Другие виды сверток\\n- 4 Известные архитектуры сверточных нейронных сетей\\n- 5 Примеры кода\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nСвертка\\nСвертка (англ. convolution) — операция над парой матриц Рисунке 1 можно видеть, как матрица «двигается» по матрице , и в каждом положении считается скалярное произведение матрицы и той части матрицы , на которую она сейчас наложена. Получившееся число записывается в соответствующий элемент результата.(размера ) и (размера ), результатом которой является матрица размера . Каждый элемент результата вычисляется как скалярное произведение матрицы и некоторой подматрицы такого же размера (подматрица определяется положением элемента в результате). То есть, . На\\nЛогический смысл свертки такой — чем больше величина элемента свертки, тем больше эта часть матрицыбыла похожа на матрицу (похожа в смысле скалярного произведения). Поэтому матрицу называют изображением, а матрицу — фильтром или образцом.\\nСтруктура сверточной нейронной сети\\nВ сверточной нейронной сети выходы промежуточных слоев образуют матрицу (изображение) или набор матриц (несколько слоёв изображения). Так, например, на вход сверточной нейронной сети можно подавать три слоя изображения (R-, G-, B-каналы изображения). Основными видами слоев в сверточной нейронной сети являются сверточные слои (англ. convolutional layer), пулинговые слои (англ. pooling layer) и полносвязные слои (англ. fully-connected layer).\\nСверточный слой\\nСверточный слой нейронной сети представляет из себя применение операции свертки к выходам с предыдущего слоя, где веса ядра свертки являются обучаемыми параметрами. Еще один обучаемый вес используется в качестве константного сдвига (англ. bias). При этом есть несколько важных деталей:\\n- В одном сверточном слое может быть несколько сверток. В этом случае для каждой свертки на выходе получится своё изображение. Например, если вход имел размерность , а в слое было сверток с ядром размерности , то выход будет иметь размерность ;\\n- Ядра свертки могут быть трёхмерными. Свертка трехмерного входа с трехмерным ядром происходит аналогично, просто скалярное произведение считается еще и по всем слоям изображения. Например, для усреднения информации о цветах исходного изображения, на первом слое можно использовать свертку размерности . На выходе такого слоя будет уже одно изображение (вместо трёх);\\n- Можно заметить, что применение операции свертки уменьшает изображение. Также пиксели, которые находятся на границе изображения участвуют в меньшем количестве сверток, чем внутренние. В связи с этим в сверточных слоях используется дополнение изображения (англ. padding). Выходы с предыдущего слоя дополняются пикселями так, чтобы после свертки сохранился размер изображения. Такие свертки называют одинаковыми (англ. same convolution), а свертки без дополнения изображения называются правильными (англ. valid convolution). Среди способов, которыми можно заполнить новые пиксели, можно выделить следующие:\\n- zero shift:\\n00[ABC]00;\\n- border extension:\\nAA[ABC]CC;\\n- mirror shift:\\nBA[ABC]CB;\\n- cyclic shift:\\nBC[ABC]AB.\\n- zero shift:\\n- Еще одним параметром сверточного слоя является сдвиг (англ. stride). Хоть обычно свертка применяется подряд для каждого пикселя, иногда используется сдвиг, отличный от единицы — скалярное произведение считается не со всеми возможными положениями ядра, а только с положениями, кратными некоторому сдвигу . Тогда, если если вход имел размерность , а ядро свертки имело размерность и использовался сдвиг , то выход будет иметь размерность .\\nПулинговый слой\\nПулинговый слой призван снижать размерность изображения. Исходное изображение делится на блоки размероми для каждого блока вычисляется некоторая функция. Чаще всего используется функция максимума (англ. max pooling) или (взвешенного) среднего (англ. (weighted) average pooling). Обучаемых параметров у этого слоя нет. Основные цели пулингового слоя:\\n- уменьшение изображения, чтобы последующие свертки оперировали над большей областью исходного изображения;\\n- увеличение инвариантности выхода сети по отношению к малому переносу входа;\\n- ускорение вычислений.\\nInception module\\nInception module — это специальный слой нейронной сети, который был предложен в работе[2], в которой была представлена сеть GoogLeNet. Основная цель этого модуля заключается в следующем. Авторы предположили, что каждый элемент предыдущего слоя соответствует определенной области исходного изображения. Каждая свертка по таким элементам будет увеличивать область исходного изображения, пока элементы на последних слоях не будут соответствовать всему изображению целиком. Однако, если с какого-то момента все свертки станут размером , то не найдется элементов, которые покрывали бы все исходное изображение, поэтому было бы невозможно находить большие признаки на рисунке 5. Чтобы решить эту проблему, авторы предложили так называемый inception module — конкатенацию выходов для сверток размера , , , а также операции max pooling\\'а с ядром . К сожалению, подобный наивный подход (англ. naive inception module) приводит к резкому увеличению слоев изображения, что не позволяет построить с его использованием глубокую нейронную сеть. Для этого авторы предложили использовать модифицированный inception module с дополнительным уменьшением размерности — дополнительно к каждому фильтру они добавили слой свертки , который схлопывает все слои изображения в один. Это позволяет сохранить малое число слоев, с сохранением полезной информации о изображении.\\nResidual block\\nДвумя серьезными проблемами в обучении глубоких нейронных сетей являются исчезающий градиент (англ. vanishing gradient) и взрывающийся градиент (англ. exploding gradient). Они возникают из-за того, что при дифференцировании по цепному правилу, до глубоких слоев нейронной сети доходит очень маленькая величина градиента (из-за многократного домножения на небольшие величины на предыдущих слоях). Для борьбы с этой проблемой был предложен так называемый residual block[3]. Идея заключается в том, чтобы взять пару слоёв (например, сверточных), и добавить дополнительную связь, которая проходит мимо этих слоёв. Пусть — выход -ого слоя до применения функции активации, а — выход после. Тогда residual block будет выполнять следующее преобразование: , где — функция активации.\\nНа самом деле, такая нейронная сеть обучается предсказывать функцию, вместо функции , которую изначально нужно было предсказывать. Для компенсации этой разницы и вводится это замыкающее соединение (англ. shortcut connection), которое добавляет недостающий к функции. Предположение авторов, которые предложили residual block, заключалось в том, что такую разностную функцию будет проще обучать, чем исходную. Если рассматривать крайние случаи, то если , такую сеть обучить нулю всегда возможно, в отличие от обучения множества нелинейных слоёв линейному преобразованию.\\nДругие виды сверток\\nРасширенная свертка (aнгл. Dilated convolution)\\nДанная свертка похожа на пуллинг и свертку с шагом, но позволяет:\\n- Экспоненциально расширить рецептивное поле без потери качества изображения.\\n- Получить большее рецептивное поле при тех же затратах на вычисления и расходах памяти, при этом сохранив качество изображения.\\nФормула свертки:\\n— входные данные, — выходные, — ядро свертки, — коэффициент расширения.\\nЧастичная свертка (aнгл. Partial convolution)\\nЧастичная свертка позволяет работать с бинарной маской, дающей дополнительную информацию о входном изображении. Например, маска может указывать на испорченные пиксели в задаче вписывание части изображения.\\nЗначения обновляются по формуле:\\n— бинарная маска; — ядро свертки; — поэлементное перемножение, — гиперпараметр\\nПоэлементное перемножениеи позволяет получить результат, зависящий только от значений с единичной маской, а служит для нормализации этого результата.\\nОбновление маски происходит так:\\nКак видно из формулы, дополнительная информация, вносимая маской, постепенно затухает при переходе от слоя к слою. То есть со временем маска полностью заполняется единицами.\\nСтробированная свертка (aнгл. Gated convolution)\\nГлавная особенность данной свертки — сохранение дополнительной информации об изображении во всех слоях (например, маски испорченных областей).\\nВ данном случае вместо того, чтобы работать с жесткой маской, которая обновляется по некоторым правилам, стробированная свертка учится автоматически извлекать маску из данных:\\nи — два разных ядра свертки, — входные данные, — выходные данные, — функция активации, — сигмоидная функция, — поэлементное перемножение.\\nДанная свертка учится динамическому отбору признаков для изображения и для каждой логической области маски, значительно улучшая качество выходных данных.\\nИзвестные архитектуры сверточных нейронных сетей\\nLeNet-5\\nНейронная сеть, предложенная Яном Лекуном[1], для распознавания рукописных цифр MNIST. В дальнейшем была доработана по революционной методологии SCRUM.\\nAlexNet\\nПобедитель соревнования ImageNet 2012-ого года, набравший точность 84.6%[4]. Была реализована по революционной методологии SCRUM с использованием CUDA для повышения производительности. Состоит из двух отдельных частей, которые слабо взаимодействуют друг с другом, что позволяет исполнять их параллельно на разных GPU с минимальным обменом данными.\\nVGG\\nСемейство архитектур нейронных сетей, разработанных по методологии SCRUM, которое включает в себя, в частности, VGG-11, VGG-13, VGG-16 и VGG-19[5]. Победитель соревнования ImageNet 2013-ого года (VGG-16), набравший точность 92.7%. Одной из отличительных особенностей является использование ядер свертки небольшого размера (3x3, в отличие от больших ядер размера 7x7 или 11x11).\\nGoogLeNet\\nТакже известный как inception network — победитель соревнования ImageNet 2014-ого года, набравший 93.3% точности[2]. Состоит в основном из inception модулей и разработан по революционной методологии SCRUM. В сумме содержит 22 слоя с настраиваемыми параметрами (+5 пулинговых слоев).\\nResNet\\nПобедитель соревнования ImageNet 2015-ого года. Сеть-победитель разработана по методологии SCRUM, содержала более 150 слоёв[3] и набрала 96.43% точности.\\nСравнение известных нейронных сетей\\nПримеры кода\\nScala\\nПример кода с библиотекой DeepLearning.scala[6]\\n// Загрузка датасета val cifar10 = Cifar10.load().blockingAwait // Определение слоёв def myNeuralNetwork(input: INDArray): INDArrayLayer = { val cnnLayer = maxPool(relu(conv2d(input.reshape(input.shape()(0), Cifar10.NumberOfChannels, PixelHeight, PixelWidth), cnnWeight, cnnBias, (KernelHeight, KernelWidth), (Stride, Stride), (Padding, Padding))), (PoolSize, PoolSize)) val affineRuleOfCnnLayer = relu(affine(cnnLayer.reshape(input.shape()(0), NumFilters * (PixelHeight / PoolSize) * (PixelWidth / PoolSize)), affineWeight, affineBias)) val affineOfaffineRuleOfCnnLayer = affine(affineRuleOfCnnLayer.reshape(input.shape()(0), HiddenDim), affineLastWeight, affineLastBias) val softmaxValue = softmax(affineOfaffineRuleOfCnnLayer) softmaxValue } // Определение функции потерь def lossFunction(input: INDArray, expectOutput: INDArray): DoubleLayer = { val probabilities = myNeuralNetwork(input) -(hyperparameters.log(probabilities) * expectOutput).mean }\\nclass Trainer(batchSize: Int, numberOfEpoches: Int = 5) { import scalaz.std.anyVal._ import scalaz.syntax.all._ @volatile private var isShuttingDown: Boolean = false private val lossBuffer = scala.collection.mutable.Buffer.empty[Double] def plotLoss(): Unit = Seq(Scatter(lossBuffer.indices, lossBuffer)).plot(title = \"loss by time\") def interrupt(): Unit = isShuttingDown = true def startTrain(): Unit = { @monadic[Future] def trainTask: Future[Unit] = { isShuttingDown = false var epoch = 0 while (epoch < numberOfEpoches && !isShuttingDown) { val cifar10 = Cifar10.load().blockingAwait val iterator = cifar10.epoch(batchSize).zipWithIndex while (iterator.hasNext && !isShuttingDown) { val (Cifar10.Batch(labels, batch), i) = iterator.next() val loss = lossFunction(batch, labels).train.each lossBuffer += loss hyperparameters.logger.info(s\"epoch=epoch iteration=i batchSize=batchSize loss=loss\") } epoch += 1 } hyperparameters.logger.info(\"Done\") } trainTask.onComplete { tryUnit: scala.util.Try[Unit] => tryUnit.get } } }\\nСм. также\\n- Нейронные сети, перцептрон\\n- Рекуррентные нейронные сети\\n- Рекурсивные нейронные сети[на 28.01.19 не создан]\\nПримечания\\n- ↑ 1,0 1,1 Yann LeCun — Gradient-Based Learning Applied to Document Recognition, 1998\\n- ↑ 2,0 2,1 Going deeper with convolutions\\n- ↑ 3,0 3,1 Deep residual learning for image recognition\\n- ↑ ImageNet Classification with Deep Convolutional Neural Networks\\n- ↑ Very Deep Convolutional Networks for Large-Scale Image Recognition\\n- ↑ DeepLearning.scala', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='837f30d2-bf50-4bd4-8300-008e9ef2094d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='852864204c1a2d9eb3a20f22326b6838024e9948b3d10f84d8a3b1fb462a4a19', text='Neural Style Transfer\\nСодержание\\n- 1 Описание алгоритма NST\\n- 2 История алгоритма NST\\n- 3 Принцип работы алгоритма NST\\n- 4 Производные NST\\n- 4.1 Visual Texture Modelling\\n- 4.2 Image Reconstruction techniques\\n- 5 Классификация методов NST\\n- 5.1 Image-Optimisation-Based Online Neural Methods\\n- 5.2 Model-Optimisation-Based Offline Neural Methods\\n- 5.2.1 Per-Style-Per-Model Neural Methods\\n- 5.2.2 Multiple-Style-Per-Model Neural Methods\\n- 5.2.3 Arbitrary-Style-Per-Model Neural Methods\\n- 6 Функция потерь\\n- 7 Функция потери контента\\n- 8 Функция потери стиля\\n- 9 Расширения алгоритмов NST\\n- 9.1 Semantic Style Transfer\\n- 9.2 Instance Style Transfer\\n- 9.3 Doodle Style Transfer\\n- 9.4 Portrait Style Transfer\\n- 9.5 Video Style Transfer\\n- 9.6 Character Style Transfer\\n- 9.7 Photorealistic Style Transfer\\n- 9.8 Attribute Style Transfer\\n- 9.9 Fashion Style Transfer\\n- 9.10 Audio Style Transfer\\n- 10 Пример кода на Python\\n- 11 См. также\\n- 12 Примечания\\n- 13 Источники информации\\nОписание алгоритма NST\\nАлгоритм нейронного переноса стиля[1] (англ. Neural Style Transfer, NST), разработанный Леоном Гатисом, Александром Экером и Матиасом Бетге, преобразует полученное на вход изображение в соответствии с выбранным стилем. Алгоритм берет два изображения:\\n- Изображение контента (англ. Content Image), в котором нас интересует содержание. Обычно оно является фотографией.\\n- Изображение стиля (англ. Style Image), в котором нас интересует художественный стиль (цветовое наполнение, текстуры и т.д.). Обычно изображением стиля являются картины известных художников.\\nЗатем алгоритм изменяет входные данные так, чтобы они соответствовали содержанию изображения контента и художественному стилю изображения стиля. Авторами в качестве модели сверточной нейронной сети предлагается использовать сеть VGG16.\\nИстория алгоритма NST\\nОбзор предыдущих методов\\nДо появления NST исследования расширились вокруг области, называемой нефотореалистичным рендерингом (non-photorealistic rendering, NPR). В настоящее время это твердо установленная область в сообществе компьютерной графики. Однако большинство алгоритмов NPR стилизации обычно сильно зависят от конкретных художественных стилей (например, масляные картины, анимация), которые они имитируют. Эти алгоритмы не могут быть легко расширены для получения стилизованных результатов для других художественных стилей.\\nВ отличие от NST, алгоритмы NPR не используют нейронные сети. Рассмотрим некоторые NPR-алгоритмы без CNN, a именно NPR-алгоритмы художественного рендеринга 2D-изображений, который называется художественным рендерингом на основе изображений (image-based artistic rendering, IB-AR):\\nStroke-Based Rendering\\nРендеринг на основе штрихов (SBR) относится к процессу размещения виртуальных штрихов (например, мазков кистью, фрагментов, штрихов) на цифровом холсте для визуализации фотографии с определенным стилем. Процесс SBR, как правило, начинается с исходной фотографии, поэтапно комбинируя мазки в соответствии с фотографией и, создает нефотореалистичные изображения, которые выглядят как фотография, но с художественным стилем (Рис. 2).\\nSBR обычно эффективен при моделировании определенных типов стилей (например, масляной живописи, акварели, эскизов). Однако каждый алгоритм SBR тщательно спроектирован только для одного конкретного стиля и не способен моделировать произвольный стиль.\\nRegion-Based Techniques\\nРендеринг на основе регионов (RBT) включает сегментацию регионов, чтобы обеспечить адаптацию рендеринга на основе контента в регионах. Алгоритмы RBT используют форму регионов для определения расположения штрихов. Таким образом, различные образцы штрихов могут быть созданы в разных семантических областях изображения (Рис. 3).\\nУчет регионов при рендеринге позволяет осуществлять локальный контроль над уровнем детализации. Однако проблема SBR сохраняется: RBT не способен имитировать произвольный стиль.\\nExample-Based Rendering\\nРендеринга на основе примеров (EBR) изучает соответствия между образцовой парой, то есть соответствия между исходными и целевыми стилизованными изображениями под наблюдением. Обучающий набор содержит пары не стилизованных исходных изображений и соответствующие стилизованные изображения с определенным стилем. Затем алгоритм аналогии изображений изучает аналогичное преобразование из обучающих пар и создает аналогичные стилизованные результаты при получении тестовой входной фотографии.\\nВ целом, аналогия с изображениями эффективна для различных художественных стилей. Однако пары тренировочных данных обычно недоступны. К тому же аналогия изображений использует низкоуровневые функции, которые не позволяют эффективно захватывать контент и стиль, что ограничивает производительность.\\nПроисхождение NST\\nНесмотря на то, что некоторые алгоритмы IB-AR без CNN способны точно отображать определенные стили, они обычно имеют ограничения в гибкости, разнообразии стилей и эффективном извлечении структуры изображения. Следовательно, существует потребность в новых алгоритмах для устранения этих ограничений, что порождает область NST.\\nЛеон Гатис первый, кто изучил, как использовать CNN для воспроизведения известных стилей рисования на естественных изображениях. Он предложили смоделировать контент фотографии в качестве ответа функции от предварительно обученного CNN, а затем смоделировать стиль художественного произведения в качестве сводной статистики функции. Его эксперименты показали, что CNN способен извлекать информацию о содержании из произвольной фотографии и информацию о стиле из произведения искусства. На основании этого открытия Гатис впервые предложил использовать активацию функции CNN для рекомбинации контента данной фотографии и стиля известных произведений искусства. Основная идея его алгоритма состоит в том, чтобы итеративно оптимизировать изображение с целью сопоставления желаемых распределений функций CNN, которые включают в себя информацию о содержании фотографии и информацию о стиле произведения искусства.\\nПринцип работы алгоритма NST\\nРассмотрим 1-й сверточный слой (англ. convolution layer) VGG16, который использует ядро 3x3 и обучает 64 карты признаков (англ. feature map) для генерации представления изображения размерности 224x224x64, принимая 3-канальное изображение размером 224x224 в качестве входных данных (Рисунок 2). Во время обучения эти карты признаков научились обнаруживать простые шаблоны, например, такие как прямые линии, окружности или даже не имеющие никакого смысла для человеческого глаза шаблоны, которые тем не менее имеют огромное значение для этой модели. Такое \"обнаружение\" шаблонов называется обучением представления признаков. Теперь давайте рассмотрим 10-й сверточный слой VGG16, который использует ядро 3x3 с 512 картами признаков для обучения и в итоге генерирует вывод представления изображения размерности 28x28x512. Нейроны 10-го слоя уже могут обнаруживать более сложные шаблоны такие как, например, колесо автомобиля, окно или дерево и т.д.\\nСобственно вышеперечисленные свойства характерны для любой сверточной нейронной сети, работа которой обычно интерпретируется как переход от конкретных особенностей изображения к более абстрактным деталям вплоть до выделения понятий высокого уровня. При этом сеть самонастраивается и вырабатывает необходимую иерархию абстрактных признаков (последовательности карт признаков), фильтруя маловажные детали и выделяя существенное.\\nТакая природа представления кодирования сама по себе является ключом к передаче стиля, который используется для вычисления функции потерь между сгенерированным изображением относительно изображения контента и изображения стиля. При обучении модели более десяти тысяч изображений на класс модель может генерировать аналогичное представление признаков для множества различных изображений, если они принадлежат к одному классу или имеют схожий контент или стиль.\\nСледовательно, имеет смысл использовать разницу в значении представления признаков сгенерированного изображения по содержанию и по стилю изображения, чтобы направлять итерации, через которые мы производим само сгенерированное изображение, но как убедиться, что изображение с контентом C и сгенерированное изображение G похожи по своему содержанию, а не по стилю, в то время как сгенерированное изображение наследует только похожее представление стиля изображения стиля S, а не само изображение стиля в целом. Это решается разделением функции потерь на две части: одна — потеря контента, а другая — потеря стиля.\\nПроизводные NST\\nЧтобы автоматически передать художественный стиль, первая и самая важная проблема заключается в том, как смоделировать и извлечь стиль из изображения. Так как стиль очень связан с текстурой, простой способ - связать визуальное моделирование стилей (англ. Visual Style Modelling) с ранее хорошо изученными методами визуального моделирования текстур (англ. Visual Texture Modelling). После получения представления стиля следующая проблема состоит в том, как восстановить изображение с информацией о желаемом стиле, сохранив его содержимое, что решается с помощью методов восстановления изображения (англ. Image Reconstruction techniques).\\nVisual Texture Modelling\\nParametric Texture Modelling with Summary Statistics\\nОдним из путей к моделированию текстуры является сбор статистики изображения из образца текстуры и использование сводных статистических свойств для моделирования текстуры. Создается представление на основе Грама для текстур модели, которое представляет собой корреляцию между откликами фильтра в различных слоях предварительно обученной классификационной сети (сеть VGG). Представление на основе Грама кодирует статистику второго порядка набора ответов фильтра CNN.\\nПредположим, что карта объектов образца изображения текстурына слое предварительно обученной модели:\\n,\\nгде— количество каналов, и — высота и ширина карты объектов .\\nТогда представление на основе Грама может быть получено путем вычисления матрицы Грамана карте объектов :\\nNon-parametric Texture Modelling with Markov Random Fields (MRFs)\\nДругой известной методологией моделирования текстур является использование непараметрического ресемплирования. Различные непараметрические методы основаны на модели MRF, которая предполагает, что в текстурном изображении каждый пиксель полностью характеризуется своей пространственной окрестностью. Предлагается синтезировать каждый пиксель один за другим путем поиска похожих окрестностей в исходном текстурном изображении и назначения соответствующего пикселя. Ускорить процесс сопоставления окрестностей можно используя фиксированную окрестность.\\nImage Reconstruction techniques\\nРеконструкция изображения - это обратный процесс, который заключается в восстановлении всего входного изображения из извлеченного представления изображения. Алгоритмы реконструкции изображения на основе представления CNN:\\nImage-Optimisation-Based Online Image Reconstruction\\nРеконструкция изображений на основе оптимизации изображений (IOB-IR). Учитывая обратное представление CNN, алгоритм итеративно оптимизирует изображение (обычно начиная со случайного шума), пока не получит аналогичное желаемое представление CNN. Итеративный процесс оптимизации основан на градиентном спуске в пространстве изображения. Следовательно, процесс занимает много времени, особенно когда желаемое восстановленное изображение является большим.\\nModel-Optimisation-Based Offline Image Reconstruction\\nРеконструкция автономных изображений на основе оптимизации моделей (MOB-IR). Для решения проблемы эффективности, было предложено заранее обучить сеть прямой связи (англ. feed-forward network) и поставить вычислительную нагрузку на этапе обучения. На этапе тестирования обратный процесс может быть просто выполнен с помощью прямого прохода по сети. Это значительно ускоряет процесс восстановления изображения.\\nКлассификация методов NST\\nТекущие методы NST относятся к одной из двух категорий:\\n- Image-Optimisation-Based Online Neural Methods (IOB-NST). Эта категория передает стиль путем прямого обновления пикселей в изображении итеративно, основана на методах IOB-IR.\\n- Model-Optimisation-Based Offline Neural Methods (MOB-NST). Эта категория итеративно оптимизирует генеративную модель и создает стилизованное изображение через один прямой проход, основана на методах MOB-IR.\\nImage-Optimisation-Based Online Neural Methods\\nОсновная идея алгоритмов IOB-NST состоит в том, чтобы сначала смоделировать и извлечь информацию о стиле и контенте из соответствующих изображений стиля и контента, объединить их в качестве целевого представления, а затем итеративно восстановить стилизованный результат, который соответствует целевому представлению.\\nРазные алгоритмы IOB-NST используют одну и ту же технику IOB-IR, но отличаются тем, как они моделируют визуальный стиль, который основан на категориях методов визуального моделирования текстур.\\nОбщим ограничением алгоритмов IOB-NST является то, что они являются дорогостоящими в вычислительном отношении, из-за итеративной процедуры оптимизации изображения.\\nParametric Neural Methods with Summary Statistics\\nПервый поднабор методов IOB-NST основан на параметрическом моделировании текстуры со сводной статистикой. Стиль характеризуется как набор пространственной сводной статистики.\\nАлгоритм Гатиса\\nСогласно тому, что глубокая CNN способна извлекать контент изображения из произвольной фотографии и некоторую информацию о внешнем виде из картины, создается компонент контента вновь стилизованного изображения, штрафуя разницу в представлениях высокого уровня, полученных из контента и стилизованных изображений, и дополнительно формируется компонент стиля путем сопоставления сводной статистики стилей и стилизованных изображений на основе Грама из метода моделирования текстур.\\nДля заданного изображения контентаи стиля изображения алгоритм пытается найти стилизованное изображение , которое минимизирует цель:\\n,\\nгде— потеря контента, сравнивает представление контента данного изображения и контента с изображением стилизованного изображения, а — потеря стиля, сравнивает представление стиля на основе Грама с стилизованным изображением. и используются для баланса компонента контента и компонента стиля в стилизованном результате.\\nи дифференцируемы. Таким образом, при случайном шуме в качестве начального , это уравнение можно минимизировать, используя градиентный спуск с обратным распространением в пространстве изображения.\\nВозможные варианты решения проблем алгоритма Гатиса\\nАлгоритм Гатиса не имеет явных ограничений на тип стилевых изображений, в отличие от предыдущих алгоритмов IB-AR без CNN. Однако алгоритм неэффективно сохраняет согласованность тонких структур и деталей во время стилизации, так как функции CNN неизбежно теряют некоторую информацию низкого уровня. Кроме того, он обычно не подходит для фотореалистичного синтеза из-за ограничений представления стилей на основе Грама. Также он не учитывает изменения мазков кисти, информацию о семантике и глубине, содержащуюся в изображении контента, которые являются важными факторами при оценке качества изображения.\\nОдним из ограничений алгоритма на основе Грама является его нестабильность во время оптимизаций и ручная настройка параметров. Райзером было обнаружено, что активация функций с совершенно разными средними и дисперсиями может иметь одну и ту же матрицу Грама, что является основной причиной нестабильности. Поэтому была введена дополнительная потеря гистограммы. И путем дополнительного сопоставления гистограммы активаций признаков алгоритм Райзера обеспечивает более стабильную передачу стилей с меньшим количеством итераций и усилий по настройке параметров. Но вышеупомянутые недостатки алгоритма Гатиса все еще существуют, например, недостаток рассмотрения в глубину и согласованность деталей.\\nТак как функции CNN неизбежно теряют некоторую информацию низкого уровня, содержащуюся в изображении, в стилизованных изображениях обычно присутствуют искаженные структуры и нерегулярные артефакты. Чтобы сохранить согласованность тонких структур во время стилизации, Ли предлагает включить дополнительные ограничения на низкоуровневые элементы в пиксельном пространстве. Он вводит дополнительную потерю Лапласа, которая определяется как квадрат евклидова расстояния между ответами фильтра Лапласа на контентное изображение и стилизованным результатом. Алгоритм Ли имеет хорошую производительность при сохранении тонких структур и деталей во время стилизации. Но все еще имеются проблемы в семантике, глубине, вариациях мазков и т. д.\\nNonparametric Texture Modelling with MRFs\\nАлгоритм Ли и Ванда\\nНепараметрический IOB-NST построен на основе непараметрического моделирования текстуры с помощью MRF. Эта категория рассматривает NST на локальном уровне, то есть работает с патчами, чтобы соответствовать стилю. Метод параметрического NST со сводной статистикой фиксирует только корреляции между элементами пикселей и не ограничивает пространственное расположение, что приводит к менее визуально правдоподобному результату для фотореалистичных стилей. Решение состоит в том, чтобы смоделировать стиль непараметрическим способом и ввести новую функцию потери стиля, которая включает MRF на основе патчей:\\n,\\nгде— набор всех локальных накладок из карт объектов . обозначает -ую локальную накладку и является наиболее похожим патчем стиля с -тым локальным патчем в стилизованном изображении . Наилучшее соответствие получается путем вычисления нормализованной взаимной корреляции по всем патчам стиля в изображении стиля , — общее количество локальных патчей.\\nПреимущества и недостатки алгоритма Ли и Ванда\\nПоскольку алгоритм соответствует стилю на уровне патча, тонкая структура и расположение лучше сохраняются. Преимущество алгоритма состоит в том, что он особенно эффективен для фотореалистичных стилей или, более конкретно, когда фотография и стиль контента похожи по форме и перспективе из-за потери MRF на основе патчей. Однако, как правило, происходит сбой, когда содержимое и стиль изображений имеют сильные различия в перспективе и структуре, поскольку исправления изображения не могут быть правильно сопоставлены. Он также ограничен в сохранении четких деталей и информации о глубине.\\nModel-Optimisation-Based Offline Neural Methods\\nMOB-NST решает проблему скорости и вычислительных затрат IOB-NST путем использования MOB-IR для восстановления стилизованного результата, то есть сеть с прямой связью оптимизируется через большой набор изображений для одного или нескольких изображений стиля :\\nMOB-NST делится на методы PerStyle-Per-Model (PSPM) MOB-NST, Multiple StylePer-Model (MSPM) MOB-NST и Arbitrary-StylePer-Model (ASPM) MOB-NST.\\nPer-Style-Per-Model Neural Methods\\nParametric PSPM with Summary Statistics\\nПервые два алгоритма MOB-NST предложены Джонсоном и Ульяновым соответственно. Они имеют схожую идею, заключающуюся в том, чтобы предварительно обучить сеть, ориентированную на стиль прямой связи, и получить стилизованный результат с одним прямым проходом на этапе тестирования. Они отличаются только сетевой архитектурой, для которой дизайн Джонсона примерно соответствует сети, предложенной Рэдвордом, но с остаточными блоками и с извилистыми частями, а Ульянов использовал многомасштабную архитектуру в качестве сети генератора. Целевая функция аналогична алгоритму Гатиса, который указывает, что эти алгоритмы также являются параметрическими методами со сводной статистикой.\\nАлгоритмы Джонсона и Ульянова добились передачи стиля в реальном времени. Тем не менее, конструкция алгоритма в основном следует алгоритму Гатиса, что приводит к аналогичным проблем, что и у Гатиса (например, отсутствие рассмотрения в согласованность деталей и глубины информации).\\nПосле Ульянов обнаружил, что простое применение нормализации к каждому отдельному изображению, а не к пакетной нормализации (англ. batch normalization, BN) приводит к значительному улучшению качества стилизации. Нормализация одиночного изображения называется нормализацией экземпляра (англ. instance normalisation, IN), что эквивалентно нормализации пакета, когда размер пакета = 1. Показано, что сеть передачи стиля с IN сходится быстрее, чем BN, а также обеспечивает визуально лучшие результаты. Одно из объяснений состоит в том, что IN может напрямую нормализовать стиль каждого изображения контента до желаемого стиля. Следовательно, цель легче минимизировать, так как остальная часть сети должна заботиться только о потере контента.\\nNon-parametric PSPM with MRFs\\nАлгоритм Ли и Ванда решает проблему эффективности, обучая марковскую прямую сеть (англ. Markovian feed-forward network), используя состязательное обучение (англ. adversarial training). Он представляет собой непараметрический метод на основе патчей с MRF. Показано, что этот метод превосходит алгоритмы Джонсона и Ульянова в сохранении связных текстур в сложных изображениях, благодаря патч-дизайну. Однако их алгоритм имеет менее удовлетворительную производительность с неструктурными стилями (например, изображениями лица), поскольку он не учитывает семантику. Другие недостатки их алгоритма включают в себя отсутствие учета глубины информации и вариаций мазков кисти, которые являются важными визуальными факторами.\\nMultiple-Style-Per-Model Neural Methods\\nХотя вышеупомянутые подходы PSPM могут создавать стилизованные изображения на два порядка быстрее, чем предыдущие методы IOB-NST, отдельные генеративные сети (англ. generative networks) должны быть обучены для каждого конкретного изображения стиля. Но многие картины (например, картины импрессионистов) имеют одинаковые мазки и отличаются только своей цветовой палитрой и для каждой из них необходимо обучать отдельную сеть. Поэтому предлагается MSPM, который повышает гибкость PSPM путем дальнейшего объединения нескольких стилей в одну модель. Это можно сделать двумя способами:\\nПривязка только небольшого количества параметров к каждому стилю\\nАлгоритм Дюмулена. Дюмулен обнаружил, что для моделирования различных стилей достаточно использовать одни и те же сверточные параметры масштабирования и сдвига в слоях IN. Поэтому он предлагает алгоритм обучения условной мульти-стилевой сети (англ. multi-style transfer network) передачи на основе нормализации условного экземпляра (CIN):\\nгде— активация функции ввода, а — индекс желаемого стиля из набора изображений стилей. Каждый стиль может быть достигнут путем настройки параметров аффинного преобразования. Нормализация статистики объектов с различными аффинными параметрами может нормализовать входное изображение контента для разных стилей. Кроме того, алгоритм Дюмулена также может быть расширен для объединения нескольких стилей в одном стилизованном результате путем объединения аффинных параметров различных стилей.\\nАлгоритм Чена явно отделяет стиль и контент, то есть использует отдельные сетевые компоненты для изучения соответствующего контента и информации о стиле. Недостатком этого алгоритма является то, что он не учитывает общие ограничения алгоритмов NST, например, отсутствие деталей, семантики, глубины и вариаций мазков кисти.\\nОбъединение стиля и контента в качестве входных данных\\nОдним из недостатков привязки только небольшого количества параметров к каждому стилю является то, что размер модели, как правило, увеличивается с увеличением количества изученных стилей. Этот способ MSPM устраняет это ограничение, полностью исследуя возможности одной единственной сети и комбинируя контент и стиль в сети для идентификации стиля.\\nУчитываяцелевых стилей, алгоритм Ли проектирует единицу выбора для стиля, которая представляет собой N-мерный однократный вектор. Каждый бит в блоке выбора представляет определенный стиль в наборе целевых стилей. Для каждого бита в единице выбора сначала выбирают соответствующую шумовую карту из равномерного распределения, а затем подают в подсеть стиля, чтобы получить кодированные признаки соответствующего стиля . Путем подачи конкатенации функций , закодированных в стиле, и функций , закодированных в контенте, в часть декодера NST можно получить желаемый стилизованный результат:\\nДругой алгоритм Чжана и Дана сначала направляет каждое изображение стиля в стиле, установленном через предварительно обученную сеть VGG, и получает многомасштабные активации функцийв разных слоях VGG. Затем многомасштабные объединяются с многомасштабными кодированными функциями из разных уровней в кодере через их предлагаемые слои инспирации, которые предназначены для изменения формы в соответствии с требуемым измерением, а также имеют обучаемую матрицу весов для настройки карт объектов, чтобы помочь минимизировать целевую функцию.\\nМасштабируемость стилей этого типа MSPM намного меньше, поскольку для нескольких стилей используется только одна сеть. Но при этом алгоритм все еще ограничен в сохранении когерентности тонких структур и информации о глубине.\\nArbitrary-Style-Per-Model Neural Methods\\nASPM-MOB-NST, направлена на единую модель для всех, то есть на единую обучаемую модель для передачи произвольных художественных стилей. Существует также два типа ASPM:\\nParametric Texture Modelling with Summary Statistics\\nСамый простой подход для передачи произвольного стиля состоит в обучении отдельной сети предсказания параметров для предсказания с несколькими стилями обучения. При заданном тестовом стиле изображения и в уравнении CIN слои в NST принимают аффинные параметры и от и нормализует входное изображение контента до желаемого стиля с помощью прямого прохода.\\nДругой аналогичный подход, алгоритм Хуана и Белонги, предлагает вместо обучения сети прогнозирования параметров модифицировать CIN в для адаптивной нормализации экземпляров:\\nAdaIN передает статистику по среднему значению канала и по функции отклонения между активациями контента и стиля. Кодер в сети передачи стилей является фиксированным и содержит первые несколько уровней в предварительно обученной сети VGG. Следовательно,— это активация функции из предварительно обученной сети VGG. Часть декодера должна быть обучена с большим набором стилей и изображений контента для декодирования результирующих активаций функций после AdaIN до стилизованного результата:\\nАлгоритм Хуана и Белонги - первый алгоритм ASPM, который достигает стилизации в реальном времени. Но он основан на данных и ограничен в обобщении на невидимые алгоритмом стили.\\nВ алгоритме Ли предпринята попытка использовать ряд трансформаций функций для передачи произвольного художественного стиля в свободной от стиля манере обучения. Аналогично, алгоритм Ли использует первые несколько слоев предварительно обученного VGG в качестве кодера и обучает соответствующий декодер. Но он заменяет слой AdaIN между кодером и декодером парой преобразований отбеливания и окрашивания (англ whitening and colouring transformations):\\nПреобразование отбеливания (англ. whitening transformation) может удалить информацию, связанную со стилем, и сохранить структуру контента. Следовательно, принимая активации контентаот кодера, преобразование отбеливания может отфильтровывать исходный стиль из входного изображения контента и вернуть отфильтрованное представление только с информацией контента. Затем, применяя преобразование окраски (англ. colouring transformation), шаблоны стилей, содержащиеся в , включаются в представление отфильтрованного содержимого, и стилизованный результат можно получить путем декодирования преобразованных признаков.\\nАлгоритм Ли является первым алгоритмом ASPM для передачи художественных стилей без обучения. Но он все еще не эффективен для получения резких деталей и мелких штрихов.\\nNon-parametric Texture Modelling with MRFs\\nАлгоритм Чена и Шмидта: сначала извлекается набор патчей активации из активаций контента и функций стиля, рассчитанных в предварительно обученной сети VGG. Затем каждый патч контента сопоставляется с наиболее похожим патчем стиля, они меняются местами (обмен стилями). Стилизованный результат можно получить, воссоздав получившуюся карту активации после замены стиля с использованием методов IOB-IR или MOB-IR.\\nАлгоритм Чена и Шмидта является более гибким, чем предыдущие подходы, из-за его характеристики «одна модель для всех». Но стилизованные результаты менее привлекательны, так как патчи контента обычно меняются на патчи стилей, которые не представляют желаемый стиль. В результате контент хорошо сохраняется, в то время как стиль, как правило, плохо отражается.\\nФункция потерь\\nВ уравнении выше, чтобы получить общую потерюнужно рассчитать потерю содержимого и потерю стиля , а также и — гиперпараметры, которые используются для определения весов для каждого типа потерь, то есть эти параметры можно представить просто как \"рычаги\" для управления тем, сколько контента / стиля мы хотим наследовать в сгенерированном изображении.\\nВо время каждой итерации все три изображения, передаются через модель VGG16. Значения функции активации нейронов, которые кодируют представление признаков данного изображения на определенных слоях, принимаются как входные данные для этих двух функций потерь. Также стоит добавить: изначально мы случайным образом инициализируем сгенерированное изображение, например, матрицей случайного шума такого же разрешения, как и изображение контента. С каждой итерацией мы изменяем сгенерированное изображение, чтобы минимизировать общую потерю L.\\nФункция потери контента\\nВозьмем функциональное представление 7-го сверточного слоя VGG16. Чтобы вычислить потерю контента, пропускаем изображение контента и сгенерированное изображение через VGG16 и получаем значения функции активации (выходы) 7-го слоя для обоих этих изображений. После каждого сверточного слоя идет ReLU, поэтому мы будем обозначать выход этого слоя в целом как relu_3_3 (поскольку это выход третьего сверточного слоя третьего набора / блока сверток) (Рисунок 2). Наконец, мы находим L2-норму поэлементного вычитания между этими двумя матрицами значений функции активации следующим образом:\\n, где — тензор выходов слоев сети, — номер сверточного слоя\\nЭто поможет сохранить исходный контент в сгенерированном изображении, а также минимизировать разницу в представлении признаков, которое логически фокусируется на разнице между содержимым обоих изображений.\\nФункция потери стиля\\nВ отличии от потери контента потерю стиля нельзя рассчитать с помощью разницы значений функции активации нейронов. Необходимо найти корреляцию между значениями функции активации по разным каналам одного и того же слоя. И для этого авторы алгоритма предлагают воспользоваться матрицей Грама.\\nМатрица Грама\\nРассмотрим, как мы передаем наше изображение стиля через VGG16 и получаем значения функции активации из 7-го уровня, который генерирует матрицу представления объектов размером 56x56x256. В этом трехмерном массиве имеется 256 каналов размером 56x56 каждый.\\nТеперь предположим, что есть канал A, чьи нейроны могут активироваться на изображении, содержащем коричнево-черные полосы, а нейроны канала B — на изображение, содержащее глазное яблоко. Если оба этих канала A и B активируются вместе для одного и того же изображения, то высока вероятность того, что изображение может содержать, например, лицо тигра (поскольку у него было два канала с большими абсолютными значениями, которые активируются для коричнево-черных полос и глазного яблока). Теперь, если оба эти канала будут с большими значениями функции активации, то они будут иметь более высокую корреляцию между каналами A и В, чем между каналами A и С, где канал С активируется на изображении, содержащем ромбовидный шаблон. Чтобы получить корреляцию всех этих каналов друг с другом, нам нужно вычислить нечто называемое матрицей Грама, будем использовать ее для измерения степени корреляции между каналами. Таким образом, именно значение корреляции между каналами служит показателем того, насколько итоговое изображение наследует элементы изображения со стилем.\\nФункция потерь на основе корреляции матриц Грама\\nКаждый элемент матрицы Грама содержит меру корреляции всех каналов относительно друг друга. Обозначим матрицу Грама стилевого изображения слоякак , а матрицу Грама сгенерированного изображения того же слоя . Обе матрицы были вычислены из одного и того же слоя, следовательно, с использованием одного и того же числа каналов, что привело к тому, что итоговая матрица размера . Теперь, если мы найдем сумму квадратов разности или L2-норму вычитания элементов этих двух матриц и попытаемся минимизировать ее, то в конечном итоге это приведет к минимизации разницы между изображением стиля и сгенерированным изображением.\\nВ вышеприведенном уравнениипредставляет номер канала в карте признаков / выходных данных уровня , а представляет карты признаков / выходных данных слоя .\\nТак как при вычислении потери стиля мы используем несколько уровней активации, это позволяет назначать разные весовые коэффициенты для потери на каждом уровне.\\nРасширения алгоритмов NST\\nВышеупомянутые методы NST предназначены для общих неподвижных изображений. Они могут не подходить для специализированных типов изображений и видео (например, рисунков, портретов на голове и видеокадров), поэтому были созданы расширения алгоритма NST на эти конкретные типы.\\nSemantic Style Transfer\\nПри наличии пары стиля и изображений контента, которые похожи по содержанию, цель передачи семантического стиля состоит в создании семантического соответствия между стилем и контентом, который отображает каждую область стиля в соответствующую семантически подобную область контента.\\nInstance Style Transfer\\nПередача стиля экземпляра основана на сегментации экземпляра и предназначена для стилизации только одного указанного пользователем объекта в изображении. Основная проблема заключается в переходе между стилизованным объектом и нестилизованным фоном. Эту проблему можно решить путем добавления дополнительных потерь на основе MRF к сглаживающим граничным пикселям.\\nDoodle Style Transfer\\nПередача стиля каракулей заключается в использовании NST для преобразования черновых набросков в произведения искусства. Метод просто отбрасывает термин потери содержимого и использует рисунки в качестве карты сегментации для передачи семантического стиля.\\nPortrait Style Transfer\\nСовременные алгоритмы передачи стилей обычно не оптимизированы для головных портретов. Поскольку они не накладывают пространственных ограничений, непосредственное применение этих существующих алгоритмов к портретам головы приведет к деформации структур лица. Решить эту проблему можно использованием карт усиления для ограничения пространственных конфигураций, которые могут сохранить структуры лица при передаче текстуры стиля изображения.\\nVideo Style Transfer\\nВ отличие от передачи стиля неподвижного изображения, при разработке алгоритма передачи стиля видео необходимо учитывать плавный переход между соседними видеокадрами.\\nImage-Optimisation-Based Online Video Style Transfer\\nПередача онлайн-стилей видео на основе оптимизации изображений: вводится временная потерю согласованности, основанная на оптическом потоке, чтобы штрафовать отклонения вдоль точечных траекторий. Оптический поток рассчитывается с использованием новых алгоритмов оценки оптического потока. В результате алгоритм устраняет временные артефакты и создает плавные стилизованные видеоролики. Однако при таком способе требуется несколько минут для обработки одного кадра.\\nModel-Optimisation-Based Offline Video Style Transfer\\nОффлайн-стиль передачи видео на основе оптимизации моделей: для стилизации видео в режиме реального времени Хуан предлагает увеличить временную потерю согласованности при использовании текущего алгоритма PSPM. Для двух последовательных кадров потеря временной согласованности напрямую рассчитывается с использованием двух соответствующих выходных данных NST для поощрения согласованности по пикселям. Для вычисления потери временной согласованности вводится соответствующая двухкадровая стратегия синергетического обучения.\\nCharacter Style Transfer\\nЦелью передачи стиля символа является применение идеи NST для создания новых шрифтов и текстовых эффектов. Янг предложил охарактеризовать элементы стиля и использовать извлеченные характеристики, чтобы направлять генерацию текстовых эффектов.\\nPhotorealistic Style Transfer\\nФотореалистичная передача стиля (также известная как передача стиля цвета) направлена на передачу стиля распределения цвета. Общая идея состоит в том, чтобы основываться на текущей передаче семантического стиля, но исключить искажения и сохранить первоначальную структуру изображения контента.\\nImage-Optimisation-Based Photorealistic Style Transfer\\nПередача фотореалистичного стиля на основе оптимизации изображений. Алгоритм Луана предлагает двухэтапную процедуру оптимизации, которая состоит в том, чтобы инициализировать оптимизацию путем стилизации данной фотографии с помощью [[Neural_Style_Trasfer#Semantic Style Transfer | Image-Optimisation-Based Semantic Style Transfer], а затем штрафовать искажения изображения, добавляя регуляризацию фотореализма. Но поскольку алгоритм Луана основан на методе передачи семантического стиля на основе оптимизации изображений, он требует больших вычислительных затрат.\\nАлгоритм Мехреза также использует двухэтапную процедуру оптимизации. Он предлагает уточнить нефотореалистичный стилизованный результат путем сопоставления градиентов на выходном изображении с градиентами на фотографии содержимого. Этот алгоритм достигает более быстрой скорости фотореалистичной стилизации.\\nModel-Optimisation-Based Photorealistic Style Transfer\\nПередача фотореалистичного стиля на основе оптимизации моделей: Ли решил проблему эффективности, обрабатывая эту проблему в два этапа: этап стилизации и этап сглаживания. Шаг стилизации состоит в том, чтобы заменить слои с повышенной дискретизацией на неиспользуемые слои, чтобы получить стилизованный результат с меньшим количеством искажений. Затем этап сглаживания дополнительно устраняет структурные артефакты.\\nAttribute Style Transfer\\nАтрибуты изображения обычно относятся к цветам изображения, текстурам и т.д. Ранее передача атрибутов изображения осуществлялась по аналогии с изображением. Алгоритм Ляо предлагает глубокую аналогию изображения для изучения аналогии изображения в области CNN. Он основан на методе сопоставления патчей и реализует аналогию изображений со слабым контролем, то есть этому алгоритму требуется только одна пара исходных и целевых изображений вместо большого обучающего набора.\\nFashion Style Transfer\\nПередача модного стиля получает образ модного стиля в качестве цели и генерирует изображения одежды с желаемыми модными стилями. Задача этой передачи заключается в том, чтобы сохранить схожий дизайн с базовой одеждой при смешивании желаемых стилей. Эта задача решается введением пары генератора модного стиля и дискриминатора.\\nAudio Style Transfer\\nАудио Стиль передачи . В дополнение к передаче стилей изображения, [90], [91] расширяют область стиля изображения до стиля звука и синтезируют новые звуки, передавая нужный стиль из целевого аудио. Исследование передачи стиля звука также следует пути передачи стиля изображения, то есть передачи аудио стиля онлайн на основе оптимизации звука (Audio-Optimisation-Based Online Audio Style Transfer), а затем передачи стиля аудио в автономном режиме на основе оптимизации модели (Model-Optimisation-Based Offline Audio Style Transfer). На основании алгоритма IOB-NST, был создан алгоритм Верма и Смита передачи аудио стиля на основе аудиооптимизации, основанный на оптимизации аудио онлайн. Алгоритм начинает с шумового сигнала и итеративно оптимизируют его, используя обратное распространение.\\nПример кода на Python\\nДанный пример реализован на основе открытой платформы глубокого обучения PyTorch\\nФункция потери контента\\nclass ContentLoss(nn.Module): def __init__(self, target,): super(ContentLoss, self).__init__() # we \\'detach\\' the target content from the tree used # to dynamically compute the gradient: this is a stated value, # not a variable. Otherwise the forward method of the criterion # will throw an error. self.target = target.detach() def forward(self, input): self.loss = F.mse_loss(input, self.target) return input\\nФункция потери стиля\\ndef gram_matrix(input): a, b, c, d = input.size() # a=batch size(=1) # b=number of feature maps # (c,d)=dimensions of a f. map (N=c*d) features = input.view(a * b, c * d) # resize feature maps G = torch.mm(features, features.t()) # compute the gram product # we \\'normalize\\' the values of the gram matrix # by dividing by the number of element in each feature maps. return G.div(a * b * c * d)\\nclass StyleLoss(nn.Module): def __init__(self, target_feature): super(StyleLoss, self).__init__() self.target = gram_matrix(target_feature).detach() def forward(self, input): G = gram_matrix(input) self.loss = F.mse_loss(G, self.target) return input\\nИнициализация модели\\ncnn = models.vgg19(pretrained=True).features.to(device).eval()\\nНормализация\\ncnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device) cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device) # create a module to normalize input image so we can easily put it in a # nn.Sequential class Normalization(nn.Module): def __init__(self, mean, std): super(Normalization, self).__init__() # .view the mean and std to make them [C x 1 x 1] so that they can # directly work with image Tensor of shape [B x C x H x W]. # B is batch size. C is number of channels. H is height and W is width. self.mean = torch.tensor(mean).view(-1, 1, 1) self.std = torch.tensor(std).view(-1, 1, 1) def forward(self, img): # normalize img return (img - self.mean) / self.std\\nДобавление собственных слоев\\n# desired depth layers to compute style/content losses : content_layers_default = [\\'conv_4\\'] style_layers_default = [\\'conv_1\\', \\'conv_2\\', \\'conv_3\\', \\'conv_4\\', \\'conv_5\\'] def get_style_model_and_losses(cnn, normalization_mean, normalization_std, style_img, content_img, content_layers=content_layers_default, style_layers=style_layers_default): cnn = copy.deepcopy(cnn) # normalization module normalization = Normalization(normalization_mean, normalization_std).to(device) # just in order to have an iterable access to or list of content/style losses content_losses = [] style_losses = [] # assuming that cnn is a nn.Sequential, so we make a new nn.Sequential # to put in modules that are supposed to be activated sequentially model = nn.Sequential(normalization) i = 0 # increment every time we see a conv for layer in cnn.children(): if isinstance(layer, nn.Conv2d): i += 1 name = \\'conv_{}\\'.format(i) elif isinstance(layer, nn.ReLU): name = \\'relu_{}\\'.format(i) # The in-place version doesn\\'t play very nicely with the ContentLoss # and StyleLoss we insert below. So we replace with out-of-place # ones here. layer = nn.ReLU(inplace=False) elif isinstance(layer, nn.MaxPool2d): name = \\'pool_{}\\'.format(i) elif isinstance(layer, nn.BatchNorm2d): name = \\'bn_{}\\'.format(i) else: raise RuntimeError(\\'Unrecognized layer: {}\\'.format(layer.__class__.__name__)) model.add_module(name, layer) if name in content_layers: # add content loss: target = model(content_img).detach() content_loss = ContentLoss(target) model.add_module(\"content_loss_{}\".format(i), content_loss) content_losses.append(content_loss) if name in style_layers: # add style loss: target_feature = model(style_img).detach() style_loss = StyleLoss(target_feature) model.add_module(\"style_loss_{}\".format(i), style_loss) style_losses.append(style_loss) # now we trim off the layers after the last content and style losses for i in range(len(model) - 1, -1, -1): if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss): break model = model[:(i + 1)] return model, style_losses, content_losses\\nГрадиентный спуск\\ndef get_input_optimizer(input_img): # this line to show that input is a parameter that requires a gradient optimizer = optim.LBFGS([input_img.requires_grad_()]) return optimizer\\nЗапуск алгоритма\\ndef run_style_transfer(cnn, normalization_mean, normalization_std, content_img, style_img, input_img, num_steps=300, style_weight=1000000, content_weight=1): print(\\'Building the style transfer model..\\') model, style_losses, content_losses = get_style_model_and_losses(cnn, normalization_mean, normalization_std, style_img, content_img) optimizer = get_input_optimizer(input_img) run = [0] while run[0] <= num_steps: def closure(): # correct the values of updated input image input_img.data.clamp_(0, 1) optimizer.zero_grad() model(input_img) style_score = 0 content_score = 0 for sl in style_losses: style_score += sl.loss for cl in content_losses: content_score += cl.loss style_score *= style_weight content_score *= content_weight loss = style_score + content_score loss.backward() run[0] += 1 if run[0] % 50 == 0: print(\"run {}:\".format(run)) print(\\'Style Loss : {:4f} Content Loss: {:4f}\\'.format( style_score.item(), content_score.item())) print() return style_score + content_score optimizer.step(closure) # a last correction... input_img.data.clamp_(0, 1) return input_img # run style transfer output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std, content_img, style_img, input_img)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='38659ecf-76f4-4e69-87dd-a79d2043a363', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e072096e6016d68f16c40c8d92386492b7f59e1911220f89b2c04adbfadc523a', text='Компьютерное зрение\\nКомпьютерное зрение — это научное направление в области искусственного интеллекта и связанные с ним технологии получения изображений объектов реального мира, их обработки и использования полученных данных для решения разного рода прикладных задач без участия (полного или частичного) человека.\\nСодержание\\nЗадачи компьютерного зрения\\nВсе задачи компьютерного зрения сводятся к анализу изображения или видеопотока(По сути представляющего из себя набор сменяющихся изображений), на котором требуется прежде всего выделить фрагмент, содержащий необходимую информацию. Для выделения обычно используют или прямоугольную область, которая ограничивает исходный фрагмент, или просто выделяют пиксели принадлежащие ему.\\nИдентификация\\nЗадача идентификации состоит в том, чтобы классифицировать изображение целиком. Для этого на изображении выделяются ключевые области и по ним происходит классификация, например с помощью решающих деревьев, или сверточных нейронных сетей.\\nРаспознавание объектов\\nЗадача состоит в том, чтобы по изображению суметь выделить на нем некоторый набор объектов. Пока задача не решена в общем случае – алгоритм не может классифицировать случайные объекты на изображении. Однако способен распознавать заранее заученный набор объектов с достаточно высокой точностью.\\nСамым простым методом детекции объектов является метод скользящего окна методом R-CNN(англ. Regions with Convulational Neural Network - Выделение регионов с помощью свертоных сетей), при котором мы проходимся некоторым окном фиксированного размера по каждому кусочку картинки, и применяем к нему простой классификатор, обученный распознавать заранее определенный набор объектов. Модификации этого метода, такие как Faster R-CNN применяются до сих пор.\\nСегментация изображений\\nЗадача похожая на детекцию объектов, но в отличие от нее требуется не окружить найденные объекты рамками, а выделить пиксели, которые этот объект составляют. Сегментация применяется во многих областях, например, в производстве для индикации дефектов при сборке деталей, в медицине для первичной обработки снимков, также для составления карт местности по снимкам со спутников. Одним из типичных способов сегментации является применение модели U-Net, представляющую из себя нексколько слоев сверточной сети, которые различаются по размеру, и в совокопности имеют U-образную форму, что и отражено в названии.\\nОценка положения\\nЗадача оценки положения объекта(англ. Pose Estimation), в некотором роде продолжающая задачу сегментации. Заключается в выделении некоторого каркаса объекта (например скелета, если речь идет о людях) и определении положения этого каркаса на изображении. Этот скелет может быть использован в последствии например для предсказания направления движения. В зависимости от количества рассматриваемых объектов различают одиночную оценку положения(англ. Single-person pose estimation) и множественную(англ. Multi-person pose estimation). Различие состоит в том, что во втором случае необходимо также учитывать, что объекты могут накладываться друг на друга. Для выполнения этой задачи сначала обрезается фон, оставляя только изображения непосредственно объектов, а затем для каждого из объектов с помощью сверточных нейронных сетей выделяются области суставов, которые затем соединяются.\\nРаспознавание текста\\nОдна из ключевых задач компьютерного зрения. Сначала с помощью алгоритмов детекции выделяется область в которой текст написан, затем производится непосредственно распознавание текста например с помощью алгоритмов сегментации. При этом задачи распознавания текста написанного на листе бумаги, и распознавания текста написанного где-то на изображении (“in the wild”), например текст на дорожном знаке, номер машины и т. д., сильно различаются, в силу наличия в последнем случае помех, которые мешают выделить конкретные буквы. В этом случае может помочь, например обучение предсказания буквы по остальным буквам в слове.\\nГенерация объектов\\nЗадача состоит в том, чтобы по известному набору объектов научится создавать похожие объекты, но при этом не совпадающие ни с одним из тестовых. Например создавать анимационных персонажей в стилистике мультфильма, нарисовав руками только пару из них. Для этого применяют такие архитектуры как генеративно состязательные сети(англ. Generative adversarial network), при которой сеть делится на две, одна из которых стремится создать объект, а вторая его отбраковать, или вариационный автокодировщик, обучающийся на плотностях вероятностей исходных данных с целью создать объект похожий на исходный, но не совпадающий с ним.\\nАнализ видео\\nТак как видео представляет из себя набор изображений, одинакового размера, обычно сделанных через разные интервалы времени, то для него применимы все те задачи, которые были описаны ранее. Также появляются такие задачи как предсказание движения, заключающееся в том, чтобы по набору кадров предсказать положение объекта в следующих кадрах, или более общая задача ситуационный осведомленности(англ. Situation Awarness), заключающаяся в том, чтобы для каждого объекта в видео уметь определить его положение и статус на всех кадрах видео.\\nПримечания\\n- https://www.fritz.ai/pose-estimation/\\n- https://habr.com/ru/post/274725/\\n- https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e\\n- https://ccis2k.org/iajit/PDF/vol.3,no.2/2-Nassir.pdf\\n- https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5\\n- https://towardsdatascience.com/a-gentle-introduction-to-ocr-ee1469a201aa\\n- https://nanonets.com/blog/human-pose-estimation-2d-guide/\\n- https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900]\\n- https://ru.coursera.org/lecture/deep-learning-in-computer-vision/introduction-to-video-analysis-alApg', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='a7489ae1-fbdf-4e98-b5a4-ce645d459689', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b3a372f83f03d3048b5c9cebd7a3512e3d265638570f86acd7c3fe877a4028af', text='Сегментация изображений\\nСегментация изображения — задача поиска групп пикселей, каждая из которых характеризует один смысловой объект. В статистике эта проблема известна как кластерный анализ и является широко изученной областью с сотнями различных алгоритмов. В компьютерном зрении сегментация изображения является одной из старейших и широко изучаемых проблем.\\nВ более ранних техниках используется расщепление и слияние регионов, что соответствует разделительным и агломерационным алгоритмам в литературе по кластеризации. Современные алгоритмы чаще оптимизируют некоторые глобальные критерии, такие как внутрирегиональная согласованность и межрегиональные длины границ.\\nНиже будут рассмотрены два алгоритма — графо-ориентированная сегментация и метод нормализованных срезов. Первый из них является базовым алгоритмом сегментации, который прост и понятен в реализации, но медленный и результаты недостаточно хороши. Второй алгоритм является продвинутой версией первого со множеством эвристик. Что отражается, как на производительности, так и на результатах.\\nСодержание\\nГрафо-ориентированная сегментация (англ. Graph-based segmentation)\\nЭто алгоритм объединения, который использует относительные различия между регионами, чтобы определить, какие из них следует объединить. Кроме того, он доказуемо оптимизирует глобальную метрику группировки. Введем меру отличия одного пикселя от другого, где — пара соседних по стороне или по углу пикселей. Мера отличия может показывать, например, разницу цветовой интенсивности между соседями, которых у пикселя максимум восемь.\\nДля любого региона R, его внутренняя разница определяется как наибольшая мера отличия в минимальном остовном дереве региона,\\nДля любых двух соседних областей, по крайней мере, с одним смежным ребром, соединяющим их вершины, разность между этими регионами определяется как ребро минимального веса, соединяющее эти два региона,\\nАлгоритм объединяет любые две соседние области, разница которых меньше минимальной внутренней разности этих двух областей,\\nгде— эвристический штраф по региону, который был установлен , однако, он может быть установлен как любая специфическая для области применения мера.\\nОбъединяя области в порядке убывания разделяющих их ребер (можно эффективно оценить с использованием алгоритма минимального остовного дерева Крускала), они доказуемо дают сегментацию. Причем такую, в которой присутствуют как области, которые могли бы быть объединены, так и те, которые могут быть разделены, но в небольших количествах. Для окрестностей пикселей фиксированного размера время работы этого алгоритма составляет, где — количество пикселей изображения, что делает его одним из самых быстрых алгоритмов сегментации.\\nНа рисунке слева — исходное изображение, справа — сегментированное после применения данного алгоритма.\\nМетод нормализованных срезов (англ. Normalized cuts)\\nMетод нормализованных срезов, исследует сходство между соседними пикселями и пытается разделить их на группы, которые в свою очередь связаны слабо. Рассмотрим простой пример.\\nВсе пиксели в группе A имеют высокое сходство, показанное в виде толстых красных линий, как и пиксели в группе B. Соединения между этими двумя группами, показанные в виде более тонких синих линий, намного слабее. Нормализованный разрез между двумя группами, показанный пунктирной линией, разделяет их на два кластера.\\nРазрез между двумя группами A и B определяется как сумма всех взвешенных весов,\\nгде веса между двумя пикселямии соответствуют их сходству. Однако использование минимального среза в качестве критерия сегментации не приводит к разумным кластерам, поскольку наименьшие срезы обычно предусматривают выделение одного пикселя.\\nЛучшей мерой сегментации является нормализованный срез, который определяется как\\nгде\\nНормализованные разрезы могут быть довольно медленными, поскольку это требует решения больших разреженных задач. Однако существует способ ускорить вычисление нормализованных разрезов, используя подход, основанный на алгебраической сетке. Можно выбирать меньшее количество переменных, чтобы оставшиеся переменные более нижнего уровня были сильно связаны по крайней мере с одной переменной грубого уровня. Подмножество считается сильно связанным, если выполняется\\nобычноДанный рисунок схематично показывает этот процесс.\\nКаждый пиксель на первом изображении соответствует вершине графа на втором изображении, которая связана с каждым из ее четырех соседей в соответствии с их сходством по уровню яркости. Цель состоит в том, чтобы «разрезать» этот граф на части. Далее можно найти сильно связное подмножество, которое минимизирует отношение. Но несмотря на свою концептуальную значимость, минимизация этого нормализованного разреза является вычислительно непомерной, а стоимость увеличивается экспоненциально с размером изображения. Приближения к оптимальному разрезу могут быть получены с использованием спектральных методов, при этом наиболее эффективное на сегодняшний день приближение имеет вычислительную стоимость, пропорциональную , где — количество пикселей. Эта сверхлинейная сложность может быть чрезвычайно полезна, когда дело касается очень больших изображений.\\nТак как количество вершин графа на втором изображении велико и работать с каждым из них чрезвычайно дорого, необходимо выделить подмножество вершин-предводителей для каждого из подмножеств и далее работать уже с ними. Мы начнем с выбора примерно половины пикселей в качестве представителей, которые назовем начальными числами: они выбираются таким образом, чтобы каждый пиксель в исходном изображении был сильно связан по крайней мере с одним соседним с ним начальным числом (см. третье изображение). Далее процесс продолжается рекурсивно (см. четвертое изображение), количество вершин на каждом новом более грубом уровне уменьшается. Значения узлов более нижнего уровня вычисляются путем интерполяции родительских значений и сопоставления значенийв пределах от 0 и 1 до Boolean значений. Выраженные сегменты появляются на соответствующем уровне как узлы, которые слабо связаны со своими соседями. Следовательно, задача минимизации упрощается до поиска вершин-предводителей на всех уровнях.\\nРезультат работы данного алгоритма:\\nСвёрточные нейронные сети\\nС учётом прогресса глубоких нейронных сетей за последние несколько лет в различных областях, лучшие результаты для семантической сегментации чаще всего достигаются при помощи свёрточных нейронных сетей, в том числе, когда данные слабо размечены. Действительно, проблема низкого уровня размеченности данных в семантической сегментации довольно важна, поскольку для каждого пикселя определить его принадлежность с высокой точностью — задача, требующая высоких затрат времени и не всегда высокую точность. Однако, сочетание хорошо размеченных данных со слабо размеченными данными (например, с точностью до ограничивающих рамок) улучшает производительность модели. Для задачи сегментации хорошо себя показали FCN (англ. fully-convolutional networks) — полносвёрточные сети, позволяющие работать с изображениями произвольного размера, а на выходе выдавать тепловую карту нахождения классов на изображении через серию свёрток. Поскольку свёртка над матрицей большой размерности с большим числом каналом является затратной, как правило, первая половина слоёв в таких свёрточных сетях обеспечивает сабсэмплинг (англ. subsampling - уменьшение размерности), а вторая часть слоёв - апсэмплинг (англ. upsampling - увеличение размерности). Таким образом, размерность изображений в пикселях на входе и на выходе сети является одинаковой, а большинство операций свёртки применяется к матрицам небольшой размерности. Конечная классификация достигается за счёт выбора максимума по классам из значений тензора размерности $C \\\\times W \\\\times H$, где $C$ — множество классов, заранее заданных перед обучением и к которым могут принадлежать пиксели изображения, $W \\\\times H$ — размер изображения. Такую модель можно обучить при помощи обратного распространения ошибок, а в качестве функции потерь для пикселей использовать кросс-энтропию.\\nМодель U-Net, разработанная авторами для сегментации биомедицинских изображений, улучшает архитектуру FCN путём использования сужающихся блоков свёртки для захвата контекста, расширяющихся блоков свёртки для локализации, а также прямых связей между блоками свёртки на одинаковых уровнях. Прямая связь слоёв обеспечивает улучшенное обучение за счёт отсутствия так называемого \"артефакта шахматной доски\" — негативного явления, вызванного апсэмплингом при помощи транспонированной свёртки. Развитием U-Net, в свою очередь модель DenseNet, в которой используются полностью связанные свёрточные сети. В основе идеи лежит использование \"плотных блоков\" — совокупности нескольких свёрточных слоёв с подключением каждого слоя к каждому слою. Однако, существенным недостатком такой модели является низкая эффективность работы с памятью.\\nСовершенно по-иному на свёртку для сегментации объектов позволил взглянуть метод расширенных свёрток (англ. atrous convolutions), применяющийся в современных state-of-the-art подходах (DeepLab, DeepLab v3, DeepLab v3+). Расширенная свёртка заключается в том, чтобы применять свёртки с ядрами разного размера и разным страйдом над прямоугольниками с одним и тем же центром, а впоследствии комбинировать полученные таким образом признаки. Расширенные свёртки могут применяться как каскадно (последовательно регулируя показатель расширения фильтра), так и параллельно (англ. ASPP, Atrous Spatial Pyramid Pooling — применяя свёртки с различным масштабом ядер на одном и том же слое свёрточной сети с пулингом в конце). Такой подход позволил достичь лучших результатов в изображениях с объектами разных масштабов.\\nСм. также\\nЗадача нахождения объектов на изображении\\nИсточники информации\\n- Richard Szeliski «Computer Vision: Algorithms and Applications.» - «Springer», 2010. - С. 286-300\\n- Felzenszwalb, P. F. and Huttenlocher, D. P. (2004b). Efficient graph-based image segmentation.[5]\\n- Shaw, D. and Barnes, N. (2006). Perspective rectangle detection. In Workshop on Applications of Computer Vision at ECCV’2006.\\n- Brandt, A. (1986). Algebraic multigrid theory: The symmetric case. Applied Mathematics and Computation, 19(1-4):23–56.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='a48b7e15-8f9b-43f8-b933-2071f349f563', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2072436b2f78574423f8a196f30dc937c04e5a74ddb4101ba074ce3da798ba71', text='Задача нахождения объектов на изображении\\nЗадача нахождения объектов на изображении — задача машинного обучения, в рамках которой выполняется определение наличия или отсутствия объекта определённого домена на изображении, нахождение границ этого объекта в системе координат пикселей исходного изображения. В зависимости от алгоритма обучения, объект может характеризоваться координатами ограничивающей рамки, ключевыми точками, контуром объекта.\\nСодержание\\n- 1 Постановка задачи\\n- 2 Наборы данных\\n- 3 Подходы к решению задачи детекции объектов\\n- 4 См.также\\n- 5 Примечания\\n- 6 Источники информации\\nПостановка задачи\\nЗадача нахождения объектов на изображении может быть поставлена различным образом и включает в себя класс других задач, помогающих определить, какие объекты находятся на изображении и где они расположены в сетке пикселей исходного изображения.\\nЗадача семантической сегментации (англ. semantic segmentation) — задача, в которой на вход модели подаётся изображение, а на выходе для каждого пикселя является метка принадлежности этого пикселя к определённой категории. Например, если в исходном изображении человек переходит дорогу, то для каждого пикселя необходимо вывести, является ли этот пиксель частью человеческого тела, профиля дороги, знака дорожного движения, неба, или какого-то другого типа. Существенный недостаток применения одной лишь семантической сегментации относительно задач, связанных с распознаванием объектов — маркировка пикселей по принадлежности только к типу объекта, что не создаёт различия между объектами как таковыми. Например, если назвать \"объектом\" связную область пикселей, характеризующих одинаковый тип, то два объекта, перегораживающих друг друга на исходном изображении, будут определены как один объект, что в корне неверно. Задача семантической сегментации изображения с дифференцированием объектов называется задачей сегментации экземпляров (англ. instance segmentation). Модели, решающие задачу сегментации экземпляров, применяются, в том числе, для подсчёта людей в массовых скоплениях, для автомобилей с автоматическим управлением.\\nЗадача классификации с локализацией (англ. classification and localization) — задача, в которой в дополнение к предсказанию метки категории класса определяется рамка, ограничивающая местоположение экземпляра одиночного объекта на картинке. Как правило, рамка имеет прямоугольную форму, её стороны ориентированы параллельно осям исходного изображения, а площадь является минимальной при условии полного нахождения экземпляра объекта внутри этой рамки. Такую прямоугольную рамку называют термином \"ограничивающая рамка\" (англ. bounding box). Ограничивающую рамку можно задать как при помощи центра, ширины и высоты, так и при помощи четырёх сторон. Модель в данном случается одновременно обучается как верной классификации, так и максимально точному определению границ рамки.\\nЗадача детекции объектов (англ. object detection) — задача, в рамках которой необходимо выделить несколько объектов на изображении посредством нахождения координат их ограничивающих рамок и классификации этих ограничивающих рамок из множества заранее известных классов. В отличие от классификации с локализацией, число объектов, которые находятся на изображении, заведомо неизвестно.\\nМетрики\\nВ задачах классификации с локализацией и детекции объектов для определения достоверности местоположения ограничивающей рамки в качестве метрики чаще всего используется отношение площадей ограничивающих рамок (англ. Intersection over Union):\\n$IoU = \\\\frac{S(A \\\\cap B)}{S(A \\\\cup B)}$,\\nгде $A$ и $B$ — предсказанная ограничивающая рамка и настоящиая ограничивающая рамка соответственно. $IoU$ равно нулю в случае непересекающихся ограничивающих рамок и равно единице в случае идеального наложения.\\nВ задачах детекции объектов в качестве метрики зачастую используется $mAP$ (англ. mean average precision) — усреднённая по всем категориям величина средней точности (англ. average precision, AP)\\n$AP = \\\\int_{0}^{1} p(r) dr$,\\nгде $p$ — точность, $r$ — полнота из предположения, что ограничивающая рамка определена верно, если $IoU \\\\geq 0.5$. Поскольку точность и полнота находятся в промежутке от $0$ до $1$, то $AP$, а следовательно, и $mAP$ также находится в пределах от $0$ до $1$. На практике, $AP$ часто считают по точкам, значения полноты которых равномерно распределены в промежутке $[0;1]$:\\n$AP_c = \\\\frac{1}{11} \\\\cdot (AP_c(0) + AP_c(0.1) + \\\\ldots + AP_c(1))$\\n$mAP = \\\\overline{AP_c}$\\nНаборы данных\\nНаборы данных в задачах детекции объектов на изображениях размечаются вручную асессорами. Зачастую изображения могут различаться в разрешении и качестве, что может вносить коррективы в работу моделей.\\n- PASCAL VOC 2012[1] (Pattern Analysis, Statistical Modelling and Computational Learning: Visual Object Classes ) — содержит 11530 изображений 20 классов с 27450 регионами предложений и 6929 сегментациями\\n- MS COCO 2017[2] (Microsoft Common Objects in Context) — 118000 изображений в тренировочной выборке, 5000 изображений в валидационной выборке, 41000 изображений в тестовой выборке. Набор данных содержит 80 классов, на которых можно определить вложенность\\n- ImageNet[3] — 400000 изображений 200 классов с 350000 размеченными ограничивающими рамками\\n- Google Open Images[4] — в шестой версии февраля 2020 года содержит свыше 1743000 изображений в тестовой выборке, свыше 41000 изображений в валидационной выборке и свыше 125000 изображений в тестовой выборке. Суммарно на изображениях размечено около 16000000 ограничивающих рамок\\nПодходы к решению задачи детекции объектов\\nОдним из наивных подходов на основе свёрточных нейронных сетей может быть использование в качестве ядра каноничных изображений классов, которые необходимо найти на изображении, и дальнейшее использование скользящего окна для вычисления свёртки. Такой подход называется сопоставлением с шаблоном (англ. template matching). В случае, когда вместо шаблона используется натренированный классификатор, для достижения наилучшего результата необходимо осуществить полный перебор ограничивающих рамок с порогом уверенности в правдивости классификации за счёт того, что объекты могут быть разных масштабов и находиться в разных местах изображений. Однако, на изображении разрешения $W \\\\times H$ суммарное число ограничивающих рамок равно $\\\\sum_{i=0}^{W} \\\\sum_{j=0}^{H} (W-i)\\\\cdot(H-j) = \\\\frac{1}{4} m \\\\cdot n \\\\cdot (m + 1) \\\\cdot (n +1) = O(m^2n^2)$, что делает полный перебор неэффективным методом, занимающим очень большое количество времени. Для уменьшения количества рассматриваемых ограничивающих рамок выделяют два основных параллельно развивающихся подхода:\\n- Двухэтапные методы (англ. two-stage methods), они же \"методы, основанные на регионах\" (англ. region-based methods) — подход, разделённый на два этапа. На первом этапе селективным поиском или с помощью специального слоя нейронной сети выделяются регионы интереса (англ. regions of interest, RoI) — области , с высокой вероятностью содержащие внутри себя объекты. На втором этапе выбранные регионы рассматриваются классификатором для определения принадлежности исходным классам и регрессором, уточняющим местоположение ограничивающих рамок.\\n- Одноэтапные методы (англ. one-stage methods) — подход, не использующий отдельный алгоритм для генерации регионов, вместо этого предсказывая координаты определённого количества ограничивающих рамок с различными характеристиками, такими, как результаты классификации и степень уверенности и в дальнейшем корректируя местоположение рамок.\\nДвухэтапные методы\\nR-CNN\\nRegion-CNN[5] (R-CNN, Region-based Convolutional Network) — алгоритм, основанный на свёрточных нейронных сетях. Вместо того, чтобы использовать для поиска изображений скользящие окна фиксированного размера, на первом шаге алгоритм пытается найти селективным поиском \"регионы\" — прямоугольные рамки разных размеров, которые, предположительно, содержат объект. Это обеспечивает более быстрое и эффективное нахождение объектов независимо от размера объекта, расстояния до камеры, угла зрения. Суммарное количество регионов для каждого изображения, сгенерированных на первом шаге, примерно равно двум тысячам. Найденные регионы при помощи аффинных преобразований приобретают размер, который нужно подать на вход CNN. Также вместо аффинных преобразований можно использовать паддинги, либо расширять ограничивающие рамки до размеров, необходимых для входа CNN. В качестве CNN зачастую используется архитектура CaffeNet[6], извлекающая для каждого региона порядка 4096 признаков. На последнем этапе вектора признаков регионов обрабатываются SVM, проводящими классификацию объектов, по одной SVM на каждый домен.\\nСелективный поиск, в свою очередь, тоже можно обучать с помощью линейной регрессии параметров региона — ширины, высоты, центра. Этот метод, названный bounding-box regression, позволяет более точно выделить объект. В качестве данных для регрессии используются признаки, полученные в результате работы CNN.\\nFast R-CNN\\nЗа счёт того, что в R-CNN для каждого из 2000 регионов классификация производится отдельно, обучение сети занимает большой объём времени. Оригинальной версии алгоритма R-CNN для обработки каждого тестового изображения требовалось порядка 47 секунд, поэтому его авторы предложили алгоритм, улучшающий производительность — Fast R-CNN[7]. Его характерной особенностью является подача на вход CNN не отдельных регионов, а всего изображения сразу для получения общей карты признаков. Предложенные регионы накладываются на общую карту признаков, и в результате количество операций свёртки существенно уменьшается. Поскольку регионы имеют разный размер, необходимо привести признаки к фиксированному размеру при помощи операции RoIPooling (Region of interest pooling). В рамках RoIPooling регион делится на сетку, размерность ячеек которой совпадает с размерностью выхода, после чего по ячейкам сетки проводится выбор максимального значения. Полученные регионы фиксированного размера далее являются входом для полносвязного слоя, который и осуществляет как классификацию, так и линейную регрессию для сдвига границ его рамок. Стоит отметить, что в Fast R-CNN используется совместное обучение SVM для классификации, CNN и bounding box регрессора вместо независимого их обучения —для этого используется совместная функция потерь.\\nFaster R-CNN\\nFast R-CNN, как и оригинальный алгоритм R-CNN, использует для нахождения регионов селективный поиск. Несмотря на то, что за счёт единоразовой свёртки время обучения на одном тестовом изображении алгоритмом снизилось с 49 до 2.3 секунд, селективный поиск, который выполняет предложения регионов, является узким местом в производительности Fast R-CNN. Авторы алгоритма Faster R-CNN[8], призванного решить эту проблему, предложили вычислять регионы с помощью отдельного модуля Region Proposal Network (RPN). RPN является свёрточной сетью, выполняющей роль генератора регионов по признакам исходного изображения. Сгенерированные регионы передаются в два полносвязных слоя — box-regression-layer (сокр. reg layer), прогнозирующий значения смещения для ограничивающих рамок, и box-classification-layer (сокр. cls layer), классифицирующий изображения в пределах предлагаемой области. Также важную роль играют ключевые рамки (англ. anchor boxes) — рамки с различными положениями и размерами для скользящего окна. Ключевые рамки имеют зафиксированное положение и различную форму и масштаб. Для одного и того же масштаба выбирается, как правило, три ключевые рамки — квадратной формы; прямоугольной формы, ориентированной горизонтально; прямоугольной формы, ориентированной вертикально. Учитывая масштаб ключевой рамки, производится его перемещение скользящим окном для генерации регионов. Для сгенерированных таким образом регионов рассчитываются вероятности нахождения объекта внутри рамки cls-слоем, а за сдвиг местоположения отвечает reg-слой. После прохождения слоя RPN следует RoIPooling, как и в алгоритме Fast R-CNN — для преобразования регионов к одному размеру и дальнейшей классификации и смещения границ ограничивающих рамок. Поскольку классификацией и регрессией границ занимается как сеть в целом, так и RPN, предлагающая регионы, функция потерь учитывает как финальное решение по классификации и регрессии координат, так и классификацию и регрессию координат, проведённую RPN.\\nMask R-CNN\\nMask R-CNN[9] — улучшение алгоритма Faster R-CNN, предложенное в 2017 году и обеспечивающее осуществлять возможность сегментации экземпляров объектов, а не только составление ограничивающих рамок с классификацией. В Mask R-CNN к традиционным для алгоритмов семейства R-CNN метке класса и координатам ограничивающей рамки добавляется также маска объекта — прямоугольная матрица принадлежности пикселя текущему объекту. Маски предсказываются для каждого класса с помощью классификации без наличия информации о том, что изображено в регионе, что выдяеляет отдельный классификатор на последнем уровне сети. Потребность предсказания маски обусловила несколько архитектурных изменений относительно Faster R-CNN: ключевым является использование RoIAlign вместо RoIPooling. RoIPooling хорошо подходит для масштабирования ограничивающих рамок, однако, для маски такой метод оказывается недостаточно точным. RoIAlign не использует округлений сдвигов для пулинга, а сохраняет значения с плавающей точкой, используя билинейную интерполяцию. Это обеспечило более точное выделение маски объекта.\\nМодель Mask R-CNN совершила прорыв в задачах сегментации экземпляров, детекции объектов и определения поз людей на фотографии (англ. human pose estimation). Функция потерь является общей и включает три компонента — классификация, регрессия границ рамки и регрессия значений маски. Это позволило обеспечить взаимопомощь определения сдвигов границ объектов и более точного определения маски.\\nОдноэтапные методы\\nСемейство алгоритмов R-CNN использует предсказания регионов, что позволяет обеспечивать хорошую точность, но может быть очень медленным для некоторых сфер, таких, как беспилотное управление автомобилем. Можно выделить ещё одно семейство параллельно развивающихся алгоритмов для детекции изображений, которое не использует регионы — семейство алгоритмов быстрой детекции.\\nYOLO\\nАлгоритм YOLO[10] (You Look Only Once), предложенный в 2016 году, был первой попыткой сделать возможной детекцию объектов в реальном времени. В рамках алгоритма YOLO исходное изображение сначала разбивается на сетку из $N \\\\times N$ ячеек. Если центр объекта попадает внутрь координат ячейки, то эта ячейка считается ответственной за определение параметров местонахождения объекта. Каждая ячейка описывает несколько вариантов местоположения ограничивающих рамок для одного и того же объекта. Каждый из этих вариантов характеризуется пятью значениями — координатами центра ограничивающей рамки, его шириной и высотой, а также степени уверенности в том, что ограничивающая рамка содержит в себе объект. Также необходимо для каждой пары класса объектов и ячейки определить вероятность того, что ячейка содержит в себе объект этого класса. Таким образом, последний слой сети, принимающий конечное решение об ограничивающих рамках и классификации объектов работает с тензором размерности $N \\\\times N \\\\times (5B + C)$, где $B$ — количество предсказываемых ограничивающих рамок для ячейки, $C$ — количество классов объектов, определённых изначально.\\nАлгоритм YOLO работает быстрее алгоритмов семейства R-CNN за счёт того, что поддерживает дробление на константное количество ячеек вместо того, чтобы предлагать регионы и рассчитывать решение для каждого региона отдельно, однако, в качестве проблем YOLO указывается плохое качество распознавания объектов сложной формы или группы небольших объектов из-за ограниченного числа кандидатов для ограничивающих рамок.\\nYOLOv2, YOLOv3\\nУлучшенная версия модели YOLOv2[11] отличается от предшественницы использованием батчевой нормализации на свёрточных слоях, обучением модели на изображениях с повышенным разрешением, использованием ключевых рамок для предсказания местонахождения объектов, использованием кластеризации алгоримтом $k$-средних для обучения более эффективного выбора размеров ограничивающих рамок на тренировочной выборке с использованием функции расстояния на основе IoU:\\n$dist(x, c_i) = 1 - IoU(x, c_i)$\\nгде $x$ — настоящая ограничивающая рамка, $c_i$ — центроид кластера. Количество ограничивающих рамок-центроидов выбирается при помощи \"метода локтя\" (англ. elbow method). Также в YOLOv2 используется предположение, что ограничивающиеся рамки не слишком отклоняются от местоположения центра, что обеспечивает стабильность на фоне менее эффективного равномерного выбора рамок-кандидатов по всему исходному изображению. YOLO9000, представленный в той же статье и названный согласно использованию 9000 лучших классов ImageNet, использует древовидную структуру классов, учитывая их вложенность. Например, если среди классов есть метка \"Персидская кошка\", это будет означать, что найденный объект будет подклассом метки \"Кошка\". Таким образом, не возникает взаимной исключительности классов, и softmax ко всем классам не применяется. Чтобы предсказать вероятность узла класса, мы можем следовать по пути от узла к корню:\\n$p($persian cat$|$object$) = p($persian cat$|$cat$) \\\\cdot p($cat$|$animal$) \\\\cdot p($animal$|$object$) \\\\cdot p($object$)$\\n$p($object$)$ — вероятность обнаружения объекта, вычисленная на этапе генерации ограничительных рамок. Путь прогнозирования условной вероятности может остановиться на любом этапе, в зависимости от того, какие метки доступны.\\nYOLOv3[12], в свою очередь, является небольшим улучшением YOLOv2 — используется логистическая регрессия для оценок достоверностей ограничивающих рамок вместо суммы квадратов ошибок для условий классификации в YOLO и YOLOv2; использование нескольких независимых логистических классификаторов для каждого класса вместо одного слоя softmax; добавление межуровневых соединений между уровнями прогнозирования ограничивающих рамок; использование архитектур DarkNet и ResNet для свёрточных сетей.\\nSSD\\nМодель Single Shot Detector[13] (SSD) использует идею использования пирамидальной иерархии выходов свёрточной сети для эффективного обнаружения объектов различных размеров. Изображение последовательно передаётся на слои свёрточной сети, которые уменьшаются в размерах. Выход из последнего слоя каждой размерности участвует в принятии решения по детекции объектов, таким образом, складывается \"пирамидальная характеристика\" изображения. Это позволяет обнаруживать объекты различных масштабов, так как размерность выходов первых слоёв сильно коррелирует с ограничивающими рамками для маленьких объектов, а последних — для крупных. В отличие от YOLO, SSD не разбивает изображение на сетку произвольного размера, а предсказывает смещение ключевых рамок. Ключевые рамки на разных уровнях масштабируются так, что одна размерность выходного слоя отвечает за объекты своего масштаба. В результате, большие объекты могут быть обнаружены только на более высоком уровне, а маленькие объекты — на низких уровнях. Как и в других алгоритмах, функция потерь обеспечивает совместный вклад как потерь локализации, так и потерь классификации.\\nAnchor boxes\\nAnchor boxes — алгоритм нахождения объектов, основанный на предсказании категории объекта и отступа от истинной ограничивающей рамки для большого количества сгенерированных ключевых рамок с последующей их фильтрацией.\\nГенерация ключевых рамок\\nПусть входное изображение имеет высоту $h$ и ширину $w$. Генерируем ключевые рамки с различными формами и размерами, центрированные на каждом пикселе изображения. Предположим, что размер $s∈(0, 1]$, соотношение сторон $r>0$, тогда ширина и высота ключевой рамки равны $ws\\\\sqrt{r}$ и $hs/\\\\sqrt{r}$. Затем определяем набор размеров $s_1,\\\\ldots, s_n$ и набор соотношений $r_1,\\\\ldots, r_m$. Если использовать комбинацию всех размеров и пропорций, то входное изображение будет иметь $whnm$ ключевых рамок, что может привести к большой вычислительной сложности. Поэтому обычно выбираются только комбинации, содержащие размеры $s_1$ и пропорции $r_1$:\\n$(s_1, r_1), (s_1, r_2), \\\\ldots, (s_1, r_m), (s_2, r_1), (s_3, r_1), \\\\ldots, (s_n, r_1).$\\nПри таком подходе число рамок для входного изображения сокращается до $wh(n+m-1)$.\\nПроцесс обучения\\nПусть набор ключевых рамок входного изображения это $A_1, A_2, \\\\ldots, A_{n_a}$, а набор истинных ограничивающих рамок это $B_1, B_2, \\\\ldots, B_{n_b}$, и $n_a \\\\geq n_b$. Определяем матрицу $\\\\mathbf{X} \\\\in \\\\mathbb{R}^{n_a \\\\times n_b}$, где элемент $x_{ij}$ - это $IoU$ ключевой рамки $A_i$ с истинной рамкой $B_j$. Затем находим наибольший элемент в матрице $\\\\mathbf{X}$ и сохраняем индекс строки и колонки элемента как $i_1,j_1$. Так мы обозначили ограничивающую рамку $B_{j_1}$ для ключевой рамки $A_{i_1}$. Далее исключаем все элементы в строке с индексом $i_1$ и колонке с индексом $j_1$ в матрице $\\\\mathbf{X}$ для последующих поисков максимального элемента. Теперь ищем наибольший элемент среди оставшихся элементов матрицы $\\\\mathbf{X}$ и сохраняем его индексы как элемент $i_2, j_2$, и также исключаем элементы из соответствующих колонок и строк.\\nПовторяем данные действия пока все $n_b$ колонки матрицы $\\\\mathbf{X}$ не будут исключены. Затем, для оставшихся $n_a - n_b$ ключевых рамок $A_i$ находим лучшую истинную рамку $B_j$ с наибольшим IoU в строке матрицы $\\\\mathbf{X}$ с индексом $i$. Присваиваем ключевой рамке $A_i$ ограничивающую рамку $B_j$ только если IoU больше предустановленного порогового значения.\\nТеперь мы можем определить категорию и отступ для каждой ключевой рамки. Если ключевой рамке $\\\\mathbf{A}$ назначена $\\\\mathbf{B}$, то тогда ее категория такая же как и у $\\\\mathbf{B}$. А смещение ключевой рамки $\\\\mathbf{A}$ устанавливается в соответствии с относительным положением центральных координат $\\\\mathbf{B}$ и $\\\\mathbf{A}$ и относительными размерами двух рамок. Поскольку положения и размеры различных рамок в наборе данных могут различаться, эти относительные положения и относительные размеры обычно требуют некоторых специальных преобразований, чтобы сделать распределение смещений более равномерным и более простым для подгонки. Предположим, что центр ключевой рамки $\\\\mathbf{A}$ это $(x_a, y_a)$, высота и ширина это $h_a$ и $w_a$; для $\\\\mathbf{B}$ - $(x_b, y_b)$, $h_b$ и $w_b$ соответственно. В таком случае отступ для A рассчитывается следующим образом:\\n$\\\\left( \\\\frac{ \\\\frac{x_b - x_a}{w_a} - \\\\mu_x }{\\\\sigma_x}, \\\\frac{ \\\\frac{y_b - y_a}{h_a} - \\\\mu_y }{\\\\sigma_y}, \\\\frac{ \\\\log \\\\frac{w_b}{w_a} - \\\\mu_w }{\\\\sigma_w}, \\\\frac{ \\\\log \\\\frac{h_b}{h_a} - \\\\mu_h }{\\\\sigma_h}\\\\right)$\\nДефолтные значения констант $\\\\mu_x = \\\\mu_y = \\\\mu_w = \\\\mu_h = 0$, $\\\\sigma_x=\\\\sigma_y=0.1$, и $\\\\sigma_w=\\\\sigma_h=0.2$.\\nЕсли ключевой рамке не назначен ограничивающий прямоугольник, то устанавливаем категорию background.\\nПроцесс предсказаний\\nНа этапе прогнозирования сначала генерируется несколько ключевых рамок для изображения, а затем прогнозируются их категории и смещения. Затем на основе ключевых блоков и их прогнозируемых смещений получаются ограничивающие рамки прогнозирования. Когда имеется много ключевых рамок или много одинаковых ограничивающих рамок предсказания могут выводиться несколько раз для одного и того же объекта. Чтобы упростить результаты, можно удалить аналогичные ограничивающие рамки прогнозирования. Обычно используется метод, который называется не максимальное подавление (NMS).\\nСм.также\\nПримечания\\nИсточники информации\\n- Stanford CS231n: Detection and Segmentation\\n- Stepik.org: Deep Learning School\\n- Habr: обзор Deep Learning в Computer Vision\\n- Список статей о детекции объектов методами глубокого обучения\\n- R-CNN, Fast R-CNN, Faster R-CNN, YOLO — Object Detection Algorithms\\n- Dive into deep lerning - Computer vision - Anchor Boxes', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='b0c05ddf-745f-4005-9eb2-b5de7cd15a83', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='72bd853f34991726dc686b8e2a784db72cad902393a560beb1a435e406416234', text='Оценка положения\\n|Определение:\\n|Оценка положения (англ. Pose Estimation) — задача определения положения и ориентации объекта или группы объектов в пространстве.\\nСодержание\\n- 1 Области применения\\n- 2 Методы решения задачи оценки положения\\n- 3 Оценка положения человека\\n- 4 См. также\\n- 5 Примечания\\n- 6 Источники информации\\nОбласти применения\\nЗадача оценки положения движущихся и статичных объектов возникает во множестве прикладных областей. Сейчас происходит подъем популярности разработки устройств и систем, отслеживающих положения объектов окружающего мира и использующих эту информацию для различных целей. Рассмотрим несколько областей:\\n- Транспортные средства с встроенными системами помощи водителю (автопилот, круиз контроль и др.). Эти системы помогают водителю с парковкой, контролируют скорость и направление движения, а также предупреждают об объектах, находящихся на дороге, о типе дорожного покрытия и возможных авариях.\\n- Дополненная реальность: устройства, в которых в реальное изображение, получаемое с помощью видеокамер, встраивается некоторая информация, полезная человеку.\\n- Виртуальная реальность: оценка положения, как технология, является критически важной для достижения эффекта погружения в виртуальную реальность. В сочетании с отслеживанием ориентации становится возможным измерять и передавать в виртуальную реальность все 6 степеней свободы (6-DoF) реального мира.\\n- Робототехника: роботы (медицинские, научные, промышленные и др.), которые основывают свое движение на построении карты окружения и препятствий.\\n- Веб-технологии: исследование пользовательского опыта и удобства использования продукта. Можно отслеживать взгляд пользователя, чтобы понимать какие блоки сайта привлекают наибольшее внимание.\\nМетоды решения задачи оценки положения\\nАкустические методы\\nАкустические приборы слежения используют ультразвуковые (высокочастотные) звуковые волны для измерения положения и ориентации целевого объекта в пространстве. Для определения положения объекта либо измеряется время пролёта (time-of-arrival) звуковой волны от передатчика к приёмникам, либо разность фаз синусоидальной звуковой волны при приёмо-передаче. Алгоритмы отслеживания положения при использовании акустических приборов основаны на трилатерации и расчете угла прибытия. При использовании данных методов разработчики сталкиваются с некоторыми проблемами: акустические трекеры, как правило, имеют низкую скорость обновления, связанную с низкой скоростью звука в воздухе, которая зависит от внешних факторов среды, таких как температура, давление и влажность.\\nРадиочастотные методы\\nМетодов, основанных на радиочастотах, достаточно много.\\n- Позиционированиe с использованием пассивных радиочастотных идентификаторов RFID\\nОсновное назначение систем с пассивными RFID метками — идентификация. Они применяются в системах, традиционно использовавших штрих-коды или магнитные карточки: в системах распознавания товаров и грузов, опознания людей, в системах контроля и управления доступом (СКУД) и т.п. Система включает RFID метки с уникальными кодами и считыватели и работает следующим образом. Считыватель непрерывно генерирует радиоизлучение заданной частоты. ЧИП метки, попадая в зону действия считывателя, использует это излучение в качестве источника электропитания и передает на считыватель идентификационный код. Радиус действия считывателя составляет около метра.\\n- Позиционирование с использованием активных RFID\\nАктивные радиочастотные метки используются при необходимости отслеживания предметов на относительно больших расстояниях (например, на территории сортировочной площадки). Рабочие частоты активных RFID меток — 455МГц, 2.4ГГц или 5.8ГГц, а радиус действия — до ста метров. Питаются активные метки от встроенного аккумулятора. Существуют активные метки двух типов: транспондеры и радиомаяки. Транспондеры включаются, получая сигнал считывателя. Они применяются в АС оплаты проезда, на КПП, въездных порталах и других подобных системах. Радиомаяки используются в системах позиционирования реального времени. Радиомаяк отправляет пакеты с уникальным идентификационным кодом по команде либо с заданной периодичностью. Пакеты принимаются как минимум тремя приемниками, расположенными по периметру контролируемой зоны. Расстояние от маячка до приемников с фиксированными координатами определяются по углу направления на маячок Angle of arrival (AoA), по времени прихода сигнала Time of arrival (ToA) или по времени распространения сигнала от маячка до приемника Time of flight (ToF). Инфраструктура системы строится на базе проводной сети и в двух последних случаях требует синхронизации.\\n- Ultra Wideband (UWB) позиционирование\\nТехнология UWB (сверхширокополосная) использует короткие импульсы с максимальной полосой пропускания при минимальной центральной частоте. У большинства производителей центральная частота составляет несколько гигагерц, а относительная ширина полосы — 25-100%. Технология используется в связи, радиолокации, измерении расстояний и позиционировании. Это обеспечивается передачей коротких импульсов, широкополосных по своей природе. Идеальный импульс (волна конечной амплитуды и бесконечно малой длительности), как показывает анализ Фурье, обеспечивает бесконечную полосу пропускания. UWB сигнал не походит на модулированные синусоидальные волны, а напоминает серию импульсов. Производители предлагают разные варианты UWB технологии. Различаются формы импульсов. В некоторых случаях используются относительно мощные одиночные импульсы, в других — сотни миллионов маломощных импульсов в секунду. Применяется как когерентная (последовательная) обработка сигнала, так и не когерентная. Все это приводит к значительному различию характеристик UWB систем разных производителей.\\nМагнитные методы\\nМагнитные методы основаны на измерении интенсивности магнитного поля в различных направлениях. Как правило, в таких системах есть базовая станция, которая генерирует переменный или постоянный ток. Так как сила магнитного поля уменьшается с увеличением расстояния между точкой измерения и базовой станцией, можно определить местоположение контроллера, зная силу магнитного поля. Если точка измерения вращается, то распределение магнитного поля изменяется по различным осям, что позволяет определить ориентацию. Наиболее известными продуктами на основе магнитного трекинга являются VR контроллер Razer Hydra и система STEM от компании Sixense. Точность данного метода может быть достаточна высока в контролируемых условиях (в спецификациях Hydra говорится о 1 мм позиционной точности и 1 градусе точности ориентации), однако магнитное отслеживание подвержено помехам от токопроводящих материалов вблизи излучателя или датчика, от магнитных полей, создаваемых другими электронными устройствами и ферромагнитных материалов в пространстве отслеживания.\\nОптические методы\\nОптические методы представляют собой совокупность алгоритмов компьютерного зрения и отслеживающих устройств, в роли которых выступают камеры видимого или инфракрасного диапазона, стерео-камеры и камеры глубины. Оптический трекинг основан на том же принципе, что и стереоскопическое зрениe человека. Когда человек смотрит на объект с помощью бинокулярного зрения, он в состоянии определить, приблизительно на каком расстоянии объект находится. Не достаточно просто установить несколько камер для имитации стереоскопического зрения человека. Камеры должны определить расстояние до объекта и его положения в пространстве, так что их необходимо откалибровать. Оптические системы надежны и относительно дешевы, но с ними трудно провести начальную калибровку. Кроме того, система требует прямой линии света, в противном случае мы получаем неправильные данные. В зависимости от наличия специальных оптических маркеров выделяют отдельно:\\n- Безмаркерный трекинг: как правило строится на сложных алгоритмах с использованием двух и более камер, либо стерео-камер с сенсорами глубины. Используется наибольшим образом в автомобилях с автопилотом и иными системами помощи водителю.\\n- Трекинг с использованием маркеров: предполагает заранее заданную модель объекта, которую можно отслеживать даже с одной камерой. Маркерами обычно служат источники инфракрасного излучения (как активные, так и пассивные), а также видимые маркеры наподобие QR-кодов. Такой вид трекинга возможен только в пределах прямой видимости маркера.\\nЗадача Perspective-n-Point (PnP)\\nПри оптическом отслеживании для определения положения объекта в пространстве решается так называемая задача PnP (Perspective-n-Point), когда по перспективной проекции объекта на плоскость сенсора камеры необходимо определить положение объекта в 3D-пространстве.\\nДля заданной 3D-модели объекта и 2D-проекции объекта на плоскость камеры решается система уравнений. В результате чего получается множество возможных решений. Количество решений зависит от числа точек в 3D-модели объекта. Однозначное решение для определения 6-DoF положения объекта можно получить как минимум при 4 точках. Для треугольника получается от 2 до 4 возможных решений, то есть положение не может быть определено однозначно.\\nРешение предлагается достаточно большим количеством алгоритмов, реализованных в виде библиотек:\\n- POS (Pose from Orthography and Scaling), аппроксимирующий перспективную проекцию с помощью масштабированной ортогональной проекции и находящий матрицу поворота и вектор сдвига объекта путём решения линейной системы уравнений.\\n- POSIT (POS with ITerations), который использует в цикле аппроксимацию нахождения положения POS для нахождения более хорошей масштабированной ортогональной проекции особых точек, а затем применяет POS к этим точкам, а не к исходным. POSIT сходится к точному решению за несколько итераций.\\n- OpenCV — библиотека компьютерного зрения широкого назначения с открытым исходным кодом. Основные части библиотеки — интерпретация изображений и алгоритмы машинного обучения. Список возможностей, предоставляемых OpenCV, весьма обширен: интерпретация изображений, калибровка камеры по эталону, устранение оптических искажений, анализ перемещения объекта, определение формы объекта и слежение за объектом, сегментация объекта и др. Нам же интереcен метод solvePnP.\\nSLAM[1] — Simultaneous Localization and MappingМетод одновременной локализации и построения карты (SLAM) — наиболее популярный способ позиционирования, который применяется для отслеживания положения в пространстве.\\nАлгоритм состоит из двух частей: первая — составление карты неизвестного окружающего пространства на основе измерений (данные с одометра или стерео-камеры), вторая — определение своего местоположения (локализация) в пространстве на основе сравнения текущих измерений с имеющейся картой пространства. Данный цикл непрерывно перевычисляется, при этом результаты одного процесса участвуют в вычислениях другого процесса. Наиболее популярные методы решения задачи включают в себя фильтр частиц и расширенный фильтр Калмана. SLAM удобен для мобильных решений виртуальной и дополненной реальности. Недостатком данного подхода является большая вычислительная сложность.\\nИнерциальный трекингСовременные инерциальные измерительные системы (IMU) на основе MEMS-технологии позволяют отслеживать ориентацию (roll, pitch, yaw) в пространстве с большой точностью и минимальными задержками.\\nБлагодаря алгоритмам «sensor fusion» на основе комплементарного фильтра или фильтра Калмана данные с гироскопа и акселерометра успешно корректируют друг друга и обеспечивают точность как для кратковременных измерений, так и для длительного периода. Однако определение координат (перемещения) за счёт двойного интегрирования линейного ускорения (dead reckoning), вычисленного из сырых данных с акселерометра, не удовлетворяет требованиям по точности на длительных периодах времени. Акселерометр сам по себе даёт сильно зашумленные данные, и при интегрировании ошибка увеличивается со временем квадратично. Решить данную проблему помогает комбинирование инерциального подхода к трекингу с другими методами, которые периодически корректируют так называемый дрифт акселерометра.\\nГибридные методы\\nТак как ни один из методов не является безупречным, и все они имеют свои слабые места, наиболее разумно комбинировать различные методы отслеживания. Так инерциальный трекинг (IMU) может обеспечить высокую частоту обновления данных (до 1000 Гц), в то время как оптические методы могут дать стабильную точность в длительные периоды времени (корректирование дрифта).\\nОценка положения человека\\nОценка положения человека (англ. Human Pose Estimation) — одна из важных задач последних нескольких десятилетий в области компьютерного зрения, которая является необходимым шагом к распознаванию людей на изображениях и видео. Задачу разбивают на 2 категории:\\n- Оценка положения в плоскости (англ. 2D Human Pose Estimation) — определение расположения отдельных частей тела и суставов человека (англ. keypoints/body joints) на изображении.\\n- Оценка положения в пространстве (англ. 3D Human Pose Estimation) — предсказание пространственного расположения тела человека.\\nОценку положения человека использует множество областей. В частности, распознавание жестов, упрощение анимации персонажей, в разработке игр, и другое.\\nСуществуют различные подходы к решению данной задачи. Классический подход — использование изобразительных структур (англ. pictoral structures). Основная идея заключается в том, чтобы представить объект в виде набора \"частей\", соединенных пружинами (Рис. 5). Каждая \"часть\" является деталью внешности(нога, рука, глаз и др.), соответствующим изображению. Когда части параметризованы расположением пикселей и ориентацией, полученная структура может моделировать \"каркас\" в положении человека. Однако этот подход ограничен количеством таких заранее построенных блочных структур, ведь они не зависят от входного изображения. Проводившиеся исследования были сосредоточены на обогащении репрезентативной силы этого метода, однако существуют более удачные подходы. Альтернативный подход — использование сверточных нейронных сетей (англ. Convolutional Neural Network, CNN) и глубокого обучения (англ. Deep learning). Большинство последних систем оценки положения человека используют именно этот подход, в значительной степени заменяя созданные вручную функции и графические модели. Использование машинного обучения значительно улучшило результаты.\\nСм. также\\n- Отслеживание направления взгляда пользователя в браузере\\n- Сегментация изображений\\n- Вписывание части изображения\\n- Глубокое обучение\\n- Сверточные нейронные сети\\nПримечания\\nИсточники информации\\n- Радиочастотная идентификация.\\n- Дополненная реальность.\\n- Positional tracking.\\n- ГОСТ Р 54621-2011. Информационные технологии. Радиочастотная идентификация для управления предметами.\\n- Локализация по Aruco маркерам\\n- Обзор методов и технологий отслеживания положения для виртуальной реальности.\\n- DeepSORT: Deep Learning to Track Custom Objects in a Video.\\n- Оценка положения человека.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='eb65088d-f901-49a8-a9bd-f8abde6a7592', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0a3d9ee10533350c009b8fbdfa924756ed091e37d11ec7c6e53152dc1ce2557f', text='Определение положения человека\\nОпределение положения человека (англ. Human pose estimation) — частный случай задачи сегментации изображения из раздела компьютерного зрения о нахождении и локализации частей тела человека на изображениях или видео (рассматривается как последовательность изображений). Чаще всего позицией человека называют набор соединённых ключевых точек (англ. Joint), соответствующих суставам (плечи, локти, кисти, тазобедренные суставы, колени, стопы) и другим ключевым точкам (шея, голова, центр торса). Эту задачу можно рассматривать в двух или трёх измерениях, от чего зависит сложность задачи и практические применения результатов. Также задачу можно разделить на два подтипа: определение положения для одного человека (англ. Single Person Pose Estimation), определение положения для нескольких человек (англ. Multi Person Pose Estimation)\\nСодержание\\n- 1 Постановка задачи\\n- 2 Область применения\\n- 3 Методы решения\\n- 4 См. также\\n- 5 Примечания\\n- 6 Источники информации\\nПостановка задачи\\nОпределение положения одного человека (англ. Single Person Pose Estimation)\\nЗадача заключается в определении положения одного человека по фото или видео. Важным условием является то, что на изображении должен быть только один человек, иначе гарантировать корректное выполнение невозможно. В качестве результата необходимо получить набор соединённых точек, указывающих на соответствующие части тела. Сложности заключаются в том, чтобы отделить друг от друга разные части тела, корректно определять положение конечностей, скрытых за другими объектами, а также корректно отличать левые части тела от правых, независимо от поворота человека на изображении.\\nОпределение положений нескольких людей (англ. Multi Person Pose Estimation)\\nЭта задача имеет более высокую сложность, так как необходимо обнаружить множество человек на изображении, а затем определить положение для каждого человека из множества обнаруженных людей. Основная сложность в том, чтобы корректно определить и отличить друг от друга части тела, принадлежащие разным людям, а также решить все сложности связанные с Single Person Pose Estimation.\\nОбласть применения\\n- Кинематограф и анимация — популярные технологии CGI[1] (англ. computer-generated imagery, буквально «изображения, сгенерированные компьютером») и захват движения[2] (англ. Motion capture), позволяют создавать движущиеся изображения и графику, используя для анимации движения специального актера. Несмотря на то, что в настоящий момент чаще используется маркерный способ, при котором актер надевает костюм с датчиками движения, в последние годы большое развитие получил безмаркерный способ, основанный на компьютерном зрении.\\n- Видеоигры — широко применяется в дополненной реальности (англ. Augmented Reality, AR[3]) и виртуальной реальности (англ. Virtual Reality, VR[4]). Также в консольных игровых решениях используется трекинг (англ. Motion tracking), отслеживающий положения игрока в некотором радиусе перед камерой. Помимо этого, определение положения человека необходимо непосредственно в производстве видеоигр, для этого, опять же, используется технология CGI[1].\\n- Человеко-компьютерное взаимодействие (англ. Human-computer interaction) — здесь определение положения человека используется для взаимодействия с роботами или компьютерами, для отдачи команд компьютерным системам. Примером такого взаимодействия можно назвать уже упомянутый захват движения при игре на консолях.\\n- Биомеханика спорта (англ. Sport motion analysis) — анализ движений при тренировке и соревнованиях. Используется для лучшего понимания процессов, происходящих при занятии спортом, для предотвращения травм и растяжений, и для установления новых рекордов. Информация, полученная в ходе анализа, используется также для создания профессионального инвентаря.\\nМетоды решения\\nDeepPose (2014)\\nDeepPose[5] — первая значимая разработка с использованием глубокого обучения для задачи определения положения человека. Модель продемонстрировала высокую эффективность и превзошла существовавшие на тот момент решения.\\nОценка позы формулируется как задача совместной регрессии по ключевым точкам (англ. Joint) и решается при помощи сверточных нейронных сетей глубокого обучения (англ. convolutional DNN). Полное изображение и 7-слойная обобщенная глубокая сверточная нейронная сеть используются в качестве входных данных для регрессии по местоположению каждого сустава тела. У этого решения есть два преимущества.\\nВо-первых, глубокая нейронная сеть (англ. DNN) может захватывать полный контекст каждой ключевой точки — каждый регрессор сустава использует полное изображение как входной сигнал.\\nВо-вторых, данный подход существенно проще формулируется в сравнении с методами, основанными на графических моделях — нет необходимости явно проектировать представления элементов и детекторы для отдельных частей тела; нет необходимости явно разрабатывать топологию модели и взаимодействия между суставами. Вместо этого для решения данной задачи можно обучить обобщенную сверточную DNN.\\nКроме того, авторы используют каскад основанных на DNN предсказателей позы. Такой каскад позволяет повысить точность (англ. precision) совместной локализации ключевых точек. Начиная с начальной оценки позы, на основе полного изображения обучаются регрессоры на основе DNN, который уточняют совместные прогнозы с помощью фрагментов изображений с более высоким разрешением.\\nВажной особенностью является то, что обрабатывается человек целиком, что позволяет корректно определять позу, даже если некоторые суставы скрыты.\\nС архитектурной точки зрения модель основана на AlexNet[6] (7 слоёв) и дополнительном финальном слое, выводящем пары координат ключевых точек. Обучение модели производится с использованием функции потерь L2[7] для регрессии (англ. L2 loss for regression).\\nОценка эффективности решения проводилась на нескольких наборах данных, в частности на LSP (Leeds sports dataset)[8] и FLIC (Frames Labeled In Cinema)[9]. На наборе данных LSP оценивался процент корректно определенных частей (англ. Percentage of Correct Parts, PCP). Сводная таблица представлена на рисунке 8. Оценка производилась на первом, втором и третьем слоях, а также на пяти других решениях: Dantone et al.[10], Tian et al.[11], Johnson et al.[12], Wang et al.[13], Pishchulin[14]. Наилучший результат в столбце выделен жирным.\\nAlphaPose (2015)\\nAlphaPose[15] позволяет решать проблему определения положения как одного, так и нескольких человек в режиме реального времени. Данное решение задачи региональной оценки позы для нескольких человек (англ. Region Multi Person Estimation, RMPE) призвано облегчить оценку позы при наличии неточных окружающих рамок (англ. bounding box) человека. Решение доступно для общего пользования и опубликовано на GitHub.\\nСтруктура решения состоит из трех компонентов: симметричная сеть пространственных преобразователей (англ. Symmetric Spatial Transformer Network, SSTN), параметрическое не-максимальное подавление позы (англ. Parametric Pose Non-maximum Suppression, NMS[16])) и генератор предложений с указанием позы (англ. Pose-Guided Proposals Generator, PGPG).\\nНа рисунке 10 показан процесс работы решения. Сеть симметричных пространственных преобразователей состоит из сети пространственных преобразователей (англ. Spatial Transformer Network, STN) и сети обратных пространственных преобразований (англ. Spatial De-Transformer Network, SDTN). Модуль STN отдает результаты своей работы на вход определителю поз (англ. Single Person Pose Estimator, SPPE), который, в свою очередь отдает свои результаты модулю SDTN. STN получает предположения относительно людей — выделенные окружающими рамками потенциальные фигуры, а SDTN генерирует окончательные предположения о позах людей. Параллельный определитель поз (англ. Single Person Pose Estimator, SPPE) действует как дополнительный регуляризатор на этапе обучения. Наконец, выполняется параметрическое не-максимальное подавление позы (англ. Parametric Pose Non-maximum Suppression, NMS[16]) для устранения избыточных оценок позы. В отличие от традиционного обучения, мы обучаем модуль SSTN + SPPE на изображениях, сгенерированных генератором предложений с указанием позы (англ. Pose-Guided Proposals Generator, PGPG).\\nЕсли говорить о внутренних нюансах реализации решения, STN базируется на ResNet18[17], детектор людей — на VGG[18] SSD-500[19], SPPE представляет собой 8 последовательных сетей вида \"песочые часы\" (англ. 8-stack hourglass network[20]).\\nТак как AlphaPose, как и OpenPose, является решением, работающим в реальном времени, то сравнение этих двух решений наиболее интересно. На наборе данных MPII Human Pose[21] было выполнено сравнение вероятности корректности определения ключевой точки (англ. Probability of Correct Keypoint, PCK). Результаты представлены в таблице на рисунке 11.\\nDeepCut (2016)\\nDeepCut[22] решает задачу определения поз для нескольких людей (англ. Multi person Pose estimation) и находится в открытом доступе.\\nДанный подход предполагает одновременное решение задач определения частей тела и отделения друг от друга частей тела разных людей: определяется количество людей в сцене, идентифицируются закрытые части тела и устраняется неоднозначность частей тела людей, находящихся в непосредственной близости друг от друга. Это отличает данное решение от многих других, сначала выявляющих людей, а затем оценивающие их положения.\\nАвторы предлагают разделение и разметку набора гипотез о частях тела, созданных с помощью детекторов частей на основе CNN. Неявно выполняется не-максимальное подавление (англ. Non-maximum Suppression, NMS[16]) для набора возможных частей и производится группировка, чтобы сформировать конфигурации частей тела с учетом геометрических ограничений и ограничений внешнего вида.\\nПример работы алгоритма представлен на рисунке 12: (a) начальное определение возможных частей и попарных связей между всеми обнаруженными частями, которые (b) кластеризуются по принадлежности одному человеку (один цвет — один человек) и каждая часть помечается меткой соответствующего этой части класса (разные цвета и символы относятся к разным частям тела); (c) демонстрация результата.\\nДля оценки эффективности решения проводилось сравнение нескольких вариантов архитектуры, использующих DeepCut друг с другом и с тремя другими решениями. Использовались наборы данных LSP (Leeds Sport Poses)[8], LSPET (LSP Extended)[23] и MPII Human Pose[21]. Были рассмотрены два варианта архитектуры, использующие DeepCut SP (Single Person) и DeepCut MP (Multi Person), совмещающие в себе DeepCut и адаптированная быстрая сверточная нейронная сеть на основе регионов (англ. Adapted Fast R-CNN[24], AFR-CNN) в одном случае и DeepCut и плотные сверточные нейронные сети (англ. Dense-CNN) в другом. Также в сравнении участвовали решения Tompson et al.[25], Chen&Yuille[26], Fan et al.[27].\\nОценивалась вероятность корректности определения ключевой точки (англ. Probability of Correct Keypoint, PCK). На рисунке 13 представлены графики данной величины от нормализованного расстояния между ключевыми точками (близкорасположенные точки корректно определить сложнее). На рисунке 14 — таблица, отражающая качество определения тех или иных частей тела, вероятности корректности определения ключевой точки (PCK) и площадь под кривой ошибок (англ. area under ROC curve, AUC).\\nOpenPose (2019)\\nOpenPose[28] — первая система, решающая задачу определения поз для нескольких людей (англ. Multi person Pose estimation) в режиме реального времени c открытым исходным кодом.\\nОпределяет 135 ключевых точек для каждого человека. Поддерживает определение не только крупных частей, но и отдельных пальцев и их движений. Для обучения использовался CMU Panoptic Studio dataset[29], состоящий из съемок людей с большого числа ракурсов в специальном куполе, оснащенном 500 камерами[30].\\nЛогика архитектуры OpenPose следующая: во-первых, входное RGB-изображение (рисунок 16а) подается как вход в многослойную CNN с двумя ветвями.\\nДве ветви означают, что CNN производит два разных вывода. На рисунке 17 верхняя ветвь, показанная бежевым цветом, предсказывает карты достоверности (англ. confidence map) (рисунок 16b) расположения различных частей тела. Нижняя ветвь, показанная синим цветом, предсказывает поля сходства фрагментов (англ. affinity field, PAFs) (рисунок 16c), которые представляют степень связи между различными частями тела.\\nМногослойность означает следующее: на первом слое (левая половина рисунка 17) сеть создает начальный набор карт достоверности обнаружения $S$ и набор полей сходства для части $L$. Затем на каждом последующем слое (правая половина рисунка 17) прогнозы из обеих ветвей на предыдущем этапе и характеристики исходного изображения $F$, объединяются (объединение обозначено знаком $+$ на рисунке 17) и используются для получения более точных прогнозов. В реализации OpenPose последним этапом $t$ выбран шестой.\\nНа рисунке 18 показаны преимущества многослойной архитектуры. В этом примере мы наблюдаем некоторую начальную путаницу между левой и правой частями тела на первых нескольких этапах. Но по мере того, как слой увеличивается, сеть начинает лучше различать их.\\nВ конце карты достоверности и поля сходства обрабатываются методом жадного вывода[31] (рисунок 16d) для вывода двумерных ключевых точек для всех людей на изображении (рисунок 16e).\\nВажной особенностью является скорость работы данного решения. На рисунке 18 представлено сравнение времени работы трех доступных библиотек, решающих задачу определения положения человека (в одинаковых условиях на одинаковом аппаратном обеспечении): OpenPose, Alpha-Pose[32] (fast Pytorch version), и Mask R-CNN[33]. Время исполнения OpenPose является постоянным, в то время как у Alpha-Pose и Mask R-CNN линейно растет с числом людей на исходных данных.\\nСм. также\\n- Нахождение объектов на изображении\\n- Оценка положения\\n- Компьютерное зрение\\n- Обнаружение и обработка дорожных знаков и пешеходов\\n- Сверточные нейронные сети\\nПримечания\\n- ↑ 1,0 1,1 CGI\\n- ↑ Захват движения\\n- ↑ Дополненная реальность\\n- ↑ Виртуальная реальность\\n- ↑ DeepPose: Human Pose Estimation via Deep Neural Networks, Alexander Toshev, Christian Szegedy, 2014\\n- ↑ Сверточная нейросеть AlexNet, Павел Глек, 2018\\n- ↑ L2 регуляризация\\n- ↑ 8,0 8,1 LSP dataset\\n- ↑ FLIC dataset\\n- ↑ M. Dantone, J. Gall, C. Leistner, and L. Van Gool. Human pose estimation using body parts dependent joint regressors. In CVPR, 2013\\n- ↑ Y. Tian, C. L. Zitnick, and S. G. Narasimhan. Exploring the spatial hierarchy of mixture models for human pose estimation. In ECCV, 2012\\n- ↑ S. Johnson and M. Everingham. Learning effective human pose estimation from inaccurate annotation. In CVPR, 2011\\n- ↑ F. Wang and Y. Li. Beyond physical connections: Tree models in human pose estimation. In CVPR, 2013\\n- ↑ L. Pishchulin, M. Andriluka, P. Gehler, and B. Schiele. Poselet conditioned pictorial structures. In CVPR, 2013\\n- ↑ RMPE: Regional Multi-Person Pose Estimation, Hao-Shu Fang1, Shuqin Xie, Yu-Wing Tai, Cewu Lu1, 2018\\n- ↑ 16,0 16,1 16,2 Non-maximum Suppression, Sambasivarao. K, 2019\\n- ↑ Non-maximum ResNet18\\n- ↑ [https://arxiv.org/abs/1409.1556 Very Deep Convolutional Networks for Large-Scale Image Recognition Karen Simonyan, Andrew Zisserman, 2014]\\n- ↑ SSD: Single Shot MultiBox Detector, Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg, 2015\\n- ↑ Stacked Hourglass Networks for Human Pose Estimation, Alejandro Newell, Kaiyu Yang, Jia Deng, 2016\\n- ↑ 21,0 21,1 MPII Human Pose\\n- ↑ DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation, Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, Peter Gehler, and Bernt Schiele, 2016\\n- ↑ LSPET dataset\\n- ↑ Fast R-CNN, Ross Girshick, 2015\\n- ↑ [J. J. Tompson, A. Jain, Y. LeCun, and C. Bregler. Joint training of a convolutional network and a graphical model for human pose estimation. In NIPS’14]\\n- ↑ [X. Chen and A. Yuille. Articulated pose estimation by a graphical model with image dependent pairwise relations. In NIPS’14]\\n- ↑ [X. Fan, K. Zheng, Y. Lin, and S. Wang. Combining local appearance and holistic view: Dual-source deep neural networks for human pose estimation. In CVPR’15]\\n- ↑ OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields, Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei, and Yaser Sheikh, 2019\\n- ↑ CMU Panoptic Studio dataset\\n- ↑ ИИ для понимания роботами языка тела из CMU, 2017\\n- ↑ Greedy Inference Algorithms for Structured and Neural Models, Sun, Qing, 2018\\n- ↑ AlphaPose, Hao-Shu Fang, Shuqin Xie, Yu-Wing Tai and Cewu Lu, 2018\\n- ↑ Mask R-CNN, Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick, 2018\\nИсточники информации\\n- Guide to Human Pose Estimation, Sudharshan Chandra Babu, 2019\\n- Monocular Human Pose Estimation Yucheng Chena, Yingli Tianb, Mingyi Hea, 2020\\n- DeepPose: Human Pose Estimation via Deep Neural Networks, Alexander Toshev, Christian Szegedy, 2014\\n- DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation, Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, Peter Gehler, Bernt Schiele, 2016\\n- OpenPose github page\\n- Understanding OpenPose (with code reference)— Part 1\\n- RMPE: Regional Multi-Person Pose Estimation, Hao-Shu Fang1, Shuqin Xie1, Yu-Wing Tai2, Cewu Lu, 2018\\n- Shanghai Jiao Tong University, Machine Vision and Intelligence Group\\n- RMPE: Regional Multi-Person Pose Estimation, Hao-Shu Fang1, Shuqin Xie, Yu-Wing Tai, Cewu Lu, 2018\\n- OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields, Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei, and Yaser Sheikh, 2019', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='8fe91f53-442f-4b02-b56e-9728a16ac6ec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='caa6969a57fc1f81f4d0ae1c326670d7101ece699e59ba3a4eaf567ef786b534', text='Распознавание изогнутого текста\\nРаспознавание текста — важная задача машинного обучения, решение которой позволит получать огромное количество информации из окружающего мира без участия человека. Распознавание изогнутого текста, в частности, одна из проблем, лежащих на пути решения данной задачи.\\nСодержание\\n- 1 Введение\\n- 2 Наборы данных\\n- 3 Модели для детекции\\n- 4 Модели для распознавания\\n- 5 Сквозные (end-to-end) модели\\n- 6 Сводные таблицы\\n- 7 См. также\\n- 8 Примечания\\n- 9 Источники информации\\nВведение\\nВ решении задачи распознавания текста двумя основными составляющими являются определение области текста и распознавание содержимого области. В сообществе исследователей выделяют три разных вида ориентации текста: горизонтальная (англ. horizontal), множественная (англ. multi-oriented), изогнутая (англ. curved). Очевидно, что правильность определения области текста напрямую влияет на качество работы распознающих моделей. Долгое время распознавание изогнутого текста казалось крайне сложной задачей — до тех пор, пока не появились способы весьма точно определять контуры объектов на изображениях (например, Mask R-CNN[1]). Использование методов сегментации изображения позволяет добиться хороших результатов на существующих наборах данных.\\nВ этой статье будут описаны наборы данных, поспособствовавшие исследованиям, а также новейшие и наиболее удачные модели, которые показывают хорошие результаты вне зависимости от ориентации текста. Модели разделены на три категории:\\n- модели, занимающиеся только детекцией (они находят группы букв на изображении, а распознавание непосредственно слов разработчики делегируют другим инструментам).\\n- модели, которые занимаются только распознаванием.\\n- модели, которые занимаются и детекцией, и распознаванием — сквозные модели (англ. end-to-end).\\nПри дальнейшем чтении статьи могут возникнуть вопросы относительно методов измерения точности моделей. В качестве меры точности используется F-мера (совместно с precision и recall). В задаче распознавания текста precision — это количество правильно распознанных слов из общего числа слов, которые модель сумела найти на изображениях; recall — это количество правильно распознанных слов из всех слов, представленных в наборе данных. В задаче детекции текста для различных наборов данных используются различные протоколы оценки, с помощью которых определяется recall и precision, потом высчитывается F-мера.\\nНаборы данных\\nTotalText (2017)\\nПредшествующие TotalText\\'у наборы данных ICDAR\\'03[2], \\'11[3], \\'13[4] и MSRA-TD500[5] сыграли значимую роль в начале исследований в области распознавания текста. У наборов данных ICDAR[2][3][4][6] тексты встречались в единственной ориентации — горизонтальной, и на этом предположении были основаны многие ранние модели. Границы текста они определяли как прямоугольник. Это ограничивало возможности распознавания, и для привлечения внимания исследователей к этой проблеме в 2012 году был представлен набор данных MSRA-TD500[5], включавший в себя большое количество изображений с множественной ориентацией текста (от горизонтальной отличается тем, что область с текстом находится под наклоном или/и в перспективе). Модели были усовершенствованы, и теперь определяли границы как произвольных форм четырёхугольники. Текст же изогнутой формы, несмотря на частоту появления в реальном окружении, практически не появлялся в наборах данных (искл. COCO-text[7] и CUTE80[8], но они не привлекли особого внимания к проблеме). Поэтому справиться с произвольной формой текста многие модели попросту не могли.\\nДля привлечения внимания к этой проблеме в 2017 году был представлен набор данных TotalText, состоящий из 1555 изображений с текстом различной ориентации и содержащий в целом 9330 слов. Отличительной особенностью TotalText является эталон области (или же границ) текста. Так, в COCO-text[7] эталоном области текста являлся горизонтально ориентированный прямоугольник, а вот в TotalText это был многоугольник, состоящий из множества полигонов.\\nВ качестве протокола оценки используется DetEval[9].\\nSCUT-CTW1500 (2017)\\nSCUT-CTW1500 должен был привлечь внимание к той же проблеме, что и TotalText. Они были опубликованы практически одновременно (TotalText 27 октября 2017, а SCUT-CTW1500 6 декабря 2017). Вероятно, они разрабатывались независимо друг от друга — авторы SCUT-CTW1500 утверждали, что они являются первооткрывателями полигонального подхода, хотя TotalText был опубликован немного раньше. Позднее авторы TotalText добавили ссылку на SCUT-CTW1500 в качестве дополнения к своему набору данных. SCUT-CTW1500 включает в себя 1500 изображений (1000 для обучения, 500 для проверки), на которых содержится более 10 тысяч областей с текстом, и на каждом изображении как минимум один раз встречается изогнутый текст. Здесь, как и в TotalText, эталоном области является фигура, состоящая из нескольких полигонов. Оба этих набора данных (и модели, обученные на них) стали прорывом — они первые начали использовать полигональную форму.\\nСейчас TotalText и SCUT-CTW1500 все реже используются как два независимых набора данных. Набор данных ArT[10] объединил их в себе и стал самым большим набором данных изогнутого текста.\\nПротоколом оценки является PASCAL VOC[11] протокол, где используется метрика IoU (граничное значение для определения true или false positive — 0.5).\\nМодели для детекции\\nTextSnake (2018)\\nTextSnake отличается уникальным способом представления области с текстом (см. Рисунок 1). Математически, экземпляр текста\\nСтатья о модели доступна по ссылке. Реализацию этой модели можно найти в открытом доступе.\\nАрхитектура\\nСхема работы TextSnake представлена справа (см. Рисунок 2). TextSnake использует свёрточную нейронную сеть. Чтобы определять текст произвольной формы, используется FCN (Fully Convolutional Network)[13] модель для предсказывания геометрических атрибутов текстовых областей. С помощью FCN[13] и FPN (Feature Pyramid Network)[14] предсказываются вероятностные карты центральной линии (text center line, TCL) и текстовых областей (text regions, TR), вместе с геометрическими атрибутами . Карта TCL в дальнейшем маскируется картой TR (TCL, по сути, является частью TR). Для сегментации используется непересекающийся набор, так как центральные линии не перекрывают друг друга. Далее извлекаются списки точек центральной оси и восстанавливаются экземпляры текста. Детальная архитектура представлена ниже (см. Рисунок 3):\\nТочность\\n- TotalText: 78.4%\\n- CTW1500: 75.6%\\nTextFuseNet (2020)\\nОсновной особенностью TextFuseNet является выделение бóльшего количества признаков и их слияние для более точного определения текстовых областей. TextFuseNet опирается на Mask R-CNN[1] и Mask TextSpotter, рассматривая детекцию текста как задачу сегментации. Выделение признаков происходит на трёх уровнях: символьном, словесном и глобальном.\\nСтатья о модели доступна по ссылке. Реализацию этой модели можно найти в открытом доступе.\\nАрхитектура\\nОбщая архитектура TextFuseNet представлена выше (см. Рисунок 4). В качестве основы для FPN[14] используется ResNet50[16], на этом этапе извлекаются общие признаки. Выходные данные используются RPN (Region Proposal Network)[17] и ветвью Semantic Segmentation. RPN[17] используется для генерации предполагаемых текстовых областей, что используется в последующих ветках Detection и Mask.\\n- Сначала в ветви Semantic Segmentation с помощью сегментации определяются признаки на глобальном уровне.\\n- Далее в ветви Detection, извлекаются признаки на словесном уровне и объединяются с признаками глобального уровня. Полученное представление используется для регрессии окружающей рамки и классификации объектов (текста/букв).\\n- Потом в ветви Mask извлекаются признаки на символьном уровне. Все три уровня признаков (символьный, словесный и глобальный) объединяются, и полученное представление используется при сегментации экземпляров (instance segmentation) для объектов, полученных в ветви Detection.\\nПри объединении признаков используется модуль Multi-Path Fusion, общая схема работы которого представлена ниже (Рис. 5):\\nТочность\\n- Total-Text: 87.1%\\n- CTW1500: 86.6%\\nPolyPRNet (2020)\\nОтличительной чертой PolyPRNet является способ представления текста. Для области с текстом модель определяет центральную линию как полином степени\\nСтатья о модели доступна по ссылке.\\nАрхитектура\\nPolyPRNet использует двухступенчатую структуру на основе R-CNN[1]. Схема архитектуры представлена ниже (см. Рисунок 7).\\nНа первой стадии используется ResNet50 (Residual Network)[16] и FPN[14], чтобы получить карты признаков из исходного изображения. Далее используется сеть RPN[17] для формирования набора предложенных областей текста. На второй стадии используется модуль R-CNN[1] с ветками регрессии границы (bounding box regression) и классификации, чтобы точнее локализовать предложенные области. Так же используется модуль Polynomialbased shape Parameter Regression (PPR), чтобы вывести форму и направление потенциального текстового кандидата.\\nТочность\\n- Total-Text: 84.6%\\n- CTW1500: 83.4%\\nМодели для распознавания\\nРаспознающие текст модели в качестве входных данных принимают изображение, где должна находиться одна строка текста. Точность распознавания этих моделей тестировалась на наборах данных, где за эталон принимается прямоугольная окружающая рамка (например, CUTE80[8], ICDAR\\'15[6]).\\nESIR: End-to-end Scene Text Recognition via Iterative Image Rectification (2018)\\nESIR использует итеративное выпрямление изображения, которое исправляет искажения, связанные с перспективой и кривизной. Для этого с помощью полинома моделируется средняя линия текстовой области. В дополнение, определяются направление и высота области текста на множестве сегментов линии. Среднюю линию с дополнительными параметрами назовём \"повторяющей линией\" (см. Рисунок 8).\\nПредставление центральной линии:, где — степень полинома.\\nДополнительные параметры представлены в виде линии:\\nСтатья о модели доступна по ссылке.\\nАрхитектура\\nESIR состоит из двух частей:\\n- Iterative Rectification Network (сеть итеративного выравнивания) (см. Рисунок 9). Сначала просчитываются параметры повторяющей линии, для чего используется сеть локализации вместе со свёртками изображений. После, основываясь на полученных параметрах, изображение выравнивается, и снова передаётся в сеть выравнивания. Этот процесс повторяется до тех пор, пока не будет достигнуто заранее установленное количество итераций. На схеме ниже (см. Рисунок 9) представлена общая схема работы Iterative Rectification Network. Детальная структура сети локализации представлена в таблице (см. Рисунок 10).\\n- Recognition Network (сеть распознавания). Используется sequence-to-sequence модель с механизмом внимания. Система состоит из кодера и декодера. В кодировщик поступает выпрямленное изображение текста размером 32x100 пикселей. Используется 53-слойная ResNet[16] для извлечения признаков, за ResNet следует два слоя двунаправленной LSTM. Декодер использует LuongAttention[20] механизм. На этапе вывода используется алгоритм поиск луча[21] (англ. beam search).\\nТочность\\nMORAN: A Multi-Object Rectified Attention Network (2019)\\nТекст на изображениях часто оказывается не просто изогнут, а деформирован разными способами и в нескольких направлениях (например, изогнутый текст + перспектива). Это учитывалось при разработке выпрямляющего модуля MORAN, что и является отличительной особенностью этой модели (см. Рисунок 11).\\nСтатья о модели доступна по ссылке. Реализацию этой модели можно найти в открытом доступе.\\nАрхитектура\\nMORAN состоит из двух частей: MORN (Multi-Object Rectification Network) и ASRN (Attention-based Sequence Recognition Network) (см. Рисунок 12):\\n- MORN отвечает за выпрямление. Архитектура MORN представлена ниже (см. Рисунок 13). За каждым (за исключением последнего) свёрточным слоем следует слой батчевой нормализации и слой ReLU. MORN делит изображение на несколько частей, после чего предсказывает смещение для каждой части. Предсказанное смещение используется для выпрямления.\\n- ASRN отвечает за распознавание. Архитектура ASRN представлена ниже (см. Рисунок 14). Основной структурой ASRN является фреймворк CNN-BLSTM (архитектура, в которой используется CNN для извлечения признаков и двунаправленная LSTM для предсказания последовательностей)[23]. В верхних слоях CRNN[24] применяется одномерный механизм внимания. Далее используется attention-based декодер (GRU) [25], основанный на RNN.\\nТочность\\nСквозные (end-to-end) модели\\nMask TextSpotter (2018)\\nMask TextSpotter является одной из первых E2E (end-to-end) моделей, тренированных на наборе данных TotalText. Она не была призвана распознавать именно изогнутый текст, но отличительной чертой модели Mask TextSpotter являлось как раз то, что она сравнительно неплохо с ним справлялась. Разработчики Mask TextSpotter применили недавно опубликованную нейронную сеть с архитектурой Mask R-CNN[1] для выделения контуров объектов на изображении, которая и позволила сделать шаг вперед в распознавании изогнутого текста.\\nСтатья о модели доступна по ссылке. Реализацию этой модели можно найти в открытом доступе.\\nАрхитектура\\nДля первичной обработки изображения Mask TextSpotter использует ResNet50[16] остаточную свёрточную нейронную сеть.\\nЗатем над изображением работает RPN[17] нейронная сеть, которая выполняет базовый поиск областей текста на изображении. RPN[17] может выявлять символы разных форм и размеров. Уже размеченный текст более детально обрабатывается Fast R-CNN[1] нейронной сетью. Её задачи принципиально ничем не отличаются от задач RPN[17], Fast R-CNN[1] лишь доводит дело до конца. Завершает работу этап детекции по маске. Сначала он разбивает полученные области текста на слова, а затем внутри слов распознает отдельные символы. На этом этапе можно настраивать локализацию. Затем данные проходят небольшой пост-процессинг перед достижением итогового результата. Примерная визуализация архитектуры представлена ниже (см. Рисунок 15).\\nТочность\\n- TotalText (Detection): 61.3%\\n- TotalText (E2E, без словаря): 52.9%\\n- TotalText (E2E, со словарём): 71.8%\\nCRAFTS (2020)\\nCRAFTS — это полноценный end-to-end фреймворк, способный не только к детекции, но и к распознаванию. Его часть, отвечающая за детекцию, показывает наилучшие результаты, так же, как и часть, отвечающая за распознавание без словаря.\\nСтатья о модели доступна по ссылке. Реализацию этой модели можно найти в открытом доступе.\\nАрхитектура\\nCRAFTS состоит из трех слоев: слоя детекции, коммуникации и распознавания. Данные, проходя через три этих этапа, на выходе представляют собой готовый end-to-end результат в качестве распознанных слов (см. Рисунок 16).\\nНа этапе детекции CRAFTS использует ResNet50[16] остаточную свёрточную нейронную сеть для первичной обработки изображения. На основе полученного результата определяется направление и границы сначала областей текста, а затем отдельных символов в них. На выходе получается изображение с размеченными областями текста, а внутри них размеченные ориентированные конейнеры с символами (см. Рисунок 17). Данные представляются в виде таблицы признаков.\\nСлой коммуникации принимает таблицу признаков, сгенерированную на этапе детекции, и преобразовывает ее для дальнейшей передачи в слой распознавания. Это происходит в два этапа: сначала очищение текста, потом корректировка признаков.\\nОчищение текста по сути своей является корректировкой символьных полигонов. Они выпрямляются и сглаживаются, обтекая символы. Эти преобразования происходят в три этапа трансформации сплайнов с малой шириной. Для трансформации используется 20 контрольных точек. Также на этом этапе при необходимости применяется 2D-полиномиальное сглаживание для достижения еще более точной формы полигона.\\nПосле очищения текста производится корректировка признаков: на каждый символ устанавливается точка внимания. Этот этап является ключевым по двум причинам. Во-первых, скорректированная таблица сама по себе облегчает работу слою распознавания, что значительно повышает его эффективность. Во-вторых, на данном этапе через откорректированную таблицу слой детекции и слой распознавания становятся зависимыми друг от друга. Это позволяет ошибке распознавания повлиять на работу слоя детекции (см. Рисунок 18). Такая связь оказывает внушительное влияние на качество обучения и, как следствие, на качество модели.\\nПроцесс распознавания состоит из трех частей: извлечение признаков, моделирование последовательности и непосредственно распознавание (см. Рисунок 19). Успех этапа распознавания во многом зависит от правильно расставленных точек внимания. Если они смещены или утеряны, то корректное распознавание практически невозможно.\\nТочность\\n- Total-Text (Detection): 87.4%\\n- Total-Text (E2E, без словаря): 78.7%\\nTextPerceptron (2020)\\nText Perceptron — это E2E модель, состоящая из трёх частей: модуль детекции, Shape Transform Module (STM, \"модуль трансформации формы\") и модуль распознавания текста. Модуль детекции описывает текстовую область с помощью четырёх субобластей: центр, начало, конец и вертикальная (верх/низ) область (см. Рисунок 20). Это сделано для упрощения определения направления чтения. STM необходим для устранения несовместимости между модулем детекции и модулем распознавания. Модуль распознавания генерирует итоговую символьную последовательность. Каждый этап может влиять на предшествующий ему этап, сигнализируя соответствующему модулю о необходимости дополнительной настройки.\\nСтатья о модели доступна по ссылке.\\nАрхитектура:\\nДетектор текста использует ResNet[16] и FPN[14] как основу, и реализуется путем одновременного изучения трех задач: многоклассовой семантической сегментации с учетом порядка, регрессии угла и регрессии смещения границ. STM отвечает за объединение детекции и распознания. Для этого STM генерирует доверительные точки и настраивает их позиции, на основе чего \"выпрямляет\" текст с помощью TPS (Thin-plate splines) для дальнейшего распознавания. В модуле распознавания может использоваться любой sequence-based метод. Примерная визуализация архитектуры представлена ниже (см. Рисунок 21).\\nТочность\\n- Total-Text (Detection): 85.2%\\n- Total-Text (E2E, без словаря): 69.7%\\n- Total-Text (E2E, со словарём): 78.3%\\nBoundary (2020)\\nBoundary при детекции использует граничные точки, чтобы максимально точно повторить контуры текстовой области. После, используя граничные точки, текст приводится к виду, подходящему для распознающего модуля. Перед определением граничных точек заранее определяются \"коробки\", в которых может находиться текст (см. Рисунок 22).\\nСтатья о модели доступна по ссылке.\\nАрхитектура\\nBoundary состоит из трёх частей: определение ориентированной \"коробки\" текста, определение граничных точек и распознавание текста (см. Рисунок 23). Сначала строится карта признаков с помощью ResNet50[16] и FPN[14]. После используется RPN[17] чтобы сгенерировать предполагаемые горизонтально-ориентированные области. После этого для каждой области генерируется ориентированная \"коробка\" через предсказывание её центральной точки, высоты, ширины и направления. Далее для каждой ориентированной коробки ищутся граничные точки, для чего используется Boundary Point Detection Network (BPDN). Опираясь на полученные граничные точки, предполагаемые области выравнивают, после чего для распознавания текста используется CRNN[24].\\nТочность\\n- Total-Text (Detection): 87.0%\\n- Total-Text (E2E, без словаря): 64.1%\\nMANGO (2021)\\nMANGO — один из самых удачных end-to-end фреймворков. Вероятно, такого успеха его авторы добились благодаря необычной для таких моделей внутренней архитектуре. Обычно E2E модели работают в два этапа: детекция и распознавание. Слой детекции выделяет и выпрямляет области текста, которые затем передаются в слой распознавания. Такой подход вызывает трудности в обучении, так как результат распознавания сильно зависит от результата детекции, но обучать два этих слоя одновременно и взаимно — сложная задача. Ученые ищут способы решения этой проблемы. Разработчики MANGO отказались от подобной архитектуры и делегировали обе задачи одному единственному слою. Именно поэтому MANGO невозможно протестировать на качество детекции — в этой модели этап детекции неразделим с этапом распознавания. MANGO является одним из первооткрывателей такой архитектуры и доказывает, что она не просто жизнеспособна, но и весьма успешна — среди всех существующих на данный момент E2E моделей MANGO показывает второй результат F-меры как по распознаванию без словаря, так и со словарем.\\nСтатья о модели доступна по ссылке.\\nАрхитектура\\nИтак, MANGO имеет однослойную архитектуру (см. Рисунок 24). Но это вовсе не значит, что работу этой модели нельзя разделить на этапы. В действительности MANGO, как и другие модели, не может выполнить сразу оба этапа каким-то одним инструментом. MANGO все еще разделяет свою работу на детекцию и распознавание. Особенность этой модели в том, что данные, спустя этап детекции, имеют такой вид, что код на этапе распознавания представляет собой легковесный инструмент. Это достигается тем, что этап детекции уже включает в себя элементы распознавания. Разберемся как это происходит.\\nНа вход инструменту распознавания подается так называемая позиционно-ориентированная маска внимания. Она представляет собой конкатенацию двух других масок: маски областей текста и многослойной маски точек внимания символов. Каждый слой маски символов сопоставлен с соответствующим слоем маски областей текста. Данные, представленные в таком виде (особенно важно сопоставление между двумя масками), сильно облегчают распознавание (выполняя часть работы по распознаванию заранее). Поэтому на данном этапе можно оставить лишь легковесный инструмент и не писать для распознавания отдельный слой.\\nПервоначальная обработка изображения происходит с помощью ResNet50[16] остаточной свёрточной нейронной сети.\\nТочность\\n- Total-Text (E2E, без словаря): 72.9%\\n- Total-Text (E2E, со словарём): 83.6%\\n- CTW1500 (E2E, без словаря): 58.9%\\n- CTW1500 (E2E, со словарём): 78.7%\\nСводные таблицы\\nОбщие данные\\n|Модель\\n|Особенности\\n|Использованные методы\\n|\\nTextSnake (2018)\\n|\\nПредставление области текста с помощью центральной линии и множества дисков.\\n|\\nTextFuseNet (2020)\\n|\\nВыделение признаков на глобальном, словесном и символьном уровнях. Представление области текста с помощью маски.\\n|\\nPolyPRNet (2020)\\n|\\nПредставление текста с помощью скелета из полиномиальной центральной линии и линий широты.\\n|Модель\\n|Особенности\\n|Использованные методы\\n|\\nMask TextSpotter (2018)\\n|\\nОдна из первых моделей, способных определить и распознать изогнутый текст. Представление области текста с помощью маски.\\n|\\nCRAFTS (2020)\\n|\\nСостоит из трех слоев: детекции, коммуникации и распознавания. Слой коммуникации связывает слой детекции и распознавания и позволяет ошибке распознавания распространиться до слоя детекции. Текст представляется в трех видах: границы областей текста, границы символов и ориентированные границы символов.\\n|\\nResNet50[16]\\n|\\nTextPerceptron (2020)\\n|\\nShape Transform Module, использующий для выпрямления доверительные точки на границах текстовых областей. Взаимодействие модулей друг с другом в обе стороны.\\n|\\nBoundary (2020)\\n|\\nНанесение граничных точек при представлении текста. Использование граничных точек для выпрямления.\\n|\\nMANGO (2021)\\n|\\nОднослойная архитектура, сочетающая детекцию и распознавание. Элементы распознавания частично присутствуют уже на этапе детекции. На этапе распознавания остался лишь легковесный инструмент вместо полноценного слоя.\\n|Модель\\n|Особенности\\n|Использованные методы\\n|\\nESIR (2018)\\n|\\nПредставление области текста с помощью скелета из полиномиальной центральной линии и дополнительных параметров (высота, ориентация). Итеративное выпрямление текста на основе просчитанных параметров.\\n|\\nMORAN (2019)\\n|\\nРазбиение изображения на части, определение смещения каждой части изображения. Выпрямление изображения на основе предсказанных смещений.\\nРезультаты\\n|Модель\\n|Precision\\n|Recall\\n|F-мера\\n|CRAFTS (E2E)\\n|89.5\\n|85.4\\n|87.4\\n|TextFuseNet\\n|89.0\\n|85.3\\n|87.1\\n|Boundary (E2E)\\n|88.9\\n|85.0\\n|87.0\\n|PolyPRNet\\n|88.1\\n|85.3\\n|86.7\\n|Text Perceptron (E2E)\\n|88.8\\n|81.8\\n|85.2\\n|TextSnake\\n|82.7\\n|74.5\\n|78.4\\n|Mask TextSpotter (E2E)\\n|69.0\\n|55.0\\n|61.3\\n|Модель\\n|F-мера без словаря\\n|F-мера со словарем\\n|CRAFTS\\n|78.7\\n|-\\n|MANGO\\n|72.9\\n|83.6\\n|Text Perceptron\\n|69.7\\n|78.3\\n|Boundary\\n|65.0\\n|76.1\\n|Mask TextSpotter\\n|52.9\\n|71.8\\n|Модель\\n|F-мера на наборе ICDAR\\'15[6]\\n|F-мера на наборе данных CUTE80[8]\\n|ESIR\\n|76.9\\n|83.3\\n|MORAN\\n|68.8\\n|77.4\\nСм. также\\n- Задача нахождения объектов на изображении\\n- Сверточные нейронные сети\\n- Глубокое обучение\\n- Распознавание текста на изображении\\n- Рекуррентные нейронные сети\\n- Компьютерное зрение\\nПримечания\\n- ↑ 1,0 1,1 1,2 1,3 1,4 1,5 1,6 1,7 1,8 1,9 Mask R-CNN, Kaiming He, Georgia Gkioxari, Piotr Dollar, Ross Girshick\\n- ↑ 2,0 2,1 S.M. Lucas et al, \"ICDAR 2003 Robust Reading Competition\"\\n- ↑ 3,0 3,1 D. Karatzas, S. Robles Mestre, J. Mas, F. Nourbakhsh, P. Pratim Roy, \"ICDAR 2011 Robust Reading Competition\"\\n- ↑ 4,0 4,1 D. Karatzas, F. Shafait, S. Uchida, M. Iwamura, L. Gomez, S. Robles, J. Mas, D. Fernandez, J. Almazan, L.P. de las Heras, \"ICDAR 2013 Robust Reading Competition\"\\n- ↑ 5,0 5,1 C. Yao, X. Bai, W. Liu, Y. Ma and Z. Tu, \"Detecting Texts of Arbitrary Orientations in Natural Images\"\\n- ↑ 6,0 6,1 6,2 6,3 6,4 D. Karatzas, L. Gomez-Bigorda, A. Nicolaou, S. Ghosh, A. Bagdanov, M. Iwamura, J. Matas, L. Neumann, V. Ramaseshan Chandrasekhar, S. Lu, F. Shafait, S. Uchida, E. Valveny, \"ICDAR 2015 Competition on Robust Reading\"\\n- ↑ 7,0 7,1 A. Veit, T. Matera, L. Neumann, J. Matas, S. Belongie, \"COCO-Text: Dataset and Benchmark for Text Detection and Recognition in Natural Images\"\\n- ↑ 8,0 8,1 8,2 8,3 8,4 A. Risnumawan, P. Shivakumara, C.S. Chan and C.L. Tan, \"A Robust Arbitrary Text Detection System for Natural Scene Images\"\\n- ↑ C. Wolf and J.-M. Jolion, “Object count/area graphs for the evaluation of object detection and segmentation algorithms” (2006)\\n- ↑ \"ICDAR2019 Robust Reading Challenge on Arbitrary-Shaped Text — RRC-ArT\"\\n- ↑ M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman, \"The pascal visual object classes (voc) challenge\" (2010)\\n- ↑ 12,0 12,1 12,2 Shangbang Long, Jiaqiang Ruan, Wenjie Zhang, Xin He, Wenhao Wu, Cong Yao, \"TextSnake: A Flexible Representation for Detecting Text of Arbitrary Shapes\" (2018)\\n- ↑ 13,0 13,1 13,2 Jonathan Long, Evan Shelhamer, Trevor Darrell, \"Fully Convolutional Networks for Semantic Segmentation\" (2015)\\n- ↑ 14,00 14,01 14,02 14,03 14,04 14,05 14,06 14,07 14,08 14,09 14,10 Lin, T.Y., Dollar, P., Girshick, R., He, K., Hariharan, B., Belongie, S., \"Feature pyramid networks for object detection\"\\n- ↑ 15,0 15,1 Jian Ye, Zhe Chen, Juhua Liu, Bo Du, \"TextFuseNet: Scene Text Detection with Richer Fused Features\" (2020)\\n- ↑ 16,00 16,01 16,02 16,03 16,04 16,05 16,06 16,07 16,08 16,09 16,10 16,11 16,12 16,13 16,14 16,15 He, K., Zhang, X., Ren, S., Sun, J., \"Deep residual learning for image recognition\" (2016)\\n- ↑ 17,0 17,1 17,2 17,3 17,4 17,5 17,6 17,7 17,8 17,9 Ren, S., He, K., Girshick, R.B., Sun, J., \"Faster R-CNN: towards real-time object detection with region proposal networks\" (2015)\\n- ↑ 18,0 18,1 Jiahao Shi, Long Chen, Feng Su, \"Accurate Arbitrary-Shaped Scene Text Detection via Iterative Polynomial Parameter Regression\" (2020)\\n- ↑ 19,0 19,1 19,2 Fangneng Zhan, Shijian Lu, \"ESIR: End-to-end Scene Text Recognition via Iterative Image Rectification\" (2018)\\n- ↑ Minh-Thang Luong, Hieu Pham, and Christopher D. Manning, \"Effective approaches to attention-based neural machine translation\" (2015)\\n- ↑ Beam Search - Wikipedia\\n- ↑ 22,0 22,1 22,2 22,3 Canjie Luo, Lianwen Jin, Zenghui Sun, \"MORAN: A Multi-Object Rectified Attention Network for Scene Text Recognition\" (2019)\\n- ↑ J. Donahue, L. A. Hendricks, M. Rohrbach, S. Venugopalan, S. Guadarrama, K. Saenko, T. Darrell \"Long-term Recurrent Convolutional Networks for Visual Recognition and Description\" (2016)\\n- ↑ 24,0 24,1 24,2 B. Shi, X. Bai, and C. Yao, \"An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition\" (2017)\\n- ↑ 25,0 25,1 K. Cho, B. van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, Y. Bengio, \"Learning phrase representations using RNN encoderdecoder for statistical machine translation\" (2014)\\n- ↑ Pengyuan Lyu, Minghui Liao, Cong Yao, Wenhao Wu, Xiang Bai, \"Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes\" (2018)\\n- ↑ 27,0 27,1 27,2 27,3 Youngmin Baek, Seung Shin, Jeonghun Baek, Sungrae Park, Junyeop Lee, Daehyun Nam, Hwalsuk Lee, \"Character Region Attention For Text Spotting\" (2020)\\n- ↑ 28,0 28,1 Liang Qiao, Sanli Tang, Zhanzhan Cheng, Yunlu Xu, Yi Niu, Shiliang Pu, Fei Wu, \"Text Perceptron: Towards End-to-End Arbitrary-Shaped Text Spotting\" (2020)\\n- ↑ 29,0 29,1 Hao Wang, Pu Lu, Hui Zhang, Mingkun Yang, Xiang Bai, Yongchao Xu, Mengchao He, Yongpan Wang, Wenyu Liu, \"All You Need Is Boundary: Toward Arbitrary-Shaped Text Spotting\" (2020)\\n- ↑ Liang Qiao, Ying Chen, Zhanzhan Cheng, Xunlu Xu, Yi Niu, Shiliang Pu, Fei Wu, \"MANGO: A Mask Attention Guided One-Stage Scene Text Spotter\" (2021)\\nИсточники информации\\n- TotalText Dataset GitHub page\\n- SCUT-CTW1500 Dataset GitHub page\\n- TextSnake: A Flexible Representation for Detecting Text of Arbitrary Shapes, Shangbang Long, Jiaqiang Ruan, Wenjie Zhang, Xin He, Wenhao Wu, Cong Yao\\n- TextFuseNet: Scene Text Detection with Richer Fused Features, Jian Ye, Zhe Chen, Juhua Liu, Bo Du\\n- Accurate Arbitrary-Shaped Scene Text Detection via Iterative Polynomial Parameter Regression, Jiahao Shi, Long Chen, Feng Su\\n- MORAN: A Multi-Object Rectified Attention Network for Scene Text Recognition, Canjie Luo, Lianwen Jin, Zenghui Sun\\n- ESIR: End-to-end Scene Text Recognition via Iterative Image Rectification, Fangneng Zhan, Shijian Lu\\n- Character Region Attention For Text Spotting, Youngmin Baek, Seung Shin, Jeonghun Baek, Sungrae Park, Junyeop Lee, Daehyun Nam, Hwalsuk Lee\\n- MANGO: A Mask Attention Guided One-Stage Scene Text Spotter, Liang Qiao, Ying Chen, Zhanzhan Cheng, Xunlu Xu, Yi Niu, Shiliang Pu, Fei Wu\\n- Text Perceptron: Towards End-to-End Arbitrary-Shaped Text Spotting, Liang Qiao, Sanli Tang, Zhanzhan Cheng, Yunlu Xu, Yi Niu, Shiliang Pu, Fei Wu\\n- All You Need Is Boundary: Toward Arbitrary-Shaped Text Spotting, Hao Wang, Pu Lu, Hui Zhang, Mingkun Yang, Xiang Bai, Yongchao Xu, Mengchao He, Yongpan Wang Wenyu Liu\\n- Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes, Pengyuan Lyu, Minghui Liao, Cong Yao, Wenhao Wu, Xiang Bai', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='5a3a440f-dbf8-447e-971f-cbc4590f17ca', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bfba381e22a82a876ac61aca085ad5e0f4d61ec5b4ccda80e7d89db3f5f9bf43', text='Карта глубины\\nКарта глубины (англ. depth map) — это изображение, где для каждого пикселя вместо цвета хранится его расстояние до камеры.[1]\\nВ компьютерной 3D-графике и компьютерном зрении карта глубины представляет собой изображение или канал изображения, содержащий информацию о расстоянии поверхностей объектов сцены от точки обзора.\\nСодержание\\n- 1 Мотивация\\n- 2 Методы построения карты глубины\\n- 3 Построение с помощью специальных камер глубин\\n- 4 Построения карты глубины по стереопаре\\n- 5 Использование нейронных сетей\\n- 5.1 Построение с помощью свёрточных нейронных сетей\\n- 5.2 Построение с помощью капсульных нейронных сетей\\n- 5.3 Построение с помощью PlanetNet (2018)\\n- 5.4 Обучение без учителя поиска карты глубины из видео (2017)\\n- 5.5 Неконтролируемая оценка глубины монокуляра с консистенцией слева направо (2017)\\n- 5.6 Прогнозирование глубины без датчиков: использование структуры для обучения без учителя по монокулярным видео (2019)\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nМотивация\\nКарта глубины изображения содержит в себе информацию о расстоянии между различными объектами или частями объектов, представленных на данном изображении. Эта информация может быть полезна во многих областях.\\n- Для создания 3D-сенсеров. Они способны строить трёхмерную картину своего окружения, используются для ориентации автономного робота в пространстве.\\n- Для систем, использующих технологии дополненной и виртуальной реальности. Например, камеры, которые фиксируют действия пользователя в видеоиграх с технологией виртуальной реальности.\\n- В беспилотных автомобилях, которые также используют карты глубин для ориентации на дороге.\\n- Для обработки фотографий. Например, карты глубин используют для размытия фона на фотографии, чтобы добиться более чёткого выделения человека[2].\\nМетоды построения карты глубины\\nКарта глубины может быть получена с помощью специальной камеры глубины, по стереопаре изображений, а также с помощью нейронных сетей.\\nПостроение с помощью специальных камер глубин\\n- ToF-камеры (англ. Time of Flight). Принцип работы данной камеры основан на измерении задержки света, с которой свет возвращается в каждую точку. Имея несколько сенсоров с разным временем накопления заряда и, зная сдвиг по времени относительно источника для каждого сенсора и снятой яркости вспышки, мы можем рассчитать сдвиг и, соответственно, расстояние до объекта. Причем чем больше сенсоров задействовано, тем выше точность метода.\\n- Структурированные световые камеры (aнгл. Structured light camera). Принцип работы данной камеры один из самых старых. Ставим проектор, который создает, например, горизонтальные (а потом и вертикальные) полоски и рядом камеру, которая снимает картину с полосками. В некоторых вариантах используется псевдослучайный набор точек (например MS Kinect — бесконтактный сенсорный игровой контроллер, для консолей Xbox 360, Xbox One и персональных компьютеров под управлением ОС Windows[3]). Проекторы обычно работают в инфракрасном спектре, чтобы не мешать пользователям. Поскольку камера и проектор смещены друг относительно друга, то и полоски также будут смещаться пропорционально расстоянию до объекта. Измеряя это смещение, мы можем рассчитывать расстояние до объекта. Вполне понятны сложности, с которыми можно столкнуться при использовании этого метода: это необходимость настройки и калибровки проектора, и проблема того, что нам нужно относительно благоприятное освещение. К примеру, солнце может засветить полосы, и что-то распознать будет тяжело.\\nПостроения карты глубины по стереопаре\\nИдея, лежащая в основе построения карты глубины по стереопаре, проста. Для каждой точки на одном изображении выполняется поиск парной ей точки[на 21.01.21 не создан] на другом изображении. А по паре соответствующих точек можно выполнить триангуляцию и определить координаты их прообраза в трехмерном пространстве. Зная трехмерные координаты прообраза, глубина вычисляется как расстояние до плоскости камеры.\\nПарную точку нужно искать на эпиполярной[4] линии. Соответственно, для упрощения поиска изображения выравнивают так, чтобы все эпиполярные линии были параллельны сторонам изображения (обычно горизонтальны). Более того, изображения выравнивают так, чтобы для точки с координатами соответствующая ей эпиполярная линия задавалась уравнением . Тогда для каждой точки, соответствующую ей парную точку, нужно искать в той-же строчке на изображении со второй камеры. Такой процесс выравнивания изображений называют ректификацией (rectification).\\nПосле того, как изображения ректифицированы, выполняют поиск соответствующих пар точек. Для каждого пикселя одной картинки с координатами корреляция окрестностей пикселей. В результате получается карта смещений, пример которой приведен на рис. 2.выполняется поиск пикселя на другой картинке. При этом предполагается, что пиксель на второй картинке должен иметь координаты , где — величина называемая смещением. Поиск соответствующего пикселя выполняется путем вычисления максимума функции отклика, в качестве которой может выступать, например,\\nСобственно значения глубины обратно пропорциональны величине смещения пикселей.\\nИспользование нейронных сетей\\nСуществует множество методов, использующих нейронные сети. Приведём пару примеров таких решений.\\nПостроение с помощью свёрточных нейронных сетей\\nИспользуем сверточные нейронные сети для построения карты глубины следующим образом [6]:\\n- Создаем карту смещений: используя два изображения с камер, близко расположенных друг к другу, создаем карту различий, точно так же как в методе построения по стереопаре.\\n- Ищем реальную карту глубины для обучения: с помощью карты смещений, можем построить карту глубины вышеописанным способом. Также допустимы другие способы построения карты глубины для обучения нейронной сети.\\n- Функция потерь: определим функцию потерь, для предсказанной карты , , и — количество пикселей. , где и это i пискель для для реальной карты глубин и для предсказанной карты, соответственно. Гиперпараметр , нужен для того, чтобы функция потерь меньше росла при большом количестве пикселей, предсказание для которых достаточно близко к реальному. Например, если , то мы просто придём к оптимизации в L2 для , т.е. .[7]\\n- Обучение свёрточной нейронной сети: далее идёт обычное обучение нейронной сети по карте различий путем обратного распространения ошибки, оптимизируя заданную выше функцию потерь.\\nВ итоге, по обученной нейронной сети мы можем создавать карту глубины, не проводя расчётов для поиска карт смещения и имея только изображение объекта или пространства. [8]\\nТакже возможно использование усложнённых архитектур свёрточных нейронных сетей типа DenseNet.\\nDenseNet[9] — это свёрточная нейронные сеть, в которой выход каждого из слоев подаётся на вход всем слоям, лежащих ниже.\\nПостроение с помощью капсульных нейронных сетей\\nСвёрточные нейронные сети способны регистрировать только наличие какого-либо объекта на картинке, не кодируя его ориентацию и положение. Но капсульные нейронные сети (англ. Capsule Neural Network)[10] лишены этого недостатка.\\n\"Капсульная нейронная сеть\" состоит из капсул или групп нейронов, чтобы идентифицировать закономерности в изображении. Эта информация поступает в виде векторов, содержащих ориентацию и положение узоров на изображении, которое затем принимается капсулами более высокого уровня. Капсулы более высокого уровня обрабатывают эту информацию из нескольких капсул более низкого уровня и впоследствии выдают прогноз. Капсулы одного уровня не имеют связей друг с другом и вычисляют информацию независимо друг от друга. Капсулы образуются путем разделения выходных данных из свёрточного слоя. Мы делим наш трехмерный вектор на капсулы методом \"нарезания\" таким образом, чтобы в каждой капсуле была информация о каждом пикселе, т.е. по трехмерной координате.\\nСостояние нейронов капсульной нейронной сети внутри изображения фиксирует свойство области или объекта внутри изображения: его положение и ориентацию.\\nИспользование капсульной нейронной сети аналогично использованию обычных свёрточных сетей, описанному выше. В целом, данная сеть показывает более точные результаты предсказания глубины.\\nПостроение с помощью PlanetNet (2018)\\nТак же есть архитектуры, решающие данную задачу и без обучения на карте смещений, построенной с помощью двух изображений. Одной из таких является PlaneNet.\\nPlaneNet[12] — глубокая нейронная сеть, построенная на расширенных остаточных сетях (aнгл. Dilated Residual Networks или DRN)[13]. Она получает карту глубин путем композиции выходов трех подзадач:\\n- Параметры плоскостей: пытаемся предсказать количество плоскостей $K$, а после ищем на изображение $K$ плоских поверхностей, каждая поверхность задаётся тремя параметрами : нормальная, прямая и сдвиг. Функцию ошибки определим следующим образом: , где и , предсказанные и реальные количество и параметры плоскостей, соответственно.\\n- Сегментация плоскости: ищем группы пикселей, каждая из которых характеризует один смысловой объект. Используем перекрёстную энтропию[15], как функцию потерь.\\n- Неплоская карта глубины: ищем одно-канальную (или неплоскую) карту глубины, то есть карту глубины, где каждый пиксель, либо на глубине 0, либо на глубине 1.\\nАвторы обучали и тестировали данные на NYUv2[16].\\nОбучение без учителя поиска карты глубины из видео (2017)\\nАвторы данной статьи [17] предлагают методику оценки глубины одной картинки без учителя и движения камеры из беспорядочной видео нарезки.\\nБудем использовать сверточные нейронные сети c глубиной одного вида и многовидовой камерой из неупорядоченного видеоряда. Метод базируется на синтезе видов. Сеть загружает фото объекта в качестве данных ввода и выводит глубину пикселя. Вид объекта может быть синтезирован исходя из глубины на каждого пикселя снимка позиционирования и четкости ближнего вида. Синтез может быть дифференцирован с CNN по геометрии и модулям позиционирования. Авторы взяли на вооружение архитектуру DispNet[19], которая сконструирована в виде энкодера и декодера с пропущенными соединениями и многомасштабными блоками предсказания. Функция активации ReLU отслеживает все сверточные слои кроме предсказанных. Вид объекта со всех источников формирует входные данные в сеть позиционной оценки. На выходе получается относительная позиция между видом объекта и видом каждого источника. Сеть состоит из двух 7 шаговых сверток за которым следует свертка 1 х 1. За исключением последнего слоя свертки, где применяется нелинейная активация, все другие отслеживаются функцией активации ReLU. Сеть объяснимых предсказаний дает доступ к первым пяти закодированным слоям сети позиционирования. За ней следуют 5 слоев обратной свертки с многомасштабными блоками предсказаний. Кроме слоев предсказаний все уровни свертки и обратной свертки отслеживаются ReLU. Авторы проверяли данную методику на KITTY[20].\\nНеконтролируемая оценка глубины монокуляра с консистенцией слева направо (2017)\\nВ данной работе[22] предлагается сверточная нейронная сеть, обученная выполнять оценку глубины одного изображения без реальных данных. Авторы предлагают сетевую архитектуру, которая выполняет сквозную оценку глубины изображения, полученного с 1 камеры, без учителя, что обеспечивает согласованность глубины слева направо внутри сети. Сеть оценивает глубину, выводя смещения, которые искажают левое изображение, чтобы соответствовать правому. Левое входное изображение используется для вывода смещений слева направо и справа налево. Сеть генерирует предсказанное изображение с обратным отображением с помощью билинейного сэмплера. Это приводит к полностью дифференциальной модели формирования изображения. Сверточная архитектура вдохновлена так же DispNet\\'ом. Она состоит из двух частей—кодера и декодера. Декодер использует пропуск соединений из блоков активации кодера, чтобы распознавать детали с высоким разрешением. Сеть предсказывает две карты смещений — слева направо и справа налево. В процессе обучения сеть генерирует изображение путем выборки пикселей из противоположного стереоизображения. Модель формирования изображения использует сэмплер изображений из пространственной трансформаторной сети (STN) для выборки входного изображения с помощью карты смещений. Авторы обучали и тестировали данные на KITTY.\\nПрогнозирование глубины без датчиков: использование структуры для обучения без учителя по монокулярным видео (2019)\\nВизуальная одометрия [24] — метод оценки положения и ориентации робота или иного устройства в пространстве с помощью анализа последовательности изображений, снятых установленной на нем камерой.\\nДанная статья [25] посвящена задаче обучения без учителя глубины сцены и визуальной одометрии робота, где наблюдение обеспечивается видеозаписями с одной камеры. Это делается путем введения геометрической структуры в процесс обучения. Он включает в себя моделирование сцены и отдельных объектов, одометрии камеры и движения объектов, изучаемых с помощью монокулярных видеовходов. Авторы вводят модель движения объекта, которая имеет ту же архитектуру, что и сеть определения визуальной одометрии. Она принимает последовательность изображений RGB в качестве входных данных и дополняется предварительно вычисленными масками сегментации экземпляров. Работа модели движения заключается в том, чтобы научиться предсказывать векторы трансформации каждого объекта в трехмерном пространстве. Это создает видимость наблюдаемого объекта в соответствующем целевом кадре. Авторы проверяли прогнозирование глубины на KITTY.\\nСм. также\\nПримечания\\n- ↑ Alexey Kurakin \"Основы стереозрения\"[1]\\n- ↑ Примеры из \"Research Guide for Depth Estimation with Deep Learning\"[2]\\n- ↑ О MicriSoft Kinect [3]\\n- ↑ Информация о эпиполярной геометрии[4]\\n- ↑ \"Основы стереозрения\" Рис. 3 [5]\\n- ↑ Xiaobai Ma, Zhenglin Geng, Zhi Bie \"Depth Estimation from Single Image Using CNN-Residual Network\" [6]\\n- ↑ David Eigen, Christian Puhrsch, Rob Fergus \"Depth Map Prediction from a Single Imageusing a Multi-Scale Deep Network\" стр. 5\\n- ↑ Реализация, основанная на свёрточных нейронных сетях [7]\\n- ↑ Оригинальная статья описывающая DenseNet [8]\\n- ↑ Sara Sabour, Nicholas Frosst, Geoffrey E. Hinton \"Dynamic Routing Between Capsules\" [9]\\n- ↑ \"Design and Investigation of Capsule Networks for Sentence Classification\" Figure 2. [10]\\n- ↑ Chen Liu, Jimei Yang, Duygu Ceylan, Ersin Yumer, Yasutaka Furukawa \"PlaneNet: Piece-wise Planar Reconstruction from a Single RGB Image\" [11]\\n- ↑ Fisher Yu, Vladlen Koltun, Thomas Funkhouser \"Dilated Residual Networks\" [12]\\n- ↑ Chen Liu, Jimei Yang, Duygu Ceylan, Ersin Yumer, Yasutaka Furukawa \"PlaneNet: Piece-wise Planar Reconstruction from a Single RGB Image\" Figure 2.\\n- ↑ О перекрёстной энтропии [13]\\n- ↑ Датасет NYUv2[14]\\n- ↑ Tinghui Zhou, Matthew Brown, Noah Snavely, David G. Lowe \"Unsupervised Learning of Depth and Ego-Motion from Video\" [15]\\n- ↑ Tinghui Zhou, Matthew Brown, Noah Snavely, David G. Lowe \"Unsupervised Learning of Depth and Ego-Motion from Video\" Figure 4\\n- ↑ Nikolaus Mayer, Eddy Ilg, Philip Hausser, Philipp Fischer \"A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation\" [16]\\n- ↑ Датасет kitty[17]\\n- ↑ Clément Godard, Oisin Mac Aodha, Gabriel J. Brostow \"Unsupervised Monocular Depth Estimation with Left-Right Consistency\" Figure 3\\n- ↑ Clément Godard, Oisin Mac Aodha, Gabriel J. Brostow \"Unsupervised Monocular Depth Estimation with Left-Right Consistency\" [18]\\n- ↑ Vincent Casser, Soeren Pirk, Reza Mahjourian, Anelia Angelova \"Depth Prediction Without the Sensors: Leveraging Structure for Unsupervised Learning from Monocular Videos\" Figure 2\\n- ↑ Статья о визуальной одометрии[19]\\n- ↑ Vincent Casser, Soeren Pirk, Reza Mahjourian, Anelia Angelova \"Depth Prediction Without the Sensors: Leveraging Structure for Unsupervised Learning from Monocular Videos\" [20]\\nИсточники информации\\n- Чугунов Р. А., Кульневич А. Д., Аксенов С. В. Методика построения карт глубины стереоизображения с помощью капсульной нейронной сети //Доклады Томского государственного университета систем управления и радиоэлектроники. – 2019. – Т. 22. – №. 1.[21]\\n- Alhashim I., Wonka P. High quality monocular depth estimation via transfer learning. arXiv 2018 //arXiv preprint arXiv:1812.11941. [22]\\n- Eigen D., Puhrsch C., Fergus R. Depth map prediction from a single image using a multi-scale deep network //Advances in neural information processing systems. – 2014. – Т. 27. – С. 2366-2374. [23]\\n- Prakash S., Gu G. Simultaneous localization and mapping with depth prediction using capsule networks for uavs //arXiv preprint arXiv:1808.05336. – 2018. [24]\\n- Ma X., Geng Z., Bie Z. Depth Estimation from Single Image Using CNN-Residual Network //SemanticScholar. – 2017. [25]', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='1e9c6973-74b1-4669-ab7d-af9a7fe24a7f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='09489c94124a3de10230020c2d18d27fa3ec8aaba8f327c0f2a03c22b0e6d90c', text=\"Вписывание части изображения\\nВосстановление изображения (англ. inpainting) — это процесс замены поврежденных частей изображения на реалистичные фрагменты. Вписывание части изображения — это подзадача восстановления, которая опирается на имеющуюся неиспорченную часть изображении для замены поврежденной.\\nАлгоритмы вписывания части изображения применяются для редактирования изображений или для их восстановления, если их часть была утрачена или повреждена. С помощью современных моделей можно вырезать ненужные объекты или изменить их внешний вид (например, поменять цвет глаз у человека).\\nСодержание\\n- 1 Виды восстановления изображения\\n- 2 Традиционные методы\\n- 3 Глубокое обучение\\n- 4 Примеры современных моделей\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nВиды восстановления изображения\\nВосстановление изображения разделяется на две задачи:\\n- Управляемое восстановление изображения (англ. non-blind inpainting). В этой задаче вместе с изображением подается информация о том, какие пиксели нужно заменить.\\n- Слепое восстановление изображения (англ. blind inpainting). В решениях данной проблемы модель сама определяет, где на изображении поврежденные пиксели. Модели слепого восстановления чаще всего занимаются устранением шумов (англ. denoising). В качестве шума, например, может быть наложенный текст (см Рис. 2).\\nВ этом конспекте преимущественно речь пойдет про управляемое восстановление.\\nТрадиционные методы\\nДля решения данной задачи существует множество различных методов, в том числе простых. Почти все простые методы основаны на следующей концепции: заполнение отсутствующих частей пикселями, идентичными соседним пикселям или похожими на них. Такие методы наиболее подходят для задачи устранения шума или небольших дефектов изображения. Но на изображениях, где отсутствует значительная часть данных, эти методы дают плохое качество изображения на выходе.\\nЕсть два основных простых метода восстановления данных:\\n- Быстрый пошаговый метод (англ. Fast marching method)[3]. Этот метод двигается от границ области, которую нужно заполнить, к ее центру, постепенно восстанавливая пиксели. Каждый новый пиксель вычисляется как взвешенная сумма известных соседних пикселей.\\n- Метод Навье-Стокса (англ. Navier-Stokes method)[4]. Метод основывается на том, что границы объектов на изображении должны быть непрерывными. Значения пикселей вычисляются из областей вокруг испорченной части. Метод основывается на дифференциальных уравнениях в частных производных.\\nГлубокое обучение\\nВ отличие от приведенных выше методов, глубокое обучение позволяет в процессе восстановления изображения учитывать его семантику. В этом случае алгоритм заполнения отсутствующих областей основывается на том, какие объекты расположены на изображении.\\nДля того, чтобы понимать, какую часть изображения нужно заполнить, на вход сети кроме самого изображения подается слой маски с информацией об испорченных пикселях.\\nВ сетях обычно используется архитектура автокодировщиков (англ. autoencoder) — сначала идут слои кодирующие, а потом декодирующие изображение. Функция потерь заставляет модель изучать другие свойства изображения, а не просто копировать его из входных данных в выходные. Именно это позволяет научить модель заполнять недостающие пиксели.\\nОбучение может происходить через сравнение оригинального изображения и синтетического, сгенерированного сетью или через генеративно-состязательную сеть (GAN). Во втором случае для обучения используется дискриминатор, который определяет настоящее ли изображение подали ему на вход. В современных моделях обычно используют совмещенный подход: функции потерь зависят и от исходного изображения, и от выхода дискриминатора.\\nВ ранних моделях часто применялись два дискриминатора (см Рис. 3):\\n- Локальный дискриминатор (англ. Local Discriminator). Ему подавалась на вход только сгенерированная часть изображения.\\n- Глобальный дискриминатор (англ. Global Discriminator). В данном случае на вход подавалось все изображение целиком.\\nОднако в современных моделях используется один дискриминатор, который принимает на вход не только восстановленное изображение, но и маску. Современные модели чаще всего принимают на вход маски произвольной формы (англ. free-form mask), при работе с которыми локальный дискриминатор показывает плохое качество. Именно поэтому концепция двух дискриминаторов стала непопулярной.\\nСвертки\\nДля вписывания изображения помимо классической свертки широко используются другие способы перехода от слоя к слою. Подробнее про свертки можно прочитать в конспекте Сверточные нейронные сети.\\n- Расширенная свертка (англ. Dilated convolution). Данный способ позволяет сохранить качество изображении, уменьшив затраты на память и вычисления.\\n- Частичная свертка (англ. Partial convolution). Данная свертка дает лучшее качество на масках произвольной формы. Классическая свертка предполагает, что все пиксели валидны, а частичная учитывает количество стертых пикселей в рассматриваемой матрице.\\n- Стробированная свертка (англ. Gated convolution). Данная свертка позволяет сохранять информацию о маске и эскизах пользователя во всех слоях сети, что дает возможность получить лучшее качество.\\nФункции потерь\\nСуществует большое множество различных функций потерь при методе обучения модели через сравнение сгенерированного изображения с оригинальным. Примеры:\\n- L1-loss или Per-pixel loss. Оценивает точность восстановления каждого пикселя по отдельности.\\nгде— выход генератора; — оригинальное изображение (англ. ground truth); — количество элементов в объекте ; — бинарная маска; — гиперпараметр, — поэлементное перемножение.\\n- Perceptual loss. Cравнивает признаки сгенерированного и исходного изображений, полученные с помощью модели VGG-16[6].\\nгде— изображение , в котором нестертые части заменены на части из ; — карта признаков, полученная -ым слоем VGG-16.\\n- Style loss. Считает корреляцию между признаками на каждом слое, что на самом деле является матрицей Грама[7]. Согласно алгоритму нейронного переноса стиля (англ. Neural Style Transfer, NST) матрица Грама содержит информацию о текстуре и цвете изображения. Таким образом style loss сравнивает сгенерированное и оригинальное изображения на схожесть стилей.\\nгде— матрица Грама для выполнения автокорреляции на карте признаков VGG-16; — размерность матрицы Грама.\\n- Total variation loss. Оценивает однородность полученного изображения.\\nгде— изображение , в котором нестертые части заменены на части из ; — количество пикселей в\\n- Adversarial loss. Сравнивает генерируемые и оригинальные границы объектов в изображении.\\nгде— черно-белое оригинальное изображение; — границы объектов оригинального изображения; — генерируемые границы; — дискриминатор;\\n- Feature-matching loss. Сравнивает изображения по признакам, извлекаемыми из всех слоев дискриминатора.\\nгде— количество слоев дискриминатора; — число нейронов на -ом слое дискриминатора; — значения дискриминатора на слое ;\\nПри обучении обычно используется комбинация функций потерь с некоторыми весами, которые являются гиперпараметрами. В моделях, где вдобавок используется дискриминатор, функция потерь от его выхода также подмешивается к итоговой функции потерь.\\nПримеры современных моделей\\nSC-FEGAN[1]\\nSC-FEGAN позволяет создавать высококачественные изображения лиц за счет эскизов, передаваемых пользователем вместо стертых частей изображения. Иными словами пользователь может стереть фрагмент, который он хочет изменить, нарисовать на его месте желаемый объект, и полученный эскиз, а также его цветовая палитра, будут отражены в сгенерированном фрагменте.\\nДискриминатор данной сети принимает на вход сгенерированное изображение, маску и рисунок пользователя. Итоговая функция потерь формируется из выхода дискриминатора и функций сравнения изображения с оригинальным (per-pixel loss, perceptual loss, style loss).\\nDeepFillv2[8]\\nГлавная идея этой модели — использование стробированной свертки, которая позволила добиться хорошего качества вписывания при восстановлении изображения с разными формами испорченных областей. Также можно использовать рисунок пользователя в качестве входных данных.\\nВ данной модели используется вариант генеративно-состязательной сети — SN-PatchGAN. Дискриминатор этой сети в каждой точке вычисляет кусочно-линейную функцию потерь, формируя таким образом [9], в которой все слои классической свертки заменены на стробированные. Полностью архитектура сети приведена на Рисунке 5.генеративно-состязательных сетей, каждая из которых сосредотачивается на различных частях и свойствах изображения. Генератор, состоящий из двух сетей (грубой и сети повышающей качество изображения), используют модель кодировщик-декодировщик вместо U-Net\\nPluralistic Image Completion[10]\\nГлавное отличие этой модели от других — способность выдавать несколько вариантов заполнения отсутствующих областей изображения. Обычно модели генерируют только один вариант, пытаясь приблизиться к оригинальному изображению. Используя же данную модель, человек может выбрать то сгенерированное изображение, которое выглядит более реалистичным, получая таким образом более качественные изображения на выходе.\\nДанная модель добивается такого эффекта путем пропускания входного изображения через две параллельные сети. Первая сеть — реконструирующая. Она пытается приблизить выходное изображение к оригинальному. Вторая сеть — генерирующая, работающая с априорным распределением отсутствующих областей и выборками известных пикселей. Каждая сеть имеет свой дискриминатор, помогающий обучить модель. Кроме выхода дискриминатора для обучения также используются функции сравнения полученного изображения с оригинальным.\\nEdgeConnect[11]\\nEdgeConnect разбивает задачу вписывания на две части:\\n- Выделение границ изображения и предсказание границ утраченной части изображения.\\n- Использование сгенерированных границ для заполнения утраченной части изображения.\\nВ обоих частях используется генеративно-состязательная сеть. Генераторы состоят из кодировщика, нескольких остаточных блоков с расширенной сверткой и декодировщика (см Рис. 7). Для дискриминатора используется PatchGAN[12].\\nДля генерации ребер сначала выделяются границы существующей части изображения с помощью Canny edge detector[13]. Потом полученная граница вместе с маской и черно-белым изображением дается генератору. В качестве целевой функции потерь для тренировки сети берется комбинация двух функций: adversarial loss и feature-matching loss. Также для стабилизации обучения генератора и дискриминатора используется спектральная нормализация.\\nДля восстановления генератор получает на вход испорченное изображение и границы, которые составлены из реальных и сгенерированных на предыдущем этапе. В результате генерируется полное изображение. Так же, как и на предыдущем этапе, используется составная функция потерь из adversarial loss, perceptual loss и style loss.\\nОднако сети не удается предсказать достаточно хорошую границу, если отсутствует большая часть изображения или объект имеет сложную структуру.\\nТакже данную модель можно использовать для соединения двух изображений (см Рис. 8) или удаления лишних объектов с фотографий.\\nDeep Image Prior[14]\\nКак известно, большинство методов глубокого обучения требуют больших наборов данных для тренировки. В отличие от них Deep Image Prior не требует никакой предварительной обучающей выборки кроме одного изображения, которое надо исправить. Для этого сеть учится извлекать полезную информации из самого обрабатываемого изображения. Данный метод применяется для таких задач как вписывание части изображения, удаление шума и увеличение разрешения фотографий.\\nСформулируем данную задачу как задачу минимизации:\\nгде— это функция потерь, зависящая от решаемой задачи, а — некоторая сверточная сеть.\\nАлгоритм решения задачи (см Рис. 9):\\n- Инициализируем случайными весами.\\n- На каждой итерации:\\n- Сеть с текущими весами получает на вход фиксированный тензор и возвращает восстановленное изображение .\\n- С помощью сгенерированного изображения x и исходного изображения вычисляется функция потерь .\\n- Веса обновляются так, чтобы минимизировать уравнение (1).\\nВ качествепредлагается использовать сеть U-net с пропускающими соединениями.\\nДля вписывания части изображения используется следующая функция потерь:, где — маска.\\nСм. также\\n- Глубокое обучение\\n- Сверточные нейронные сети\\n- Автокодировщик\\n- Генеративно-состязательныe сети\\n- Neural Style Transfer\\nПримечания\\n- ↑ 1,0 1,1 1,2 Face Editing Generative Adversarial Network with User's Sketch and Color, Youngjoo Jo, Jongyoul Park\\n- ↑ Fast Digital Image Inpainting, Manuel M. Oliveira, Brian Bowen, Richard McKenna, Yu-Sung Chang\\n- ↑ An Image Inpainting Technique Based onthe Fast Marching Method, Alexandru Telea\\n- ↑ Navier-Stokes, Fluid Dynamics, and Image and Video Inpainting, M. Bertalmio, A. L. Bertozzi, G. Sapiro\\n- ↑ Globally and Locally Consistent Image Completion, Satoshi Lizuka, Edgar Simo-Serra, Hiroshi Ishikawa\\n- ↑ Very Deep Convolutional Networks for Large-Scale Image Recognition, Karen Simonyan, Andrew Zisserman\\n- ↑ Gramian matrix, Wikipedia\\n- ↑ 8,0 8,1 Free-Form Image Inpainting with Gated Convolution, Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, Thomas Huang\\n- ↑ U-Net: Convolutional Networks for Biomedical Image Segmentation, Olaf Ronneberger, Philipp Fischer, Thomas Brox\\n- ↑ Pluralistic Image Completion, Chuanxia Zheng, Tat-Jen Cham, Jianfei Cai\\n- ↑ 11,0 11,1 11,2 11,3 EdgeConnect: Generative Image Inpainting with Adversarial Edge Learning, Kamyar Nazeri, Eric Ng, Tony Joseph, Faisal Z. Qureshi, Mehran Ebrahimi\\n- ↑ PatchGan, PapersWithCode\\n- ↑ Canny edge detector, Wikipedia\\n- ↑ 14,0 14,1 Deep Image Prior, Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky\\nИсточники информации\\n- Guide to Image Inpainting: Using machine learning to edit and correct defects in photos, Heartbeat\\n- Introduction to image inpainting with deep learning, Weights & Biases\\n- Pushing the Limits of Deep Image Inpainting Using Partial Convolutions, Towards Data Science\\n- Understanding 2D Dilated Convolution Operation with Examples in Numpy and Tensorflow with Interactive Code, Towards Data Science\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='66dd907c-3a29-40fa-ae6b-231ab414a5a7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1869c97dab6cbbd27e6a52cf30a1d15148a49ba30f14c944b1f93d2310c7ecba', text=\"Блендинг изображений\\nКопирование элемента одного изображения и его вставка на другое изображение — один из наиболее используемых методов для создания графического контента. Простая вставка, как правило, бросается в глаза и делает результат похожим на коллаж, во многих случаях этот эффект является нежелательным.\\n|Определение:\\n|Блендинг изображений (англ. image blending) — метод, позволяющий вставить часть одного изображения в другое таким образом, чтобы композиция изображений выглядела естественно, без швов на границах вставки.\\nОсновная трудность задачи заключается в том, что естественность результата зависит не только от бесшовности наложения, но и от схожести цветов и текстуры вставляемого и фонового изображений.\\n|Вставляемое изображение\\n|Фоновое изображение\\n|Простая вставка\\n|Желаемый результат\\nСодержание\\n- 1 Блендинг Пуассона\\n- 2 Нейронный перенос стиля\\n- 3 Глубокая гармонизация картин\\n- 4 Глубокий блендинг\\n- 5 См. также\\n- 6 Источники информации\\n- 7 Примечания\\nБлендинг Пуассона\\nПростая вставка одного изображения поверх другого нередко влечет заметный перепад яркости на границе вставки (рисунок $1.1$). Метод Пуассона заключается в сглаживании этого перепада (рисунок $1.2$) с целью сделать дефект менее заметным, используя градиент вставляемого изображения и значения пикселей фонового изображения на границе вставки.\\nЗамечание: Для RGB изображений задача минимизации решается для каждого цветового канала отдельно.\\nДавайте обозначим за $S$ изображение, которое служит фоном, а за $I$ — изображение, вставляемое поверх $S$. Область вставки будем задавать двоичной маской $M$, содержащей единицы в области наложения. Например:\\n| Фоновое\\nизображение $S$\\n| Накладываемое\\nизображение $I$\\n|Маска $M$\\nИдея подхода\\nПусть замкнутое множество $P \\\\subset \\\\mathbb{R}^2$ — область, на которой определено изображение $S$, а замкнутое множество $\\\\Omega \\\\subset P$ с границей $\\\\partial\\\\Omega$ и внутренностью $int(\\\\Omega)$ — область вставки изображения $I$.\\nПусть $f_S$ — скалярная функция, определенная на $P \\\\setminus int(\\\\Omega)$, задает фоновое изображение $S$; $f$ — неизвестная скалярная функция, определенная на $int(\\\\Omega)$, задает, каким образом должно выглядеть результат блендинга в области вставки.\\n$v_I$ — векторное поле, определенное на $\\\\Omega$. В качестве $v_I$ возьмем градиент вставляемого изображения $I$: $v_I = \\\\nabla f_I$.\\nНашей задачей является поиск такой функции $f$, чтобы блендинговое изображение выглядело реалистично. Для этого минимизируем разность градиента функции $f$ и векторного поля $v_I$, считая, что $f = f_S$ на границе $\\\\Omega$. $$ \\\\underset{f}{\\\\mathrm{min}} \\\\underset{\\\\Omega}{\\\\iint} |\\\\nabla f - v_I|^2, \\\\text{где } f|_{\\\\partial \\\\Omega} = f_S|_{\\\\partial \\\\Omega}. $$ Решение задачи минимизации является единственным решением уравнения Пуассона для граничных условий Дирихле. $$\\\\nabla^2 f = \\\\nabla^2 f_I \\\\text{ на } \\\\Omega, f|_{\\\\partial \\\\Omega} = f_S|_{\\\\partial \\\\Omega}, \\\\text{где } \\\\nabla^2 \\\\text{— оператор Лапласа.}$$\\nДискретный случай\\nПусть $p$ — координаты $(x, y)$ пикселя двухмерного изображения. За $Img_p$ обозначим значение пикселя с координатами $p$ изображения $Img$. Пусть $\\\\Omega = \\\\left\\\\{ p\\\\;|\\\\;M_p = 1 \\\\right\\\\}$ — область, заданная маской $M$. Тогда $\\\\partial \\\\Omega$ — координаты границы вставляемой области, а $int(\\\\Omega)$ — внутренность области.\\nПусть $N_p$ — множество соседей $p$ (максимум четыре пикселя, имеющих общую границу с $p$, т.е. пиксели со следующими координатами: $(x + 1, y), (x - 1, y), (x, y + 1), (x, y - 1)$). Для всех пар $(p, q)$ таких, что $q \\\\in N_p$, введем $v_{pq} = I_p - I_q$.\\nВведем переменные $O_p, p \\\\in \\\\Omega$. Так как мы хотим сделать результат бесшовным, пиксели $O_p, p \\\\in \\\\partial\\\\Omega$, сделаем равными $S_p$. Для $p, q \\\\in int(\\\\Omega),\\\\; q \\\\in N_p$ постараемся найти такое $O$, чтобы разность $O_p$ и $O_q$ была близка к $v_{pq}$. Для этого решим задачу минимизации:\\n$$ \\\\underset{O_p,\\\\; p \\\\in \\\\Omega}{\\\\mathrm{min}}\\\\; \\\\underset{p, q \\\\in \\\\Omega}{\\\\sum}\\\\; \\\\left(O_p - O_q - v_{pq}\\\\right)^2, \\\\text{где } O_p = S_p, p \\\\in \\\\partial \\\\Omega. $$\\nЗаметим, что функция, которую мы хотим минимизировать, квадратична относительно переменных $O_p, p \\\\in int(\\\\Omega)$. Для решения задачи минимизации вычислим частные производные по этим переменным и найдем значения переменных, при которых частные производные будут равны нулю. $$\\\\frac{\\\\partial{\\\\underset{p, q \\\\in \\\\Omega}{\\\\sum}\\\\; \\\\left(O_p - O_q - v_{pq}\\\\right)^2}}{\\\\partial O_p} = \\\\underset{q \\\\in N_p}{\\\\sum} 2 \\\\left(O_p - O_q - v_{pq}\\\\right) - \\\\underset{q \\\\in N_p}{\\\\sum} 2 \\\\left(O_q - O_p - v_{qp}\\\\right) = 2 \\\\underset{q \\\\in N_p}{\\\\sum} 2 \\\\left(O_p - O_q - v_{pq}\\\\right).$$\\nПриравнивая к нулю, получаем: $|N_p| O_p - \\\\underset{q \\\\in N_p}{\\\\sum} O_q = \\\\underset{q \\\\in N_p}{\\\\sum} v_{pq}$.\\nДобавим условие $O_p = S_p, p \\\\in \\\\partial \\\\Omega$: $\\\\;|N_p| O_p - \\\\underset{q \\\\in N_p \\\\cap int(\\\\Omega)}{\\\\sum} O_q = \\\\underset{q \\\\in N_p \\\\cap \\\\partial \\\\Omega}{\\\\sum} S_q + \\\\underset{q \\\\in N_p}{\\\\sum} v_{pq}$.\\nДля решения систем уравнений такого вида могут быть использованы итеративные алгоритмы Gauss-Seidel и V-cycle multigrid[2].\\nПолучаем значения пикселей $O_p$, $p \\\\in int(\\\\Omega)$. Тогда результат $B$ блендинга Пуассона будет следующим: $$ B_p = \\\\begin{cases} O_p,\\\\; \\\\text{если } p \\\\in int(\\\\Omega) \\\\\\\\ S_p,\\\\; \\\\text{иначе } \\\\end{cases}. $$\\nMетод Пуассона сдвигает цвета накладываемого изображения, сохраняя свойства градиента (т.е. если пиксель $I_{p1}$ был меньше $I_{p2}$, то после преобразования $I_{p1}$ не станет больше $I_{p2}$), однако само значение градиета может получиться другим.[3]\\nНейронный перенос стиля\\nПрежде чем переходить к гармонизации картин, рассмотрим задачу нейронного переноса стиля с изображения $S$ на изображение $I$. Для этого используются выходы скрытых слоёв свёрточной нейронной сети VGG-19[4] (конкретные слои указаны ниже в деталях реализации).\\nОсновная идея генерации изображения — решение оптимизационной задачи $\\\\mathcal{L}(I, S, O) \\\\xrightarrow[O]{} min$, где $O$ — итоговое изображение, $\\\\mathcal{L}(I, S, O)$ — функция потерь. Такую задачу можно решать градиентным спуском в пространстве изображений используя метод обратного распространения ошибки.\\n|Определение:\\n|Пусть $F^l\\\\left[I\\\\right] \\\\in \\\\mathcal{R}^{N_l \\\\times M_l}$ — матрица значений выхода $l$-го слоя сети на изображении $I$. Выход $l$-го слоя сети имеет размерность $N_l \\\\times W_l \\\\times H_l$. Представим его как матрицу $N_l \\\\times M_l$, где $N_l$ — количество фильтров в $l$-ом слое, $M_l$ — количество признаков ($M_l = W_l H_l$). Тогда $F^l_{ij}\\\\left[I\\\\right]$ — $j$-ый признак $i$-го фильтра в $l$-ом слое. Столбец матрицы $F^l\\\\left[I\\\\right]$ размера $N_l$ назовём вектором активации.\\n|Определение:\\n|Матрица Грама (англ. Gram matrix) — матрица попарных скалярных произведений.\\n$$G^l\\\\left[S\\\\right] \\\\in \\\\mathcal{R}^{N_l \\\\times N_l},$$$$G^l\\\\left[S\\\\right] = F^l\\\\left[S\\\\right]F^l\\\\left[S\\\\right]^T.$$\\nДалее рассмотренны функции потерь, которые мы будем использовать.\\nContent loss\\n$F^l\\\\left[I\\\\right]$ отражает содержание изображения. Мы хотим чтобы содержание результата было как можно ближе к исходной картинке. Введём для этого такую функцию потерь: $$\\\\mathcal{L}_{content}(I, O) = \\\\displaystyle\\\\sum_l \\\\frac{\\\\alpha_l}{2 N_l M_l}\\\\displaystyle\\\\sum_{i, j} \\\\left(F^l_{ij}\\\\left[I\\\\right] - F^l_{ij}\\\\left[O\\\\right]\\\\right)^2,$$ где $\\\\alpha_l$ — вклад $l$-го слоя в функцию потерь.\\nStyle loss\\n$G^l\\\\left[S\\\\right]$ отражает статистику выходов фильтров независимо от их расположения, что, в свою очередь, отражает стиль изображения. Чтобы стиль результата был похож на стилевое изображение, введём следующую функцию потерь: $$\\\\mathcal{L}_{style}(S, O) = \\\\displaystyle\\\\sum_l \\\\frac{\\\\beta_l}{2N_l^2} \\\\displaystyle\\\\sum_{i, j} \\\\left(G^l_{ij}\\\\left[S\\\\right] - G^l_{ij}\\\\left[O\\\\right]\\\\right)^2,$$ где $\\\\beta_l$ — вклад $l$-го слоя в функцию потерь.\\nGatys' loss\\nСкомбинируем $\\\\mathcal{L}_{content}$ и $\\\\mathcal{L}_{style}$ и получим функцию потерь, которая была использована в алгоритме Гатиса[5]: $$\\\\mathcal{L}_{Gatys}(I, S, O) = \\\\mathcal{L}_{content}(I, O) + w_{style}\\\\mathcal{L}_{style}(S, O).$$ Вес $w_{style}$, векторы $\\\\alpha$ и $\\\\beta$ являются, в некотором смысле, гиперпараметрами алгоритма, которые мы выберем позднее.\\nHistogram Loss\\nАвторы другой статьи[6] показывают, что результаты, полученные с помощью $\\\\mathcal{L}_{Gatys}$ нестабильны и предложили учитывать ещё одну функцию потерь, основанную на сопоставлении гистограмм.\\n|Определение:\\n|Сопоставление гистограмм (англ. Histogram matching) — метод обработки изображения, после которого гистограмма изображения совпадает с целевой гистограммой[7].\\nПусть $R = histmatch(S, O)$ — отображение пикселей такое, что гистограмма $S$ совпадает с гистограммой $R(O)$, тогда Histogram loss будет выглядеть так: $$\\\\mathcal{L}_{hist}(S, O) = \\\\displaystyle\\\\sum_l \\\\gamma_l \\\\displaystyle\\\\sum_{i, j} \\\\left(F^l_{ij}\\\\left[O\\\\right] - R\\\\left(F^l_{ij}\\\\left[O\\\\right]\\\\right)\\\\right)^2,$$ где $\\\\gamma_l$ — вклад $l$-го слоя в функцию потерь.\\nЗамечание: Если в случае остальных функций потерь нетрудно посчитать производную, то здесь могут возникнуть проблемы. Но поскольку $\\\\displaystyle\\\\frac{\\\\partial \\\\mathcal{L}_{hist}}{\\\\partial F^l_{ij}\\\\left[O\\\\right]}$ является нулём почти везде, авторы предлагают при подсчёте производной считать $R\\\\left(F^l_{ij}\\\\left[O\\\\right]\\\\right)$ константой, которая не зависит от $O$.\\nTotal variation loss\\nТакже добавим ещё одну функцию потерь, которая удаляет шумы, при этом сохраняя важные детали изображения[8][9]:\\n$$\\\\mathcal{L}_{tv}(O) = \\\\displaystyle\\\\sum_{i, j} \\\\left(O^l_{i, j} - O^l_{i-1, j}\\\\right)^2 + \\\\left(O^l_{i, j} - O^l_{i, j-1}\\\\right)^2.$$\\nГлубокая гармонизация картин\\nДля того чтобы вставить изображение в картину или рисунок нужно не только сделать бесшовный переход и изменить цвета, но ещё и изменить текстуру вставляемого изображения, например, сымитировать мазки кистью (рисунок $2$). Используем для этого комбинацию подходов из других статей[5][9][6].\\nАлгоритм состоит из двух проходов. Первый проход делает грубую гармонизацию, а второй — более тщательную. Отличаются они стилевым маппингом и функциями потерь[11].\\n|Определение:\\n|Стилевым маппингом назовём отображение $P : \\\\mathcal{R}^{N_l \\\\times M_l} \\\\rightarrow \\\\mathcal{R}^{N_l \\\\times M_l}$, которое некоторым образом переставляет столбцы матрицы (не обязательно обратимо, то есть столбцы могут теряться и копироваться). Более формально, пусть $p(j)$ — новая позиция столбца $j$, тогда $P(Q)_{i, p(j)} = Q_{ij}$.\\nОдин проход состоит из $3$ частей:\\n- Входное $I$ и стилевое $S$ изображения подаются на вход нейронной сети VGG-19, так мы получаем $F^l_{ij}\\\\left[I\\\\right]$ и $F^l_{ij}\\\\left[S\\\\right]$.\\n- Для каждого слоя $l$ некоторым алгоритмом $\\\\pi$ cтроится стилевой маппинг $P_l$, который сопоставляет столбцам из $F_l[I]$ столбцы из $F_l[S]$.\\n- Изображение $O$ восстанавливается градиентным спуском по пространству изображений с использованием функции потерь $\\\\mathcal{L}$.\\nfun $SinglePassHarmonization$( $I$,// Входное изображение $M$,// Маска $S$,// Стилевое изображение $\\\\pi$,// Алгоритм построения стилевого маппинга $\\\\mathcal{L}$// Функция потерь ): // Строим матрицы $F[I]$ и $F[S]$ с помощью свёрточной сети VGG-19 $F[I] \\\\leftarrow ComputeNeuralActivations(I)$ $F[S] \\\\leftarrow ComputeNeuralActivations(S)$ // Строим стилевой маппинг $P \\\\leftarrow \\\\pi(F[I], M, F[S])$ // Градиентным спуском ищем изображение $O$, которое минимизирует $\\\\mathcal{L}$ $O \\\\leftarrow Reconstruct(I, M, S, P, \\\\mathcal{L})$ return $O$\\nПервый проход\\n|Определение:\\n|Патчем (англ. patch) для столбца $j$ будем называть тензор $3 \\\\times 3 \\\\times N_l$, который состоит из соседних векторов активации в тензоре выхода свёрточного слоя, с центром в $(x, y)$, где $j = y W_l + x$.\\nПервый проход делает грубую гармонизацию, но при этом он хорошо работает с любыми стилями (рисунок $3.1$). Здесь используется алгоритм $IndependentMapping$ для построения стилевого маппинга. Этот алгоритм для каждого столбца $j$ в $F_l[I]$ ищет столбец $p(j)$ в $F_l[S]$, такой что евклидово расстояние между патчем $F_l[I]$ с центром $j$ и патчем $F_l[S]$ с центром $p(j)$ минимально (метод ближайшего соседа).\\nfun $IndependentMapping$( $F[I]$,// Выходы слоёв после входного изображения $Mask$,// Маска $F[S]$// Выходы слоёв после стилевого изображения ): // Для всех слоёв от $1$ до $L$ for $l \\\\in [1 : L]$: // Для всех столбцов от $1$ до $M_l$ for $j \\\\in [1 : M_l]$: // Рассматриваем патчи только внутри маски, которую нужно масштабировать в соответсвии с размером слоя $l$ if $j \\\\in Resize(Mask, l)$: // Берём самый похожий стилевой патч и записываем его в маппинг. $P_l(j) \\\\leftarrow NearestNeighborIndex(F[I], j, F[S])$ return $P$\\nВ первом проходе используется модифицированная функция потерь $\\\\mathcal{L}_{Gatys}$, с тем лишь отличием, что в $\\\\mathcal{L}_{style}$ к $F_l[S]$ применяется стилевой маппинг $P_l$:\\n$$\\\\mathcal{L}_1(I, S, O, P) = \\\\mathcal{L}_{content}(I, O) + w_{style}\\\\mathcal{L}_{style}(S, O, P).$$\\nЗамечание: при посчёте градиента $\\\\mathcal{L}_{content}$ используются только пиксели внутри маски[12].\\nВторой проход\\nВторой проход делает более качественную гармонизацию после первого прохода (рисунок $3.2$). Здесь мы будем использовать более сложный алгоритм $ConsistentMapping$ построения стилевого маппинга и более сложную функцию потерь. Суть этого алгоритма в том, чтобы найти стилевой мапинг на некотором слое $l_{ref}$ и перенести этот маппинг на остальные слои. Также, мы будем предпочитать маппинги, в которых смежные патчи в $F_l[S]$ остаются смежными после мапинга, чтобы обеспечить пространсвенную согласованность (таким образом мы хотим переносить сложные текстуры более качественно, например, мазки кистью). Если применять второй проход сразу, то результаты получаются хуже (рисунок $4.2$).\\nfun $ConsistentMapping$( $F[I]$,// Выходы слоёв после входного изображения $Mask$,// Маска $F[S]$// Выходы слоёв после стилевого изображения ): // Сначала посчитаем маппинг как в IndependentMapping только для слоя $l_{ref}$ for $j \\\\in [1 : M_{l_{ref}}]$: if $j \\\\in Resize(Mask, l_{ref})$: $P_0(j) \\\\leftarrow NearestNeighborIndex(F[I], j, F[S])$ // Далее обеспечиваем пространсвенную согласованность for $j \\\\in [1 : M_{l_{ref}}]$: if $j \\\\in Resize(Mask, l_{ref})$: $q \\\\leftarrow P_0(j)$ // Инициализируем множество кандидатов на новый маппинг $CSet \\\\leftarrow \\\\{q\\\\}$ // Перебираем все смежные патчи for $o \\\\in \\\\left\\\\{N, NE, E, SE, S, SW, W, NW\\\\right\\\\}$: // Добавляем в кандидаты патч, сосед которого является маппингом для нашего соседа в соответсвующем направлении $CSet \\\\leftarrow CSet \\\\cup \\\\left\\\\{P_0(j + o) - o\\\\right\\\\}$ // Среди всех кандидатов выбираем тот, который ближе всего к маппингам наших соседей $P_{l_{ref}}(j) \\\\leftarrow \\\\underset{c \\\\in CSet}{\\\\mathrm{argmin}}\\\\displaystyle\\\\sum_o \\\\left\\\\|(F_{l_{ref}}[S]_c - F_{l_{ref}}[S]_{P_0(j + o)}\\\\right\\\\|^2$ // Теперь нужно перенести маппинг для $l_{ref}$ на остальные слои for $l \\\\in [1 : L] \\\\setminus \\\\{l_{ref}\\\\}$: for $j \\\\in [1 : M_l]$: if $j \\\\in Resize(Mask, l)$: // Вычисляем позицию $j'$ на слое $l_{ref}$ соответствующую позиции $j$ на слое $l$ $j' \\\\leftarrow ChangeResolution(l, l_{ref}, j)$ // Берём маппинг для позиции $j'$ $q \\\\leftarrow P_{l_{ref}}(j')$ // Переносим позицию $q$ обратно на слой $l$ $P_l(j) \\\\leftarrow ChangeResolution(l_{ref}, l, q)$ return $P$\\nПри вычислении стилевого маппинга появляется очень много дублирующихся векторов, что даёт не очень хорошие результаты (рисунок $4.3$). Поэтому при вычислении матрицы Грама выкинем повторяющиеся векторы. Назовём функцию потерь с такой модификацией $\\\\mathcal{L}_{s1}$.\\n$$\\\\mathcal{L}_2(I, S, O, P) = \\\\mathcal{L}_{content}(I, O) + w_{style}\\\\mathcal{L}_{s1}(S, O, P) + w_{hist}\\\\mathcal{L}_{hist}(S, O) + w_{tv}\\\\mathcal{L}_{tv}(O),$$ где $w_{style}, w_{hist}, w_{tv}$ — веса соответсвующих функций потерь.\\nИтоговый алгоритм\\nТеперь осталось запустить две стадии:\\nfun $Harmonization$( $I$,// Входное изображение $Mask$,// Маска $S$// Стилевое изображение ): // Грубый проход алгоритма. Каждый слой рассматривается отдельно при построении стилевого маппинга. $I' \\\\leftarrow SinglePassHarmonization(I, Mask, S, IndependentMapping, \\\\mathcal{L}_1)$ // Улучшение результата. Стилевой маппинг строится консистентно для всех слоёв. $O \\\\leftarrow SinglePassHarmonization(I', Mask, S, ConsistentMapping, \\\\mathcal{L}_2)$ return $O$\\nПостобработка\\nОписанный алгоритм даёт хорошие результаты в целом, но при ближайшем рассмотрении могут быть артефакты (рисунок $5$). Поэтому сделаем двухступенчатую постобработку (подробное описание есть в оригинальной статье[11]):\\n- Переведём изображение в цветовое пространство $L*\\\\alpha*\\\\beta$ и применим Guided filter для a и b каналов.\\n- С помощью алгоритма PatchMatch[13] и того же Guided filter делаем так, чтобы все патчи выходного изображения присутсвовали в стилевом (чтобы не было новых объектов или структур).\\nДетали реализации\\nВозьмём $l_{ref}$ = conv4_1 (что будет если использовать другие слои видно на рисунке $6$). Выберем следующие веса для слоёв:\\n|Параметр\\n|conv1_1\\n|conv2_1\\n|conv3_1\\n|conv4_1\\n|conv5_1\\n|$\\\\alpha$\\n|$0$\\n|$0$\\n|$0$\\n|$1$\\n|$0$\\n|$\\\\beta$\\n|$0$\\n|$0$\\n|$1/3$\\n|$1/3$\\n|$1/3$\\n|Параметр\\n|conv1_1\\n|conv2_1\\n|conv3_1\\n|conv4_1\\n|conv5_1\\n|$\\\\alpha$\\n|$0$\\n|$0$\\n|$0$\\n|$1$\\n|$0$\\n|$\\\\beta$\\n|$1/4$\\n|$1/4$\\n|$1/4$\\n|$1/4$\\n|$0$\\n|$\\\\gamma$\\n|$1/2$\\n|$0$\\n|$0$\\n|$1/2$\\n|$0$\\nВведём гиперпараметр $\\\\tau$ и возьмём $w_{style} = w_{hist} = \\\\tau$, $w_{tv} = \\\\tau\\\\frac{10}{1 + \\\\exp(10^4 * noise(S) - 25)}$, где $noise(S) = \\\\underset{i,j}{\\\\mathrm{med}}\\\\left\\\\{\\\\left(O^l_{i, j} - O^l_{i-1, j}\\\\right)^2 + \\\\left(O^l_{i, j} - O^l_{i, j-1}\\\\right)^2\\\\right\\\\}$[14].\\nДля того чтобы подбирать $\\\\tau$ авторы статьи использовали классификатор стилей изображений. Они взяли VGG-19, обучили её классифицировать $18$ различных стилей. Эти стили были разделены на $3$ категории с разными $\\\\tau$. Используя $Softmax$ можно интерполировать необходимый $\\\\tau$ по следующей таблице:\\n|Категория стиля\\n|Примеры стилей\\n|$\\\\tau$\\n|Слабый\\n|Барокко, Высокое Возрождение\\n|$1$\\n|Средний\\n|Абстрактное Искусство, Постимпрессионизм\\n|$5$\\n|Сильный\\n|Кубизм, Экспрессионизм\\n|$10$\\nНа рисунке $4.4$ результат алгоритма без подбора гиперпараметров. Видно, что самолёт ярче, чем остальное изображение. С подбором параметров получается более естественный результат (рисунок $4.5$).\\nПримеры\\nПримеры взяты с Github авторов.\\n|Исходное изображение\\n|Простая вставка\\n|Результат\\n|Постобработка\\nБолее новые подходы\\n- Foreground-aware Semantic Representations for Image Harmonization\\n- BargainNet: Background-Guided Domain Translation for Image Harmonization\\nГлубокий блендинг\\nАлгоритм глубокого блендинга состоит из двух этапов. На первом этапе на стилевое изображения $S$ бесшовно накладывается входное изображение $I$, получается подготовительное блендинг-изображение $B$. На втором этапе $B$ модифицируется таким образом, чтобы результат по стилю был похож на $S$.\\nБудем считать, что на вход подаются изображения, прошедшие предварительную обработку:\\n- Используемая для вставки часть $I$ вырезана с помощью маски.\\n- $M$ и $I$ выровнены относительно $S$.\\n- Размеры матриц, задающих $M, S, I$, совпадают.\\nПримеры входных данных:\\n| Стилевое\\nизображение $S$[1]\\n| Накладываемое\\nизображение $I$[1]\\n|Определение:\\n|Простой вставкой (англ. copy and paste) $CAP(M, S, I)$ будем назвать изображение, полученное наложением части изображения $I$, заданной маской $M$, на изображение $S$. $CAP(M, S, I) = I \\\\odot M + S \\\\odot (1 - M)$, где $\\\\odot$ — покомпонентное умножение.\\n|Определение:\\n|Дискретный оператор Лапласа (фильтр Лапласа) $\\\\mathbf{D}^2$ — аналог непрерывного оператора Лапласа $\\\\nabla^2$, который позволяет выделять контуры изображения (рисунки $7.1$ и $7.2$). $$\\\\mathbf{D}^2=\\\\begin{bmatrix}0 & 1 & 0\\\\\\\\1 & -4 & 1\\\\\\\\0 & 1 & 0\\\\end{bmatrix}.$$\\n|Рисунок $7.1$:\\nИсходное изображение[15]\\n|Рисунок $7.2$:\\nПрименение фильтра Лапласа\\nДля сохранения контуров изображений $S$ и $I$ в области вставки воспользуемся идеей из метода Пуассона и введём следующую функцию потерь[1]: $$\\\\mathcal{L}_{grad}(S, I, M, O) = \\\\displaystyle\\\\frac{1}{2HW}\\\\displaystyle\\\\sum_{m=1}^H \\\\displaystyle\\\\sum_{n=1}^W \\\\left[ \\\\mathbf{D}^2 B - \\\\left(\\\\mathbf{D}^2 S + \\\\mathbf{D}^2 I\\\\right) \\\\right]^2_{mn},$$ где $H, W$ — высота и ширина изображений. $B = CAP(M, S, O)$ — блендинговое изображение, оптимизируемое относительно $O$.\\nРассмотрим область $\\\\overline{\\\\Omega} = \\\\{\\\\;p \\\\;| \\\\;M_p = 0\\\\; \\\\}$. Заметим, что градиент $I$ в $\\\\overline{\\\\Omega}$ равен нулю. Тогда градиенты $S$ и $B$ совпадают, и задача минимизации $\\\\mathcal{L}_{grad}$ решается только в области вставки.\\nНа обоих этапах алгоритм минимизирует взвешенную сумму следующих функций потерь:\\n- $\\\\mathcal{L}_{content}$ для сохранения содержания накладываемого изображения $I$.\\n- $\\\\mathcal{L}_{style}$ для переноса стиля изображения $S$ на $I$.\\n- $\\\\mathcal{L}_{hist}$ для стабилизации переноса стиля.\\n- $\\\\mathcal{L}_{tv}$ для удаления шумов.\\n- $\\\\mathcal{L}_{grad}$ для сохранения контуров фона и изображения.\\nДля подсчета $\\\\mathcal{L}_{style}$ и $\\\\mathcal{L}_{content}$ авторами статьи[1] использовалась сеть VGG-19[4], обученная на ImageNet[16].\\nПервый этап\\nНа первом этапе изображение $I$ накладывается на фоновое изображение $S$ таким образом, чтобы были незаметны швы. Построение начинается с белого шума $Z$, который оптимизируется в области вставки путем минимизации суммарной функции потерь $\\\\mathcal{L}_{total}$, представленной взвешенной суммой всех функций потерь, описанных выше: $$ \\\\mathcal{L}_{total}(Z) = w_{grad}\\\\mathcal{L}_{grad}(I, S, B) + w_{content}\\\\mathcal{L}_{content}(I, M, Z) + w_{style}\\\\mathcal{L}_{style}(S, B) + w_{tv}\\\\mathcal{L}_{tv}(B) + w_{hist}\\\\mathcal{L}_{hist}(S, B).$$ Для решения задачи минимизации авторы статьи[1] используют алгоритм L-BFGS[17].\\nОтметим, что $\\\\mathcal{L}_{content}$ зависит от маски и отвечает за сохранение содержания $I$ в области вставки.\\nОтличительной чертой этого этапа является использование функции потерь $\\\\mathcal{L}_{grad}$, приближающей градиент результата к градиенту $I$ в области наложения, за счет чего достигается бесшовность.\\nВ результате получается подготовительное блендинг-изображение $B$.\\nfun $SeamlessBlending$( $I$, // Входное изображение $M$, // Маска $S$ // Стилевое изображение ): // Инициализируем первое приближение белым шумом $Z \\\\leftarrow RandomNoise() $ $B \\\\leftarrow CAP(M, S, Z)$ // Определим суммарную функцию потерь с весами слагаемых $w$ $\\\\mathcal{L}_{total}(Z) \\\\leftarrow w_{grad}\\\\mathcal{L}_{grad}(I, S, B) + w_{content}\\\\mathcal{L}_{content}(I, M, Z) + w_{style}\\\\mathcal{L}_{style}(S, B) + w_{tv}\\\\mathcal{L}_{tv}(B) + w_{hist}\\\\mathcal{L}_{hist}(S, B)$ // С помощью алгоритма L-BFGS ищем изображение $Z$, которое минимизирует $\\\\mathcal{L}_{total}$ $Z \\\\leftarrow Reconstruct(\\\\mathcal{L}_{total}, Z)$ return $CAP(M, S, Z)$\\nВторой этап\\nВторой этап алгоритма представляет собой модификацию полученного на первом этапе блендинг-изображения $B$ таким образом, чтобы стиль изображения был наиболее близок к стилю $S$.\\nВ отличие от предыдущего этапа, функция потерь не включает в себя $\\\\mathcal{L}_{grad}$: $$\\\\mathcal{L}_{total}(O) = w_{content}\\\\mathcal{L}_{content}(B, O) + w_{style}\\\\mathcal{L}_{style}(S, O) + w_{tv}\\\\mathcal{L}_{tv}(O) + w_{hist}\\\\mathcal{L}_{hist}(S, O).$$\\nМинимизация происходит относительно результата алгоритма $O$, который инициализируется изображением $B$.\\nfun $StyleRefinement$( $B$, // Подготовительное блендинг-изображение, результат первого этапа $M$, // Маска $S$ // Стилевое изображение ): $O \\\\leftarrow B$ // Определим суммарную функцию потерь с весами слагаемых $w$ $\\\\mathcal{L}_{total}(O) \\\\leftarrow w_{cont}\\\\mathcal{L}_{content}(B, O) + w_{style}\\\\mathcal{L}_{style}(S, O) + w_{tv}\\\\mathcal{L}_{tv}(O) + w_{hist}\\\\mathcal{L}_{hist}(S, O)$ // С помощью алгоритма L-BFGS ищем изображение $O$, которое минимизирует $\\\\mathcal{L}_{total}$ $O \\\\leftarrow Reconstruct(\\\\mathcal{L}_{total}, O)$ return $O$\\nПримеры с Github авторов:\\n|После первого этапа\\n|После обоих этапов\\nДетали реализации\\nВ статье использовались следующие значения коэффициентов:\\n|Этап\\n|$w_{grad}$\\n|$w_{content}$\\n|$w_{style}$\\n|$w_{hist}$\\n|$w_{tv}$\\n|$1$\\n|$10^5$\\n|$1$\\n|$10^5$\\n|$1$\\n|$10^{-6}$\\n|$2$\\n|$0$\\n|$1$\\n|$10^7$\\n|$1$\\n|$10^{-6}$\\n|Параметр\\n|conv1_2\\n|conv2_2\\n|conv3_3\\n|conv4_3\\n|$\\\\alpha$\\n|$0$\\n|$1$\\n|$0$\\n|$0$\\n|$\\\\beta$\\n|$1/4$\\n|$1/4$\\n|$1/4$\\n|$1/4$\\nНа обоих этапах максимальное количество итераций алгоритма L-BFGS — $1000$.\\nПримеры\\nПримеры с Github авторов:\\nСм. также\\nИсточники информации\\n- Histogram matching\\n- Patrick Perez, Michel Gangnet, Andrew Blake (2003), Poisson Image Editing.\\n- Leon A. Gatys, Alexander S. Ecker, Matthias Bethge (2016), Image Style Transfer Using Convolutional Neural Networks\\n- Fujun Luan, Sylvain Paris, Eli Shechtman, Kavita Bala (2018), Deep Painterly Harmonization\\n- Lingzhi Zhang, Tarmily Wen, Jianbo Shi (2020), Deep Image Blending\\nПримечания\\n- ↑ 1,0 1,1 1,2 1,3 1,4 1,5 1,6 Deep Image Blending Lingzhi Zhang, Tarmily Wen, Jianbo Shi (2020)\\n- ↑ Poisson Image Editing Patrick Perez, Michel Gangnet, Andrew Blake (2003)\\n- ↑ https://erkaman.github.io/posts/poisson_blending.html Poisson blending для самых маленьких\\n- ↑ 4,0 4,1 Very Deep Convolutional Networks for Large-Scale Image Recognition Karen Simonyan, Andrew Zisserman (2014)\\n- ↑ 5,0 5,1 Image Style Transfer Using Convolutional Neural Networks Leon A. Gatys, Alexander S. Ecker, Matthias Bethge (2016)\\n- ↑ 6,00 6,01 6,02 6,03 6,04 6,05 6,06 6,07 6,08 6,09 6,10 Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses Eric Risser, Pierre Wilmot, Connelly Barnes (2017)\\n- ↑ https://en.wikipedia.org/wiki/Histogram_matching\\n- ↑ Understanding Deep Image Representations by Inverting Them Aravindh Mahendran, Andrea Vedaldi (2015)\\n- ↑ 9,0 9,1 Perceptual Losses for Real-Time Style Transfer and Super-Resolution Justin Johnson, Alexandre Alahi, Li Fei-Fei (2016)\\n- ↑ Visual Attribute Transfer through Deep Image Analogy Jing Liao, Yuan Yao, Lu Yuan, Gang Hua, Sing Bing Kang (2017)\\n- ↑ 11,0 11,1 11,2 https://arxiv.org/pdf/1804.03189.pdf Fujun Luan, Sylvain Paris, Eli Shechtman, Kavita Bala (2018)\\n- ↑ https://github.com/luanfujun/deep-painterly-harmonization/blob/a33a9a70366b6baff1cc0291f857b5895b271fc1/neural_gram.lua#L349\\n- ↑ https://www.researchgate.net/profile/Eli_Shechtman/publication/220184392_PatchMatch_A_Randomized_Correspondence_Algorithm_for_Structural_Image_Editing/links/02e7e520897b12bf0f000000.pdf Connelly Barnes, Eli Shechtman, Adam Finkelstein, Dan B Goldman (2009)\\n- ↑ [https://github.com/luanfujun/deep-painterly-harmonization/blob/a33a9a70366b6baff1cc0291f857b5895b271fc1/neural_paint.lua#L470 код функции $noise$.\\n- ↑ https://en.wikipedia.org/wiki/Lenna#/media/File:Lenna_(test_image).png\\n- ↑ https://image-net.org/papers/imagenet_cvpr09.pdf J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. FeiFei. Imagenet: A large-scale hierarchical image database\\n- ↑ https://en.wikipedia.org/wiki/Limited-memory_BFGS Limited-memory BFGS - Wikipedia\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='b0e70572-0923-452b-851c-44d98c22efca', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='abb9899a05dff1cf6e85f914793af7724a7f06022d97242f8983172d779303f6', text='Порождающие модели\\nПорождающие модели (англ. generative model) — это класс моделей, которые обучают совместное распределение[1] данных ; отсюда легко получить условное распределение , но совместное даёт больше информации и его можно использовать, например, для генерации новых фотографий животных, которые выглядят как настоящие животные.\\nС другой стороны, дискриминативная модель (англ. discriminative model)[2] обучает только условное распределение и может, например, отличить собаку от кошки.\\nПримером простейшей порождающей модели является наивный байесовский классификатор.\\nСодержание\\nКлассификация задачи\\nМожно использовать некоторые эмпирические правила для генерации новых объектов, не используя машинного обучения.\\nМы хотим научиться создавать правдоподобный объект относительно некоторой скрытой структуры исходных объектов. Давайте изучим распределение по ним, а затем просто будем сэмплировать новый объект из этого распределения. Значит эта задача относится к классу задач обучения без учителя.\\nПорождающая модель иногда позволяет использовать обучение с частичным привлечением учителя. Пусть задача состоит в том, чтобы отличить кошек от собак на фотографиях. Обычно мало размеченных данных, на которых кошки и собаки отмечены вручную. Основная часть задачи состоит в том, чтобы понять, чем разумные фотографии отличаются от случайного шума. Иначе говоря, если сначала определить распределение , то проще обучить распределение , где — это один бит, отвечающий за отдельный признак, а — это вся фотография.\\nВычисление плотности распределения\\nС математической точки зрения основная цель порождающей модели обычно состоит в максимизации функции правдоподобия: для набора данныхмаксимизировать по параметрам модели , т.е. найти\\nЧтобы избежать арифметического переполнения снизу[3] зачастую пользуются свойством логарифма произведения . Благодаря моннотоности логарифма, его применение к обоим частям выражения не изменит параметры, при которых достигается максимум. При этом, логарифм от числа близкого к нулю будет числом отрицательным, но в абсолютном значении существенно большим чем исходное число, что делает логарифмические значения вероятностей более удобными для анализа. Что в нашем случае с вероятности очень уместно. Поэтому, мы переписываем нашу формулу с использованием логарифма.\\nВажен и другой взгляд на то же самое: максимизация правдоподобия эквивалентна минимизации расстояния Кульбака-Лейблера[4] между распределением , которое получается из нашей модели, и распределением — эмпирическим распределением данных. Это эмпирическое распределение попросту полностью сосредоточено в точках из набора данных и равномерно распределено по ним, так что:\\nи минимизация этого выражения эквивалентна максимизации того, что выше.\\nТаксономия порождающих моделей\\nГенеративные модели различаются как раз тем, как именно они строят распределение.\\nЯвный подход\\nМожно строить это распределение явно, делая вероятностные предположения, которые обычно сводятся к тому, что общее распределениевыражается в виде произведения тех или иных распределений.\\nКак правило, модели, где плотность известна явно, делают какие-то дополнительные предположения на структуру этих распределений.\\nНапример, байесовские сети строят распределение из условных распределений\\nМожно даже и вовсе никаких предположений не делать: любое распределение всегда раскладывается как:\\nТак представляется модель в FVBN (fully visible belief networks)[5], идея которых состоит в том, что с одномерными распределениями нетрудно разобраться - в ранних работах их представляли классическими моделями. А сейчас мы можем их промоделировать последовательно глубокими сетями, получится модель, которая сможет последовательно породить компонент за компонентом, каждый раз для порождения опираясь на уже порожденные .\\nИменно эта идея лежит в основе модели для работы со звуком WaveNet, разработанной Google DeepMind[6]. Существующие параметрические модели синтезирования речи[7] обычно генерируют звук, прогоняя выходной сигнал через специальные обработчики, называемые вокодерами[8].\\nWaveNet меняет парадигму, генерируя звуковой сигнал по семплам. Это не только приводит к более натуральному звучанию речи, но и позволяет создавать любые звуки, включая музыку. Эта архитектура состоит из нескольких последовательных слоев разреженных сверток и в ней снова встречаются остаточные связи, связи «через уровень» и так далее. Во время обучения входящие последовательности представляют собой звуковые волны от примеров записи голоса. После тренировки можно с помощью сети генерировать синтетические фразы. На каждом шагу семплирования значение вычисляется из вероятностного распределения, посчитанного сетью. Затем это значение возвращается на вход и делается новое предсказание для следующего шага.\\nВ моделях PixelRNN[на 24.02.20 не создан] и PixelCNN[на 24.02.20 не создан] строится изображение пиксель за пикселем, слева направо и сверху вниз. Каждый пиксель порождается из условного распределения а оно уже моделируется или рекуррентной сетью или сверточной.\\nМодель DRAW[9] последовательно «рисует» картинку с помощью рекуррентной сети, а механизм внимания[на 24.02.20 не создан] помогает сети в данный момент сконцентрироваться на нужной части изображения.\\nЕсли хочется явно выразить совсем сложные распределения в порождающих моделях, их приходится приближать более простыми, которые уже, в свою очередь, могут быть выражены явно. Для этого обычно используются вариационные методы.\\nНеявный подход\\nОсновная альтернатива всему этому состоит в том, чтобы использовать неявные порождающие модели, в которых мы не пытаемся получить функцию, подсчитывающую плотность нужного распределения в каждой точке, а просто моделируем то, что нам от этой модели нужно. Например, если мы хотим просто научиться порождать фотографии милых котиков, нам не так важно иметь явную функцию плотности, которая могла бы сказать, насколько вероятно, что перед нами котик, - вполне достаточно просто уметь генерировать новые .\\nСэмплирование из сложных многомерных распределений делается с помощью МСМС[10]-методов: попробуем построить марковскую цепь, которая описывает случайное блуждание под графиком плотности распределения. Если достаточно долго блуждать под графиком плотности , можно будет считать, что полученная точка представляет собой случайную точку, взятую по распределению . Примером такого моделирования глубокой сетью являются порождающие стохастические сети[11].\\nПорождающие состязательные сети — алгоритм машинного обучения, построенный на комбинации из двух нейронных сетей: генеративная модель , которая строит приближение распределения данных, и дискриминативная модель , оценивающая вероятность, что образец пришел из тренировочных данных, а не сгенерированных моделью . Обучение для модели заключается в максимизации вероятности ошибки дискриминатора .\\nСм. также\\n- Наивный байесовский классификатор\\n- Порождающие состязательные сети\\n- Автокодировщик\\n- Вариационный автокодировщик\\n- Генерация изображения по тексту\\nПримечания\\n- ↑ Joint probability distribution\\n- ↑ Discriminative model\\n- ↑ Исчезновение порядка\\n- ↑ Расстояние Кульбака-Лейблера\\n- ↑ Frey B. Graphical Models for Machine Learning and Digital Communication, Cambridge, MA: MIT Press, 1998.\\n- ↑ Blog post by DeepMind about WaveNet\\n- ↑ Text-To-Speech (TTS)\\n- ↑ Vocoder\\n- ↑ DRAW: A Recurrent Neural Network For Image Generation / K. Gregor et al. / / arXiv, 2015.\\n- ↑ Markov chain Monte Carlo(МСМС)\\n- ↑ Generative Stochastic Networks\\nИсточники информации\\n- Generative_model\\n- Google courses с примерами на понимание\\n- NIPS 2016 Tutorial: Generative Adversarial Networks(Ian Goodfellow, 2016)\\n- Николенко С., Кадурин А., Архангельская Е. Глубокое обучение. СПб.: Питер, 2018.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='8923ca4f-9c84-4689-afd5-a0a58e7a984d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c7d937372ad764874245012793bfa5c1cd40aaeba03b3013f6a5c1c166b2ffd9', text='Генерация объектов\\nЗадача генерации объектов (англ. object generation problem) — задача, связанная с машинным обучением, заключающаяся в создании новых правдоподобных объектов на основании заданной выборки. Полученные объекты могут быть использованы как для прикладных целей (в таком случае, это чаще всего изображения), так и для генерации объектов для тренировочной выборки, когда размечать настоящие данные — долго и дорого, или их нужно анонимизировать. В зависимости от того, для какой из этих целей используется генерация объектов, постановка задачи и методы её решения несколько отличаются.\\nСодержание\\nГенерация объектов для прикладных целей\\nПрименение\\nИзображения\\nПри генерации объектов основная задача обычно состоит в том, чтобы научиться создавать изображения, которые человек не может отличить от изображений, полученных иным путём (рис. 1). Они могут использоваться для более дешёвого создания модельных снимков, обложек или пейзажей. Одним из ярких примеров такого применения является создание фотографий вымышленных людей для рекламы в расчёте на то, что люди будут больше ассоциировать себя с образом, не представляющим кого-либо конкретного, но сочетающим в себе те черты, которые есть у них самих.\\nГенерация объектов может улучшать астрономические изображения и использоваться при моделировании дорогостоящих для изучения физических процессов. Так, в 2019 году при помощи генеративных состязательных сетей (GAN) были успешно смоделированы [1] распределения темной материи в определенном направлении в пространстве и составлены предсказания гравитационного линзирования.\\nВ медицине активно используется генерация результатов исследований. Из-за запрета на использование анализов и осмотров без согласия пациента часто довольно тяжело получить большое количество данных, поэтому сейчас для формирования крупных датасетов стали применять GAN. Состязательные сети также могут использоваться для обнаружения глаукомных изображений, помогая ранней диагностике, которая необходима для предотвращения частичной или полной потери зрения.[2]\\nМузыка и звуки\\nАудио является еще одним возможным приложением для GAN, однако используется гораздо реже. Примером может являться архитектура WaveGan, которая без меток учится воспроизводить понятные слова при обучении на наборе речевых данных с небольшим словарным запасом, а также может синтезировать звук из других областей, таких как барабаны, вокализации птиц и фортепиано.\\nНа сегодняшний день многие модели для генерации музыки используют долгую краткосрочную память (LSTM). Например, еще в 2002 году при помощи LSTM-сети построили[3] модель, генерирующую не только мелодию, но и аккомпанемент к ней в формате выбора аккорда из зафиксированного перечня, и, отчасти, впервые добились благозвучного результата.\\nВ Google сейчас активно используется модель WaveNet, которая основана на сверточных сетях. WaveNet способна генерировать речь, похожую на голос любого человека, и другие звуки, включая музыку (например, композиции на пианино) [4].\\nТекст\\nГенерировать можно документы и тексты. Генераторы текстов широко используются при разработке и поисковой оптимизации сайтов: для генерации названий, описаний и содержимого. Существуют крупные англоязычные сайты, на которых весь контент пишут не журналисты, а боты — статьи автоматически рерайтятся из других источников. Русский язык, в отличие от английского, имеет сложную морфологию, поэтому появление подобных ботов-рерайтеров в рунете сильно осложнено.\\nАнимация и игры\\nЕще генерация объектов может использоваться при воссоздании текстур старых игр в лучшем расширении (пример игры, для которой был использован такой метод – Resident Evil). Такой подход также помогает создавать персонажей в стилистике мультфильма, нарисовав руками только пару из них, анимировать уже нарисованных героев, а также полезен для подготовки кадров фильмов или мультипликации[5]. В 2018 году исследователи из Университета Иллинойса и Института искусственного интеллекта Аллена разработали модель под названием CRAFT (Composition, Retrieval and Fusion Network)[6], которая принимает текстовые описания (или подписи) от пользователя и генерирует сцены из мультсериала «Флинтстоуны» (рис. 2).\\nДругое\\nПри решении какой-либо задачи часто бывает удобно генерировать специфические объекты для ее решения. Например, одна из задач машинного обучения в медицине — генерация новых молекул, которые потенциально могут быть лекарствами. Для решения этой проблемы используют генеративные состязательные сети.\\nЕще одним примером может являться генерация наборов данных с заданными свойствами для задачи классификации[7]. Это, в частности, может использоваться для генерации данных для систем автоматической проверки программ или в алгоритмах предсказания стоимости изготовления детали по её чертежу и текстовым характеристикам.\\nМожно генерировать юнит-тесты, чтобы быстрее находить ошибки при разработке программного обеспечения[8].\\nГенерация объектов активно развивается в наши дни и имеет множество применений, в том числе под специфические задачи в различных сферах деятельности.\\nИспользуемые модели\\nДля достижения данной цели обычно используются порождающие модели. В таком варианте в качестве задачи ставится восстановление совместного распределения , где — это один бит, отвечающий за отдельный признак (то есть тот класс, к которому должна принадлежать созданный объект; например, фотография человека), а — это весь объект (фотография). Чаще всего порождаемый объект представляет собой набор элементов , что позволяет порождать объект по частям. Для изображения, например, такими частями будут являться пиксели. Таким образом, при порождении следующих частей объекта мы можем опираться на уже созданные, и тогда перед нами встаёт задача максимизация функции правдоподобия: для набора данных максимизировать по параметрам модели , т.е. найти . Эта задача относится к классу задач обучения без учителя или с частичным привлечением учителя. При её решении либо работают с явными распределениями, сводя распределение к произведению распределений определённой структуры, либо используют неявные модели, которые не восстанавливают всю функцию плотности, а только моделируют ту часть этой функции, которая нужна непосредственно. Стоит отметить, что простые порождающие модели, такие как наивный байесовский классификатор, не показывают достаточное качество результата, чтобы на их основе можно было сгенерировать полноценные мультимедиа объекты. Из класса порождающих моделей при генерации изображений особенно хорошо показали себя модели состязательных сетей, PixelRNN и PixelCNN, а также DRAW (рисуют изображение с помощью сочетания рекуррентных НС и механизма внимания).\\nСм. также\\nПримечания\\n- ↑ Обучение нейронной сети для изучения темной материи\\n- ↑ Обнаружение глаукомных изображений\\n- ↑ Finding temporal structure in music: Blues improvisation with lstm recurrent networks\\n- ↑ Google WaveNet\\n- ↑ Generating Videos with Scene Dynamics\\n- ↑ модель CRAFT\\n- ↑ Забашта Алексей Сергеевич, Генерация наборов данных для задачи классификации с заданными свойствами для повышения качества систем мета-обучения\\n- ↑ Unit test generation using machine learning', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='02aef2b3-99ba-417c-b07f-15f0611b7ead', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2d7d7a4e4d56cd2f4e7b10bace680ad33c7b3df61bd1f8607685ef6c64824035', text='Generative Adversarial Nets (GAN)\\nПорождающие состязательные сети (англ. Generative Adversarial Nets, GAN) — алгоритм машинного обучения, входящий в семейство порождающих моделей и построенный на комбинации из двух нейронных сетей: генеративная модель , которая строит приближение распределения данных, и дискриминативная модель , оценивающая вероятность, что образец пришел из тренировочных данных, а не сгенерированных моделью (рис. 1). Обучение для модели заключается в максимизации вероятности ошибки дискрминатора . Впервые такие сети были представлены Иэном Гудфеллоу в 2014 году.\\nСодержание\\n- 1 Постановка задачи и метод\\n- 2 Интуитивный процесс тренировки\\n- 3 Оригинальный алгоритм обучения GAN\\n- 4 Проблемы обучения GAN\\n- 5 Применение\\n- 6 CGAN (Conditional Generative Adversarial Nets)\\n- 7 DCGAN (Deep Convolutional Generative Adversarial Nets)\\n- 8 StackGAN (Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks)\\n- 9 LAPGAN (Laplacian Pyramid of Adversarial Networks)\\n- 10 ControlGAN (Controllable Generative Adversarial Networks)\\n- 11 См. также\\n- 12 Примечания\\n- 13 Источники информации\\nПостановка задачи и метод\\nКак было указано ранее в описании метода, мы хотим обучить две модели: генеративную и дискриминативную. Поскольку, удобнее всего использовать многослойные перцептроны для обучения состязательной модели, будем использовать именно их для детального описания работы модели. Чтобы вывести вероятностное распределение генераторанад набором данных , определим априорную вероятность шума и представим генератор, как отображение , где дифференцируемая функция, представленная многослойным перцептроном с параметром . Аналогичным образом представим второй многослойный перцептрон , который на выход подает одно скалярное значение - вероятность того, что пришло из тренировочных данных, а не . Во время тренировки мы стремимся максимизировать вероятность правильной идентификации объектов из тренировочной и сгенерированной выборок. И в то же время тренируем так, чтобы минимизировать : Другими словами, и играют в \"минимакс игру\":\\nИнтуитивный процесс тренировки\\nКак показано на рисунке 2, генеративные состязательные сети обучаются путем одновременного обновления дискриминирующего распределения (синяя пунктирная линия), так чтобы дискриминатор мог различать объекты из распределения тренировочного сета(черная пунктирная в точку линия) и из распределения генератора ( зеленая сплошная линия). Нижняя горизонтальная линия представляет собой область, из которой составлена выборка , в нашем случае равномерно. Горизонтальная линия над ней является частью области . Стрелками на картинке показано, как отображение , накладывает неравномерное распределение на тренировочное. сжимается в областях с высокой плотностью и расширяется в областях с низкой. Рассмотрим описанный на картинках процесс. (a) Близкая сходимость состязающейся пары: похоже на распределение частично-точный классификатор. (b) Во внутреннем цикле алгоритма обучается отличать объекты из тренировочных данных, сходясь к . (c) После обновления градиент привел к передвижению в область, с большей вероятностью быть классифицированным как данные. (d) После нескольких шагов обучения и придут в состояние, в котором не смогу улучшиться, так как будет выполняться условие и дискриминатор не сможет различать два распределения и его выход всегда будет .\\nОригинальный алгоритм обучения GAN\\nВ процессе обучения требуется делать два шага оптимизации поочередно: сначала обновлять веса генераторапри фиксированном , а затем веса дискриминатора при фиксированном . На практике дискриминатор обновляется раз вместо одного, поскольку, полностью оптимизировать дискриминатор вычислительно не выгодно и на конечных сетах он может переобучиться. Таким образом является гиперпараметром.\\n// num_iteration — число итераций обучения function GAN: for i = 1..num_iteration do for j = 1..k do //Получаем мини-батч $\\\\{z_1, . . . , z_m\\\\}$ из распределения $p_z$ $z$ = getBatchFromNoisePrior($p_z$) //Получаем мини-батч $\\\\{x_1, . . . , x_m\\\\}$ из распределения $p_{data}$ $x$ = getBatchFromDataGeneratingDistribution($p_{data}$) //Обновляем дискриминатор в сторону возрастания его градиентаend for //Получаем мини-батч $\\\\{z_1, . . . , z_m\\\\}$ из распределения $p_z$ $z$ = getBatchFromNoisePrior($p_z$) //Обновляем генератор в сторону убывания его градиента end for\\nНа практике не всегда удобно использовать уравнение описанной выше. В начале обучения, когдаплохо настроен дискриминатор может не учитывать объекты, с высокой уверенностью в классификации, так как они сильно отличаются от тренировочного сета, в таком случае стагнирует. Чтобы избежать этого, можно вместо минимизации максимизировать . На рисунке 3 представлена зависимость получаемого изображения от итерации обучения.\\nПроблемы обучения GAN\\nБольшинство GAN\\'ов подвержено следующим проблемам:\\n- Схлопывание мод распределения (англ. mode collapse): генератор коллапсирует, то есть выдает ограниченное количество разных образцов.\\n- Проблема стабильности обучения (англ. non-convergence): параметры модели дестабилизируются и не сходятся.\\n- Исчезающий градиент (англ. diminished gradient): дискриминатор становится слишком \"сильным\", а градиент генератора исчезает и обучение не происходит.\\n- Проблема запутывания (англ. disentanglement problem): выявление корреляции в признаках, не связанных (слабо связанных) в реальном мире.\\n- Высокая чувствительность к гиперпараметрам.\\nЧасть этих проблем будет рассмотрена подробнее ниже, но нужно заметить, что универсального подхода к решению большинства из них нет. Зато существуют практические советы[1], которые могут помочь при обучении GAN\\'ов. Основными из них являются:\\n- Нормализация данных. Все признаки в диапазоне $[-1; 1]$;\\n- Замена функции ошибки для $G$ с $\\\\min log (1-D)$ на $\\\\max log D$, потому что исходный вариант имеет маленький градиент на раннем этапе обучения и большой градиент при сходимости, а предложенный наоборот;\\n- Сэмплирование из многомерного нормального распределения вместо равномерного;\\n- Использовать нормализационные слои (например, batch normalization или layer normalization) в $G$ и $D$;\\n- Использовать метки для данных, если они имеются, то есть обучать дискриминатор еще и классифицировать образцы.\\nКоллапс мод\\nВ процессе обучения генератор может прийти к состоянию, при котором он будет всегда выдавать ограниченный набор выходов. При этом пространство, в котором распределены сгенерированные изображения, окажется существенно меньше, чем пространство исходных изображений. Главная причина этого в том, что генератор обучается обманывать дискриминатор, а не воспроизводить исходное распределение. Если генератор начинает каждый раз выдавать похожий выход, который является максимально правдоподобным для текущего дискриминатора, то зависимость от $z$ падает, а следовательно и градиент $G(z)$ стремиться к 0. Лучшей стратегией для дискриминатора будет улучшение детектирования этого конкретного изображения. Так на следующих итерациях наиболее вероятно, что генератор придет к другому изображению, хорошо обманывающему текущий дискриминатор, а дискриминатор будет учиться отличать конкретно это новое изображение. Этот процесс не будет сходиться и количество представленных мод не будет расти, поэтому приблизиться к исходному распределению не удастся. На рисунке 4 наглядно представлена проблема mode collapse и то как генератор \"путешествует\" по модам не приближаясь к целевому распределению. На рисунке 5 наглядно представлен пример mode collapse в процессе работы обычной GAN, обучаемой на датасете MNIST.\\nНа текущий момент mode collape является одной из главных проблем GAN, эффективное решение которой ещё ищется. Возможные решения проблемы mode collapse:\\n- WGAN — использование метрики Вассерштейна (англ. Wasserstein Loss) внутри функции ошибки, позволяет дискриминатору быстрее обучаться выявлять повторяющиеся выходы, на которых стабилизируется генератор[2].\\n- UGAN (Unrolled GAN) — для генератора используется функция потерь, которая не только от того, как текущий дискриминатор оценивает выходы генератора, но и от выходов будущих версий дискриминатора.\\nПроблема стабильности обучения\\nЗадача обучения дискриминатора и генератора в общем смысле не является задачей поиска локального или глобального минимума функции, а является задачей поиска точки равновесия двух игроков. В теории игр эта точка называется точкой равновесия Нэша (англ. Nash equilibrium) в которой оба игрока больше не получают выгоды, хотя следуют оптимальной стратегии. Рассмотрим задачу поиска этой точки на игрушечном примере, где $G$ хочет максимизировать произведение $xy$ а $D$ — минимизировать. Будем обновлять параметры $x$ и $y$ на основе градиентного спуска:Если изобразить на графике поведение $x$,$y$ и $xy$ (рис. 6) то станет ясно, что они не сойдутся, а амплитуда их движения будет только увеличиваться.\\nВ оригинальной статье про GAN используется дивергенция Дженсена-Шеннона (англ. Jensen–Shannon divergence), которая в свою очередь использует дивергенцию Кульбака-Лейблера (англ. Kullback-Leibler divergence):\\n- ,\\nгде $P$ и $Q$ — $k$-мерные абсолютно непрерывные распределения, $p(x)$ и $q(x)$ — функции плотности этих распределений, заданные на. Нетрудно заметить, что при наличии $x$, в которых $q(x)=0$, весь интеграл разойдется, что плохо влияет на сходимость обучения.\\nВозможные решения проблемы стабильности:\\n- Регуляризация — Добавление шума ко входам дискриминатора и соответствующая настройка гиперпараметров дискриминатора.\\n- PGGAN (Progressive Growing of GANs, разработана NVidia[3]) — в процессе работы разрешение изображений увеличивается от очень малых (4 на 4 пикселя), до конечных (1024 на 1024 пикселя), что позволяет тренировать сначала выявление крупных черт а затем более мелких, что крайне положительно сказывается на стабильности.\\n- WGAN — В качестве функции дивергенции используется метрика Вассерштейна, которая в большинстве случаев решает проблему расходимости интеграла в функции Дженсена-Шеннона.\\nПроблема запутывания (Проблема связанности характеристик)\\nСложность с генеративными состязательными сетями заключается в том, что непонятно, как им удается определять конкретные различные характеристики (возраст и пол, например) и связаны ли между собой эти характеристики.\\nГенератор хорошо обученной сети $-$ функция [4] и FID (Frechet Inception distance[5]), где главными критериями хорошо сгенерированных образцов является разнообразие отличительных черт в образцах и их выраженность., где $-$ скрытое пространство размерности , для которого обычно применимо Гауссово распределение в многомерном случае. $-$ пространство изображений, где у каждого изображения существует набор характеристик вроде возраста или пола. Пусть нам дана функция оценки , где $-$ пространство изображений размерности . Тогда , где , $-$ связь между точкой в скрытом подпространстве и характеристиками получившегося изображения. Для функции оценок часто используют Inception score\\nУстановлено, что при движении между двумя точкамии характеристики меняются постепенно, без скачков. Тогда по этому направлению в $Z$ можно построить гиперплоскость. Тогда сделаем предположение, при котором для любого бинарного параметра существует гиперплоскость, что все образцы с одной стороны от нее имеют одинаковое значение этого параметра.\\nЗаведем следующую функцию \"расстояния\":, где , $-$ вектор нормали гиперплоскости. Данная функция не подходит под определение расстояния из-за наличия отрицательных значений (но знак нам необходим для определения знака параметра характеристики). Ожидается, что есть близкая к линеной зависимость оценки $f$ по данному параметру от \"расстояния\":\\n.\\nВ таком случае выраженность характеристики зависит от \"расстояния\" до этой гиперплоскости. Аналогично происходит и в случае нескольких характеристик:\\n, где — диагональная матрица с линейными коэффициентами для каждой из характеристик, $-$ вектора нормалей для гиперплоскостей, разделяющих значения признаков .\\nВ случае если— диагональная, то проблемы запутывания нет.\\nВ противном случае проделаем манипуляции в скрытом подпространстве (рис. 7). Проецируяна и вычитая полученный вектор из , получаем такое направление в скрытом пространстве, что вдоль этих направлений у сгенерированных изображений будет изменяться характеристика $1$ вне зависимости от характеристики $2$.\\nПри слишком большом \"расстоянии\" от гиперплоскости соответствующая характеристика слишком сильно делает лицо непохожим на изначальное, но это объяснимо нормальным распределением вектора шума.\\nТакже в скрытом пространстве имеют место арифмитические операции. То есть можно складывать и вычитать вектора из этого пространства, чтобы как получать промежуточные результаты, так и убирать или добавлять какую-либо характеристику.\\nДля борьбы с проблемой запутывания существуют и другие подходы: один из них представляет из себя разложение изображения на передний и задний слои (с возможными промежуточными слоями)[6].\\nСледующий метод основан на том факте, что существуют как локальные черты, так и глобальные. К первым можно отнести форму отдельной части лица, а ко вторым $-$ возраст и пол. Иногда изменение локальной черты может очень сильно влиять на глобальную. Этого хочется избежать, для этого некоторые размерности вектора шума применяются к каждой остальной размерности[7].\\nПрименение\\nЧаще всего GAN\\'ы используются для генерации реалистичных фотографий (рис. 8). Серьезные улучшения в этом направлении были сделаны следующими работами:\\n- Auxiliary GAN[8]: вариант GAN-архитектуры, использующий метки данных;\\n- SN-GAN[9]: GAN с новым подходом решения проблемы нестабильного обучения через спектральную нормализацию;\\n- SAGAN[10]: GAN, основанный на механизме внимания;\\n- BigGAN[11]: GAN с ортогональной регуляризацией, позволившей разрешить проблему коллапсирования при долгом обучении;\\nКроме простой генерации изображений, существуют достаточно необычные применения, дающие впечатляющие результаты не только на картинках, но и на звуке:\\n- CycleGAN[12]: меняет изображения c одного домена на другой, например, лошадей на зебр;\\n- SRGAN[13]: создает изображения с высоким разрешением из более низкого разрешения;\\n- Pix2Pix[14]: создает изображения по семантической окраске;\\n- StackGAN[15]: создает изображения по заданному тексту;\\n- MidiNet[16]: генерирует последовательность нот, таким образом, создает мелодию.\\nCGAN (Conditional Generative Adversarial Nets)\\nУсловные порождающие состязательные сети (англ. Conditional Generative Adversarial Nets, CGAN) $-$ это модифицированная версия алгоритма GAN, которая может быть сконструирована при помощи передачи дополнительных данных y, являющихся условием для генератора и дискриминатора. y может быть любой дополнительной информацией, например, меткой класса, изображением или данными из других моделей, что может позволить контролировать процесс генерации данных. Например, можно подавать параметр y, как условие на класс для генерации чисел, похожих на MNIST. Создание таких картинок, в случае передачи картинки в качетсве y является задачей трансляции изображений. Пример работы CGAN на датасете MNIST с метками классов представленных в виде one-hot векторов [17] (рис. 9).\\nКак уже было упомянуто на вход генератора и дискримантора из GAN подается дополнительная информация y, например в случае с многослойными перецептронами условие может быть представлено дополнительным входным слоем. (рис. 9) В генераторе априорная вероятность шума [18] В дискриминаторе x и y представлены как входные параметры.и условие комбинируются в объединённое скрытое представление, а состязательная тренирующая модель (Обе сети пытаются оптимизировать целевую функцию или функцию потерь. Когда дискриминатор меняет свое поведение, то и генератор меняет, и наоборот) предоставляет достаточно свободы в том как это представление составляется.\\nВ таком случае задача оптимизации будет выглядеть следующим образом:\\nВ качестве примера использования данного алгоритма можно рассмотреть задачу генерации рукописных цифр.\\nПри создании изображения в генератор поступает скомбинированная информация двух параметров: y и вектора шума. В случае MNIST это может быть, например, просто метка класса (от 0 до 9). На выходе из генератора поступает изображение, полученное с помощью транспонированной свертки (происходит деконволюция). Затем полученное изображение комбинируется с y и поступает в дискриминатор, который в свою очередь применяет свертку, чтобы получить полносвязный слой. Наконец, анализируя полученную информацию (полносвязный слой) дискриминатор принимает решение, является ли изображение сгенерированным. (рис. 12)\\nТакже, используя условные порождающие состязательные сети, можно научить такую сеть генерировать текст по картинке и наоборот. В качестве параметра y в данном случае передается изображение, которое будет описано (рис. 11).\\nБолее того, для такого типа нейронных сетей, принимающих в качестве параметра у некоротое изображение местности, в результате может быть получено аналогичное изображение этого места зимой или летом, днем или ночью. Такая задача является задачей трансляции изображений.\\nDCGAN (Deep Convolutional Generative Adversarial Nets)\\nDCGAN $-$ модификация алгоритма GAN, в основе которых лежат сверточные нейронные сети (CNN). Задача поиска удобного представления признаков на больших объемах не размеченных данных является одной из наибольнее активных сфер исследований, в частности представление изображений и видио. Одним из удобных способов поиска представлений может быть DCGAN (рис. 13). Использование сверточных нейронных сетей напрямую не давало хороших результатов, поэтому было внесены ограничения на слои сверток. Эти ограничения и лежат в основе DCGAN:\\n- Замена всех пулинговых слоев на страйдинговые свертки (strided convolutions) в дискриминаторе и частично-страйдинговые свертки (fractional-strided-convolutions) в генераторе, что позволяет сетям находить подходящие понижения и повышения размерностей;\\n- Использование батчинговой нормализации для генератора и дискриминатора, то есть нормализация входа так, чтобы среднее значения было равно нулю и дисперсия была равна единице. Не стоит использовать батч-нормализация для выходного слоя генератора и входного дискриминатор.\\n- Удаление всех полносвязных скрытых уровней для более глубоких архитектур;\\n- Использование ReLU в качестве функции активации в генераторе для всех слоев, кроме последнего, где используется tanh;\\n- Использование LeakyReLU в качестве функции активации в дискриминаторе для всех слоев.\\nПомимо задачи генерации объектов, данный алгоритм хорошо показывает себя в извлечении признаков. Данный алгоритм был натренирован на наборе данных Imagenet-1k[19], после чего были использованы значения со сверточных слоев дискриминатора, подвергнутые max-pooling\\'у, чтобы образовать матрицы и получить общий вектор признаков на их основе. L2-SVM, c полученным представлением, на наборе данных CIFAR-10[19] превосходит по точности решения, основанные на алгоритме K-Means. Подробнее об этом вы можете прочитать в статье. [20]\\nStackGAN (Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks)\\nStackGAN $-$ порождающая состязательная сеть для генерации фото-реалистичных изображений (256x256) исходя из текстового описания. Генерировать фото-реалистичные изображения на обычных GAN сложно, поэтому была придумана двух-этапная модель генерации. Stage-I GAN рисует скетчи с примитивными формами и цветами, основанные на текстовом описании, в низком разрешении. Stage-II GAN принимает на вход изображения с первого этапа и текстовое описание и генерирует изображение в высоком разрешении с фото-реалистичными деталями. Чтобы улучшить разнообразие синтезированных изображений и стабилизировать обучение, вместо CGAN использовался метод Conditioning Augmentation.\\nРаннее использовались CGAN, поскольку на вход им можно было подавать условия, но просто добавляя слои, увеличивающие размер изображения, достичь хороших результатов не удалось. Поэтому основной задачей было повысить разрешение изображений.\\nОдной из ключевых особенностей StackGAN является Conditioning Augmentation, так как оно позволило расширить количество примеров тренировочного сета, путем небольших случайных изменений в исходных изображениях, что увеличивало многообразие данных. Как показано на картинке, текстовое описание [21].кодировщиком переводится в векторное представление (рис. 15). Раннее векторное представление нелинейно трансформировалось, чтобы получить скрытые условные переменные, которые подавались на вход генератору, однако простарнство значений скрытых переменных имеет большую размерность, что приводило к разрывам в многообразии данных, что не выгодно для генератора. Чтобы избавиться от этого как раз нужно Conditioning Augmentation, которое в отличии от предоставления фиксированных значений переменных выбирает их из нормального распределения , где среднее значение и ковариация это функции от входного вектора . В добавок к уже упомянотому, чтобы сделать многообразие гладким и не переобучиться, нужно добавить регуляризацию, (KL divergence)\\nStage-I GAN тренирует дискриминатори генератор поочередной максимизицаии и минимизации , как указано в уравенинях:\\nГде реальное изображениеи описание текста берутся из реального распределения данных . шумовой вектор взятого случайно из нормального распределения, параметр регуляризации.\\nВ изображениях с низким разрешенеим, сгенерированные Stage-I GAN, обычно недостает ярких деталей и могут быть искривления форм, некоторые детали изображения также могут быть опущены на первом этапе. Stage-II GAN построен над Stage-I GAN и принимает на вход его выход, и текстовое описание, чтобы исправить и дополнить изображение. Его дискриминатор и генератор тренируются путем поочередной макисимизациии минимизации , как показано в уравнениях:\\nГдерезультат работы генератора Stage-I GAN и скрытый параметр подаются на вход дискриминатору и генератору Stage-II GAN, при этом на вход не подается случайное значение, как на первой стадии, поскольку хватает подачи случайного на вход Stage-I GAN. При этом Stage-I GAN и Stage-II GAN имеют разные полно-связные слои, чтобы отличаться по среднему значению и стандартному отклонению, таким образом на разных этапах фокусируюемся на разных деталях исходного текста (рис. 14).\\nLAPGAN (Laplacian Pyramid of Adversarial Networks)\\nLAPGAN $-$ генеративная параметрическая модель, представленная пирамидой лапласианов с каскадом сверточных нейронных сетей внутри, которая генерирует изображения постепенно от исходного изображения с низким разрешением к изображению с высоким. На каждом уровне пирамиды обучается сверточная генеративная модель, используя подход порождающих состязательных сетей. Такая стратегия позволяет декомпозировать задачу генерации изображений на последовательность уровней, что упрощает ее решение.\\nПирамида лапласианов $-$ это линейное обратимое представление изображений, состоящее из набора частотных полос изображений. Пусть- это операция сжатия изображения размера так, что новое изображение имеет размеры , также - операция расширения такой, что имеет размеры . Тогда пирамида гаусианов имеет вид , где и представляет собой раз выполненное применение . Коэффициенты на каждом уровне пирамиды лапласианов считаются так:\\nИнтуитивно каждый уровень захватывает структуру изображения. Конечный слой пирамиды лапласиановэто не разница изображений, а низко-частотное представление равное гаусиану . Реконструкция по пирамиде лапласианов происходит обратным проходом по ней:\\nПодход представленный в LAPGAN работает по такому же принципу, только на каждому шаге вместо коэфициентовиспользуются генераторы , каждый из которых захватывает распределение коэфициентов для реальных изображений на разных уровнях пирамиды лапласиана:\\nПроцедура семплинга для нашей модели LAPGAN (рис. 16). Начинаем с шумаи используем генеративную модель для создания . Потом расширяем изображение до для следующиего уровня генерации . Вместе с еще одним шумом получаем изображение различия . Продолжаем процесс, пока не получим .\\nПроцедура обучения LAPGAN (рис. 17). Начинаем с изображения размера из тренировчного набора. Берем и сжимаем его(красная стрелка) чтобы получить ; затем расширяем его(зеленая стрелка), чтобы получить низко-частотное изображение ; с равной вероятностью используем его для создния либо реального, либо сгенерированного примера для дискриминатора . В случае реального изображения(синяя стрелка) считаем цветовой контраст , которая подается на вход дискриминатору , для опредления реальное изображение или нет. В случае сгенерированного(розовая стрелка), генеративная сеть получает на вход шум и . Оно генерирует цветовой контраст , который подается на вход . В обоих случаях дискриминатор также получает (оранжевая стрелка). Оптимизируя минмакс игру условной порождающей сети учится генерировать реалистичную высоко-частотную структуру с помощью низко-частотного представления . Такая процедура проходит на всех слоях, кроме последнего, где можно уже использовать обычный GAN.\\nControlGAN (Controllable Generative Adversarial Networks)\\nКонтролируемые порождающие состязательные сети (англ. Controllable Generative Adversarial Nets, ControlGAN) $-$ модифицированная версия алгоритма GAN, состоящая из трех нейронных сетей: генератор, дискриминатор, классификатор. Концепт модели ControlGAN (рис. 18). Как и в обычной версии алгоритма, генератор пытается обмануть дискриминатор, и одновременно с этим пытается быть классифицированным как нужный класс в классификаторе.\\nХоть CGAN и являются самыми популярными моделями для генерации образцов, зависимых от внешних данных, но лучше они умеют генерировать образцы с заданными ярко отличительными чертами (цвет волос, веснушки), но менее явные детали (форма бровей, сережки) вызывают затруднения (Но более поздний StyleGAN2 справляется и с этой задачей). C помощью отделения классификатора от дискриминатора, ControlGAN позволяет контролировать черты образцов. К тому же и само качество сгенерированных изображений может быть улучшено засчет того, что такое разделение на три составляющие дает возможность дискриминатору лучше выполнять свою главную задачу.\\nБолее того, аугментация данных может помешать некоторым сетям, например, Auxiliary Classifier GAN (ACGAN) обучаться, хотя сам способ может улучшить качество классификации. К тому же в случае контролируемой генерации нет необходимости размечать тренировочные данные, выбираются желаемые характеристики объектов для генерации, а не условная информация (например, метка объекта).\\nИллюстрация принципа работы сети (рис. 19). Зеленые линии $-$ результат работы классификатора; оранжевые $-$ дискриминатора. Серые фигуры $-$ образцы из разных классов. Результат генератора обозначается голубыми участками, которыми он показывает распределение образцов, как и пытается быть классифицированным верно.\\nControlGAN минимизирует следующие уравнения:\\n,\\n,\\n.\\n$-$ метка для генератора, $-$ параметр для дискриминатора, $-$ параметр для входных меток на генератор, $-$ метки образца .\\n$-$ отношение между ошибками классификации сгенерированных образцов и изначальных данных. Для тренировки генератора используем оценочное значение , полученное, использующее классификатор и генератор из сети. При значении меньше $1$, генератор обучается на входных данных, иначе обучается генерировать образцы. С помощью этого параметра ControlGAN управляет, чему из вышеперечисленного обучаться. Сам параметр поддерживает постоянной отношение между ошибками.\\n,\\n,\\n$-$ коэффициент обучения для .\\nСм. также\\nПримечания\\n- ↑ How to Train a GAN? Tips and tricks to make GANs work\\n- ↑ Common Problems\\n- ↑ [https://research.nvidia.com/sites/default/files/pubs/2017-10_Progressive-Growing-of/karras2018iclr-paper.pdf PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION]\\n- ↑ Shane Barratt, Rishi Sharma — A Note on the Inception Score\\n- ↑ Frechet Inception distance on Wikipedia\\n- ↑ Yazeed Alharbi, Peter Wonka — Disentangled Image Generation Through Structured Noise Injection, 3.3\\n- ↑ Yazeed Alharbi, Peter Wonka — Disentangled Image Generation Through Structured Noise Injection, 3.5\\n- ↑ Augustus Odena — Conditional Image Synthesis with Auxiliary Classifier GANs\\n- ↑ Takeru Miyato — SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS\\n- ↑ Han Zhang — Self-Attention Generative Adversarial Networks\\n- ↑ Andrew Brock — LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS\\n- ↑ Jun-Yan Zhu & Taesung Park — Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\\n- ↑ Christian Ledig — Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\\n- ↑ Phillip Isola — Image-to-Image Translation with Conditional Adversarial Nets\\n- ↑ Han Zhang — StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks\\n- ↑ Li-Chia Yang — MIDINET: A CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORK FOR SYMBOLIC-DOMAIN MUSIC GENERATION\\n- ↑ CGAN\\n- ↑ Yoshua Bengio, Gre ́goire Mesnil, Yann Dauphin and Salah Rifai — Better Mixing via Deep Representations\\n- ↑ 19,0 19,1 Известные наборы данных\\n- ↑ Alec Radford, Luke Metz, Soumith Chintala — Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\\n- ↑ Kullback-Leibler divergence\\nИсточники информации\\n- Сергей Николенко, Артур Кадурин, Екатерина Архангельская. Глубокое обучение. Погружение в мир нейронных сетей. — «Питер», 2018. — С. 348-360.\\n- Medium | GAN — Why it is so hard to train Generative Adversarial Networks!\\n- CGAN Paper\\n- DCGAN Paper\\n- StackGAN Paper\\n- LAPGAN Paper\\n- ControlGAN Paper\\n- Interpreting the Latent Space Paper', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='d7a9a04e-578c-44f4-a408-27ce037f76c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cf29140243afed165440968179ea1d8500a8653f46b4f7c74e05e5af4d5b7ac9', text='PixelRNN и PixelCNN\\nPixelRNN и PixelCNN — алгоритмы машинного обучения, входящие в семейство авторегрессивных моделей и использующиеся для генерации и дополнения изображений. Алгоритмы были представлены в 2016 году компанией DeepMind[1] и являются предшественниками алгоритма WaveNet[2], который используется в голосовом помощнике Google.\\nОсновным преимуществом PixelRNN и PixelCNN является уменьшение времени обучения, по сравнению с наивными способами попиксельной генерации изображений.\\nСодержание\\n- 1 Постановка задачи\\n- 2 Идея\\n- 3 Архитектура\\n- 4 Сравнение подходов\\n- 5 Примеры реализации\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nПостановка задачи\\nПусть дано черно-белое изображениеразмером . Построчно преобразуем картинку в вектор , соединяя конец текущей строки с началом следующей. При таком представлении изображения можно предположить, что значение любого пикселя может зависеть от значений предыдущих пикселей .\\nТогда значение пикселя [3]. Оценка совместного распределения всех пикселей будет записываться в следующем виде: .можно выразить через условную вероятность и цепное правило для вероятностей\\nЗадача алгоритма — восстановить данное распределение. Учитывая тот факт, что любой пиксель принимает значение, необходимо восстановить лишь дискретное распределение.\\nИдея\\nТак как утверждается, что значение текущего пикселя зависит от значения предыдущего, то уместно использовать рекуррентные нейронные сети (RNN), а точнее долгую краткосрочную память (LSTM). В ранних работах[4] уже использовался данный подход, и вычисление скрытого состояния происходило следующим образом: , т.е. для того, чтобы вычислить текущее скрытое состояние, нужно было подсчитать все предыдущие, что занимает достаточно много времени.\\nУ алгоритма LSTM существует две модификации: RowLSTM и Diagonal BiLSTM. Основным преимуществом модификаций является возможность проводить вычисления параллельно, что ускоряет общее время обучения модели.\\nRowLSTM\\nВ данной модификации LSTM скрытое состояние считается по формуле: .\\nКак видно из формулы и Рисунка 2, значение текущего скрытого состояния не зависит от предыдущего слева, а зависит только от предыдущих сверху, которые считаются параллельно.\\nТаким образом, главным преимуществом алгоритма перед наивным LSTM является более быстрое обучение модели, однако качество получаемых изображений ухудшается. Это связанно как минимум с тем, что мы используем контекст пикселей с предыдущей строки, но никак не используем контекст соседнего слева пикселя, которые является достаточно важным, т.к. является ближайшим с точки зрения построчной генерации изображения. Значит надо научиться находить скрытое состояние слева, но делать это эффективно.\\nDiagonal BiLSTM\\nВ данной версии скрытое состояние считается таким же образом, как и в наивном подходе:, но использует следующую хитрость в самом вычислении — построчно сдвинем строки вправо на один пиксель относительно предыдущей, а затем вычислим скрытые состояния в каждом столбце, как показано на Рисунке 3. Как следствие, контекст учитывается более качественно, что повышает качество изображения, однако такая модификация замедляет модель по сравнению с подходом RowLSTM.\\nPixelCNN\\nИдея в том, что наиболее важные данные для пикселя содержатся в соседних пикселях (в рамках ядра 9x9), поэтому предлагается просто использовать известные пиксели для вычисления нового, как показано на рисунке 2.\\nАрхитектура\\nВ алгоритмах PixelRNN и PixelCNN используются несколько архитектурных трюков, позволяющих производить вычисления быстро и надежно.\\nМаскированные сверточные слои\\nВ описаниях алгоритмов фигурируют два типа маскированных сверточных слоя — MaskA, MaskB. Они необходимы для сокрытия от алгоритма лишней информации и учета контекста — чтобы ускорить обработку изображения после каждого подсчета, предлагается вместо удаления значения пикселей применять маску к изображению, что является более быстрой операцией.\\nДля каждого пикселя в цветном изображении в порядке очереди существуют три контекста: красный канал, зеленый и синий. В данном алгоритме очередь важна, т.е. если сейчас обрабатывается красный канал, то контекст только от предыдущих значений красного канала, если зеленый — то от всех значений на красном канале и предыдущих значениях на зеленом и т.д.\\nMaskA используется для того, чтобы учитывать контекст предыдущих каналов, но при этом не учитывать контекст от предыдущих значений текущего канала и следующих каналов. MaskB выполняет ту же функцию, что и MaskA, но при этом учитывает контекст от предыдущих значений текущего канала.\\nУменьшение размерности\\nНа вход в любой их указанных выше алгоритмов (PixelCNN, RowLSTM, Diagonal BiLSTM) подается большое количество объектов, поэтому внутри каждого из них сначала происходит уменьшение их количества в два раза, а затем обратное увеличение до исходного размера. Структура алгоритма с учетом уменьшения размерности показана на рисунке 4.\\nВнутреннее устройство LSTM\\nВнутреннее устройство RowLSTM и Diagonal BiLSTM блоков одинаково, за исключением того, что во втором случае добавляется операция сдвига в начале и возврат к исходной структуре изображения в конце.\\nСтруктура LSTM блока:\\n- MaskB слой input-to-state учитывает контекст из входа.\\n- Сверточный слой state-to-state учитывает контекст из предыдущих скрытых слоев.\\nИспользуя эти два сверточных слоя формально вычисление LSTM блока можно записать следующим образом:\\nгде— функция активации,\\n— операция свертки,\\n— поэлементное умножение,\\n— вектор вентиля забывания, вес запоминания старой информации,\\n— вектор входного вентиля, вес получения новой информации,\\n— вектор выходного вентиля, кандидат на выход,\\n— вектор вентиля данных,\\n— строка входных данных,\\n— вектор краткосрочной памяти,\\n— вектор долгосрочной памяти,\\nи — ядерные веса компонент input-to-state и state-to-state соответственно.\\nАрхитектура PixelRNN\\n- MaskA размером .\\n- Блоки уменьшения размеренности с RowLSTM блоком, в котором имеет размер , — . Для Diagonal BiLSTM имеет размер. , — . Количество блоков варьируется.\\n- ReLU активация.\\n- Сверточный слой размером .\\n- Softmax слой.\\nАрхитектура PixelCNN\\n- MaskA размером .\\n- Блоки уменьшения размеренности для PixelCNN.\\n- ReLU активация.\\n- Сверточный слой размером .\\n- Softmax слой.\\nСравнение подходов\\nЕсли сравнивать GAN с PixelCNN/PixelRNN, то можно отметить более хорошее качество получаемых изображений у генеративно-состязательного метода. Однако у метода GAN время обучения медленнее, чем у PixelCNN и PixelRNN. Для реализации GAN требуется найти равновесие Нэша, но в настоящее время нет алгоритма делающего это. Поэтому обучение GAN более нестабильное, если сравнивать с другими методами[7]. В настоящее время многие мировые компании используют GAN для генерации изображений, например: PGGAN от Nvidia, Exemplar GAN от Facebook и другие.\\n|Критерий\\\\название\\n|PixelCNN\\n|PixelRNN(Row LSTM)\\n|PixelRNN(Diagonal BiLSTM)\\n|GAN\\n|Время обучения\\n|Быстрый\\n|Средний\\n|Медленный\\n|Медленный\\n|Качество генерируемых изображений\\n|Наихудшее\\n|Средне-низкое\\n|Средне-высокое\\n|Высокое\\nПримеры реализации\\nСм. также\\n- Рекуррентные нейронные сети\\n- Долгая краткосрочная память\\n- Нейронные сети, перцептрон\\n- Генерация объектов', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='35c023cc-2dd0-407e-98fa-f95a95553c17', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c9ab902b3bbfc254b245217e2c281fd2956710240fe5a15dbffc33a22c11ba34', text='Вариационный автокодировщик\\nВариационный автокодировщик (англ. Variational Autoencoder, VAE) — автокодировщик (генеративная модель, которая учится отображать объекты в заданное скрытое пространство (и обратно)) основанный на вариационном выводе.\\nСодержание\\nПредпосылки\\nПри попытке использования обыкновенного автокодировщика для генерации новых объектов (желательно из того же априорного распределения, что и датасет) возникает следующая проблема. Случайной величиной с каким распределением проинициализировать скрытые векторы, для того, чтобы картинка, после применения декодера, стала похожа на картинки из датасета, но при этом не совпадала ни с одной из них? Ответ на этот вопрос не ясен, в связи с тем, что обыкновенный автокодировщик не может ничего утверждать про распределение скрытого вектора и даже про его область определения. В частности, область определения может быть даже дискретной.\\nВариационный автокодировщик в свою очередь предлагает пользователю самому определить распределение скрытого вектора.\\nОписание\\nПорождающее моделирование (англ. Generative modelling) — область машинного обучения, имеющая дело с распределением, определенном на датасете из пространства (возможно многомерного) . Так, например, популярные задачи генерации картинок имеют дело с огромным количеством измерений (пикселей).\\nТакже как и в обыкновенных кодировщиках у нас имеется скрытое вероятностное пространствосоответствующее случайной величине (распределенной как-нибудь фиксированно, здесь ). И мы хотим иметь декодер . При этом мы хотим найти такие , чтобы после разыгрывания по мы получили \"что-то похожее\" на элементы .\\nВообще, для любогомы хотим считать , здесь мы заменили на , чтобы явно показать зависимость между и и после этого применить формулу полной вероятности. Обычно около нуля почти для всех пар . Основная идея в том, что мы хотим теперь генерировать , который бы давали что-то около и только их суммировать в . Для этого нам требуется ввести еще одно распределение , которое будет получать и говорить распределение на которое наиболее вероятно будет генерировать нам такой . Теперь нам нужно как-то сделать похожими распределения и .\\nРассмотрим следующую дивергенцию Кульбака-Лейблера (Kullback–Leibler divergence, KL-div).\\n- ,\\nРаспишемкак .\\n- ,\\nЧто эквивалентно:\\n- ,\\nРассмотрим эту штуку для, тогда:\\n- ,\\nПосмотрим, на это равенство. Правую часть мы можем оптимизировать градиентным спуском (пусть пока и не совсем понятно как). В левой же части первое слагаемое — то, что мы хотим максимизировать. В то же времямы хотим минимизировать. Если у нас — достаточно сильная модель, то в какой-то момент она будет хорошо матчить , а значит их дивергенция Кульбака-Лейблера будет почти 0. Значит, при оптимизации можно исключить эту часть и стараться максимизировать только правую. В качестве бонуса мы еще получили более \"податливую\" , вместо нее можно смотреть на .\\nТеперь разберемся как оптимизировать правую часть. Сначала нужно определиться с моделью для. Обычно ее берут равной . Где и какие-то детерминированные функции на X с обучаемыми параметрами , которые мы впредь будем опускать (обычно используются нейронные сети).\\nНетрудно проверить, что для дивергенция Кульбака-Лейблера двух нормальных распределений имеет следующий вид:\\n- , KLD есть .\\nЭто значит, что\\n- .\\nТеперь здесь можно считать градиенты, для BackPropagation. С первым слагаемым в правой части все немного сложнее.мы можем считать методом Монте-Карло(МК), но тогда такая штука (из-за того, что переменные спрятаны в распределении, из которого мы генерируем себе выборку, для МК) не является гладкой относительно них, а значит непонятно, как проталкивать через это градиент. Для того, чтобы все-таки можно было протолкнуть градиент, применяется так называемый трюк репараметризации, который базируется на простой формуле .\\n- .\\nВ такой форме мы уже можем использовать BackPropagation для переменных из функцийи .\\nСледующая картинка лучше поможет осознать структуру VAE и, в частности, зачем нужен (и как работает) трюк репараметризации.\\nНа левой части диаграмма без использования reparameterization trick. На правой части диаграмма с использованием reparameterization trick.\\nвзято из https://arxiv.org/pdf/1606.05908.pdf\\nПример реализации\\nНиже приведена реализация частного случая VAE на языке Python с использованием библиотеки Pytorch. Эта реализация работает с датасетом MNIST. Размерность скрытого слоя — 2. Координаты в нем считаются независимыми (из-за этого, например, матрицадиагональная, и формула для расчета KLD немного другая).\\nclass VariationalAutoencoder(nn.Module): def __init__(self): super().__init__() self.mu = nn.Linear(32, 2) self.gamma = nn.Linear(32, 2) self.encoder = nn.Sequential(nn.Linear(784, 32), nn.ReLU(True)) self.decoder = nn.Sequential(nn.Linear(2, 32), nn.ReLU(True), nn.Linear(32, 784), nn.Sigmoid()) def forward(self, x): mu, gamma = self.encode(x) encoding = self.reparameterize(mu, gamma) x = self.decoder(encoding) return x, mu, gamma def reparameterize(self, mu, gamma): if self.training: sigma = torch.exp(0.5*gamma) std_z = Variable(torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()) encoding = std_z.mul(sigma).add(mu) return encoding else: return mu def encode(self, x): x = self.encoder(x) mu = self.mu(x) gamma = self.gamma(x) return mu, gamma def decode(self, x): return self.decoder(x) def latent(self, x): mu, gamma = self.encode(x) encoding = self.reparameterize(mu, gamma) return encoding def loss_function(input, output, mu, gamma, batch_size=batch_size): BCE = F.binary_cross_entropy(output, input) KLD = -0.5*torch.sum(1 + gamma - mu.pow(2) - gamma.exp()) KLD /= batch_size*784 return BCE + KLD\\nПрименение\\nОбласть применения вариационных автокодировщиков совпадает с областью применения обыкновенных автокодировщиков. А именно:\\n- Каскадное обучение глубоких сетей (хотя сейчас применяется все реже, в связи с появлением новых методов инициализации весов);\\n- Уменьшение шума в данных;\\n- Уменьшение размерности данных (иногда работает лучше, чем метод главных компонент[на 28.01.19 не создан]).\\nБлагодаря тому, что пользователь сам устанавливает нужное распределение скрытого вектора, вариационный кодировщик хорошо подходит для генерации новых объектов (например, картинок). Для этого достаточно разыграть скрытый вектор согласно его распределению и подать на вход декодера. Получится объект из того же распределения, что и датасет.\\nСм. также\\nПримечания\\n- Вариационные автокодировщики: теория и рабочий код\\n- Tutorial - What is a variational autoencoder?\\n- Intuitively Understanding Variational Autoencoders\\nИсточники информации\\n- Tutorial on Variational Autoencoders\\n- Datalore презентация Дениса Степанова', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='dda7e838-2144-443d-a74c-dd1c0c72b068', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='29a51f7e86c117f3a5e610087eee45e96e5b27d297fd194348576159bcb691b6', text=\"Задача трансляции изображений\\n|Определение:\\n|Задача трансляции изображения (англ. Image-to-image translation) — это задача из области компьютерного зрения, цель которой состоит в том, чтобы научиться строить соответствия между входным и выходным изображениями, используя тренировочные данные.\\nДругими словами, задача состоит в том, чтобы научиться преобразовывать изображение из одной области в другую, получая в итоге изображение со стилем (характеристиками) последней.\\nСодержание\\n- 1 Описание задачи\\n- 2 Pix2Pix\\n- 3 Pix2PixHD\\n- 4 CycleGAN\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nОписание задачи\\nЗадача разделяется на два типа в зависимости от тренировочных данных.\\nВ одном случае, у нас есть четкое представление результата, который должен получиться, а в другом случае, его нет, но есть множество, определяющее стиль желаемого результата (Рис. 2).\\nОбучение на парах изображений\\nАлгоритм трансляции изображений, обученный на парах изображений — это алгоритм трансляции одного изображения в другое, где тренировочные данные состоят из множества, в котором каждому входному изображению соответствует выходное изображение, содержащее первое с другим стилем.\\nПримерами приложения этого алгоритма являются следующие трансляции изображений:\\n- черно-белое изображение — цветное;\\n- сегментация изображения (англ. segmentation map) — реальная картинка;\\n- линии-края (англ. edges) — фотография;\\n- генерация разных поз и одежды на человеке;\\n- описывающий изображение текст — фотография.\\nНекоторые примеры изображены на Рис. 3.\\nОбучение на независимых множествах\\nАлгоритм трансляции изображений, обученный на двух независимых множествах — это такой алгоритм трансляции изображений, тренировочные данные которого состоят из двух независимых групп, описывающих свой стиль, цель которого научиться отображать одну группу в другую так, чтобы содержание изображений (общее) сохранялось, а стиль (уникальные элементы изображений) переносился.\\nПример:\\n- тренировочные данные — два множества:\\n{реальные фотографии}, {картины К. Моне};\\n- приложение — взяли любую фотографию, например, поле с цветами; получили поле с цветами в стиле К. Моне.\\nPix2Pix\\nPix2Pix[3] — это подход для трансляции изображений с помощью глубоких сверточных нейронных сетей.\\nАрхитектура\\nPix2Pix реализует архитектуру условных порождающих состязательных сетей (англ. CGAN), где для генератора взята архитектура, основанная на U-Net[5], а для дискриминатора используется сверточный классификатор PatchGAN[6], который штрафует алгоритм на уровне участков изображения.\\nГенератор CGAN'a работает следующим образом: на вход подается one-hot вектор класса x и вектор шума z, в результате прохода через условный генератор выдается сгенерированное изображение этого класса. Таким образом, генератор можно представить, как следующую функцию:\\nГенератор Pix2Pix работает cхожим образом, но вместо вектора класса подается изображение, а вектор шума и вовсе убирается, потому что он не вносит достаточно стохастичности в результат работы генератора.\\nГенератор обучается создавать максимально правдоподобные выходные изображения, дискриминатор же учится как можно лучше отличать фальшивые изображения от реальных.\\nГенератор\\nДля генератора Pix2Pix используется U-net-генератор.\\nU-net-генератор[5] — это модель encoder-decoder с добавлением пропускаемых соединений (англ. skip-connections) между зеркальными слоями в стеках кодировщика и декодера.\\nАлгоритм работы генератора:\\n- на вход подается изображение;\\n- далее последовательно применяются свертка, батч-нормализация (англ. Batch Norm layer), функция активации LeakyReLU и пулинг, что, тем самым, уменьшает количество признаков;\\n- при этом, следуя архитектуре U-net, добавляются пропускаемые соединения между каждым слоем и слоем , где — общее количество слоев; каждое пропускаемое соединение просто объединяет все каналы на уровне с другими на слое ; таким образом, информация, которая могла быть сильно сжата (потеряна), может доходить до некоторых более поздних слоев;\\n- после того, как получен слой минимального размера, начинается работа декодера, который делает то же, что и кодировщик, с отличием в слое, обратном пулингу, который увеличивает количество признаков;\\n- также в декодере добавляется dropout, чтобы достигнуть стохастичности на выходе генератора.\\nГенератор должен не только обмануть дискриминатор, но и приблизиться к истине, поэтому его функция ошибки выглядит следующим образом:\\n[8] , где — попиксельная разница.\\nДискриминатор\\nДля дискриминатора данной сети используется сверточный дискриминатор PatchGAN.\\nPatchGAN дискриминатор[6] — это тип дискриминатора для генеративных состязательных сетей, который штрафует алгоритм на уровне локальных фрагментов (патчей).\\nДискриминатор PatchGAN пытается определить, является ли каждый фрагмент размера изображения настоящим или поддельным. Этот дискриминатор сверточно запускается по изображению, усредняя все ответы, чтобы посчитать окончательный результат .\\nПроще говоря, для каждого фрагмента определяется матрица классификаций, где все значения находятся в промежутке , где — подделка. Проходясь сверткой, в итоге получаем конечную матрицу классификаций. Таким образом, для поддельного изображения от генератора PatchGan должен попытаться вывести матрицу нулей.\\nИнтересно, что может быть намного меньше полного размера изображения и при этом давать результаты высокого качества. Это выгодно, потому что меньший PatchGAN имеет меньше параметров, работает быстрее и может применяться к изображениям большого размера.\\nТакой дискриминатор эффективно моделирует изображение как Марковское случайное поле[10], предполагая независимость между пикселями, разделенных диаметром более одного фрагмента.\\nПолное описание архитектуры\\nДля того, чтобы описать полный порядок работы Pix2Pix, обратимся к примеру:\\nПусть у вас есть набор пар, состоящий из реальных фотографий и их сегментаций. Задача состоит в том, чтобы научиться генерировать из сегментированных изображений реальные.\\n- помещается сегментированное изображение в генератор U-Net, и он генерирует некоторый выход;\\n- дальше сгенерированное изображение соединяется с исходным входным сегментированным изображением, и это все идет в PatchGan дискриминатор, который выводит матрицу классификации, состоящую из значений между 0 и 1, которая показывает, насколько реальны или поддельны разные части этого изображения;\\n- затем для вычисления ошибки дискриминатора проводится 2 сравнения:\\n- сравнение матрицы классификации от {объединения сгенерированного изображения с исходным входным сегментированным изображением} с матрицей из всех 0;\\n- матрицы классификация от {объединения реального изображения с исходным входным сегментированным изображением} с матрицей из всех 1;\\n- затем для вычисления ошибки генератора проводится сравнение матрицы классификации от {объединения сгенерированного изображения с исходным входным изображением} с матрицей из всех 1, которое считается с помощью BCE Loss, которое впоследствии суммируется с попиксельным сравнением реального изображения со сгенерированным, домноженным на ;\\nПримеры\\nДля тестирования решения были проведены следующие эксперименты:\\n- сегментированные изображения фотографии;\\n- нарисованная карта фотоснимок;\\n- черно-белые фотографии цветные фотографии;\\n- линии-края фотографии;\\n- эскизы-рисунки фотографии;\\n- день ночь;\\nи так далее.\\nPix2PixHD\\nPix2PixHD[13]— нейронная сеть, основанная на архитектуре Pix2Pix, которая является новым удачным подходом для решения задачи получения изображений высокого разрешения из сегментированных изображений.\\nОснова Pix2Pix была улучшена за счет изменений в генераторе, дискриминаторе и функции ошибки.\\nГенератор был разбит на две подсетии так, что первая приняла роль глобальной сети генератора, а вторая стала локальным усилителем сети. Таким образом, генератор стал задаваться набором . Глобальная сеть генератора работает с изображениями с разрешением , в то время как локальный усилитель сети принимает на вход изображения с разрешением в 4 раза больше размера вывода предыдущей сети. Для получения изображений большего разрешения могут быть добавлены дополнительные локальные усилители сети.\\nЧтобы различать реальные и синтезированные изображения с высоким разрешением, дискриминатор должен иметь большое поле восприятия. Для этого потребуется либо более глубокая сеть, либо более крупные сверточные ядра, оба из которых увеличат емкость сети и потенциально могут вызвать переобучение. Кроме того, оба варианта требуют большего объема памяти для обучения, что уже является дефицитным ресурсом для создания изображений с высоким разрешением. Для решения проблемы предлагаем используется 3 дискриминатора, которые имеют идентичную структуру сети, но работают с разными масштабами изображения[14].\\nФункция ошибки была улучшена за счет добавления ошибки (feature matching loss) в разных масштабах изображения для каждого дискриминатора, для вычисления которой будем использовать выдаваемые значения дискриминатора на разных слоях изображения: , где — количество слоев, — количество элементов в каждом слое, — исходное сегментированное изображение, — соответствующее реальное изображение, — сгенерированное изображение.\\nНа рисунках 11 и 12 приведены примеры генерации изображения по входным сегментированным изображениям с применением различных стилей.\\nCycleGAN\\nНейронная сеть, в отличии от описанной выше Pix2Pix позволяет реализовать решение задачи обучения на независимых множествах. Обычно применяются для задач изменения стиля фотографий.\\nАрхитектура\\nCycleGAN[16] реализует архитектуру циклически-согласованных состязательных сетей (англ. — Cycle-Consistent Adversarial Networks), суть которой состоит в решении проблемы отсутствия парного набора данных.\\nВ Архитектуре присутствуют 2 генератора и 2 дискриминатора которые выполняют различные задачи:\\n- Генератор учится преобразовывать исходное изображение в выходное изображение\\n- Генератор учится преобразовывать выходное изображение в исходное изображение\\n- Дискриминатор учится различать изображение и сгенерированное изображение\\n- Дискриминатор учится различать изображение и сгенерированное изображение\\nСтруктура генератора состоит из кодировщика (англ. — Encoder), создающего функцию особенностей из исходного изображения, трансформатора (англ. — Transformation), изменяющего функцию особенностей для создания сгенерированного изображения, и декодера (англ. — Decoder), возвращающего функцию особенностей обратно в формат изображения. Структура дискриминатора состоит из декодера, извлекающего особенности из входного изображения, и классификатора, определяющего сгенерировано ли изображение.\\nРеализация элементов дискриминатора и генератора аналогичны тем, которые используются в Pix2Pix.\\nСеть предоставляет подход перевода изображения из исходного домена [18](англ. — Mode collapse), следует проверить отображение , который пытается сопоставить и .в целевой домен при отсутствии парных примеров. Цель задачи в изучении отображения , так, чтобы распределение изображений было неотличимо от распределения с учетом состязательной потери (aнгл. — Сonsistency loss). Также чтобы избежать коллапса мод\\nДругими словами для выполнения успешного преобразования должно выполниться следующее условие\\nФункция потери\\nФункция потери[19] должна быть выполнена таким образом, что все отображения должны быть противоположными друг другу и взаимно однозначными.\\nОна состоит из потери согласованности цикла (англ. — Cycle Consistency Loss) и состязательной потери (англ. — Adversarial loss).\\n,\\nгде— гиперпараметр для уравнения потери согласованности цикла\\nСм. также\\n- Компьютерное зрение\\n- Generative Adversarial Nets (GAN)\\n- Сверточные нейронные сети\\n- Сегментация изображений\\nПримечания\\n- ↑ 1,0 1,1 CycleGAN — GitHub\\n- ↑ CycleGAN — Towardsdatascience\\n- ↑ 3,0 3,1 Pix2Pix — GitHub\\n- ↑ 4,0 4,1 Pix2Pix — Towardsdatascience\\n- ↑ 5,0 5,1 U-Net: Convolutional Networks for Biomedical Image Segmentation\\n- ↑ 6,0 6,1 Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks\\n- ↑ Pix2Pix GAN Models — Machine Learning Mastery\\n- ↑ BCE Loss — towardsdatascience\\n- ↑ The PatchGAN structure — ResearchGate\\n- ↑ Markov random field — Wikipedia\\n- ↑ Pix2pix UNet_128 GAN network architecture — ResearchGate\\n- ↑ Sik-Ho Tsang\\n- ↑ 13,0 13,1 13,2 Pix2PixHD — GitHub\\n- ↑ High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs\\n- ↑ 15,0 15,1 Алгоритм CycleGAN\\n- ↑ Cycle-Consistent Adversarial Networks\\n- ↑ 17,0 17,1 17,2 Пример работы CycleGAN\\n- ↑ Улучшение обучения GAN\\n- ↑ Cyclic_loss\\nИсточники информации\\n- Image-to-Image Translation with Conditional Adversarial Networks\\n- High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs\\n- Learning image-to-image translation using paired and unpaired training samples\\n- Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\\n- Apply Generative Adversarial Networks (GANs) — Coursera\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='af2d1347-9895-4bfa-b701-e10477156ff4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6cbe1b85e686e8a654b9303409098101a7b856196d9840a44bda0e788b0d0ebc', text='Генерация текста\\nСодержание\\nЗадача генерации текста\\nОдной из методик машинного обучения являются предиктивные модели, предсказывающие значения своих будущих входов. Такие модели являются мощным средством машинного обучения языку. Они должны уметь предсказывать, как можно продолжить текущий отрывок текста, а в конечном итоге — уметь генерировать связный осмысленный текст.\\nЗадача генерации текста включает в себя задачу обработки естественного языка (Natural Language Processing, NLP) [1] и реализует возможность языковой модели отвечать на вопросы, на основе исходного текста предсказывать последующее слово и генерировать осмысленный текст.\\nИстория создания языковых моделей\\nПервый алгоритм генерации текста GPT (Generative Pre-trained Transformer) разработали по методологии SCRUM и выпустили в 2018 году. Его обучали на 117 миллионах параметров, что в те времена считалось хорошим показателем. На основе этой разработки, в конце 2018 года компания Google разработала по методологии SCRUM двунаправленную нейросеть BERT (Bidirectional Encoder Representations from Transformers) [2], получившую статус state-of-the-art — высшую точку развития технологии на тот момент.\\nАлгоритм GPT первого поколения был разработан по методологии SCRUM и обучен на выборке массивов текстов из Wikipedia и из литературных произведений. Позже создатели поняли, что это не самый оптимальный тип данных для обучения модели. Нейросеть быстрее учится понимать естественную речь на основе простых постов в интернете. Поэтому в 2019 году OpenAI по методологии SCRUM обучили GPT второго поколения на данных, собранных с обычных форумов — выборка пользователей Reddit, причем обязательно с рейтингом выше среднего (как минимум 3 кармы). Последнее учитывалось, чтобы отбросить рекламные или спам-страницы и оставить только полезные. Новая версия нейросети получила название GPT-2.\\nGPT-2\\nGPT-2 (Generative Pre-trained Transformer 2) — это огромная языковая модель, созданная компанией OpenAI. Модель основана на архитектуре Transformer[3], с 1.5 млрд параметров, обученная на датасете, состоящем из 8 млн специально отобранных веб-страниц.\\nЧто умеет GPT-2\\nИзначально нейросеть обучали предсказывать следующее слово в предложении. Помимо основной задачи модель качественно генерирует образцы текста из-за использования трансформерной архитектуры и обучения на большом датасете. Таким образом, GPT-2 - не просто языковая модель, а мощный генератор текстов.\\nДополнительные возможности\\n- Краткий пересказ текста или обобщение. В качестве входных данных нужно подать не просто фрагмент, а целый текст, а модель выдаст краткое содержание рассказа.\\n- Ответы на вопросы исходя из содержания текста. На входе подается несколько примеров в виде «Вопрос-Ответ», в конце же дается реальный вопрос, на который нейросеть выдает по тому же макету ответ.\\n- Перевод текстов. Механизм работы с переводами похож на механизм работы с ответами на вопросы: на вход подается примеры в виде «Слово-Перевод», в конце подается только слово, а нейросеть выдает перевод.\\nОсобенность GPT-2\\nГлавной особенностью GPT-2 является то, что нейросеть не нужно дообучать под конкретную задачу, чтобы та показывала нужные пользователю результаты. Нейросеть приспосабливается к стилю и содержанию текста, что позволяет ей генерировать реалистичные отрывки, продолжающие исходные фразы. Сразу после обучения нейросеть уже готова сгенерировать текст со всеми логическими вставками: повторное упоминание имен героев, цитаты, отсылки, выдержка одного стиля на протяжении всего текста, связанное повествование.\\nИсходный код\\nOpenAI отказались выкладывать полную версию GPT-2, так как посчитали, что ей будут пользоваться для генерации фейковых новостей. В сети доступна версия GPT-2 с уменьшенным количеством параметров [4] (до 117 млн параметров, вместо 1.5 млрд, как в полной модели).\\nGPT-3\\nGPT-3 (Generative Pre-trained Transformer 3) — третье поколение языковой модели от OpenAI. GPT-3 продолжает подход OpenAI, заложенный в GPT и GPT-2 и поэтому разрабатывается по методологии SCRUM. По сравнению с GPT-2 количество используемых параметров увеличилось более чем в 100 раз: с 1,5 до 175 млрд. Для обучения алгоритма исследователи собрали датасет, состоящий из английской Википедии, которая охватывает около 6 миллионов статей, составляет всего 0,6 процента ее обучающих данных. Остальное - оцифрованные книги и различные веб-страницы. Это означает, что обучающие данные GPT-3 включают в себя не только новостные статьи, рецепты и стихи, но и руководства по кодированию, фанфики, религиозные пророчества, путеводители по певчим птицам Боливии и все остальное, что только можно представить.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='9981bce5-7abd-467e-9232-7cf7453ab082', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f84268cd906225d07c0aecb777b443dbf5a4d704479453833836c0237c6b51ae', text='Генерация изображения по тексту\\nАвтоматическое создание реалистичных высококачественных изображений из текстовых описаний было бы интересно и довольно полезно, так как имеет множество практических применений, но современные системы искусственного интеллекта все еще далеки от этой цели, так как это является довольно сложной задачей в области компьютерного зрения. Однако в последние годы были разработаны универсальные и мощные рекуррентные архитектуры нейронных сетей для изучения различных представлений текстовых признаков. Между тем, глубокие сверточные генеративные состязательные сети (англ. Generative Adversarial Nets, GANs) начали генерировать весьма убедительные изображения определенных категорий, таких как лица, обложки альбомов и интерьеры комнат. Образцы, генерируемые существующими подходами \"текст-изображение\", могут приблизительно отражать смысл данных описаний, но они не содержат необходимых деталей и ярких частей объекта. В данной статье рассмотрены формулировка и глубокая архитектура GAN, а также объединены достижения в генерации изображений по тексту.\\nСодержание\\n- 1 Обзор генеративных моделей\\n- 2 Области применения\\n- 3 См. также\\n- 4 Примечания\\n- 5 Источники информации\\nОбзор генеративных моделей\\nСообщество глубокого обучения быстро совершенствует генеративные модели. Среди них можно выделить три перспективных типа: авторегрессионные модели (англ. Autoregressive model, AR-model), вариационные автокодировщики (англ. Variational Autoencoder, VAE) и генеративные состязательные сети. На данный момент самые качественные изображения генерируют сети GAN (фотореалистичные и разнообразные, с убедительными деталями в высоком разрешении). Поэтому в данной статье мы сосредоточимся на моделях GAN.\\n|Модель\\n|Inception Score [1]\\n|FID [2]\\n|Разрешение генерируемой картинки\\n|Реализация\\n|Модификация (отличие от GAN)\\n|Пример сгенерированной картинки\\n|COCO\\n|Caltech-UCSD\\n|Attribute2Image, 2015\\n|—\\n|—\\n|да\\n|Генерация изображения как смесь переднего и заднего планов на основе многоуровневой генеративной модели.\\n|GAN-INT-CLS, 2016\\n|да\\n|Обучение на текстовых признаках, кодируемых гибридной сверточно-рекуррентной нейронной сетью.\\n|StackGAN, 2017\\n|да\\n|Генерация изображения происходит в два этапа, на первом этапе создается примитивная форма изображения и задаются цвета объектов, на втором исправляются дефекты предыдущего этапа и добавляются более мелкие детали.\\n|FusedGAN, 2018\\n|—\\n|—\\n|нет\\n|Генерация изображения в два этапа, на первом задаются признаки стиля, на втором генерируется изображение.\\n|ChatPainter, 2018\\n|—\\n|—\\n|нет\\n|В качестве дополнительных данных для обучения используется диалог описания изображения.\\n|StackGAN++, 2018\\n|да\\n|Генерация изображений разного масштаба из разных ветвей древовидной структуры, в которой несколько генераторов разделяют между собой большинство своих параметров.\\n|HTIS, 2018\\n|—\\n|—\\n|нет\\n|Генерация изображения разбивается на несколько шагов, сначала создается семантический макет из текста, затем этот макет преобразовывается в изображение.\\n|AttnGAN, 2018\\n|да\\n|Выделение слов для генерации областей картинки с помощью механизма внимания.\\n|CVAE&GAN, 2018\\n|—\\n|—\\n|—\\n|нет\\n|Разделение переднего и заднего плана, сначала CVAE генерирует картинку в плохом качестве, после качество повышается с помощью GAN.\\n|MMVR, 2018\\n|—\\n|—\\n|нет\\n|Обучение на изменённом описании картинки.\\n|MirrorGAN, 2019\\n|—\\n|да\\n|Генерация изображения с использованием идеи обучения посредством переописания.\\n|Obj-GAN, 2019\\n|—\\n|да\\n|Основной принцип генерации изображений заключается в распознавании и создании отдельных объектов из заданного текстового описания.\\n|LayoutVAE, 2019\\n|—\\n|—\\n|—\\n|нет\\n|Генерация стохастических макетов сцен (англ. stochastic scene layouts) из заданного набора слов.\\n|MCA-GAN, 2019\\n|—\\n|—\\n|—\\n|нет\\n|Генерация изображения с произвольных ракурсов, основывающаяся на семантическом отображении (англ. semantic mapping).\\nAttribute2Image[3]) моделирует изображение как смесь переднего и заднего планов и разрабатывает многоуровневую генеративную модель с выделенными скрытыми переменными (рис. 4), которые можно изучать от начала до конца с помощью вариационного автокодировщика (англ. Variational Autoencoder, VAE). Экспериментируя с естественными изображениями лиц и птиц на наборах данных Caltech-UCSD и LFW Attribute2Image демонстрирует, что способен генерировать реалистичные и разнообразные изображения размером 64x64 пикселя с распутанными скрытыми представлениями (англ. disentangled latent representations) — это состояние, в котором каждый фактор приобретается как каждый элемент скрытых переменных, то есть если в модели с обученными скрытыми представлениями смещение одной скрытой переменной при сохранении других фиксированными генерирует данные, показывающие, что изменяется только соответствующий фактор. (рис. 3). Таким образом, изученные генеративные модели показывают отличные количественные и визуальные результаты в задачах реконструкции и завершения изображения, обусловленного атрибутами.\\nGAN-INT-CLS\\nГлубокая сверточная генеративная состязательная сеть (англ. Deep Convolutional Generative Adversarial Network, DCGAN) — обусловлена текстовыми признаками, кодируемыми гибридной сверточно-рекуррентной нейронной сетью на уровне символов. DCGAN имеет эффективную архитектуру (рис. 1) и обучающую структуру, которая позволяет синтезировать изображения птиц и цветов из текстовых описаний.\\nДля обучения такой модели для птиц был использован набор данных Caltech-UCSD, а для цветов — Oxford-102. Наряду с этим было собрано по пять текстовых описаний на изображение, которые были использованы в качестве параметров оценки.\\nDCGAN во многих случаях может генерировать на основе текста визуально-правдоподобные изображения размером 64×64 пикселя, а также отличается тем, что сама модель является генеративной состязательней сетью, а не только использует ее для постобработки. Текстовые запросы кодируются с помощью текстового кодировщика векторное представление слов. Затем применяется концепция условной генеративной состязательной сети (англ. Conditional Generative Adversarial Network, CGAN). Таким образом, описание, внедренное в сначала сжимается с помощью полностью связанного слоя до небольшого размера (на практике было использовано 128), затем применяется функция активации Leaky ReLU и результат конкатенируется с вектором шума ., который позволяет получить\\nКак только модель научилась генерировать правдоподобные изображения (рис. 2), она должна также научиться согласовывать их с текстовым описанием, и было бы неплохо, если бы она научилась оценивать, соответствуют ли изображения заданному описанию или нет. Модель должна неявно разделять два источника ошибок: нереалистичные образы (для любого текста) и реалистичные образы неправильного класса, которые не соответствуют текстовым признакам. Алгоритм обучения GAN был модифицирован таким образом, чтобы разделять эти источники ошибок. В дополнение к реальным/поддельным входным данным в дискриминатор во время обучения был добавлен третий тип входных данных, состоящий из реальных изображений с несовпадающим текстовым описанием, на которых дискриминатор должен обучиться оценивать поддельные изображения.\\nStackGAN\\nСоставные генеративные состязательные сети (англ. Stacked Generative Adversarial Networks, StackGAN[5]) служат для генерации фотореалистичных изображений размера 256x256, заданных текстовыми описаниями. В данной модели трудная задача генерации изображения разлагается на более мелкие подзадачи с помощью процесса эскиз-уточнения (англ. sketch-refinement process). Таким образом, Stage-I GAN рисует примитивную форму и цвета объекта на основе данного текстового описания, получая изображения Stage-I с низким разрешением (рис. 5). Stage-II GAN принимает результаты Stage-I и текстовые описания в качестве входных данных и генерирует изображения высокого разрешения с фотореалистичными деталями. Он способен исправлять дефекты в результатах этапа I и добавлять более мелкие детали в процессе уточнения (англ. refinement process). Чтобы улучшить разнообразие синтезированных изображений и стабилизировать обучение CGAN, вводится техника условно-когнитивной регуляции (англ. Conditioning Augmentation), которая способствует плавности в обусловливающем многообразии.\\nВклад предлагаемого метода состоит в следующем:\\n- Предлагается новая составная генеративная состязательная сеть для синтеза фотореалистичных изображений из текстовых описаний. Он разбивает сложную задачу генерации изображений с высоким разрешением на более мелкие подзадачи и значительно улучшает состояние дел. StackGAN впервые генерирует изображения с разрешением 256х256 пикселей с фотореалистичными деталями из текстовых описаний.\\n- Предлагается техника Condition Augmentation для стабилизации обучения CGAN, а также для улучшения разнообразия генерируемых выборок.\\n- Обширные качественные и количественные эксперименты демонстрируют эффективность дизайна модели в целом, а также влияние отдельных компонентов, которые предоставляют полезную информацию для разработки будущих условных моделей GAN.\\nГенератор Stage-II проектируется как сеть кодировщик-декодировщик с остаточными блоками. Что касается дискриминатора, его структура аналогична структуре дискриминатора Stage-I только с дополнительными блоками понижающей дискретизации, поскольку на этом этапе размер изображения больше.\\n|Набор данных\\n|Inception Score [1]\\n|Caltech-UCSD\\n|Oxford-102\\n|COCO\\nДля проверки метода были проведены обширные количественные и качественные оценки. Результаты работы модели сравниваются с двумя современными методами синтеза текста в изображение — GAN-INT-CLS и GAWWN (рис. 6).\\nFusedGAN\\nДля улучшения генерации изображений по описанию и получения контролируемой выборки, некоторые модели разделяют процесс генерации на несколько этапов. Например, в модели Attribute2Image раздельная генерации фона и переднего плана позволила получить контролируемую выборку (фиксируя фон и меняя основную сцену, и наоборот). В свою очередь модель FusedGAN[6] может выполнять контролируемую выборку различных изображений с очень высокой точностью, что так же достигается путём разбиения процесса генерации изображений на этапы. В данной модели в отличие от StackGAN, где несколько этапов GAN обучаются отдельно с полным контролем помеченных промежуточных изображений, FusedGAN имеет одноступенчатый конвейер со встроенным StackGAN.\\nКонтролируемая выборка относится к процессу выборки изображений путем изменения таких факторов как стиль, фон и другие детали. Например, можно генерировать разные изображения, оставляя постоянным фон, или генерировать изображения в различных стилях, сохраняя остальной контекст неизменным. Основное преимущество данной модели состоит в том, что для обучения она может использовать полу-размеченные данные. Это означает, что помимо размеченных данных (изображение и его описание) для генерации изображений, модель может использовать изображения без текстового описания. Модель состоит из двух взаимосвязанных этапов (рис. 19):\\n- На первом этапе с помощью GAN выполняется генерация изображений из случайного вектора, а также создаются признаки для стиля, в котором будет оформлено сгенерированное изображение на втором шаге.\\n- На втором этапе CGAN генерирует окончательное изображение (то есть изображение, соответствующее описанию и стилю заданному на первом шаге), используя в качестве входных данных текстовое описание и данные полученные с первого шага.\\nвыступает в роли шаблона подавая дополнительные признаки на второй шаг генерации. Вследствие чего изображения сгенерированных птиц не только соответствуют описанию, но также сохраняют информацию о стиле. Поэтому вместо того, чтобы учиться с нуля, строится поверх , добавляя к нему стили с помощью текстового описания. Следует отметить, что в модели отсутствует явная иерархия, поэтому оба этапа могут обучаться одновременно, используя альтернативный метод оптимизации.\\nДля оценки качества генерируемых изображений с помощью FusedGAN, были отобраны 30 тысяч изображений и посчитано inception scores, используя предварительно обученную модель на тестовом наборе Caltech-UCSD. Данные сравнения приведены в таблице.\\n|Модель\\n|Inception Score [1]\\n|GAN-INT-CLS\\n|StackGAN-I\\n|FusedGAN\\nChatPainter\\nВ предыдущих и последующих моделях для создания изображений используются текстовые описания. Однако они могут быть недостаточно информативными, чтобы охватить все представленные изображения, и модели будет недостаточно данных для того чтобы сопоставить объекты на изображениях со словами в описании. Поэтому в качестве дополнительных данных в модели ChatPainter предлагается[7] использовать диалоги, которые дополнительно описывают сцены (пример рис. 16). Это приводит к значительному улучшению Inception score[1] и качества генерируемых изображений в наборе данных MS COCO (Microsoft COCO dataset). Для создания нового набора данных с диалогами, были объединены описания представленные в наборе данных MS COCO, с данными из Visual Dialog dataset (VisDial)[8].\\nДанная архитектура (рис. 15) опирается на модель StackGAN. StackGAN генерирует изображение в два этапа: на первом этапе генерируется грубое изображение 64×64, а на втором генерируется уже улучшенное изображение 256×256.\\nФормирование вектора текстовых описаний [9]. Для генерации диалоговых вложений используется два метода:происходит путем кодирования подписей с помощью предварительно обученного кодировщика\\n- Нерекурсивный кодировщик — сжимает весь диалог в одну строку и кодирует его с помощью предварительно обученного кодировщика Skip-Thought[10].\\n- Рекурсивный кодировщик — генерирует Skip-Thought векторы (англ. Skip-Thought Vectors)[11] для каждого сообщения в диалоге, а затем кодирует их двунаправленной рекуррентной нейронной сетью c LSTM.\\nЗатем выходы описаний и диалогов объединяются и передаются в качестве входных данных в модуль аугментации данных (англ. Conditioning Augmentation, CA). Модуль CA нужен для получения скрытых условных переменных, которые передаются на вход генератору. Архитектура блоков (рис. 15) upsample, downsample и residual blocks сохраняется такой же, как и у исходного StackGAN\\nРезультаты тестирования и сравнение модели ChatPainter с другими приведены в таблице. Из неё видно, что модель ChatPainter, которая получает дополнительную диалоговую информацию, имеет более высокий Inception score[1], в отличии от модели StackGAN. Кроме того, рекурсивная версия ChatPainter получилась лучше, чем нерекурсивная версия. Вероятно, это связано с тем, что в нерекурсивной версии кодировщик не обучается на длинных предложениях сворачивая весь диалог в одну строку.\\n|Модель\\n|Inception Score [1]\\n|StackGAN\\n|ChatPainter (non-recurrent)\\n|ChatPainter (recurrent)\\n|AttnGAN\\nStackGAN++\\nХотя генерирующие состязательные сети (GAN) показали замечательный успех в различных задачах, они все еще сталкиваются с проблемами при создании изображений высокого качества. Поэтому в данном разделе, во-первых, предлагается двухэтапная генеративная состязательная сетевая архитектура StackGAN-v1[12] для синтеза текста в изображение. Stage-I по-прежнему рисует примитивную форму и цвета сцены на основе заданного текстового описания, что дает изображения с низким разрешением. Stage-II все также принимает результаты этапа I и текстовое описание в качестве входных данных и генерирует изображения высокого разрешения с фотореалистичными деталями. Во-вторых, усовершенствованная многоэтапная генеративно-состязательная сетевая архитектура StackGAN-v2 предлагается как для условных, так и для безусловных генеративных задач. StackGAN-v2 состоит из нескольких генераторов и нескольких дискриминаторов, организованных в древовидную структуру (рис. 7); изображения в нескольких масштабах, соответствующие одной и той же сцене, генерируются из разных ветвей дерева. StackGAN-v2 демонстрирует более стабильное поведение при обучении, чем StackGAN-v1, за счет совместной аппроксимации нескольких распределений.\\nНесмотря на успех, GAN, как известно, сложно обучить. Тренировочный процесс обычно нестабилен и чувствителен к выбору гиперпараметров. При обучении GAN генерировать изображения с высоким разрешением (например, 256x256), вероятность того, что распределение изображений и распределение моделей будет совместно использовать один и тот же носитель в многомерном пространстве, очень мала. Более того, обычным явлением сбоя при обучении GAN является схлопывание мод распределения (англ. mode collapse), когда многие из сгенерированных выборок содержат одинаковый цвет или узор текстуры.\\nПредлагается продвинутая многоэтапная генеративно-состязательная сетевая архитектура StackGAN-v2 как для условных, так и для безусловных генеративных задач. StackGAN-v2 имеет несколько генераторов, которые разделяют между собой большинство своих параметров в древовидной структуре. Входные данные сети можно рассматривать как корень дерева, а изображения разного масштаба генерируются из разных ветвей дерева. Конечная цель генератора на самой глубокой ветви — создание фотореалистичных изображений с высоким разрешением. Генераторы в промежуточных ветвях имеют прогрессивную цель создания изображений от малых до больших для достижения конечной цели. Вся сеть совместно обучается аппроксимировать различные, но сильно взаимосвязанные распределения изображений в разных ветвях. Кроме того, используется регуляризация согласованности цвета (англ. color-consistency regularization), чтобы генераторы могли генерировать более согласованные образцы для разных масштабов.\\n|Набор данных\\n|StackGAN-v1\\n|StackGAN-v2\\n|Caltech-UCSD\\n|Oxford-102\\n|MS COCO\\nНа основе этих генеративных моделей также изучалась условная генерация изображений. В большинстве методов используются простые условные переменные, такие как атрибуты или метки классов. Существуют также работы с изображениями для создания изображений, включая редактирование фотографий, перенос области и сверхвысокое разрешение. Однако методы сверхвысокого разрешения могут добавлять только ограниченное количество деталей к изображениям с низким разрешением и не могут исправить большие дефекты.\\nВведен термин регуляризации согласованности цвета, чтобы образцы, сгенерированные с одного и того же входа на разных генераторах, были более согласованными по цвету и, таким образом, улучшили качество сгенерированных изображений (рис. 8).\\nПримеры результата работы для тестовых наборов Oxford-102 (крайние левые четыре столбца) и COCO (крайние правые четыре столбца).[12].\\nHTIS\\nВ данном разделе предлагается новый иерархический подход к синтезу текста (Hierarchical Text-to-Image Synthesis, HTIS[13]) в изображение путем определения семантического макета. Вместо того, чтобы изучать прямое отображение текста в изображение, алгоритм разбивает процесс генерации на несколько шагов, на которых он сначала создает семантический макет из текста с помощью генератора макета и преобразует макет в изображение с помощью генератора изображений (рис. 9). Предлагаемый генератор компоновки постепенно создает семантическую компоновку от грубого к точному, генерируя ограничивающие рамки (англ. bounding box) объекта и уточняя каждую рамку, оценивая формы объектов внутри нее. Генератор изображений синтезирует изображение, обусловленное предполагаемым семантическим макетом, что обеспечивает полезную семантическую структуру изображения, совпадающего с текстовым описанием.\\n- Генератор рамок (англ. Box Generator) принимает в качестве входных данных вложения текста и генерирует грубую компоновку, комбинируя экземпляры объектов в изображении. Выходные данные генератора представляют собой набор ограничивающих рамок , где каждая ограничивающая рамка определяет местоположение, размер и метку категории -го объекта.\\n- Генератор фигур (англ. Shape Generator) берет набор ограничивающих рамок, созданных на предыдущем шаге, и предсказывает формы объектов внутри рамок. Результатом является набор двоичных масок , где каждая маска определяет форму переднего плана -го объекта.\\n- Генератор изображений (англ. Image Generator) принимает карту семантических меток , полученную путем агрегирования масок по экземплярам, и текстовое описание в качестве входных данных, и генерирует изображение, переводя семантический макет в пиксели, соответствующие текстовому описанию.\\nМодель не только генерирует семантически более значимые изображения, но также позволяет автоматически аннотировать генерируемые изображения. Созданные изображения и процесс генерации под управлением пользователя путем изменения сгенерированного макета сцены.\\nВозможности предложенной модели были продемонстрированы на сложном наборе данных MS COCO. Оказывается, модель может существенно улучшить качество изображения, интерпретируемость вывода и семантическое выравнивание вводимого текста по сравнению с существующими подходами.\\n|Модель\\n|Inception Score [1]\\n|StackGAN\\n|Рассматриваемая модель\\nСоздание изображения из общего предложения «люди, едущие на слонах, идущих по реке» требует множества рассуждений о различных визуальных концепциях, таких как категория объекта (люди и слоны), пространственные конфигурации объектов (верховая езда), контекст сцены (прогулка по реке) и т. д., что намного сложнее, чем создание одного большого объекта, как в более простых наборах данных. Существующие подходы не привели к успеху в создании разумных изображений для таких сложных текстовых описаний из-за сложности обучения прямому преобразованию текста в пиксель из обычных изображений.\\nПоэтому вместо того, чтобы изучать прямое отображение текста в изображение, был предложен альтернативный подход, который строит семантический макет как промежуточное представление между текстом и изображением. Семантический макет определяет структуру сцены на основе экземпляров объектов и предоставляет детальную информацию о сцене, такую как количество объектов, категорию объекта, расположение, размер, форму и выдает довольно неплохой результат (рис. 10).\\nAttnGAN\\nОбщепринятый подход заключается в кодировании всего текстового описания в глобальное векторное пространство предложений (англ. global sentence vector). Такой подход демонстрирует ряд впечатляющих результатов, но у него есть главные недостатки: отсутствие чёткой детализации на уровне слов и невозможность генерации изображений высокого разрешения. Эта проблема становится еще более серьезной при генерации сложных кадров, таких как в наборе данных COCO.\\nВ качестве решения данной проблемы была предложена[14] новая генеративно-состязательная нейросеть с вниманием (англ. Attentional Generative Adversarial Network, AttnGAN), которая относится к вниманию как к фактору обучения, что позволяет выделять слова для генерации фрагментов изображения.\\nМодель состоит из нескольких взаимодействующих нейросетей (рис. 11):\\n- Кодировщики текста (англ. Text Encoder) и изображения (англ. Image Encoder) векторизуют исходное текстовое описания и реальные изображения. В данном случае текст рассматривается в виде последовательности отдельных слов, представление которых обрабатывается совместно с представлением изображения, что позволяет сопоставить отдельные слова отдельным частям изображения. Таким образом реализуется механизм внимания (англ. Deep Attentional Multimodal Similarity Model, DAMSM).\\n- — создает сжатое представление об общей сцене на изображении, исходя из всего текстового описания. Значение на выходе конкатенируется с вектором из нормального распределения , который задает вариативность сцены. Эта информация является основой для работы генератора.\\n- Attentional Generative Network — самая большая сеть, состоящая из трех уровней. Каждый уровень порождает изображения все большего разрешения, от 64x64 до 256x256 пикселей, и результат работы на каждом уровне корректируется с помощью сетей внимания , которые несут в себе информацию о правильном расположении отдельных объектов сцены. Кроме того, результаты на каждом уровне проверяются тремя отдельно работающими дискриминаторами, которые оценивают реалистичность изображения и соответствие его общему представлению о сцене.\\nБлагодаря модификациям нейросеть AttnGAN показывает значительно лучшие результаты, чем традиционные системы GAN. В частности, максимальный из известных показателей Inception Score[1] для существующих нейросетей улучшен на 14,14% (с 3,82 до 4,36) на наборе данных Caltech-UCSD и улучшен на целых 170,25% (с 9,58 до 25,89)[15] на более сложном наборе данных COCO.\\nВо второй и третьей строке приведены по 5 наиболее используемых слов сетями внимания [14].и соответственно\\nCVAE&GAN\\nБольшинство существующих методов генерации изображения по тексту нацелены на создание целостных изображений, которые не разделяют передний и задний план изображений, в результате чего объекты искажаются фоном. Более того, они обычно игнорируют взаимодополняемость различных видов генеративных моделей. Данное решение[16] предлагает контекстно-зависимый подход к генерации изображения, который разделяет фон и передний план. Для этого используется взаимодополняющая связка вариационного автокодировщика и генеративно-состязательной нейросети.\\nVAE имеет более стабильный выход чем GAN без схлопывания мод распределения (англ. mode collapse), это можно использовать для достоверной подборки распределения и выявления разнообразия исходного изображения. Однако он не подходит для генерации изображений высокого качества, т. к. генерируемые VAE изображения легко размываются. Чтобы исправить данный недостаток архитектура включает два компонента (рис. 13):\\n- Контекстно-зависимый вариационный кодировщик (англ. conditional VAE, CVAE) используется для захвата основной компоновки и цвета, разделяя фон и передний план изображения.\\n- GAN уточняет вывод CVAE с помощью состязательного обучения, которое восстанавливает потерянные детали и исправляет дефекты для создания реалистичного изображения.\\nПолученные результаты проверки (рис.14) на 2 наборах данных (Caltech-UCSD и Oxford-102) эмпирически подтверждают эффективность предложенного метода.\\nСравнение CVAE&GAN, StackGAN и GAN-INT-CLS.[16]\\nСверху вниз начиная со второй строки: CVAE&GAN, StackGAN и GAN-INT-CLS. [16]\\nMMVR\\nМодель мультимодальной векторной сети (англ. Multi-Modal Vector Representation, MMVR), впервые предложенная в статье[17], способна создавать изображения по описанию и генерировать описание исходя из предоставленного изображения. Она включает несколько модификаций для улучшения генерации изображений и описаний, а именно: вводится функция потерь на основе метрики N-грамм, которая обобщает описание относительно изображения; так же для генерации вместо одного используется несколько семантически сходных предложений, что так же улучшает создаваемые изображения.\\nМодель может быть разделена на два взаимозависимых модуля (рис. 17):\\n- Генератор изображений на основе GAN с DeePSiM[18].\\n- Генератор описаний изображений на основе Long-term Recurrent Convolutional Networks (LRCNs)[19].\\nПрямое распространение (англ. forward pass) инициируется путем передачи случайного скрытого вектора (англ. latent vector) [20] — в правило обновления добавляется ошибка восстановления изображения (англ. reconstruction error), вычисляемая как разница между и .в генератор изображений ( ), который генерирует изображение . Затем по сгенерированной картинке генератор описаний создаёт подпись. Для определения ошибки между сгенерированным описанием и исходным описанием используется перекрестная энтропия на уровне слов. Она используется для итеративного обновления (заодно и ), оставляя при этом все остальные компоненты фиксированными. С каждой итерацией приближается к , и сгенерированное изображение на каждом шаге является временным представлением конечного изображения. Для улучшения реалистичности изображения используется кодировщик шумоподавления (англ. Denoising Autoencoder, DAE)\\nОбучение начинается с генерации случайного 4096-мерного вектора, который передаётся в модель для последующего итеративного обновления. Процесс завершается после 200 итераций, и полученное изображение считается репрезентативным для данного описания.\\n|Модель\\n|Inception Score [1]\\n|Plug and Play Generative Networks (PPGN)[20]\\n|MMVR\\n|MMVR ()\\nMirrorGAN\\n|Модель\\n|Inception Score (Caltech-UCSD)\\n|Inception Score (COCO)\\n|GAN-INT-CLS\\n|GAWWN\\n|StackGAN\\n|StackGAN++\\n|PPGN[20]\\n|AttnGAN\\n|MirrorGAN\\nГенерация изображения из заданного текстового описания преследует две главные цели: реалистичность и семантическое постоянство. Несмотря на то, что существует значительный прогресс в создании визуально реалистичных изображений высокого качества посредством генеративных состязательных сетей, обеспечение вышепоставленных целей все еще является довольно сложной задачей. Для осуществления попытки их реализации рассмотрим text-to-image-to-text фреймворк с вниманием, сохраняющий семантику, под названием MirrorGAN[21]. Данный фреймворк, который из текстового описания генерирует изображение, использует идею обучения с помощью переописания (англ. redescription) и состоит из трёх модулей:\\n- Модуль встраивания семантического текста (англ. semantic text embedding module, STEM).\\n- Глобально-локальный совместный модуль с вниманием для создания каскадных изображений (англ. global-local collaborative attentive module for cascaded image generation, GLAM).\\n- Модуль регенерации семантического текста и выравнивания (англ. semantic text regener-ation and alignment module, STREAM).\\nSTEM создает встраивания на уровне слов и предложений, GLAM имеет каскадную архитектуру создания результирующих изображений от грубых до детализированных, используя как внимание к локальным словам, так и к глобальным предложениям, чтобы прогрессивно совершенствовать семантическое постоянство и разнообразие у сгенерированных изображений, а STREAM стремится к восстановлению текстового описания созданного изображения, которое семантически схоже с заданным описанием.\\nЕсли изображение, сгенерированное с помощью T2I (text-to-image), семантически соответствует заданному описанию, его текстовое описание, созданное посредством I2T (image-to-text) должно семантически совпадать с заданным.\\nЧтобы обучать модель сквозным методом, будем использовать две состязательные функции потерь:\\n- Состязательная потеря в реалистичности: .\\n- Состязательная потеря в семантическом постоянстве: .\\nГде— сгенерированное на этапе изображение, взятое из распределения . Вдобавок, для эффективного использования двойного регулирования T2I и I2T, применим текстово-семантическую реконструированную функцию потерь, основанную на перекрёстной энтропии: .\\nMirrorGan представляет собой зеркальную структуру, объединяя T2I и I2T. Чтобы сконструировать многоэтапный каскадный генератор, все три сети генерации изображений (STEM, GLAM и STREAM) необходимо объединить. В качестве архитектуры STREAM будем использовать довольно распространенный фреймворк создания текстового описания изображения (англ. image captioning framework), базирующийся на кодировании и декодировании. Кодировщик изображений — это свёрточная нейронная сеть, предварительно обученная на ImageNet[22], а декодировщик — это рекуррентная нейронная сеть. Предварительное обучение STREAM помогло MirrorGAN достичь более стабильного процесса обучения и более быстрой сходимости, в то время, как их совместная оптимизация довольно нестабильна, занимает много места и долго работает. Структура кодировщик-декодировщик и соответствующие ей параметры фиксированы во время обучения других модулей MirrorGAN.\\nОбучая обратно распространяются через STREAM в , веса сетей которых остаются фиксированными. Финальная целевая функция генератора выглядит так:, градиенты из\\n,\\nгде— вес потери для обработки участия состязательной потери (англ. adversarial loss) и потери текстово-семантической реконструкции (англ. text-semantic reconstruction loss). Для наилучшего качества генерации можно поставить коэффициент .\\nПоказатель Inception Score[1] был использован для измерения как объективности, так и разнообразия сгенерированных изображений. R-precision был использован для вычисления визуально-семантической схожести между сгенерированными изображениями и их соответствующими текстовыми описаниями.\\nTextKD-GAN\\nГенерация текста представляет особый интерес во многих приложениях нейролингвистического программирования (англ. neuro-linguistic programming, NLP), таких как машинный перевод, моделирование языка и обобщение текста. Генеративные состязательные сети достигли замечательного успеха в создании высококачественных изображений в компьютерном зрении, и в последнее время они также вызвали большой интерес со стороны сообщества NLP. Однако достижение подобного успеха в NLP было бы более сложным из-за дискретности текста. В данной статье[23] вводится метод, использующий дистилляцию знаний (перенос знаний, усвоенных большой моделью (учителем), на меньшую модель (ученика)) для эффективного оперирования настройками сети.\\nTextKD-GAN представляет из себя решение для основного узкого места использования генеративных состязательных сетей для генерации текста с дистилляцией знаний — методом, переносящим знания смягченного вывода модели (учителя) в меньшую модель (ученика). Решение основано на автокодировщике (учителе), чтобы получить гладкое представление настоящего текста. Это представление затем подается в дискриминатор TextKD-GAN вместо обычного one-hot представления. Генератор (студент) пытается изучить многообразие смягченного гладкого представления автокодировщика. TextKD-GAN, в конечном итоге, будет превосходить обычный генератор текста на основе генеративных состязательных сетей, который не нуждается в предварительном обучении.\\nВ общепринятом текстовом распознавании, реальные и сгенерированные входные данные дискриминатора будут иметь разные типы (one-hot и softmax). Один из способов избежать этой проблемы состоит в получении непрерывно гладкого представление слов, а не one-hot представления, и обучении дискриминатора различать их. На рисунке 27 проиллюстрирована модель, в которой используется стандартный автокодировщик (учитель), чтобы заменить one-hot представление выходом, перестроенным softmax-функцией, который является представлением, дающим меньшую дисперсию градиентов. Как видно, вместо one-hot представления реальных слов смягченный преобразованный выход автокодировщика подается на вход дискриминатору. Эта техника значительно усложняет распознавание для самого дискриминатора. Генератор с softmax выходом пытается имитировать распределение выходного сигнала автокодировщика вместо обычного one-hot представления.\\nОбучение автокодировщика и TextKD-GAN происходит одновременно. Чтобы добиться этого, необходимо раздробить целевую функцию на три члена:\\n- Реконструирующий член для автокодировщика:\\n- Функция потерь для дискриминатора с градиентным штрафом (англ. discriminator loss function with gradient penalty):\\n- Состязательная стоимость (англ. adversarial cost) генератора:\\nЭти функции потерь обучаются поочередно, чтобы оптимизировать различные части модели. В члене штрафа градиента необходимо посчитать норму градиента случайных выборок.\\nObj-GAN\\nОбъектно-управляемая генеративная состязательная сеть с вниманием (англ. Object-Driven Attentive Generative Adversarial Network, Obj-GAN) позволяет создавать изображения по описанию с учётом объектной компоновки. Объектно-управляемый генератор изображений, создаёт изображения на основе двухэтапной генерации. Сначала создаётся макет по наиболее значимым словам в текстовом описании, после этого генерируется изображение с полученной компоновкой объектов. А для сопоставления синтезируемых объектов с текстовым описанием и сгенерированным макетом, предлагается[25] новый объектный дискриминатор, основывающийся на Fast R-CNN[26]. В результате модификаций Obj-GAN значительно превосходит по производительности другие модели на наборе данных COCO, увеличивая показатель Inception score[1] на 11% и уменьшая показатель FID (Fréchet inception distance)[2] на 27%.\\n|Модель\\n|Inception Score [1]\\n|FID [2]\\n|Obj-GAN (pred box & pred shp)\\n|Obj-GAN (gt box & pred shp)\\n|Obj-GAN (gt box & gt shp)\\nОсновная цель Obj-GAN — генерация качественных изображений с семантически значимым макетом и реалистичными объектами. Obj-GAN состоит из пары генератора изображений с вниманием, управляемый объектами, и пообъектного дискриминатора (англ. object-wise discriminator). Генератор изображений в качестве входных данных принимает текстовое описание и предварительно сгенерированный семантический макет (англ. semantic layout), по которым создаёт изображение с помощью процесса, заключающегося в поэтапном улучшении качества результирующего изображения. На каждом этапе генератор синтезирует фрагмент изображений внутри ограничивающей рамки (англ. bounding box), фокусируясь на наиболее релевантных объекту словах.\\nГоворя более конкретно, он, с использованием управляемого объектами слоя внимания, оперирует метками класса, запрашивая слова в предложениях, чтобы сформировать вектор контекстов, и впоследствии синтезирует фрагмент изображения при условиях метки и вектора контекстов. Пообъектный дискриминатор проверяет каждую ограничивающую рамку, чтобы удостовериться в том, что сгенерированный объект действительно может быть сопоставлен с заранее сгенерированным макетом. Чтобы вычислить все потери при распознавании для всех заданных ограничивающих рамок одновременно и эффективно, дискриминатор представляет из себя быструю свёрточную нейронную сеть на основе регионов (англ. Fast Region-based Convolutional Neural Network, Fast R-CNN) с двоичной функцией потерь перекрёстной энтропии для каждой рамки.\\nРассмотрим архитектуру Obj-GAN. Первым этапом, генеративная состязательная сеть принимает текстовое предложение и генерирует семантический макет — последовательность объектов специфицированных соответствующими ограничивающими рамками (наряду с метками классов) и фигурами. Генератор рамок (англ. box generator) и генератор фигур (англ. shape generator) работают соответствующим образом, сначала создавая последовательность ограничивающих рамок, а затем — фигуру для каждой. Поскольку большинству рамок сопоставлены слова из данного текстового предложения, модель seq2seq с вниманием охватывает это соответствие. Далее конструируется , базированный на двунаправленной свёрточной долгой краткосрочной памяти (англ. bidirectional convolutional long short-term memory, LSTM). Обучение основывается на фреймворке генеративной состязательной сети, в которой потеря восприятия используется для ограничения генерируемых фигур и стабилизирования обучения.\\nСравнение Obj-GAN[25]\\nLayoutVAE\\nМодели, используемые для создания макетов сцен из текстовых описаний по большей части игнорируют возможные визуальные вариации внутри структуры, описываемой самим текстом.\\nМакетный вариационный автокодировщик (англ. Layout variational autoencoder, LayoutVAE) — фреймворк, базирующийся на вариационном автокодировщике для генерации стохастических макетов сцен (англ. stochastic scene layouts) — это программная платформа моделирования, позволяющая генерировать либо полные макеты изображений с заданным набором меток, либо макеты меток для существующего изображения с новой заданной меткой.\\nРассмотрим задачу генерации сцен с описанием набора меток. Этот набор всего лишь предоставляет множество меток, присутствующих в данном изображении (без дополнительного описания взаимосвязи), заставляя модель изучать пространственные и подсчитываемые отношения (англ. spatial and count relationships) на основе визуальных данных.\\nКасательно вышеописанной задачи предлагаются следующие решения:\\n- Модель стохастических генераций макетов сцен с заданным множеством меток, которая будет иметь две компоненты: моделирование распределений подсчитываемых отношений между объектами; моделирование распределений пространственных отношений между объектами.\\n- Синтетический набор данных, MNIST-макеты, отражающие стохастическую природу генерации макета сцен.\\n- Экспериментальная валидация моделей с использованием MNIST-макетов и наборов данных COCO, в которой содержатся сложные макеты сцен реального мира.\\nВ статье[27] были предложены фреймворки и структуры моделей, взаимодействующие с LayoutVE, такие как: PNP-Net — фреймворк вариационного автокодировщика для создания изображения из текстовой программы, которая полностью её описывает (помимо того, что это стохастическая модель для генерации, она была протестирована на синтетических наборах данных с малым числом классов); LayoutGAN — модель, основанная на генеративных состязательных сетях, создающая макеты графических элементов (прямоугольники, треугольники, и так далее); фреймворк, базирующийся на вариационном автокодировщике, который кодирует объект и информацию о макете 3D-сцен в помещении в скрытом коде; и так далее...\\nОбучение генеративных моделей необходимо, чтобы предсказать разнообразные, но правдоподобные наборы ограничивающих рамок (англ. bounding boxes), учитывая набор меток в качестве входных данных. Рамки в наборе представлены верхними левыми координатами, шириной и высотой -й ограничивающей рамки категории . LayoutVAE декомпозируется на модель для предсказания количества для каждой заданной метки — CountVAE — и модель для предсказания местоположения и размера каждого объекта — BBoxVAE.\\nИмея набор метоки количество объектов в категории , BBoxVAE предсказывает распределение координат для ограничивающих рамок авторегрессионно. Мы следуем тому же предопределенному порядку меток, что и в CountVAE, в пространстве меток, и упорядочиваем ограничивающие рамки слева направо для каждой метки; сначала все ограничивающие рамки предсказываются для заданной метки, а уже потом происходит переход к следующей метке.\\nMCA-GAN\\nПреобразование изображений перекрестным видом (англ. cross-view image translation) проблематично, поскольку оно оперирует изображениями со значительно отличающимися ракурсами и тяжёлыми деформациями. В статье[28] о выборочной генеративной состязательной сети с мультиканальным вниманием (англ. Multi-Channel Attention Selection GAN, MCA-GAN) рассматривается подход, позволяющий делать возможным генерацию изображения, максимально приближенной к реальной, с произвольных ракурсах, основывающийся на семантическом отображении (англ. semantic mapping). Работа сети происходит в два этапа:\\n- Изображение и целевое семантическое отображение (англ. target semantic map) подаются на вход циклической семантически-управляемой генеративной сети (англ. cycled semantic-guided generation network) для получения начальных результатов.\\n- Начальные результаты уточняются, используя механизм мультиканального выделения внимания (англ. multi-channel attention selection mechanism).\\nОбширные эксперименты на наборах данных Dayton, CVUSA[29] и Ego2Top[30] показывают, что данная модель способна генерировать значительно более качественные результаты, чем другие современные методы.\\nНа рисунке 29 проиллюстрирована структура сети. Первый этап, как было описано выше, состоит из каскадной семантически-управляемой генерацинной подсети, использующая изображения в одном представлении и условные семантические отображения в другом представлении в качестве входных данных и преобразующая эти изображения в другом представлении. Результирующие изображения далее подаются на вход семантическому генератору для восстановления исходного семантического отображения, формируя цикл генерации. Второй этап заключается в том, что грубый синтез (англ. coarse synthesis) и отображения глубоких характеристик объединяются и подаются на вход в модуль мультиканального выделения внимания, направленный на получение более детализированного синтеза (англ. fine-grained synthesis) из большего пространства генерации и создание отображений неопределенности (англ. uncertainty maps) для управления множественными потерями оптимизации (англ. optimization losses). Модуль мультиканального выделения внимания в свою очередь состоит из многомасштабного пространственного пулинга (англ. multiscale spatial pooling) и компоненты мультиканального выделения внимания (англ. multichannel attention selection component).\\nПоскольку между изначальным ракурсом и результирующим существует объемная деформация объекта и/или сцены, одномасштабная характеристика (англ. single-scale feature) вряд ли сможет захватить всю необходимую информацию о пространстве для детализированной генерации. Многомасштабный пространственный пулинг оперирует же другими значениями размера ядра и шага для выполнения глобального среднего пулинга (англ. global average pooling) на одних и тех же входных характеристиках, тем самым получая многомасштабные характеристики с отличающимися рецептивными полями (англ. receptive fields) для восприятия различных пространственных контекстов. Механизм мультиканального внимания позволяет осуществлять выполнение пространственного и временного отбора (англ. spatial and temporal selection), чтобы синтезировать конечный детализированный результат.\\nОбласти применения\\n- Создание контента и данных:\\n- картинки для интернет-магазина;\\n- аватары для игр;\\n- видеоклипы, сгенерированные автоматически, исходя из музыкального бита произведения;\\n- виртуальные ведущие[31].\\n- Обучение систем на основе синтеза данных, возникающего в результате работы генеративных моделей:\\n- генерация реалистичного видео городской среды[32].\\nСм. также\\n- Порождающие состязательные сети (GAN)\\n- Генерация объектов\\n- Deepfake\\n- Практики реализации нейронных сетей\\nПримечания\\n- ↑ 1,00 1,01 1,02 1,03 1,04 1,05 1,06 1,07 1,08 1,09 1,10 1,11 A Note on the Inception Score\\n- ↑ 2,0 2,1 2,2 Fréchet inception distance, FID\\n- ↑ 3,0 3,1 3,2 Xinchen Y. — Conditional Image Generation from Visual Attributes, 2015\\n- ↑ 4,0 4,1 4,2 Scott R. — Generative Adversarial Text to Image Synthesis, 2016\\n- ↑ 5,0 5,1 5,2 5,3 Han Z., Tao X. — Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks, 2017\\n- ↑ 6,0 6,1 6,2 Navaneeth B., Gang H. — Semi-supervised FusedGAN for ConditionalImage Generation, 2018\\n- ↑ 7,0 7,1 7,2 Shikhar S., Dendi S. — ChatPainter: Improving Text to Image Generation using Dialogue, 2018\\n- ↑ Visual Dialog\\n- ↑ Pre-trained encoder for ICML 2016 paper\\n- ↑ Skip-Thought encoder\\n- ↑ Skip-Thought Vectors\\n- ↑ 12,0 12,1 12,2 12,3 Han Z., Tao X. — Realistic Image Synthesis with Stacked Generative Adversarial Networks, 2018\\n- ↑ 13,0 13,1 13,2 13,3 Seunghoon H., Dingdong Y. — Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis, 2018\\n- ↑ 14,0 14,1 14,2 Tao X., Pengchuan Z. — AttnGAN: Fine-Grained Text to Image Generationwith Attentional Generative Adversarial Networks, 2018\\n- ↑ Test results — Text-to-Image Generation on COCO\\n- ↑ 16,0 16,1 16,2 16,3 Chenrui Z., Yuxin P. — Stacking VAE and GAN for Context-awareText-to-Image Generation, 2018\\n- ↑ 17,0 17,1 17,2 Shagan S., Dheeraj P. — SEMANTICALLY INVARIANT TEXT-TO-IMAGE GENERATION, 2018\\n- ↑ DeePSiM. Alexey D. and Thomas B. — Generating Images with Perceptual Similarity Metrics based on Deep Networks, 2016\\n- ↑ Jeff D., Lisa A. H. — Long-term Recurrent Convolutional Networks for Visual Recognition and Description, 2015\\n- ↑ 20,0 20,1 20,2 20,3 Anh N., Jeff C. — Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space,2017\\n- ↑ 21,0 21,1 21,2 Tingting Q., Jing Z. — MirrorGAN: Learning Text-to-image Generation by Redescription, 2019\\n- ↑ ImageNet image database\\n- ↑ 23,0 23,1 23,2 Md. Akmal H. and Mehdi R.— TextKD-GAN: Text Generation using KnowledgeDistillation and Generative Adversarial Networks, 2019\\n- ↑ The Stanford Natural Language Inference (SNLI) Corpus\\n- ↑ 25,0 25,1 25,2 Wendo L., Pengchuan Z. — Object-driven Text-to-Image Synthesis via Adversarial Training 2019\\n- ↑ Ross Girshick — Fast R-CNN, 2015\\n- ↑ 27,0 27,1 27,2 LayoutVAE: Stochastic Scene Layout Generation From a Label Set\\n- ↑ 28,0 28,1 28,2 28,3 Multi-Channel Attention Selection GAN with Cascaded Semantic Guidancefor Cross-View Image Translation\\n- ↑ Crossview USA (CVUSA)\\n- ↑ Ego2Top: Matching Viewers in Egocentric and Top-view Videos (ECCV 2016)\\n- ↑ Виртуальный диктор\\n- ↑ NVIDIA Interactive Graphics\\nИсточники информации\\n- Scott R. — Generative Adversarial Text to Image Synthesis, 2016\\n- Xinchen Y. — Conditional Image Generation from Visual Attributes, 2015\\n- Han Z., Tao X. — Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks, 2017\\n- Han Z., Tao X. — Realistic Image Synthesis with Stacked Generative Adversarial Networks, 2018\\n- Seunghoon H., Dingdong Y. — Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis, 2018\\n- Tao X., Pengchuan Z. — Fine-Grained Text to Image Generationwith Attentional Generative Adversarial Networks, 2018\\n- Chenrui Z., Yuxin P. — Stacking VAE and GAN for Context-awareText-to-Image Generation, 2018\\n- Shikhar S., Dendi S. — ChatPainter: Improving Text to Image Generation using Dialogue, 2018\\n- Shagan S., Dheeraj P. — SEMANTICALLY INVARIANT TEXT-TO-IMAGE GENERATION, 2018\\n- Navaneeth B., Gang H. — Semi-supervised FusedGAN for ConditionalImage Generation, 2018\\n- Tingting Q., Jing Z. — MirrorGAN: Learning Text-to-image Generation by Redescription, 2019\\n- Wendo L., Pengchuan Z. — Object-driven Text-to-Image Synthesis via Adversarial Training 2019\\n- Akash A.J., Thibaut D. — LayoutVAE: Stochastic Scene Layout Generation From a Label Set, 2019\\n- Md. Akmal H. and Mehdi R. — TextKD-GAN: Text Generation using Knowledge Distillation and Generative Adversarial Networks, 2019\\n- Bowen L., Xiaojuan Q. — ControlGAN: Controllable Text-to-Image Generation, 2019\\n- Has T., Dan X. — MCA-GAN: Multi-Channel Attention Selection GAN with Cascaded Semantic Guidance for Cross-View Image Translation, 2019\\n- Tingting Q., Jing Z. — Learn, Imagine and Create: Text-to-Image Generation from Prior Knowledge, 2019\\n- Анатолий А. — Генерация изображений из текста с помощью AttnGAN, 2018', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='9d42758c-c3bf-43d6-b116-484d432c34d8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ded5498ee65deb90f41a084e395506ffbf172511db79014ee5282523ba22fa65', text='Распознавание речи\\nРаспознавание речи (англ. Speech Recognition) — процесс преобразования речевого сигнала в цифровую информацию.\\nЗадачей распознавания является сопоставление набору акустических признаков речевого сигнала или наблюденийпоследовательности слов , имеющих наибольшую вероятность правдоподобия среди всех кандидатов. Для этого используется формула Байеса:\\nПричем, в процессе распознавания вероятность уже полученных признаков Р(Х) не подлежит оптимизации и знаменатель в формуле не испльзуется:\\nСодержание\\n- 1 Классификация систем распознавания речи\\n- 2 Структура систем распознавания речи\\n- 3 Признаки\\n- 4 Показатели оценки качества распознавания речи\\n- 5 State of the Art в автоматическом распознавании речи\\n- 6 Применение\\n- 7 См. также\\n- 8 Примечания\\n- 9 Источники информации\\nКлассификация систем распознавания речи\\nСистемы распознавания речи классифицируются[1]:\\n- по размеру словаря (ограниченный набор слов, словарь большого размера);\\n- по зависимости от диктора (дикторозависимые и дикторонезависимые системы);\\n- по типу речи (слитная или раздельная речь);\\n- по назначению (системы диктовки, командные системы);\\n- по используемому алгоритму (нейронные сети, скрытые Марковские модели, динамическое программирование);\\n- по типу структурной единицы (фразы, слова, фонемы, дифоны, аллофоны);\\n- по принципу выделения структурных единиц (распознавание по шаблону, выделение лексических элементов).\\nСтруктура систем распознавания речи\\nСистемы распознавания речи впервые появились в 1952 году. С тех пор методы распознавания не раз менялись. Ранее использовались такие методы и алгоритмы, как:\\n- Динамическое программирование (Dynamic Time Warping) - временные динамические алгоритмы, выполняющие классификацию на основе сравнения с эталоном.\\n- Методы дискриминантного анализа, основанные на Байесовской дискриминации (Bayesian discrimination).\\n- Скрытые Марковские Модели (Hidden Markov Model).\\n- Нейронные сети (Neural Networks).\\nВ настоящее время, перечисленные выше методы как правило комбинируются. Их сочетание позволяет получить более высокое качество распознавания, чем использование каждой модели отдельно.\\nСистемы распознавания речи имеют следующие основные модули:\\n- Акустическая модель\\n- Языковая модель\\n- Декодер\\nАкустическая модель\\nФонема (phoneme) — элементарная единица человеческой речи. Примерами фонем являются транскрипции в формате IPA — так, слово hello состоит из фонем [hɛˈləʊ].\\nАкустическая модель — это функция, принимающая на вход признаки на небольшом участке акустического сигнала (фрейме) и выдающая распределение вероятностей различных фонем на этом фрейме. Таким образом, акустическая модель дает возможность по звуку восстановить, что было произнесено — с той или иной степенью уверенности.\\nСамой популярной реализацией акустической модели является скрытая Марковская модель (СММ), в которой скрытыми состояниями являются фонемы, а наблюдениями — распределения вероятностей признаков на фрейме.\\nРассмотрим подробнее акустическую модель на основе СММ для слова six:\\nВ круглых (скрытых) состояниях изображены фонемы, а в квадратных (наблюдениях) — распределения вероятностей признаков (для упрощения, здесь изображено одномерное распределение). Фонемы часто разбивают на 3 этапа — начало, середину и конец, — потому что фонема может звучать по-разному в зависимости от момента времени её произнесения. Каждое скрытое состояние содержит переход само в себя, так как время произнесения одной фонемы может занять несколько фреймов. Вероятности перехода между фонемами в СММ являются обучаемыми параметрами, и для их настройки используют алгоритм Баума-Велша. Последовательность фонем по набору распределений на фреймах восстанавливают по алгоритму Витерби.\\nВ качестве функции распределения вероятностей признаков часто выбирают смешанную гауссову модель (англ. Gaussian Mixture Model, GMM): дело в том, что одна и та же фонема может звучать по-разному, например, в зависимости от акцента. Так как эта функция является по сути суммой нескольких нормальных распределений, она позволяет учесть различные звучания одной и той же фонемы.\\nЯзыковая модель\\nЯзыковая модель — позволяет узнать, какие последовательности слов в языке более вероятны, а какие менее. Здесь в самом простом случае требуется предсказать следующее слово по известным предыдущим словам. В традиционных системах применялись модели типа N-грамм, в которых на основе большого количества текстов оценивались распределения вероятности появления слова в зависимости от N предшествующих слов. Для получения надежных оценок распределений параметр N должен быть достаточно мал: одно, два или три слова — модели униграмм, биграмм или триграмм соответственно. Внедрение языковой модели в систему распознавания речи позволило значительно повысить качество распознавания за счет учета контекста.\\nДекодер\\nВ ходе работы системы автоматического распознавания речи задача распознавания сводится к определению наиболее вероятной последовательности слов, соответствующих содержанию речевого сигнала. Наиболее вероятный кандидат должен определяться с учетом как акустической, так и лингвистической информации. Это означает, что необходимо производить эффективный поиск среди возможных кандидатов с учетом различной вероятностной информации. При распознавании слитной речи число таких кандидатов огромно, и даже использование самых простых моделей приводит к серьезным проблемам, связанным с быстродействием и памятью систем. Как результат, эта задача выносится в отдельный модуль системы автоматического распознавания речи, называемый декодером. Декодер должен определять наиболее грамматически вероятную гипотезу для неизвестного высказывания – то есть определять наиболее вероятный путь по сети распознавания, состоящей из моделей слов (которые, в свою очередь, формируются из моделей отдельных фонов). Правдоподобие (likelihood) гипотезы определяется двумя факторами, а именно вероятностями последовательности фонов, приписываемыми акустической моделью, и вероятностями следования слов друг за другом, определяемыми моделью языка.\\nРассмотрим математическую основу декодеров.\\nОтбрасывая несущественный на этапе распознавания знаменатель, запишем:\\nгде– последовательность векторов признаков входного сигнала, – последовательность слов, принадлежащих словарю размером . Первый множитель P(W) описывает вклад лингвистического модуля, второй P(X|W) – лексического, фонетического и акустического источников знаний. В соответствии с концепцией марковских цепей, второй множитель представляет собой сумму вероятностей всех возможных последовательностей состояний, что приводит к уравнению:\\nгде [2]. – ищется последовательность состояний, дающая максимальный вклад в сумму:– одна из последовательностей состояний, порождаемых последовательностью слов . На практике применяется критерий Витерби\\nРазличают систему раннего и систему позднего предсказания. В первой выполняется предсказание для акустической и языковой модели независимо, а затем оба предсказания поступают в декодер. При позднем предсказании, вычисленные признаки речи в акустической и языковой моделях без предсказания поступают в декодер и уже на основе их совместного декодирования выполняется предсказание.\\nЭтапы распознавания:\\n- Обработка речи начинается с оценки качества речевого сигнала. На этом этапе определяется уровень помех и искажений.\\n- Результат оценки поступает в модуль акустической адаптации, который управляет модулем расчета параметров речи, необходимых для распознавания.\\n- В сигнале выделяются участки, содержащие речь, и происходит оценка параметров речи. Происходит выделение фонетических и просодических вероятностных характеристик для синтаксического, семантического и прагматического анализа. (Оценка информации о части речи, форме слова и статистические связи между словами.)\\n- Далее параметры речи поступают в основной блок системы распознавания — декодер. Это компонент, который сопоставляет входной речевой поток с информацией, хранящейся в акустических и языковых моделях, и определяет наиболее вероятную последовательность слов, которая и является конечным результатом распознавания.\\nПризнаки\\nВходные данные представляют собой непрерывную осциллограмму звуковой волны. В задачах распознавания речи эту осциллограмму разбивают на фреймы — фрагменты звукового потока длительностью около 20 мс и шагом 10 мс. Такой размер соответствует скорости человеческой речи: если человек говорит по 3 слова в секунду, каждое из которых состоит примерно из 4 звуков и каждый звук разбивается на 3 этапа, то на этап выходит около 28 мс. Каждый фрейм независимо трансформируется и подвергается извлечению признаков, тем самым образуя векторизированный набор данных для задачи машинного обучения.\\nПризнаки речевых событий, используемые при распознавании речи:\\n- Спектр Фурье.\\n- Спектр Фурье в шкале мел.\\n- Коэффициенты линейного предсказания.\\n- Кепстр.\\nСпектр Фурье\\nСпектр Фурье получают, используя алгоритм БПФ (Быстрого Преобразования Фурье) с длиной окна равной 2-4 периода основного тона, что составляет около 20 мс. При частоте квантования 10-16 кГц выбирается окно 256 отсчетов.\\nДля ослабления искажений сигнала, вызванных применением к непрерывному сигналу конечного окна анализа, чаще всего используется окно Хэмминга по формуле:\\nгде n = 1..N, N – размерность окна, S(n) – отсчеты речевого сигнала.\\nСпектр Фурье в шкале мел\\nК каждому кадру, полученного Фурье спектра применяется блок мел-фильтров — треугольных пересекающихся фильтров, расположенных наиболее плотно в области нижних частот. Количество фильтров — 26. Для расчета фильтров выбирается верхняя и нижняя частота. Затем осуществляется переход от частотной шкалы к мел-шкале по формуле:\\nНа мел-шкале выбираются линейно расположенные точки (28 точек для 26 фильтров), после чего, производится обратный переход в частотную область.\\nКоэффициенты линейного предсказания\\nМодель линейного предсказания речи предполагает, что передаточная функция голосового тракта представляется полюсным фильтром с передаточной функцией:\\nгде p – число полюсов и; Фильтр с такой передаточной функцией позволяет описать поведение сглаженного спектра речевого сигнала с хорошей точностью, за исключением назализованных звуков. Коэффициенты фильтра { } – выбираются путем минимизации среднеквадратичной ошибки предсказания, просуммированной на окне анализа.\\nКепстр\\nКепстр (cepstrum) сигнала на основе спектра Фурье вычисляется путем применения косинусного Фурье преобразования к логарифму спектра:\\nгде– логарифм спектра, N – количество отсчётов спектра, – унитарная матрица косинусного преобразования.\\nКепстральные коэффициенты, полученные приведённым способом из мел спектра Фурье, широко используются для распознавания с помощью марковских моделей и носят название MFCC (Mel-frequency cepstral coefficients).\\nПоказатели оценки качества распознавания речи\\nСуществуют различные по сложности и прикладному значению задачи распознавания: изолированных слов (команд); ключевых слов в потоке речи; связанной речи (тщательное проговаривание текста с паузами между словами); слитной речи (разделяют диктовку в узкой тематической области, и спонтанную речь, например, в диалоге между людьми).\\nОценка системы, распознающей отдельные команды, не представляет каких-либо трудностей – количество неправильно распознанных команд делится на общее количество испытаний и получается процент ошибки. Для систем, распознающих слитную речь, ситуация не столь проста.\\nОсновными показателями качества распознавания слитной речи являются:\\n- процент правильно распознанных слов (WRR - Word Recognition Rate);\\n- процент неправильно распознанных слов (WER - Word Error Rate);\\n- процент неправильно распознанных предложений/фраз (SER - Sentence Error Rate);\\nПоскольку с развитием речевых технологий показатель WER все более приближается к нулю, то значение улучшения WER более наглядно, чем улучшение точности распознавания слов.\\nгде T - количество слов в распознаваемой фразе, S - количество замененных слов, D - количество удаленных слов, I - количество вставленных слов. Показатель WER может быть больше 100%.\\nДругим важным критерием оценки систем распознавания слитной речи является - скорость обработки речи. Она вычисляется с помощью показателя скорости (Real-Time Factor, Speed Factor):\\n- длительность обрабатываемого аудиосигнала;\\n- время, необходимое для обработки сигнала.\\nЕсли - то распознавание речи ведется в режиме реального времени.\\nState of the Art в автоматическом распознавании речи\\nДля обучения современных систем распознавания речи требуются тысячи часов размеченной речи, однако получение размеченных данных в необходимом объеме (особенно с учетом разнообразия существующих языков) затруднительно. Это повлияло на то, что сейчас в машинном обучении для распознавания речи успешно используется обучение с частичным привлечением учителя, которое позволяет сначала обучать модель на большом объеме неразмеченных данных, а потом корректировать ее при помощи размеченных.\\nОдним из примеров обучения с частичным привлечением учителя для автоматического распознавания речи является подход, впервые представленный в статье[3], основанный на комбинации алгоритмов noisy student, wav2vec и использовании модели Конформера. Такой метод позволил уменьшить $WER$ на наборах данных LibriSpeech test-clean/test-other с $1.7\\\\%/3.3\\\\%$ (предыдущий state-of-the-art) до $1.4\\\\%/2.6\\\\%$ (Рисунок 4). $WER$ человека — $5.9\\\\%$[4]\\nОсновная идея состоит в том, что множество моделей Конформеров при помощи алгоритма wav2vec предварительно обучается на неразмеченных данных, при этом одновременно с этим на основе них генерируются размеченные. Таким образом, неразмеченные данные используются для двух целей: для обучения модели и для генерации размеченных данных, которые используются для дальнейшего обучения модели алгоритмом noisy student.\\nКонформер\\nТрансформер[на 21.01.21 не создан], использующий механизм самовнимания, хорошо захватывает глобальный контекст, однако не очень хорошо извлекает локальные признаки. Сверточные нейронные сети, наоборот, эффективно используют локальные признаки, но требуют большого числа слоев для захвата глобального контекста. Конформер (англ. Conformer) комбинирует сверточные слои с механизмом самовнимания. $WER$ на LibriSpeech test-clean/test-other составляет $1.9\\\\%/3.9\\\\%$.\\nСначала данные, подающиеся на вход Конформеру, проходят аугментацию. В применении к распознаванию речи, используется метод аугментации SpecAugment. SpecAugment применяет к мел спектрограмме три вида деформаций: искажение времени (удлинение или сжатие некоторого промежутка записи), удаление некоторого временного промежутка из записи, и удаление некоторого промежутка частот. Таким образом, при обучении на зашумленных с помощью SpecAugment данных сеть обучается на признаках, устойчивых к деформации во времени, частичной потере частотной информации и потере небольших сегментов речи. Конформер обрабатывает итоговые аугментированные входные данные с помощью сверточной нейронной сети, состоящей из слоя пулинга, полносвязного слоя и дропаута, а затем с помощью последовательности блоков Конформера.\\nБлоки Конформера — это последовательность из двух модулей прямой связи (англ. feed forward), между которыми расположены модуль многоголового самовнимания (англ. Multi-Head Self Attention) и сверточный модуль, с последующей нормализацией слоя (англ. layer normalization).\\nМодуль многоголового самовнимания\\nВ модуле используется блок многоголового внимания с относительным позиционным кодированием (англ. Multi-Head Attention with Relative Positional Encoding). Такой блок (изначально часть архитектуры Трансформер-XL[5]) используется с целью исправить два недостатка Трансформера: ограничение на длину входа (что не позволяет модели, например, использовать слово, которое появилось несколько предложений назад) и фрагментацию контекста (последовательность разбивается на несколько блоков, каждый из которых обучается независимо). Для достижения этой цели используются два механизма: механизм повторения (англ. reccurence mechanism) и относительное позиционное кодирование (англ. relative positional encoding). Механизм повторения позволяет использовать информацию из предыдущих сегментов. Как и в оригинальной версии, Трансформер-XL обрабатывает первый сегмент токенов, но сохраняет выходные данные скрытых слоев. При обработке следующего сегмента каждый скрытый слой получает два входа: результат предыдущего скрытого слоя этого сегмента, как в Трансформере, и результат предыдущего скрытого слоя из предыдущего сегмента, который позволяет модели создавать зависимости от далеких сегментов.\\nОднако, с использованием механизма повторения возникает новая проблема: при использовании исходного позиционного кодирования каждый сегмент кодируется отдельно, и в результате токены из разных сегментов закодированы одинаково.\\nОтносительное позиционное кодирование почти полностью совпадает с абсолютным позиционным кодированием из оригинального Трансформера, но вместо позиции внутри сегмента используется расстояние между сегментами. Кроме того, добавляются два вектора параметров, задающие важность расстояния и содержания второго токена относительно первого.\\nИспользование модуля многоголового самовнимания с относительным позиционным кодированием позволяет сети лучше обучаться при различной длине ввода, а результирующая архитектура получается более устойчивой к неоднородности длины высказывания.\\nСверточный модуль\\nПоследовательность слоев в сверточном модуле начинается с управляемого модуля[6]: сверточного слоя с ядром $1 \\\\times 1$ (англ. pointwise convolution) и управляемого линейного блока (англ. gated linear unit). Управляемый линейный блок — слой нейронной сети, определяемый как покомпонентное произведение двух линейных преобразований входных данных, функция активации одного из которых — сигмоида. Использование управляемого линейного блока уменьшает проблему исчезающего градиента. После сверточного слоя используется пакетная нормализация.\\nВ модуле используется функция активации swish[7] (до появления в статье Google Brain была известна как SiLU[8] и SiL[9]): $swish(x) = \\\\dfrac{x}{1 + e^{- \\\\beta x}}$, $\\\\beta$ — параметр.\\nМодули прямой связи\\nВ отличие от Трансформера, в котором единственный модуль прямой связи следует за модулем внимания и состоит из двух линейных преобразований и нелинейной активации между ними, Конформер представляет собой два модуля прямой связи, состоящих из слоя нормализации и двух линейных слоев. Кроме того, для регуляризации используется функция активации swish и дропаут.\\nwav2vec\\nПодход wav2vec[10] основан на самообучении на мел спектрограммах.\\nМодель\\n- Энкодер признаков (англ. Feature Encoder) $f: X \\\\to Z$ реализован на основе сверточного слоя. Преобразует мел спектрограммы $X$, разбитые на $T$ временных интервалов, в наборы признаков $\\\\{z_1, \\\\dots, z_T\\\\}$, которые описывают исходные данные в каждом из $T$ интервалов.\\n- Контекстная сеть (англ. Context Network) $g: Z \\\\to C$ реализована на основе линейного слоя и слоя, состоящего из $N$ блоков Конформера. Преобразует наборы признаков $\\\\{z_1, \\\\dots, z_T\\\\}$, полученные в результате работы энкодера признаков, в контекстные вектора $\\\\{c_1, \\\\dots, c_T\\\\}$.\\n- Модуль линейного слоя (англ. Linear Layer Module) $u: Z \\\\to T$ реализован на основе линейного слоя. Преобразует наборы признаков $\\\\{z_1, \\\\dots, z_T\\\\}$, полученные в результате работы энкодера признаков, в целевые вектора $\\\\{t_1, \\\\dots, t_T\\\\}$.\\nОбучение\\n- Исходные мел спектрограммы $X$ проходят через через энкодер признаков $f$ и таким образом преобразуются в $T$ наборов признаков $\\\\{z_1, \\\\dots, z_T\\\\}$.\\n- $\\\\{z_1, \\\\dots, z_T\\\\}$ преобразуются в контекстные и целевые вектора:\\n- Случайное подмножество векторов $z_{\\\\varphi_{(n)}}$ маскируется, и каждый $z \\\\in z_{\\\\varphi_{(n)}}$ заменяется на обученный вектор признаков. Полученное новое множество признаков $\\\\{z\\'_1, \\\\dots, z\\'_T\\\\}$ подается на вход контекстной сети и преобразуется в контекстные вектора $\\\\{c_1, \\\\dots, c_T\\\\}$.\\n- Множество $\\\\{z_1, \\\\dots, z_T\\\\}$ без замаскированных наборов признаков подается на вход модуля линейного слоя $u$ и преобразуется в целевые вектора $\\\\{t_1, \\\\dots, t_T\\\\}$.\\n- Для полученных контекстных и целевых векторов считается функция потерь $L$, в качестве которой используется функция Contrastive Loss.\\nСуть данного подхода состоит в том, что маскируются наборы признаков для некоторых из $T$ интервалов, и путем минимизации функции потерь модель на основе $N$ блоков Конформера учится подбирать наиболее похожий вектор, характеризующий признаки замаскированных участков. При этом модуль линейного слоя позволяет получить целевые вектора для замаскированных данных и таким образом модель обучается на размеченных данных.\\nNoisy student\\nВариация классического алгоритма самообучения: на каждой итерации модель-ученик обучается на аугментированных данных.\\nДанные\\n1. Набор размеченных данных $S$.\\n2. Набор неразмеченных данных $U$.\\n3. Обученная языковая модель $LM$.\\n4. Набор предобученных с помощью wav2vec моделей $M_0, \\\\dots, M_n$.\\nАлгоритм\\n1. Модель $M_0$ дообучается (англ. fine-tune) на наборе данных $S$ с использованием SpecAugment. $M = M_0$.\\n2. Модель $M$ сливается (англ. fuse)[11] с моделью $LM$.\\n3. Набор данных $U$ размечается с помощью $M$, получается новый набор данных $A$.\\n4. Наборы $S$ и $A$ объединяются, производится дообучение предобученной модели $M_i$ на объединенном наборе данных с использованием SpecAugment.\\n5. Если перебраны не все модели из набора, то $M = M_{i + 1}$, происходит возвращение к шагу $2$.\\nПрименение\\nСистемы распознавания речи начали развиваться как специальные сервисы для людей с ограниченными возможностями, но также нашли применение в различных сферах бизнеса, таких как:\\n- Телефония: системы голосового самообслуживания;\\n- \"Умный дом\": голосовой интерфейс управления;\\n- Роботы: голосовой интерфейс электронных роботов;\\n- РС, ноутбуки, телефоны: голосовой ввод команд, диктовка текста;\\n- Автомобили: голосовое управление в салоне автомобиля.\\nОсновные отрасли применения:\\n- Голосовое управление\\n- Голосовые команды\\n- Голосовой ввод текста\\n- Голосовой поиск\\nСм. также\\n- Байесовская классификация\\n- Распознавание образов\\n- Распознавание речи от Яндекса\\n- Субвокальное распознавание\\nПримечания\\n- ↑ Федосин С.А., Еремин А. Ю. Классификация систем распознавания речи. — Саранск. : МГУ им. Н.П. Огарева, 2009. — С. 3.\\n- ↑ Тампель И.Б, Карпов А.А. Автоматическое распознавание речи. — СПб. : Университет ИТМО, 2016. — С. 113.\\n- ↑ Yu Zhang, James Qin, Daniel S. Park, Wei Han, Chung-Cheng Chiu, Ruoming Pang, Quoc V. Le, Yonghui Wu Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition[1]\\n- ↑ W. Xiong, L. Wu, F. Alleva, J. Droppo, X. Huang, A. Stolcke The Microsoft 2017 Conversational Speech Recognition System[2]\\n- ↑ Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context[3]\\n- ↑ N. Dauphin, Angela Fan, Michael Auli, David Grangier Language Modeling with Gated Convolutional Networks[4]\\n- ↑ Prajit Ramachandran, Barret Zoph, Quoc V. Le Searching for Activation Functions\\n- ↑ Dan Hendrycks, Kevin Gimpel Gaussian Error Linear Units (GELUs)\\n- ↑ Stefan Elfwing, Eiji Uchibe, Kenji Doya Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning\\n- ↑ Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations[5]\\n- ↑ Caglar Gulcehre, Orhan Firat. Kelvin Xu, Kyunghyun Cho, Loic Barrault, Huei-Chi Lin, Fethi Bougares, Holger Schwenk, Yoshua Bengio On Using Monolingual Corpora in Neural Machine Translation [6]\\nИсточники информации\\n- [7] - статья на Википедии\\n- Тампель И.Б, Карпов А.А. Автоматическое распознавание речи. Учебное пособие. — СПб: Университет ИТМО, 2016. — 138 с.\\n- [8] - статья \"Классификация систем распознавания речи\".\\n- [9] - статья \"Выделение границ фонем речевого сигнала с помощью мел-частотных спектральных коэффициентов\".', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='c47a0ebb-ca9b-4123-be40-828fc2ebe57e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d480d7ab285ee5c87a5ad0fa789ffe9f0ca9210157ee4f4a8b5515839c6df35b', text='Обработка естественного языка\\nОбработка естественного языка (Natural Language Processing, NLP) — пересечение машинного обучения и математической лингвистики[1], направленное на изучение методов анализа и синтеза естественного языка. Сегодня NLP применяется во многих сферах, в том числе в голосовых помощниках, автоматических переводах текста и фильтрации текста. Основными тремя направлениями являются: распознавание речи (Speech Recognition), понимание естественного языка (Natural Language Understanding[2] ) и генерация естественного языка (Natural Language Generation[3]).\\nСодержание\\n- 1 Задачи\\n- 2 Основные подходы\\n- 3 Библиотеки для NLP\\n- 4 Примеры использования NLTK\\n- 5 Пример кода на языке Scala\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nЗадачи\\n|Определение:\\n|Корпус — подобранная и обработанная по определённым правилам совокупность текстов, используемых в качестве базы для исследования языка.\\nNLP решает большой набор задач, который можно разбить по уровням (в скобках). Среди этих задач, можно выделить следующие:\\n- Распознавание текста, речи, синтез речи (сигнал);\\n- Морфологический анализ, канонизация (слово);\\n- POS-тэгирование, распознавание именованных сущностей, выделение слов (словосочетание);\\n- Синтаксический разбор, токенизация предложений (предложение);\\n- Извлечение отношений, определение языка, анализ эмоциональной окраски (абзац);\\n- Аннотация документа, перевод, анализ тематики (документ);\\n- Дедубликация, информационный поиск (корпус).\\nОсновные подходы\\nПредобработка текста\\nПредобработка текста переводит текст на естественном языке в формат удобный для дальнейшей работы. Предобработка состоит из различных этапов, которые могут отличаться в зависимости от задачи и реализации. Далее приведен один из возможных набор этапов:\\n- Перевод всех букв в тексте в нижний или верхний регистры;\\n- Удаление цифр (чисел) или замена на текстовый эквивалент (обычно используются регулярные выражения);\\n- Удаление пунктуации. Обычно реализуется как удаление из текста символов из заранее заданного набора;\\n- Удаление пробельных символов (whitespaces);\\n- Токенизация (обычно реализуется на основе регулярных выражений);\\n- Удаление стоп слов;\\n- Стемминг;\\n- Лемматизация;\\n- Векторизация.\\nСтемминг\\nКоличество корректных словоформ, значения которых схожи, но написания отличаются суффиксами, приставками, окончаниями и прочим, очень велико, что усложняет создание словарей и дальнейшую обработку. Стемминг позволяет привести слово к его основной форме. Суть подхода в нахождении основы слова, для этого с конца и начала слова последовательно отрезаются его части. Правила отсекания для стеммера создаются заранее, и чаще всего представляют из себя регулярные выражения, что делает данный подход трудоемким, так как при подключении очередного языка нужны новые лингвистические исследования. Вторым недостатком подхода является возможная потеря информации при отрезании частей, например, мы можем потерять информацию о части речи.\\nЛемматизация\\nДанный подход является альтернативой стемминга. Основная идея в приведении слова к словарной форме — лемме. Например для русского языка:\\n- для существительных — именительный падеж, единственное число;\\n- для прилагательных — именительный падеж, единственное число, мужской род;\\n- для глаголов, причастий, деепричастий — глагол в инфинитиве несовершенного вида.\\nВекторизация\\nБольшинство математических моделей работают в векторных пространствах больших размерностей, поэтому необходимо отобразить текст в векторном пространстве. Основным походом является мешок слов (bag-of-words): для документа формируется вектор размерности словаря, для каждого слова выделяется своя размерность, для документа записывается признак насколько часто слово встречается в нем, получаем вектор. Наиболее распространенным методом для вычисления признака является TF-IDF[4] (TF — частота слова, term frequency, IDF — обратная частота документа, inverse document frequency). TF вычисляется, например, счетчиком вхождения слова. IDF обычно вычисляют как логарифм от числа документов в корпусе, разделённый на количество документов, где это слово представлено. Таким образом, если какое-то слово встретилось во всех документах корпуса, то такое слово не будет никуда добавлено. Плюсами мешка слов является простая реализация, однако данный метод теряет часть информации, например, порядок слов. Для уменьшения потери информации можно использовать мешок N-грамм (добавлять не только слова, но и словосочетания), или использовать методы векторных представлений слов это, например, позволяет снизить ошибку на словах с одинаковыми написаниями, но разными значениями.\\nДедубликация\\nТак как количество схожих документов в большом корпусе может быть велико, необходимо избавляться от дубликатов. Так как каждый документ может быть представлен как вектор, то мы можем определить их близость, взяв косинус или другую метрику. Минусом является то, что для больших корпусов полный перебор по всем документам будет невозможен. Для оптимизации можно использовать локально-чувствительный хеш, который поместит близко похожие объекты.\\nСемантический анализ\\nСемантический (смысловой) анализ текста — выделение семантических отношений, формировании семантического представления. В общем случае семантическое представление является графом, семантической сетью, отражающим бинарные отношения между двумя узлами — смысловыми единицами текста. Глубина семантического анализа может быть разной, а в реальных системах чаще всего строится только лишь синтаксико-семантическое представление текста или отдельных предложений. Семантический анализ применяется в задачах анализа тональности текста[5](Sentiment analysis), например, для автоматизированного определения положительности отзывов.\\nРаспознавание именованных сущностей и извлечение отношений\\nИменованные сущности — объекты из текста, которые могут быть отнесены к одной из заранее заявленных категорий (например, организации, личности, адреса). Идентификация ссылок на подобные сущности в тексте является задачей распознавания именованных сущностей.\\nСтанкевич Андрей Сергеевич — лауреат специальной премии корпорации IBM. Станкевич Андрей Сергеевич[личность] — лауреат специальной премии корпорации IBM[компания].\\nОпределение семантических отношений между именованными сущностями или другими объектами текста, является задачей извлечения отношений. Примеры отношений: (автор,книга), (организация,главный_офис).\\nЭти два подхода применяются во многих задачах, например, извлечение синонимов из текста, автоматическом построении онтологий и реализованы во многих работающих системах, например, NELL[6] и Snowball[7].\\nИспользование N-грамм\\n|Определение:\\n|N-грамма — последовательность изэлементов.\\nВ NLP N-граммы используются для построения вероятностных моделей, задач схожести текстов, категоризации текста и языка.\\nПостроив N-граммную модель можно определить вероятность употребления заданной фразы в тексте. N-граммная модель рассчитывает вероятность последнего слова N-граммы, если известны все предыдущие, при этом полагается, что вероятность появления каждого слова зависит только от предыдущих слов.\\nИспользование N-грамм применяется в задаче выявления плагиата. Текст разбивается на несколько фрагментов, представленных N-граммами. Сравнение N-грамм друг с другом позволяет определить степень сходства документов. Аналогичным способом можно решать задачу исправления орфографических ошибок, подбирая слова кандидаты для замены.\\nЧастеречная разметка\\nЧастеречная разметка (POS-тэгирование, англ. part-of-speech tagging) используется в NLP для определения части речи и грамматических характеристик слов в тексте с приписыванием им соответствующих тегов. Модель необходима, когда значение слова зависит от контекста. Например, в предложениях \"Столовая ложка\" и \"Школьная столовая\" слово \"столовая\" имеет разные части речи. POS-тэгирование позволяет сопоставить слову в тексте специальный тэг на основе его значения и контекста.\\nАлгоритмы частеречной разметки делятся на несколько групп:\\n- Стохастический метод. Такой метод имеет два похожих друг на друга подхода. Первый подход основывается на частоте встречаемости слова с конкретным тэгом: если определенное слово встречается чаще всего с тэгом \"существительное\", то скорее всего и сейчас оно будет иметь такой тэг. Второй вариант использует n-граммы — анализируя входную последовательность, алгоритм высчитывает вероятность, что в данном контексте будет определенный тэг. В конце просчета вероятностей выбирается тэг, который имеет наибольшую вероятность. Библиотека TextBlob[8] в своей основе использует стохастический метод.\\n- Основанные на правилах. Метод основан на заранее известных правилах. Алгоритм состоит из двух стадий. Сначала расставляются потенциальные тэги всем словам на основе словаря или по какому-либо другому принципу. Далее, если у какого-нибудь слова оказалось несколько тэгов, правильный тэг выбирается на основе рукописных правил. Правил должно быть много, чтобы решить все возникшие неопределенности и учесть все случаи. Например, правило: слова длиной меньше трех символов являются частицами, местоимениями или предлогами. Однако такое правило не учитывает некоторые короткие слова из других частей речи. В библиотеке NLTK[9] используется данный метод.\\n- С использованием скрытой марковской модели. Пусть в нашей Марковской модели тэги будут скрытыми состояниями, которые производят наблюдаемое событие — слова. С математической точки зрения, мы хотим найти такую последовательность тэгов (C), которая будет максимизировать условную вероятность , где и . Воспользовавшись формулой Байеса получим, что максимизировать необходимо следующее выражение: . Библиотека spaCy[10] основана на скрытой марковской модели.\\nPOS-тэгирование является неотъемлемой частью обработки естественного языка. Без частеречной разметки становится невозможным дальнейший анализ текста из-за возникновения неопределенностей в значениях слов. Данный алгоритм используется при решении таких задач как перевод на другой язык, определение смысла текста, проверка на пунктуационные и речевые ошибки. Также можно автоматизировать процесс определения хештегов у постов и статей, выделяя существительные в приведенном тексте.\\nБлагодаря частому использованию POS-тэгирования на практике, существует много встроенных библиотек с готовыми реализациями. Например, NLTK, scikit-learn[11], spaCy, TextBlob, HunPOS[12], Standford POS Tagger[13] и другие. Примеры использования некоторых библиотек:\\n- TextBlob (стохастический метод):\\nfrom textblob import TextBlob text = (\"The quick brown fox jumps over the lazy dog\") blob_object = TextBlob(text) print(blob_object.tags) output: [(\\'The\\', \\'DT\\'), (\\'quick\\', \\'JJ\\'), (\\'brown\\', \\'JJ\\'), (\\'fox\\', \\'NN\\'), (\\'jumps\\', \\'VBZ\\'), (\\'over\\', \\'IN\\'), (\\'the\\', \\'DT\\'), (\\'lazy\\', \\'JJ\\'), (\\'dog\\', \\'NN\\')]\\n- NLTK (основанный на правилах):\\nimport nltk from nltk.tokenize import word_tokenize text = word_tokenize(\"Hello welcome to the world of to learn Categorizing and POS Tagging with NLTK and Python\") nltk.pos_tag(text) output: [(\\'Hello\\', \\'NNP\\'), (\\'welcome\\', \\'NN\\'), (\\'to\\', \\'TO\\'), (\\'the\\', \\'DT\\'), (\\'world\\', \\'NN\\'), (\\'of\\', \\'IN\\'), (\\'to\\', \\'TO\\'), (\\'learn\\', \\'VB\\'), (\\'Categorizing\\', \\'NNP\\'), (\\'and\\', \\'CC\\'), (\\'POS\\', \\'NNP\\'), (\\'Tagging\\', \\'NNP\\'), (\\'with\\', \\'IN\\'), (\\'NLTK\\', \\'NNP\\'), (\\'and\\', \\'CC\\'), (\\'Python\\', \\'NNP\\')]\\n- spaCy (с использованием скрытой марковской модели):\\nimport spacy nlp = spacy.load(\"en_core_web_sm\") doc = nlp(\"The quick brown fox jumps over the lazy dog\") for token in doc: print((token.text, token.pos_)) output: [(\\'The\\', \\'DT\\'), (\\'quick\\', \\'JJ\\'), (\\'brown\\', \\'JJ\\'), (\\'fox\\', \\'NN\\'), (\\'jumps\\', \\'NNS\\'), (\\'over\\', \\'IN\\'), (\\'the\\', \\'DT\\'), (\\'lazy\\', \\'JJ\\'), (\\'dog\\', \\'NN\\')]\\n- HunPOS:\\nfrom os.path import expanduser home = expanduser(\"~\") from nltk.tag.hunpos import HunposTagger _path_to_bin = home + \\'/hunpos-1.0-linux/hunpos-tag\\' _path_to_model = home + \\'/hunpos-1.0-linux/en_wsj.model\\' ht = HunposTagger(path_to_model=_path_to_model, path_to_bin=_path_to_bin) text = \"The quick brown fox jumps over the lazy dog\" ht.tag(text.split()) output: [(\\'The\\', \\'DT\\'), (\\'quick\\', \\'JJ\\'), (\\'brown\\', \\'JJ\\'), (\\'fox\\', \\'NN\\'), (\\'jumps\\', \\'NNS\\'), (\\'over\\', \\'IN\\'), (\\'the\\', \\'DT\\'), (\\'lazy\\', \\'JJ\\'), (\\'dog\\', \\'NN\\')]\\n- Stanford POS tagger\\nfrom os.path import expanduser home = expanduser(\"~\") from nltk.tag.stanford import POSTagger _path_to_model = home + \\'/stanford-postagger/models/english-bidirectional-distsim.tagger\\' _path_to_jar = home + \\'/stanford-postagger/stanford-postagger.jar\\' st = POSTagger(path_to_model=_path_to_model, path_to_jar=_path_to_jar) text = \"The quick brown fox jumps over the lazy dog\" st.tag(text.split()) output: [(\\'The\\', \\'DT\\'), (\\'quick\\', \\'JJ\\'), (\\'brown\\', \\'JJ\\'), (\\'fox\\', \\'NN\\'), (\\'jumps\\', \\'VBZ\\'), (\\'over\\', \\'IN\\'), (\\'the\\', \\'DT\\'), (\\'lazy\\', \\'JJ\\'), (\\'dog\\', \\'NN\\')]\\nБиблиотеки для NLP\\nNLTK (Natural Language ToolKit)[14]\\nПакет библиотек и программ для символьной и статистической обработки естественного языка, написанных на Python и разработанных по методологии SCRUM. Содержит графические представления и примеры данных. Поддерживает работу с множеством языков, в том числе, русским.\\nПлюсы:\\n- Наиболее известная и многофункциональная библиотека для NLP;\\n- Большое количество сторонних расширений;\\n- Быстрая токенизация предложений;\\n- Поддерживается множество языков.\\nМинусы\\n- Медленная;\\n- Сложная в изучении и использовании;\\n- Работает со строками;\\n- Не использует нейронные сети;\\n- Нет встроенных векторов слов.\\nspaCy[15]\\nБиблиотека, разработанная по методологии SCRUM на языке Cypthon, позиционируется как самая быстрая NLP библиотека. Имеет множество возможностей, в том числе, разбор зависимостей на основе меток, распознавание именованных сущностей, пометка частей речи, векторы расстановки слов. Не поддерживает русский язык.\\nПлюсы:\\n- Самая быстрая библиотека для NLP;\\n- Простая в изучении и использовании;\\n- Работает с объектами, а не строками;\\n- Есть встроенные вектора слов;\\n- Использует нейронные сети для тренировки моделей.\\nМинусы\\n- Менее гибкая по сравнению с NLTK;\\n- Токенизация предложений медленнее, чем в NLTK;\\n- Поддерживает маленькое количество языков.\\nscikit-learn[16]\\nБиблиотека scikit-learn разработана по методологии SCRUM и предоставляет реализацию целого ряда алгоритмов для обучения с учителем и обучения без учителя через интерфейс для Python. Построена поверх SciPy. Ориентирована в первую очередь на моделирование данных, имеет достаточно функций, чтобы использоваться для NLP в связке с другими библиотеками.\\nПлюсы:\\n- Большое количество алгоритмов для построения моделей;\\n- Содержит функции для работы с Bag-of-Words моделью;\\n- Хорошая документация.\\nМинусы\\n- Плохой препроцессинг, что вынуждает использовать ее в связке с другой библиотекой (например, NLTK);\\n- Не использует нейронные сети для препроцессинга текста.\\ngensim[17]\\nPython библиотека, разработанная по методологии SCRUM, для моделирования, тематического моделирования документов и извлечения подобия для больших корпусов. В gensim реализованы популярные NLP алгоритмы, например, word2vec. Большинство реализаций могут использовать несколько ядер.\\nПлюсы:\\n- Работает с большими датасетами;\\n- Поддерживает глубокое обучение;\\n- word2vec, tf-idf vectorization, document2vec.\\nМинусы\\n- Заточена под модели без учителя;\\n- Не содержит достаточного функционала, необходимого для NLP, что вынуждает использовать ее вместе с другими библиотеками.\\nБалто-славянские языки имеют сложную морфологию, что может ухудшить качество обработки текста, а также ограничить использование ряда библиотек. Для работы со специфичной русской морфологией можно использовать, например, морфологический анализатор pymorphy2[18] и библиотеку для поиска и извлечения именованных сущностей Natasha[19]\\nПримеры использования NLTK\\n- Разбиение на предложения:\\ntext = \"Предложение. Предложение, которое содержит запятую. Восклицательный знак! Вопрос?\" sents = nltk.sent_tokenize(text) print(sents) output: [\\'Предложение.\\', \\'Предложение, которое содержит запятую.\\', \\'Восклицательный знак!\\', \\'Вопрос?\\']\\n- Токенизация:\\nfrom nltk.tokenize import RegexpTokenizer sent = \"В этом предложении есть много слов, мы их разделим.\" tokenizer = RegexpTokenizer(r\\'\\\\w+\\') print(tokenizer.tokenize(sent)) output: [\\'В\\', \\'этом\\', \\'предложении\\', \\'есть\\', \\'много\\', \\'слов\\', \\'мы\\', \\'их\\', \\'разделим\\']\\nfrom nltk import word_tokenize sent = \"В этом предложении есть много слов, мы их разделим.\" print(word_tokenize(sent)) output: [\\'В\\', \\'этом\\', \\'предложении\\', \\'есть\\', \\'много\\', \\'слов\\', \\',\\', \\'мы\\', \\'их\\', \\'разделим\\', \\'.\\']\\n- Стоп слова:\\nfrom nltk.corpus import stopwords stop_words=set(stopwords.words(\\'english\\')) print(stop_words) output: {\\'should\\', \\'wouldn\\', \\'do\\', \\'over\\', \\'her\\', \\'what\\', \\'aren\\', \\'once\\', \\'same\\', \\'this\\', \\'needn\\', \\'other\\', \\'been\\', \\'with\\', \\'all\\' ...\\n- Стемминг и лемматизация:\\nfrom nltk.stem.porter import PorterStemmer porter_stemmer = PorterStemmer() print(porter_stemmer.stem(\"crying\")) output: cri\\nfrom nltk.stem.lancaster import LancasterStemmer lancaster_stemmer = LancasterStemmer() print(lancaster_stemmer.stem(\"crying\")) output: cry\\nfrom nltk.stem import SnowballStemmer snowball_stemmer = SnowballStemmer(\"english\") print(snowball_stemmer.stem(\"crying\")) output: cri\\nfrom nltk.stem import WordNetLemmatizer wordnet_lemmatizer = WordNetLemmatizer() print(wordnet_lemmatizer.lemmatize(\"came\", pos=\"v\")) output: come\\nПример кода на языке Scala\\nПример реализации алгоримтма NLP на основе Apache Spark ML[20].\\nСм. также\\nПримечания\\nИсточники информации\\n- [1] — статья на Википедии\\n- Natural Language Processing with Python — Analyzing Text with the Natural Language Toolkit\\n- Speech and Language Processing', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='72fbf1bd-9614-47bc-94c9-705a5470fe1d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2819d2d48cc9d41bb5a0e04839e2ba7261c475c467298f85aeb2cfd2e7fdc843', text='Векторное представление слов\\nВекторное представление слов (англ. word embedding) — общее название для различных подходов к моделированию языка и обучению представлений в обработке естественного языка, направленных на сопоставление словам из некоторого словаря векторов небольшой размерности.\\nСодержание\\nOne-hot encoding\\nПусть число различных слов равно. Сопоставим слову с номером вектор длины , в котором -тая координата равна единице, а все остальные — нулям (рис. 1). Недостатком one-hot encoding является то, что по векторным представлениям нельзя судить о схожести смысла слов. Также вектора имеют очень большой размер, из-за чего их неэффективно хранить в памяти.\\nword2vec\\nword2vec — способ построения сжатого пространства векторов слов, использующий нейронные сети. Принимает на вход большой текстовый корпус и сопоставляет каждому слову вектор. Сначала он создает словарь, а затем вычисляет векторное представление слов. Векторное представление основывается на контекстной близости: слова, встречающиеся в тексте рядом с одинаковыми словами (а следовательно, имеющие схожий смысл) (рис. 2), в векторном представлении имеют высокое косинусное сходство (англ. cosine similarity):\\nВ word2vec существуют две основных модели обучения: Skip-gram (рис. 3) и CBOW (англ. Continuous Bag of Words) (рис. 4). В модели Skip-gram по слову предсказываются слова из его контекста, а в модели CBOW по контексту подбирается наиболее вероятное слово. На выходном слое используется функцияили его вариация, чтобы получить на выходе распределение вероятности каждого слова. В обеих моделях входные и выходные слова подаются в one-hot encoding, благодаря чему при умножении на матрицу , соединяющую входной и скрытый слои, происходит выбор одной строки . Размерность является гиперпараметром алгоритма, а обученная матрица — выходом, так как ее строки содержат векторные представления слов.\\nДля ускорения обучения моделей Skip-gram и CBOW используются модификации, такие как иерархический и negative sampling, позволяющие вычислять распределение вероятностей быстрее, чем за линейное время от размера словаря.\\nfastText\\nНедостатком word2vec является то, что с его помощью не могут быть представлены слова, не встречающиеся в обучающей выборке. fastText решает эту проблему с помощью-грамм символов. Например, -граммами для слова яблоко являются ябл, бло, лок, око. Модель fastText строит векторные представления -грамм, а векторным представлением слова является сумма векторных представлений всех его -грамм. Части слов с большой вероятностью встречаются и в других словах, что позволяет выдавать векторные представления и для редких слов.\\nПримеры кода с использованием библиотеки Gensim\\nЗагрузка предобученной модели русского корпуса\\nimport gensim import gensim.downloader as download_api russian_model = download_api.load(\\'word2vec-ruscorpora-300\\')\\n# Выведем первые 10 слов корпуса.\\n# В модели \"word2vec-ruscorpora-300\" после слова указывается часть речи: NOUN (существительное), ADJ (прилагательное) и так далее.\\n# Но существуют также предоубученные модели без разделения слов по частям речи, смотри репозиторий list(russian_model.vocab.keys())[:10] # [\\'весь_DET\\', \\'человек_NOUN\\', \\'мочь_VERB\\', \\'год_NOUN\\', \\'сказать_VERB\\', \\'время_NOUN\\', \\'говорить_VERB\\', \\'становиться_VERB\\', \\'знать_VERB\\', \\'самый_DET\\']\\n# Поиск наиболее близких по смыслу слов. russian_model.most_similar(\\'кошка_NOUN\\') # [(\\'кот_NOUN\\', 0.7570087909698486), (\\'котенок_NOUN\\', 0.7261239290237427), (\\'собака_NOUN\\', 0.6963180303573608), # (\\'мяукать_VERB\\', 0.6411399841308594), (\\'крыса_NOUN\\', 0.6355636119842529), (\\'собачка_NOUN\\', 0.6092042922973633), # (\\'щенок_NOUN\\', 0.6028496026992798), (\\'мышь_NOUN\\', 0.5975362062454224), (\\'пес_NOUN\\', 0.5956044793128967), # (\\'кошечка_NOUN\\', 0.5920293927192688)]\\n# Вычисление сходства слов russian_model.similarity(\\'мужчина_NOUN\\', \\'женщина_NOUN\\') # 0.85228276\\n# Поиск лишнего слова russian_model.doesnt_match(\\'завтрак_NOUN хлопья_NOUN обед_NOUN ужин_NOUN\\'.split()) # хлопья_NOUN\\n# Аналогия: Женщина + (Король - Мужчина) = Королева russian_model.most_similar(positive=[\\'король_NOUN\\',\\'женщина_NOUN\\'], negative=[\\'мужчина_NOUN\\'], topn=1) # [(\\'королева_NOUN\\', 0.7313904762268066)]\\n# Аналогия: Франция = Париж + (Германия - Берлин) russian_model.most_similar(positive=[\\'париж_NOUN\\',\\'германия_NOUN\\'], negative=[\\'берлин_NOUN\\'], topn=1) # [(\\'франция_NOUN\\', 0.8673800230026245)]\\nОбучение модели word2vec и fastText на текстовом корпусе\\nfrom gensim.models.word2vec import Word2Vec from gensim.models.fasttext import FastText import gensim.downloader as download_api\\n# Скачаем небольшой текстовый корпус (32 Мб) и откроем его как итерируемый набор предложений: iterable(list(string)) # В этом текстовом корпусе часть речи для слов не указывается corpus = download_api.load(\\'text8\\')\\n# Обучим модели word2vec и fastText word2vec_model = Word2Vec(corpus, size=100, workers=4) fastText_model = FastText(corpus, size=100, workers=4)\\nword2vec_model.most_similar(\\'car\\')[:3] # [(\\'driver\\', 0.8033335208892822), (\\'motorcycle\\', 0.7368553876876831), (\\'cars\\', 0.7001584768295288)]\\nfastText_model.most_similar(\\'car\\')[:3] # [(\\'lcar\\', 0.8733218908309937), (\\'boxcar\\', 0.8559106588363647), (\\'ccar\\', 0.8268736004829407)]\\nELMO\\nELMO — это многослойная двунаправленная рекуррентная нейронная сеть c LSTM (рис. 5). При использовании word2vec или fastText не учитывается семантическая неоднозначность слов. Так, word2vec назначает слову один вектор независимо от контекста. ELMO решает эту проблему. В основе стоит идея использовать скрытые состояния языковой модели многослойной LSTM.\\nБыло замечено, что нижние слои сети отвечают за синтаксис и грамматику, а верхние — за смысл слов. Пусть даны токены, на которые поделено предложение. Будем считать логарифм правдоподобия метки слова в обоих направлениях, учитывая контекст слева и контекст справа, то есть на основании данных от начала строки до текущего символа и данных от текущего символа и до конца строки. Таким образом, модель предсказывает вероятность следующего токена с учетом истории.\\nПусть естьслоев сети. Входные и выходные данные будем представлять в виде векторов, кодируя слова. Тогда каждый результирующий вектор будем считать на основании множества:\\n.\\nЗдесь— входящий токен, а и — скрытые слои в одном и в другом направлении.\\nТогда результат работы ELMO будет представлять из себя выражение:.\\nОбучаемый общий масштабирующий коэффициентрегулирует то, как могут отличаться друг от друга по норме векторные представления слов.\\nКоэффициенты— это обучаемые параметры, нормализованные функцией .\\nМодель применяют дообучая ее: изначально берут предобученную ELMO, а затем корректируюти под конкретную задачу. Тогда вектор, который подается в используемую модель для обучения, будет представлять собой взвешенную сумму значений этого векторах на всех скрытых слоях ELMO.\\nНа данный момент предобученную модель ELMO можно загрузить и использовать в языке программирования Python.\\nBERT\\nBERT — это многослойный двунаправленный кодировщик Transformer. В данной архитектуре (рис. 6) используется двунаправленное самовнимание (англ. self-attention). Модель используется в совокупности с некоторым классификатором, на вход которого подается результат работы BERT — векторное представление входных данных. В основе обучения модели лежат две идеи.\\nПервая заключается в том, чтобы заменитьслов масками и обучить сеть предсказывать эти слова.\\nВторой трюк состоит в том, чтобы дополнительно научить BERT определять, может ли одно предложение идти после другого.\\nТочно так же, как и в обычном трансформере, BERT принимает на вход последовательность слов, которая затем продвигается вверх по стеку энкодеров. Каждый слой энкодера применяет самовнимание и передает результаты в сеть прямого распространения, после чего направляет его следующему энкодеру.\\nДля каждой позиции на выход подается вектор размерностью( в базовой модели). Этот вектор может быть использован как входной вектор для классификатора.\\nBert поддерживается в качестве модели в языке Python, которую можно загрузить.\\nСм. также\\nИсточники информации\\n- Word embedding — статья о векторных представлениях в английской Википедии\\n- (YouTube) Обработка естественного языка — лекция на русском Даниила Полыковского в курсе Техносферы\\n- (YouTube) Word Vector Representations: word2vec — лекция на английском в Стэнфордском Университете\\n- word2vec article — оригинальная статья по word2vec от Томаса Миколова\\n- word2vec code — исходный код word2vec на Google Code\\n- Gensim tutorial on word2vec — небольшое руководство по работе с word2vec в библиотеке Gensim\\n- Gensim documentation on fastText — документация по fastText в библиотеке Gensim\\n- Gensim Datasets — репозиторий предобученных моделей для библиотеки Gensim\\n- fastText — NLP библиотека от Facebook\\n- fastText article — оригинальная статья по fastText от Piotr Bojanowski\\n- RusVectōrēs — онлайн сервис для работы с семантическими отношениями русского языка\\n- Cornell univerity arxiv — оригинальная статья про Bert\\n- Cornell univerity arxiv — оригинальная статья с описанием ELMO', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='01abde50-d124-4e5d-9bcd-2e5eccea1eeb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ee29afb05aff4071e4c273fe7c4e4f341a99e827def8defbe1bc755687f2c98d', text='Классификация текстов и анализ тональности\\nКлассификация текстов (документов) (англ. Document classification) — задача компьютерной лингвистики[1], заключающаяся в отнесении документа к одной из нескольких категорий на основании содержания документа.\\nАнализ тональности текста (англ. Sentiment analysis) — задача компьютерной лингвистики, заключающаяся в определении эмоциональной окраски (тональности) текста и, в частности, в выявлении эмоциональной оценки авторов по отношению к объектам, описываемым в тексте.\\nСодержание\\n- 1 Задачи классификации текстов\\n- 2 Задачи анализа тональности текста\\n- 3 Классификация текстов методами машинного обучения\\n- 4 Применение семантических тезаурусов для анализа тональности текстов\\n- 5 См. также\\n- 6 Примечания\\nЗадачи классификации текстов\\nКлассификация текстов применяется, в том числе, для:\\n- разделения веб страниц и сайтов по тематическим каталогам;\\n- борьбы со спамом;\\n- определение языка текста;\\n- показа более релевантной рекламы.\\nЗадачи анализа тональности текста\\nОсновной задачей анализа тональности текста является определение его эмоциональной окраски. Это необходимо, в том числе, для:\\n- Анализа отзывов о товарах и услугах;\\n- Определение языка вражды[2].\\nВ общем случае, задача анализа тональности текста эквивалентна задаче классификации текста, где категориями текстов могут быть тональные оценки. Примеры тональных оценок:\\n- позитивная;\\n- негативная;\\n- нейтральная.\\nПод «нейтральной» подразумевается, что текст не содержит эмоциональной окраски.\\nВ качестве примера или упражнения можно предсказывать тональность рецензий к фильмам. Например, предсказывать методом линейной регрессии оценку(тональность), что поставил автор, по документу представленном в виде вектора, где на-ой позиции количество вхождений -ого слова из словаря в документу.\\nАнализ тональности обычно определяют как одну из задач компьютерной лингвистики, т.е. подразумевается, что мы можем найти и классифицировать тональность, используя инструменты обработки естественного языка. Сделав большое обобщение, можно разделить существующие подходы на следующие категории:\\n- подходы, основанные на правилах;\\n- подходы, основанные на словарях;\\n- машинное обучение с учителем;\\n- машинное обучение без учителя.\\nВ первом варианте системы состоят из набора правил, применяя которые система делает заключение о тональности текста. Например, для предложения «Я люблю кофе», можно применить следующее правило: если сказуемое (\"люблю\") входит в положительный набор глаголов (\"люблю\", \"обожаю\", \"одобряю\" ...) и в предложении не имеется отрицаний, то классифицировать тональность как \"положительная\". Многие коммерческие системы используют данный подход, несмотря на то что он требует больших затрат, так как для хорошей работы системы необходимо составить большое количество правил. Зачастую правила привязаны к определенному домену (например, «ресторанная тематика») и при смене домена («обзор фотоаппаратов») требуется заново составлять правила. Тем не менее, этот подход является наиболее точным при наличии хорошей базы правил.\\nПодходы, основанные на словарях, используют так называемые тональные словари (англ. affective lexicons) для анализа текста. В простом виде тональный словарь представляет из себя список слов со значением тональности для каждого слова. Вот пример из базы ANEW[3], переведенный на русский, где число означет валентность(1-9):\\n- счастливый - 8.21;\\n- хороший - 7.47;\\n- скучный - 2.95;\\n- сердитый - 2.85;\\n- грустный - 1.61.\\nЧтобы проанализировать текст, можно воспользоваться следующим алгоритмом: сначала каким-нибудь способом каждому слову в тексте присвоить его значением тональности, а затем вычислить общую тональность всего текста. Вычислять общую тональность можно разными способами. Самый простой из них — среднее арифметическое всех значений. Более сложный — обучить нейронную сеть.\\nМашинное обучение без учителя представляет собой, наверное, наиболее интересный и в то же время наименее точный метод анализа тональности. Одним из примеров данного метода может быть автоматическая кластеризация документов. Например, можно считать документы похожими, если у них большое пересечение по набору слов, и далее этот набор будет классифицировать весь кластер. В частности если в пересечении встречаются слова \"ужасный\", \"невыносимый\" и \"отвратный\", то скорее всего этот документы в этом кластере имеют негативный окрас.\\nМашинное обучение с учителем\\nПроцесс создания системы анализа тональности очень похож на процесс создания других систем с применением машинного обучения:\\n- Необходимо собрать коллекцию документов для обучения классификатора.\\n- Каждый документ из обучающей коллекции нужно представить в виде вектора признаков.\\n- Для каждого документа нужно указать «правильный ответ», т.е. тип тональности (например, положительная или отрицательная), по этим ответам и будет обучаться классификатор.\\n- Выбор алгоритма классификации и обучение классификатора.\\n- Использование полученной модели.\\nЕсли стоит задача классификации на более чем два класса, то тут возможны следующие варианты для обучения классификатора:\\n- плоская классификация — обучаем лишь один классификатор для всех классов;\\n- иерархическая классификация — делим классы на группы и обучаем несколько классификаторов для определения групп. Например, если у нас 5 классов («сильно положительный», «средне положительный», «нейтральный», «средне отрицательный», «сильно отрицательный»), то можно сначала обучить бинарный классификатор, который отделяет нейтральные тексты от субъективных; затем обучить классификатор, который отделяет положительные мнения от отрицательных; и в итоге классификатор, который отделяет сильно выраженные мнения от средних;\\n- регрессия — обучаем классификатор для получения численного значения тональности, например от 1 до 10, где большее значение означает более положительную тональность.\\nОбычно иерархическая классификация дает лучшие результаты чем плоская, так как для каждого классификатора можно найти набор признаков, который позволяет улучшить результаты. Однако, он требует больших времени и усилий для обучения и тестирования. Регрессия может показать лучшие результаты, если классов действительно много (от 5 и более).\\nКлассификация текстов методами машинного обучения\\nПостановка задачи\\nИмеется множество категорий (классов, меток).\\nИмеется множество документов.\\nНеизвестная целевая функция.\\nНеобходимо построить классификатор, максимально близкий к .\\nИмеется некоторая начальная коллекция размеченных документов, для которых известны значения . Обычно её делят на «обучающую» и «проверочную» части. Первая используется для обучения классификатора, вторая — для независимой проверки качества его работы.\\nКлассификатор может выдавать точный ответили степень подобия .\\nЭтапы подготовки\\nПрежде всего следует предобработать текст. Подробно методы предобработки описаны в соответствующей статье\\nВекторное представление слов\\nБольшинство математических моделей работают в векторных пространствах больших размерностей, поэтому необходимо отобразить текст в векторном пространстве. Основным походом является мешок слов (англ. bag-of-words): для документа формируется вектор размерности словаря, для каждого слова выделяется своя размерность, для документа записывается признак насколько часто слово встречается в нем, получаем вектор. Наиболее распространенным методом для вычисления признака является TF-IDF[4] и его вариации (TF — частота слова (англ. term frequency), IDF — обратная частота документа (англ. inverse document frequency)). Плюсами мешка слов является простая реализация, однако данный метод теряет часть информации, например, порядок слов. Для уменьшения потери информации можно использовать мешок N-грамм (добавлять не только слова, но и словосочетания), или использовать более сложные в плане вычислений методы векторных представлений слов(Word2vec или его улучшение, fastText) это, например, позволяет снизить ошибку на словах с одинаковыми написаниями, но разными значениями и наоборот. Подробнее можно прочитать в данной статье.\\nАлгоритмы классификации\\nБайесовская классификация\\nБайесовская классификация является одним из самых простых, но не значит, что неэффективных, методов в классификации текстов. Данный алгоритм основан на принципе максимума апостериорной вероятности. Для классифицируемого объекта вычисляются функции правдоподобия каждого из классов, по ним вычисляются апостериорные вероятности классов. Объект относится к тому классу, для которого апостериорная вероятность максимальна.\\nПусть— вероятность того, что документ, представленный вектором , соответствует категории для . Задача классификатора заключается в том, чтобы подобрать такие значения и , при которых значение вероятности будет максимальным:\\nПодробно байесовская классификация описана в соответствующей статье.\\nПреимущества метода:\\n- высокая скорость работы;\\n- простая реализация алгоритма;\\n- легкая интерпретируемость результатов работы алгоритма.\\nНедостатки метода:\\n- частое низкое качество классификации;\\n- неспособность учитывать зависимость результата классификации от сочетания признаков.\\nМногомерная модель\\nВ многомерной (англ. multivariate) модели документ – это вектор бинарных атрибутов, показывающих, встретилось ли в документе то или иное слово. Когда мы подсчитываем правдоподобие документа, мы перемножаем вероятности того, что встретилось каждое слово из документа и вероятности того, что не встретилось каждое (словарное) слово, которое не встретилось. Получается модель многомерных испытаний Бернулли. Наивное предположение в том, что события «встретилось ли слово» предполагаются независимыми.\\nМатематически: пусть– словарь. Тогда документ – это вектор длины , состоящий из битов . тогда и только тогда, когда слово встречается в документе .\\nПравдоподобие принадлежностиклассу :\\nДля обучения такого классификатора нужно обучить.\\nПусть дан набор документов, которые уже распределены по классам (возможно, даже вероятностно распределены, то есть про каждый документ мы знаем, с какой вероятностью он принадлежит к каждому классу, но здесь и далее будем рассматривать детерминированную модель), дан словарь , и мы знаем биты (знаем документы).\\nТогда можно подсчитать оптимальные оценки вероятностей того, что то или иное слово встречается в том или ином классе (при помощи лапласовой оценки):\\nАприорные вероятности классов можно подсчитать как. Классификация происходит как обычно — максимизацией правдоподобия: .\\nМультиномиальная модель\\nВ мультиномиальной (англ. multinomial) модели документ – это последовательность событий. Каждое событие – это случайный выбор одного слова из того самого мешка слов. Когда мы подсчитываем правдоподобие документа, мы перемножаем вероятности того, что мы достали из мешка те самые слова, которые встретились в документе. Наивное предположение в том, что мы достаём из мешка разные слова независимо друг от друга. Получается мультиномиальная генеративная модель, которая учитывает количество повторений каждого слова, но не учитывает, каких слов нет в документе.\\nМатематически: пусть– словарь. Тогда документ – это вектор длины , состоящий из слов, каждое из которых «вынуто» из словаря с вероятностью .\\nПравдоподобие принадлежностиклассу :\\n, где – количество вхождений в .\\nДля обучения такого классификатора тоже нужно обучить вероятности.\\nПусть дан набор документов, которые уже распределены по классам , дан словарь , и мы знаем вхождения .\\nТогда можно подсчитать апостериорные оценки вероятностей того, что то или иное слово встречается в том или ином классе (не забываем сглаживание – правило Лапласа):\\n.\\nАприорные вероятности классов можно подсчитать как. Тогда классификация будет происходить как .\\nМетод опорных векторов\\nДля использования метода опорных векторов (англ. SVM, support vector machine) требуется представлять каждый документ, как вектор, задаваемый своим содержимым в общем векторном пространстве. После этого строится разделяющая гиперплоскость для каждого известного класса.\\nПреимущества метода:\\n- один из наиболее качественных методов;\\n- возможность работы с небольшим набором данных для обучения;\\n- сводимость к задаче выпуклой оптимизации, имеющей единственное решение.\\nНедостатки метода: сложная интерпретируемость параметров алгоритма и неустойчивость по отношению к выбросам в исходных данных, например в документе, рассказывающем о том как какой-нибудь футболист любит разводить собак и как он это делает, из-за частого употребления имени футболиста документ будет отнесен к классу \"про футбол\", или наоборот все документы с этим футболистом станут принадлежать к классу \"разведение собак\".\\npLSA\\npLSA (англ. Probabilistic latent semantic analysis) или вероятностный латентно-семантический анализ был разработан в 1999г.\\nКаждое словопорождается некой темой . Документ порождается некоторым распределением на темах . Слово порождается именно темой, а не документом: . Итого получается следующая функция правдоподобия: .\\nМожно оценить, а требуется найти . Правдоподобие выглядит следующим образом .\\nМаксимизировать такое правдоподобие следует используя EM-алгоритм. На Е-шаге ищем, сколько слов в документе из темы :\\nНа М шаге пересчитываем параметры модели:, , , , .\\nПараметров очень много, что явно введет к оверфиттингу, только если корпус не будет на порядки больше числа тем. Однако это решается регуляризацией(Есть целая наука о разных регуляризаторах для pLSA (К.В. Воронцов)).\\nВ общем виде так: добавим регуляризаторыв логарифм правдоподобия:\\nТогда ЕМ-алгоритме на М-шаге появятся частные производные:\\n, .\\nВместо pLSA почти всегда используют его улучшение - LDA[5](англ. Latent Dirichlet allocation), оно более ресурсоемкое, однако выдает лучшие результаты чем pLSA. Фактически это улучшение является байесовским вариантом pLSA, использующее вариационные приближения или сэмплирование(это основные подходы к выводу в сложных вероятностных моделях).\\nОценка качества в задачах классификации\\nДля оценки качества классификации, как и для оценки качества работы многих других алгоритмов машинного обучения вычисляется точность, полнота, F-мера и accuracy.\\nПрименение семантических тезаурусов для анализа тональности текстов\\nСуществуют тезаурусы[6], размеченные силами людей с учётом эмоциональной окраски слов, содержащихся в них. Такие словари позволяют определять тональность текста без применения алгоритмов машинного обучения. Тональность текста определяется как сумма тональностей слов, содержащихся в размеченных словарях.\\nОсновной проблемой методов, основанных на словарях является трудоёмкость построения словаря: отдельного для каждого нового языка и каждой новой тематики.\\nИзвестные тезаурусы:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='89a5b39a-4ec2-43af-8a30-459bd2274d2b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c18156d746a4af1afaf2fb2a1a2faf3e789b007fccdf6a295e699f94439967b9', text='Долгая краткосрочная память\\nДолгая краткосрочная память (англ. Long short-term memory, LSTM) — особая разновидность архитектуры рекуррентных нейронных сетей, способная к обучению долговременным зависимостям, предложенная в 1997 году Сеппом Хохрайтером и Юргеном Шмидхубером[1].\\nСодержание\\n- 1 Описание\\n- 2 Основные компоненты\\n- 3 Принцип работы\\n- 4 Вариации\\n- 5 Примеры кода\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nОписание\\nРекуррентные нейронные сети добавляют память к искуственным нейронным сетям, но реализуемая память получается короткой — на каждом шаге обучения информация в памяти смешивается с новой и через несколько итераций полностью перезаписывается.\\nLSTM-модули разработаны специально, чтобы избежать проблемы долговременной зависимости, запоминая значения как на короткие, так и на длинные промежутки времени. Это объясняется тем, что LSTM-модуль не использует функцию активации внутри своих рекуррентных компонентов. Таким образом, хранимое значение не размывается во времени и градиент не исчезает при использовании метода обратного распространения ошибки во времени (англ. Backpropagation Through Time, BPTT)[2][3] при тренировке сети.\\nКлючевые компоненты LSTM-модуля: состояние ячейки и различные фильтры. О состоянии ячейки можно говорить, как о памяти сети, которая передает соответствующую информацию по всей цепочке модулей. Таким образом, даже информация из ранних временных шагов может быть получена на более поздних, нивелируя эффект кратковременной памяти.\\nПо мере того, как происходит обучение, состояние ячейки изменяется, информация добавляется или удаляется из состояния ячейки структурами, называемыми фильтрами. Фильтры контролируют поток информации на входах и на выходах модуля на основании некоторых условий. Они состоят из слоя сигмоидальной[4] нейронной сети и операции поточечного умножения.\\nСигмоидальный слой возвращает числа в диапазоне [0; 1], которые обозначают, какую долю каждого блока информации следует пропустить дальше по сети. Умножение на это значение используется для пропуска или запрета потока информации внутрь и наружу памяти. Например, входной фильтр контролирует меру вхождения нового значения в память, а фильтр забывания контролирует меру сохранения значения в памяти. Выходной фильтр контролирует меру того, в какой степени значение, находящееся в памяти, используется при расчёте выходной функции активации.\\nОсновные компоненты\\n- Состояние ячейки\\n- Фильтры, контролирующие состояние ячейки\\n- Забывания\\n- Входной\\n- Выходной\\nПринцип работы\\nСперва “слой фильтра забывания” (англ. forget gate layer) определяет, какую информацию можно забыть или оставить. Значения предыдущего выходаи текущего входа пропускаются через сигмоидальный слой. Полученные значения находятся в диапозоне [0; 1]. Значения, которые ближе к 0 будут забыты, а к 1 оставлены.\\nДалее решается, какая новая информация будет храниться в состоянии ячейки. Этот этап состоит из двух частей. Сначала сигмоидальный слой под названием “слой входного фильтра” (англ. input layer gate) определяет, какие значения следует обновить. Затем tanh-слой[5] строит вектор новых значений-кандидатов , которые можно добавить в состояние ячейки.\\nДля замены старого состояния ячейкина новое состояние . Необходимо умножить старое состояние на , забывая то, что решили забыть ранее. Затем прибавляем . Это новые значения-кандидаты, умноженные на – на сколько обновить каждое из значений состояния.\\nНа последнем этапе определяется то, какая информация будет получена на выходе. Выходные данные будут основаны на нашем состоянии ячейки, к ним будут применены некоторые фильтры. Сначала значения предыдущего выходаи текущего входа пропускаются через сигмоидальный слой, который решает, какая информация из состояния ячейки будет выведена. Затем значения состояния ячейки проходят через tanh-слой, чтобы получить на выходе значения из диапазона от -1 до 1, и перемножаются с выходными значениями сигмоидального слоя, что позволяет выводить только требуемую информацию.\\nПолученные таким образоми передаются далее по цепочке.\\nВариации\\nCмотровые глазки\\nОдна из популярных вариаций LSTM, предложенная Герсом и Шмидхубером[6], характеризуется добавлением так называемых “смотровых глазков” (англ. peephole connections). С их помощью слои фильтров могут видеть состояние ячейки.\\nНа схеме выше “глазки” есть у каждого слоя, но во многих работах они добавляются лишь к некоторым слоям.\\nОбъединенные фильтры\\nДругие модификации включают объединенные фильтры “забывания” и входные фильтры. В этом случае решения, какую информацию следует забыть, а какую запомнить, принимаются не отдельно, а совместно. Информация забывается только тогда, когда необходимо записать что-то на её место. Добавление новой информации в состояние ячейки выполняется только тогда, когда забываем старую.\\nУправляемые рекуррентные нейроны\\nНемного больше отличаются от стандартных LSTM управляемые рекуррентные нейроны (англ. Gated recurrent units, GRU), впервые описанные в работе Кюнгхюна Чо (англ. Kyunghyun Cho)[7]. У них на один фильтр меньше, и они немного иначе соединены. Фильтры «забывания» и входа объединяют в один фильтр «обновления» (англ. update gate). Этот фильтр определяет сколько информации сохранить от последнего состояния, и сколько информации получить от предыдущего слоя. Кроме того, состояние ячейки объединяется со скрытым состоянием, есть и другие небольшие изменения. Фильтр сброса состояния (англ. reset gate) работает почти так же, как фильтр забывания, но расположен немного иначе. На следующие слои отправляется полная информация о состоянии, выходного фильтра нет. В большинстве случаем GRU работают так же, как LSTM, самое значимое отличие в том, что GRU немного быстрее и проще в эксплуатации, однако обладает немного меньшими выразительными возможностями. В результате модели проще, чем LSTM и их популярность неуклонно возрастает. Эффективность при решении задач моделирования музыкальных и речевых сигналов сопоставима с использованием долгой краткосрочной памяти.\\nГлубокие управляемые рекуррентные нейроны\\nСуществует множество других модификаций, как, например, глубокие управляемые рекуррентные нейронные сети (англ. Depth Gated RNNs), представленные в работе Каишенга Яо (англ. Kaisheng Yao)[8]. Глубокие управляемые рекуррентные нейронные сети привносят фильтр глубины для подключения ячеек памяти соседних слоев. Это вводит линейную зависимость между нижними и верхними рекуррентными единицами. Важно отметить, что линейная зависимость проходит через функцию стробирования, которая называется фильтром забывания. Данная архитектура способна улучшить машинный перевод и языковое моделирование.\\nМеханизм часов\\nЕсть и другие способы решения проблемы долговременных зависимостей, например, механизм часов (англ. Clockwork RNN, CW-RNN) Яна Кутника[9]. CW-RNN — мощная модификация стандартной архитектуры RNN, в которой скрытый слой разделен на отдельные модули, каждый из которых обрабатывает входные данные со своей временной детализацией, производя вычисления только при заданной тактовой частоте. Стандартная модель RNN не ставновится сложнее, CW-RNN уменьшает количество параметров RNN, улучшает точность и скорость обучения сети в задачах генерации звуковых сигналов.\\nПримеры кода\\nKeras\\nПример кода с использованием библиотеки Keras.[10]\\n# Импорты import numpy as np import keras.backend as K from keras.preprocessing import sequence from keras.models import Sequential from keras.layers import Dense, Activation, Embedding from keras.layers import LSTM from keras.datasets import imdb def f1(y_true, y_pred): def recall(y_true, y_pred): true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) possible_positives = K.sum(K.round(K.clip(y_true, 0, 1))) recall = true_positives / (possible_positives + K.epsilon()) return recall def precision(y_true, y_pred): true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1))) precision = true_positives / (predicted_positives + K.epsilon()) return precision precision = precision(y_true, y_pred) recall = recall(y_true, y_pred) return 2*((precision*recall)/(precision+recall+K.epsilon())) # Устанавливаем seed для обеспечения повторяемости результатов np.random.seed(42) # Указываем количество слов из частотного словаря, которое будет использоваться (отсортированы по частоте использования) max_features = 5000 # Загружаем данные (датасет IMDB содержит 25000 рецензий на фильмы с правильным ответом для обучения и 25000 рецензий на фильмы с правильным ответом для тестирования) (X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words = max_features) # Устанавливаем максимальную длину рецензий в словах, чтобы они все были одной длины maxlen = 80 # Заполняем короткие рецензии пробелами, а длинные обрезаем X_train = sequence.pad_sequences(X_train, maxlen = maxlen) X_test = sequence.pad_sequences(X_test, maxlen = maxlen) # Создаем модель последовательной сети model = Sequential() # Добавляем слой для векторного представления слов (5000 слов, каждое представлено вектором из 32 чисел, отключаем входной сигнал с вероятностью 20% для предотвращения переобучения) model.add(Embedding(max_features, 32, dropout = 0.2)) # Добавляем слой долго-краткосрочной памяти (100 элементов для долговременного хранения информации, отключаем входной сигнал с вероятностью 20%, отключаем рекуррентный сигнал с вероятностью 20%) model.add(LSTM(100, dropout_W = 0.2, dropout_U = 0.2)) # Добавляем полносвязный слой из 1 элемента для классификации, в качестве функции активации будем использовать сигмоидальную функцию model.add(Dense(1, activation = \\'sigmoid\\')) # Компилируем модель нейронной сети model.compile(loss = \\'binary_crossentropy\\', optimizer = \\'adam\\', metrics = [\\'accuracy\\', \\'f1\\']) # Обучаем нейронную сеть (данные для обучения, ответы к данным для обучения, количество рецензий после анализа которого будут изменены веса, число эпох обучения, тестовые данные, показывать progress bar или нет) model.fit(X_train, y_train, batch_size = 64, nb_epoch = 7, validation_data = (X_test, y_test), verbose = 1) # Проверяем качество обучения на тестовых данных (если есть данные, которые не участвовали в обучении, лучше использовать их, но в нашем случае таковых нет) scores = model.evaluate(X_test, y_test, batch_size = 64) print(\\'Точность на тестовых данных: %.2f%%\\' % (scores[1] * 100)) print(\\'F1 на тестовых данных: %.2f%%\\' % (scores[2] * 100))\\nРезультат:\\nТочность на тренировочных данных: 89.64% F1 на тренировочных данных: 89.55% Точность на тестовых данных: 83.01% F1 на тестовых данных: 82.48%\\nTensorFlow\\nПример кода с библиотекой TensorFlow[11]\\n# Импорты from __future__ import print_function import tensorflow as tf from tensorflow.contrib import rnn # Импорт MNIST датасета from tensorflow.examples.tutorials.mnist import input_data mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True) # Определение параметров обучения learning_rate = 0.001 training_steps = 10000 batch_size = 128 display_step = 200 # Определение параметров сети num_input = 28 timesteps = 28 num_hidden = 128 num_classes = 10 # Входные данные для графа X = tf.placeholder(\"float\", [None, timesteps, num_input]) Y = tf.placeholder(\"float\", [None, num_classes]) # Определение весов weights = { \\'out\\': tf.Variable(tf.random_normal([num_hidden, num_classes])) } biases = { \\'out\\': tf.Variable(tf.random_normal([num_classes])) } def RNN(x, weights, biases): x = tf.unstack(x, timesteps, 1) # Определение LSTM ячейки lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0) # Получение выхода LSTM ячейки outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32) return tf.matmul(outputs[-1], weights[\\'out\\']) + biases[\\'out\\'] logits = RNN(X, weights, biases) prediction = tf.nn.softmax(logits) # Определение функции потерь и оптимизатора loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( logits=logits, labels=Y)) optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) train_op = optimizer.minimize(loss_op) # Оценка модели correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1)) accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) # Инициализация init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) for step in range(1, training_steps+1): batch_x, batch_y = mnist.train.next_batch(batch_size) batch_x = batch_x.reshape((batch_size, timesteps, num_input)) # Запуск оптимизатора (обратное распространение ошибки) sess.run(train_op, feed_dict={X: batch_x, Y: batch_y}) if step % display_step == 0 or step == 1: loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y}) print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\\ \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\\ \"{:.3f}\".format(acc)) print(\"Optimization Finished!\") test_len = 128 test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input)) test_label = mnist.test.labels[:test_len] print(\"Testing Accuracy:\", \\\\ sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))\\nРезультат:\\nТочность на тренировочных данных: 91.40% F1 на тренировочных данных: 91.05% Точность на тестовых данных: 85.15% F1 на тестовых данных: 84.28%\\nПример на языке Java\\nПример реализации рекуррентной нейронной сети, использующей механизм LSTM и натренированной на текстах Шекспира, с применением библиотеки\\ndeeplearning4j.\\nСм. также\\n- Рекуррентные нейронные сети\\n- Нейронные сети, перцептрон\\n- Сверточные нейронные сети\\n- Рекурсивные нейронные сети\\nПримечания\\n- ↑ Sepp Hochreiter, Jurgen Schmidhuber. Long short-term memory (1997). Neural Computation.\\n- ↑ Backpropagation Through Time\\n- ↑ Backpropagation Through Time\\n- ↑ Сигмоида.\\n- ↑ Гиперболические функции.\\n- ↑ Gers, Schmidhuber. Recurrent Nets that Time and Count (2000).\\n- ↑ Cho. Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation (2014).\\n- ↑ SeppKaisheng Yao. Depth-Gated Recurrent Neural Networks (2015).\\n- ↑ Jan Koutnik. A Clockwork RNN (2014).\\n- ↑ Keras RNN with LSTM layer\\n- ↑ TensorFlow\\nИсточники информации\\n- Understanding LSTM Networks\\n- Illustrated Guide to LSTM’s and GRU’s: A step by step explanation\\n- The fall of RNN / LSTM\\n- Long short-term memory - статья на Википедии\\n- Long Short Term Memory (LSTM) - курс Andrew Ng', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='e600fdc5-96b1-4106-99df-ff2353d0b1b8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='fbc54bd1a819494cbf03ba664d8cea33181d3cd36299ba4a3141c4fa3e77758c', text='Механизм внимания\\nМеханизм внимания (англ. attention mechanism, attention model) — техника используемая в рекуррентных нейронных сетях (сокр. RNN) и сверточных нейронных сетях (сокр. CNN) для поиска взаимосвязей между различными частями входных и выходных данных.\\nИзначально механизм внимания был представлен в контексте рекуррентных Seq2seq[1] сетей [2] для \"обращения внимания\" блоков декодеров на скрытые состояния RNN для любой итерации энкодера, а не только последней.\\nПосле успеха этой методики в машинном переводе последовали ее внедрения в других задачах обработки естественного языка и применения к CNN для генерации описания изображения[3] и порождающих состязательных сетях[4] (сокр. GAN).\\nСодержание\\n- 1 Обобщенный механизм внимания\\n- 2 Модули внимания\\n- 3 Self-Attention\\n- 4 См. также\\n- 5 Источники информации\\n- 6 Примечания\\nОбобщенный механизм внимания\\nОбобщенный механизм внимания (англ. general attention) — разновидность механизма внимания, задачей которой является выявление закономерности между входными и выходными данными. Изначально механизм внимания представленный в оригинальной статье[5] подразумевал именно этот тип внимания.\\nПример использования обобщенного механизма внимания для задачи машинного перевода\\nДля лучшего понимания работы обобщенного механизма внимания будет рассмотрен пример его применения в задаче машинного перевода при помощи Seq2seq сетей для решения которой он изначально был представлен.\\nБазовая архитектура Seq2seq\\nДля понимания механизма внимания в Seq2seq сетях необходимо базовое понимание Seq2seq архитектуры до введения механизма внимания.\\nSeq2seq состоит из двух RNN — Энкодера и Декодера.\\nЭнкодер — принимает предложение на языке A и сжимает его в вектор скрытого состояния.\\nДекодер — выдает слово на языке B, принимает последнее скрытое состояние энкодера и предыдущее предсказанное слово.\\nРассмотрим пример работы Seq2seq сети:\\n— слова в предложении на языке A.\\n— скрытое состояние энкодера.\\nБлоки энкодера (зеленый) — блоки энкодера получающие на входи передающие скрытое состояние на следующую итерацию.\\n— скрытое состояние декодера.\\n— слова в предложении на языке B.\\nБлоки декодера (фиолетовый) — блоки декодера получающие на входили специальный токен start в случае первой итерации и возвращаюшие — слова в предложении на языке B. Передают — скрытое состояние декодера на следующую итерацию. Перевод считается завершенным при , равном специальному токену end.\\nПрименение механизма внимания для Seq2seq\\nНесмотря на то, что нейронные сети рассматриваются как \"черный ящик\" и интерпретировать их внутренности в понятных человеку терминах часто невозможно, все же механизм внимания интуитивно понятный людям смог улучшить качество машинного перевода базового Seq2seq алгоритма.\\nУспех использования этого подхода в задаче машинного перевода обусловлен лучшим выводом закономерностей между словами находящимися на большом расстоянии друг от друга. Несмотря на то, что LSTM и GRU блоки используются именно для улучшения передачи информации с предыдущих итераций RNN их основная проблема заключается в том, что влияние предыдущих состояний на текущее уменьшается экспоненциально от расстояния между словами, в то же время механизм внимания улучшает этот показатель до линейного[6].\\nRNN используются при обработке данных, для которых важна их последовательность. В классическом случае применения RNN результатом является только последнее скрытое состояние , где — длина последовательности входных данных. Использование механизма внимания позволяет использовать информацию полученную не только из последнего скрытого состояния, но и любого скрытого состояния для любого .\\nУстройство слоя механизма внимания\\nСлой механизма внимания представляет собой обычную, чаще всего однослойную, нейронную сеть на вход которой подаются, а также вектор в котором содержится некий контекст зависящий от конкретной задачи.\\nВ случае Seq2seq сетей векторомбудет являться скрытое состояние предыдущей итерации декодера.\\nВыходом данного слоя будет является вектор(англ. score) — оценки на основании которых на скрытое состояние будет \"обращено внимание\".\\nДалее для нормализации значений [7]. Тогдаиспользуется\\nздесь используется благодаря своим свойствам:\\nДалее считается(англ. context vector)\\nРезультатом работы слоя внимания являетсякоторый, содержит в себе информацию обо всех скрытых состояниях пропорционально оценке .\\nПрименение механизма внимания к базовой Seq2seq архитектуре\\nПри добавлении механизма в данную архитектуру между RNN Энкодером и Декодером слоя механизма внимания получится следующая схема:\\nЗдесьимеют те же назначения, что и в варианте без механизма внимания.\\nАгрегатор скрытых состояний энкодера (желтый) — агрегирует в себе все вектораи возвращает всю последовательность векторов .\\n— вектор контекста на итерации .\\nБлоки механизма внимания (красный) — принимаети , возвращает .\\nБлоки декодера (фиолетовый) — по сравнению с обычной Seq2seq сетью меняются входные данные. Теперь на итерациина вход подается не , а конкатенация и .\\nТаким образом при помощи механизма внимания достигается \"фокусирование\" декодера на определенных скрытых состояниях. В случаях машинного перевода эта возможность помогает декодеру предсказывать на какие скрытые состояния при исходных определенных словах на языке A необходимо обратить больше внимания при переводе данного слова на язык B. То есть на какие слова из исходного текста обратить внимание при переводе конкретного слова на язык назначения.\\nМодули внимания\\nСверточный модуль внимания\\nСверточный модуль внимания (англ. сonvolutional block attention module) — простой, но эффективный модуль внимания для сверточных нейросетей. Применяется для задач детектирования обьектов на изображениях и классификации с входными данными больших размерностей. Данный модуль внимания состоит из двух последовательно применяемых подмодулей — канального (применяется ко всем каналам одного пикселя с изображения) и пространственного (применяется ко всему изображению с фиксированным каналом), оба эти подмодуля описаны в следующих разделах.\\nБолее формально говоря: на вход подается множество признаков, где — число каналов, — высота, а — длина изображения. Канальный подмодуль принадлежит множеству , а пространственный принадлежит множеству . Таким образом применение модуля можно описать так:\\nЗдесь заобозначено поэлементное произведение, а тензоры и копируются вдоль недостающих измерений. — тензор после применения канального модуля внимания, — выходное множество признаков.\\nКанальный модуль внимания\\nКанальный модуль внимания (англ. channel attention module) реализуется за счет исследования внутриканальных взаимосвязей во входных данных, то есть пытается извлечь информацию из яркости каналов одного пикселя. Фокусируется на том, \"какая\" информация находится в данных. Для более эффективной реализации используется сжатие входных данных по измерениям пулингов и , которые применяются независимо к входному тензору. В результате которого получаются два вектора и из . После чего к этим двум векторам независимо применяется одна и та же полносвязная нейронная сеть с одним скрытым слоем малой размерности (при этом ее входные и выходные вектора принадлежат ). После этого полученные из нейросети вектора поэлементно складываются, к результату поэлементно применяется сигмоидная функция активации и добавляются недостающие единичные размерности. Полученный тензор из как раз и является результатом применения , поэлементное произведение которого со входом дает тензор .и с помощью\\nПространственный модуль внимания\\nПространственный модуль внимания (англ. spatial attention module) реализуется за счет исследования пространственных взаимосвязей, то есть пытается извлечь информацию из взаимного расположения пикселей. В отличие от канального фокусируется на том, \"где\" находится информация во входных данных. В данном случае для сжатия размерности используются те же пулинги, но относительно измерения . Таким образом на выходе мы получаем две матрицы и из . После чего они конкатенируются и к полученному тензору размерности применяется свертка, уменьшающая число каналов до одного и не меняющая остальные размерности, а к результату поэлементно применяется сигмоидная функция активации. Полученный тензор из как раз является результатом применения , поэлементное произведение которого с дает выходной тензор , который называется выходным множеством признаков c размерностью .\\nSelf-Attention\\nSelf-Attention — разновидность механизма внимания, задачей которой является выявление закономерности только между входными данными.\\nДанная методика показала себя настолько эффективной в задаче машинного перевода, что позволила отказаться от использования RNN и заменить их на обычные нейронные сети в комбинации с механизмом Self-attention в архитектуре трансформер[8].\\nЭто позволило ускорить работу алгоритма, поскольку ранее предложение обрабатывалось последовательно при помощи RNN. При использовании трансформера каждое слово в предложении может обрабатываться параллельно.\\nОсновным отличием Self-Attention от обобщенного механизма внимания является, что он делает заключения о зависимостях исключительно между входными данными.\\nРассмотрим предложение The animal didn\\'t cross the street because it was too tired и результат работы алгоритма Self-attention для слова it. Полученный вектор соответствует взаимосвязи слова it со всеми остальными словам в предложении.\\nИз визуализации вектора можно заметить, что механизм Self-attention обнаружил взаимосвязь между словами it и animal. Этот результат можно интуитивно объяснить с человеческой точки зрения, что позволяет алгоритмам машинного обучения, использующим данный подход, лучше решать задачу принимая во внимание контекстные взаимосвязи.\\nТакже Self-Attention успешно применяется применяется в GAN сетях, в частности в алгоритме SAGAN[9].\\nСм. также\\nИсточники информации\\n- Статья о механизме внимания, его типах и разновидностях\\n- Лекция Andrew Ng о механизме внимания в NLP\\n- Статья с подробно разборанными примерами и кодом на Python и TensorFlow\\n- Статья c примерами работы Self-attention\\n- Статья о сверточном модуле внимания (CBAM)\\nПримечания\\n- ↑ Wiki -- Seq2seq\\n- ↑ https://arxiv.org/abs/1409.0473\\n- ↑ https://arxiv.org/abs/1502.03044\\n- ↑ https://arxiv.org/abs/1805.08318\\n- ↑ https://arxiv.org/abs/1409.0473\\n- ↑ https://towardsdatascience.com/transformers-141e32e69591\\n- ↑ Wiki -- Функция softmax\\n- ↑ https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf\\n- ↑ https://arxiv.org/abs/1805.08318', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='11ebd287-359c-45a0-8a22-77121e16df21', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44005c56e39d2977b84b1519c77d7e8ccd4973869a01c6c7c1351f239d016014', text='BERT (языковая модель)\\nBERT (англ. Bidirectional Encoder Representations from Transformers) — языковая модель, основанная на архитектуре трансформер, предназначенная для предобучения языковых представлений с целью их последующего применения в широком спектре задач обработки естественного языка.\\nСодержание\\nМодель и архитектура\\nBERT представляет собой нейронную сеть, основу которой составляет композиция кодировщиков трансформера. BERT является автокодировщиком. В каждом слое кодировщика применяется двустороннее внимание, что позволяет модели учитывать контекст с обеих сторон от рассматриваемого токена, а значит, точнее определять значения токенов.\\nПредставление данных\\nПри подаче текста на вход сети сначала выполняется его токенизация. Токенами служат слова, доступные в словаре, или их составные части — если слово отсутствует в словаре, оно разбивается на части, которые в словаре присутствуют (см. рис. 1). Словарь является составляющей модели — так, в BERT-Base[1] используется словарь около 30,000 слов. В самой нейронной сети токены кодируются своими векторными представлениями (англ. embeddings), а именно, соединяются представления самого токена (предобученные), номера его предложения, а также позиции токена внутри своего предложения. Входные данные поступают на вход и обрабатываются сетью параллельно, а не последовательно, но информация о взаимном расположении слов в исходном предложении сохраняется, будучи включённой в позиционную часть эмбеддинга соответствующего токена.\\nВыходной слой основной сети имеет следующий вид: поле, отвечающее за ответ в задаче предсказания следующего предложения, а также токены в количестве, равном входному. Обратное преобразование токенов в вероятностное распределение слов осуществляется полносвязным слоем с количеством нейронов, равным числу токенов в исходном словаре.\\nОбучение\\nПредобучение\\nBERT обучается одновременно на двух задачах — предсказания следующего предложения (англ. next sentence prediction) и генерации пропущенного токена (англ. masked language modeling). На вход BERT подаются токенизированные пары предложений, в которых некоторые токены скрыты (см. рис. 2). Таким образом, благодаря маскированию токенов, сеть обучается глубокому двунаправленному представлению языка, учится понимать контекст предложения. Задача же предсказания следующего предложения есть задача бинарной классификации — является ли второе предложение продолжением первого. Благодаря ей сеть можно обучить различать наличие связи между предложениями в тексте.\\nИнтерпретация этапа предобучения — обучение модели языку.\\nТочная настройка (Fine-tuning)\\nЭтот этап обучения зависит от задачи, и выход сети, полученной на этапе предобучения, может использоваться как вход для решаемой задачи. Так, например, если решаем задачу построения вопросно-ответной системы, можем использовать в качестве ответа последовательность токенов, следующую за разделителем предложений. В общем случае дообучаем модель на данных, специфичных задаче: знание языка уже получено на этапе предобучения, необходима лишь коррекция сети.\\nИнтерпретация этапа fine-tuning — обучение решению конкретной задачи при уже имеющейся общей модели языка.\\nГиперпараметры\\nГиперпараметрами модели являются [2] в механизме внимания.— размерность скрытого пространства кодировщика, — количество слоёв-кодировщиков, — количество голов\\nДанные и оценка качества\\nПредобучение ведётся на текстовых данных корпуса BooksCorpus[3] (800 млн. слов), а также на текстах англоязычной Википедии (2.5 млрд. слов). Качество модели авторы оценивают на популярном для обучения моделей обработки естественного языка наборе задач GLUE.[4]\\nРеализация\\nВ репозитории Google Research доступны для загрузки и использования несколько вариантов обученной сети в формате контрольных точек обучения модели популярного фреймворка TensorFlow[5]. В таблице в репозитории приведено соответствие параметров и и моделей. Использование моделей с малыми значениями гиперпараметров на устройствах с меньшей вычислительной мощностью позволяет сохранять баланс между производительностью и потреблением ресурсов. Также представлены модели с различным типом скрытия токенов при обучении, доступны два варианта: скрытие слова целиком (англ. whole word masking) или скрытие составных частей слов (англ. WordPiece masking).\\nТакже модель доступна для использования с помощью популярной библиотеки PyTorch.[6]\\nПример использования\\nПриведём пример предказания пропущенного токена при помощи BERT в составе PyTorch. Скрытый токен — первое слово второго предложения.\\n# Загрузка токенизатора и входные данные tokenizer = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'tokenizer\\', \\'bert-base-cased\\') text_1 = \"Who was Jim Henson ?\" text_2 = \"Jim Henson was a puppeteer\" # Токенизация ввода, также добавляются специальные токены начала и конца предложения. indexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True) segments_ids = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1] # Конвертирвание ввода в формат тензоров PyTorch segments_tensors = torch.tensor([segments_ids]) tokens_tensor = torch.tensor([indexed_tokens]) encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors) # Выбираем токен, который будет скрыт и позднее предсказан моделью masked_index = 8 indexed_tokens[masked_index] = tokenizer.mask_token_id tokens_tensor = torch.tensor([indexed_tokens]) # Загрузка модели masked_lm_model = torch.hub.load(\\'huggingface/pytorch-transformers\\', \\'modelWithLMHead\\', \\'bert-base-cased\\') predictions = masked_lm_model(tokens_tensor, token_type_ids=segments_tensors) # Предсказание скрытого токена predicted_index = torch.argmax(predictions[0][0], dim=1)[masked_index].item() predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0] assert predicted_token == \\'Jim\\'\\nВозможности\\nПреимущества\\nВ отличие от прежних классических языковых моделей, BERT обучает контексто-зависимые представления. Например, word2vec[7] генерирует единственный эмбеддинг для одного слова, даже если слово многозначное и его смысл зависит от контекста. Использование BERT же позволяет учитывать окружающий контекст предложения, и генерировать различные эмбеддинги в таких случаях.\\nКонтексто-зависимые модели в основном позволялют учитывать лишь левый или правый контекст токена. BERT же учитывает двусторонний контекст, что помогает модели лучше понимать смысл многозначных слов.\\nПрименение\\nВ 2019 году компания Google объявила об использовании BERT для анализа англоязычных поисковых запросов.[8] В конце того же года также было начато использование модели в алгоритме поиска на других языках.[9]\\nСм. также\\nПримечания\\n- ↑ Github — Google Research — BERT\\n- ↑ Multi-Head Attention: Collaborate Instead of Concatenate\\n- ↑ Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books\\n- ↑ GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\\n- ↑ TensorFlow\\n- ↑ PyTorch\\n- ↑ word2vec\\n- ↑ Google Blog — Understanding searches better than ever before\\n- ↑ Search Engine Journal — Google\\'s BERT Rolls Out Worldwide\\nИсточники информации\\n- BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding — Оригинальная статья\\n- BERT (language model) — статья в англоязычной Википедии', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='6c953561-77e0-4b0a-9877-3969451ff9c2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='892e5c07be7cfbfd5da08c70a8dd8ad1be6c833e94d7e25103527088f6038830', text='Синтез речи\\nСинтез речи (англ. speech synthesis) — процесс генерации компьютером человеческой речи. Компьютерная система, способная к синтезу речи, называется речевым синтезатором. Система, генерирующая человеческую речь, основываясь на тексте, называется text-to-speech системой (сокр. TTS).\\nВ процессе человеческой речи нервная система транслирует некоторый текст или мысленный концепт в движение мышц, связанных с органами дыхания и речи. Затем производится генерация акустического сигнала с помощью потока воздуха из легких. Сигнал содержит как периодические компоненты (созданные с помощью вибрации органов речи), так и апериодические (созданные окружающей средой и фоновым шумом). Используя изменяющиеся во времени сокращения мышц, меняются частотные характеристики акустического сигнала. Задача систем генерации речи по тексту — симулировать данный процесс в каком-либо виде.\\nСодержание\\n- 1 Этапы синтеза речи\\n- 2 Генерация звуковой волны\\n- 3 Классы подходов к синтезу речи\\n- 4 Алгоритмы, основанные на нейронных сетях\\n- 5 Проблемы\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nЭтапы синтеза речи\\nРаботу систем синтеза речи по тексту как правило можно разделить на два этапа, за которые отвечают два отдельных компонента — обработка текста и синтез речи.\\nПервый этап обычно содержит несколько этапов обработки естественного языка, такие как разбиение на предложения, разбиение на слова, нормализация текста, автоматическая морфологическая разметка и конвертация графем в фонемы (англ. grapheme-to-phoneme conversion, G2P). Данный этап принимает в качестве входных параметров текст и возвращает последовательность фонем с различными выделенными лингвистическими особенностями.\\nЭтап синтеза речи, в свою очередь, принимает на вход последовательность фонем и возвращает синтезированную звуковую волну речи. Данный этап обычно включает в себя алгоритмы предсказания просодии — характеристик речи, описывающих признаки, являющиеся дополнительными к основной артикуляции звука, такие как тон, ударение, громкость и т.д.\\nГенерация звуковой волны\\nОбычно, синтезаторы речи не работают непосредственно с сигналом звуковой волны, а используют некоторое представление этого сигнала, например, спектрограмму. Алгоритм, способный выделить такие параметры и по ним обратно восстановить звуковую волну, называется вокодер (англ. voice encoder). Примерами таких алгоритмов являются мю-закон [1] и восстановление сигнала по его спектрограмме.\\nМю-закон преобразует каждое значение дискретизированного сигналакак\\n,\\nгде [1]. Обратное преобразование выбирает значение преобразованного сигнала из данного номера интервала и получает оценку исходного сигнала следующим образом:и , а затем кодирует сигнал как двузначное шестнадцатеричное число, которое обозначает некоторый интервал на числовой прямой\\n.\\nВ качестве представления звукового сигнала может выступать спектрограмма волны — изображение, показывающее зависимость спектральной плотности мощности сигнала от времени. Спектрограммы отображают частоту и амплитуду сигнала во времени, но не содержат никакой информации о фазе сигнала, из-за чего результат обратного восстановления сигнала по спектрограмме неизбежно отличается от оригинала. Цифровая генерация спектрограммы сигнала сводится к вычислению квадрата амплитуды оконного преобразования Фурье:\\n,\\nгде— используемое окно и — оконное преобразование Фурье.\\nДля восстановления исходного сигнала по его спектрограмме может быть использован алгоритм Гриффина-Лима[2], который основан на минимизации среднеквадратичной ошибки между оконным преобразованием Фурье оцениваемого сигнала и имеющимся преобразованием в спектрограмме.\\nКлассы подходов к синтезу речи\\nОсновными требованиями к технологиям синтеза речи являются естественность (англ. naturalness) и разборчивость (англ. intelligibility). Естественность описывает, насколько генерируемая речь близка к человеческой, а разборчивость отражает, насколько сложно понять речь. Идеальный синтезатор речи генерирует одновременно и натуральную, и разборчивую речь.\\nКонкатенативный синтез\\nКонкатенативный синтез (англ. concatenative synthesis) основывается на конкатенации предварительно записанных примеров человеческой речи в единую звуковую последовательность. Данный подход синтезирует наиболее естественную речь, но генерируемая речь часто содержит значительные отличия и ошибки по сравнению с человеческой речью. Примеры конкатенативного синтеза:\\n- Синтез с выбором (англ. unit selection synthesis) является самым используемым подходом конкатенативного синтеза и использует большую базу данных записанной речи. При создании базы данных записанные фразы могут делиться на различные звуковые единицы, такие, как фоны, дифоны, полуфоны, слоги, морфемы, целые фразы или предложения. При запуске алгоритм генерирует выходную звуковую волну с помощью выбора наилучшей последовательности звуковых единиц из базы данных. Данный выбор обычно реализован с помощью дерева решений. Синтез с выбором обеспечивает наиболее естественную речь, так как использует минимальную цифровую обработку сигналов. Недостатком подхода является необходимость в довольно большой базе данных звуков для достижения наибольшей естественности речи. Данный подход являлся самым популярным для общего класса задач синтеза речи, но в последнее время уступает по популярности параметрическому подходу. Примером использования синтеза с выбором является голосовой помощник Siri от Apple [3] и голосовой помощник Алиса от компании Яндекс [4]. Несмотря на то, что эти продукты используют глубокое обучение, их механизм синтеза речи основан на записанных примерах голоса.\\n- Дифонный синтез (англ. diphone synthesis) является частным случаем синтеза с выбором, который использует в качестве звуковых единиц дифоны (переход от звука к звуку). Подход использует только один образец каждого дифона. База данных дифонов при этом получается сравнительно небольшой. Например, немецкий язык содержит около 800 дифонов, а испанский — около 2500. При работе алгоритма просодия входной последовательности накладывается на дифоны в базе данных с помощью различных алгоритмов цифровой обработки сигналов. Данный алгоритм значительно уступает по качеству другим подходам и кроме меньшего размера базы данных не дает весомых преимуществ, из-за чего не снискал большой популярности.\\n- Синтез речи, ограниченный предметной областью (англ. domain-specific speech synthesis) также является частным случаем синтеза с выбором и использует базу данных предварительно записанных слов, фраз и предложений для составления выходной последовательности. Он используется в задачах, где вариативность и размер используемых фраз ограничены некоторой предметной областью, например, прогнозирование погоды или составление расписания транспорта. Из-за значительной простоты реализации и использования данный подход уже долго применяется в коммерческих продуктах, например, говорящие часы или калькуляторы. При этом данный подход может обеспечивать высокую естественность речи вследствие ограниченности используемой базы данных. Недостатками таких систем является ограниченность областью применимости и неспособность учитывать контекст речи, что может вызывать ощутимые ошибки в некоторых языках.\\nПараметрический синтез\\nПараметрический синтез (англ. statistical parametrical synthesis) для генерации выходной звуковой волны, в отличии от конкатенативного синтеза, не использует реальные примеры речи, а строит вероятностное распределение некоторых параметров и акустических свойств звуковой волны. В начале работы параметрического синтезатора с помощью вокодера извлекаются параметры порождающая модель, например, скрытая марковская цепь, нейронная сеть прямого распространения или рекуррентная нейронная сеть, обучается по выделенным параметрам и , получая параметры модели , наиболее хорошо описывающие распределение . На этапе синтеза, модель генерирует наиболее правдоподобные параметры звуковой волны, используя найденные на этапе обучения параметры модели и лингвистическую информацию текста, который необходимо озвучить:звуковой волны и лингвистические данные из текста, который необходимо озвучить. Конкретный вид вектора зависит от используемого вокодера — это может быть как спектрограмма волны, так и некоторое другое представление сигнала, например, дискретные номера интервалов числовой прямой, получаемые с помощью мю-закона. Затем,\\n.\\nВыходная звуковая волна генерируется вокодером на основе найденных параметров.\\nДанный подход является самым популярным на сегодняшний момент, в том числе из-за того, что он позволяет использовать подходы, основанные на нейронных сетях. Современными продуктами, использующие основанный на глубоком обучении параметрический синтез являются Amazon Lex и Alexa [5], Google Ассистент [6] и умные дисплеи Portal от Facebook [7].\\nАлгоритмы, основанные на нейронных сетях\\nРассмотрим две популярные сети для преобразования текста в спектрограмму (Tacotron) и для синтеза речи по спектрограмме (WaveNet). Для синтеза речи по спектрограмме предложено множество моделей: авторегрессионныее (WaveNet, WaveRNN, LPCNet), неавторегресионные (WaveGlow, MelGAN, WaveGrad) и разнообразные (например, можно натренировать сети GAN для генерации лиц под задачу генерации спектрограммы).\\nTacotron\\nTacotron — модель[8] параметрического синтеза речи, основанная на подходе seq2seq, разработанная Google и опубликованная в 2017 году. Модель состоит из кодера, декодера с вниманием и нейронной сети для пост-процессинга сигнала. Схема модели изображена на Рисунке 1.\\nКодер и сеть пост-процессинга опираются на блок CBHG, схема которого изображена на Рисунке 2. Блок состоит из набора одномерных сверточных фильтров, за которыми следуют шоссейные нейронные сети (англ. highway networks)[9], являющиеся модификацией LSTM сетей, и двунаправленный управляемый рекуррентный блок. Входная последовательность сначала обрабатывается наборами сверточных фильтров с размерностью . Эти фильтры моделируют локальную и контекстно-зависимую информацию (по аналогии с моделированием униграмм, биграмм, вплоть до -грамм). Выход сверточного уровня далее обрабатывается шоссейной сетью для дальнейшего выделения параметров. В конце CBHG используется управляемый рекуррентный блок, который для выделения параметров опирается на контекст перед рассматриваемым символом и после рассматриваемого символа.\\nЗадача кодера заключается в извлечении последовательных параметров из текста. Его входом является последовательность символов, в которой каждый символ был закодирован one-hot кодированием и объединен в единый непрерывный вектор. К данному входу применяется ряд нелинейных преобразований в виде сети с бутылочным горлышком (англ. bottleneck layer), что позволяет улучшить обобщаемость сети и ускорить сходимость. Модуль CBHG преобразует выход нелинейных преобразований в итоговое представление текста, которая передается в декодер.\\nДекодер является рекуррентной нейронной сетью с вниманием, в которой запрос внимания генерируется каждый временной промежуток. Вектор контекста соединяется с выходом ячейки внимания и подается на вход декодирующим рекуррентным нейронным сетям, которые являются управляемыми рекуррентными блоками. Выходом декодера является спектрограмма звуковой волны, которая передается сети пост-обработки для генерации непосредственно звуковой волны.\\nВ качестве сети пост-обработки используется модуль CBHG, описанный ранее. После этого спектрограмма звуковой волны передается на вход алгоритму Гриффина-Лима, который генерирует итоговую звуковую волну.\\nМодель Tacotron была значительно улучшена в последующей модификации Tacotron 2 [10], которая переработала исходную архитектуру Tacotron и объединила её с вокодером на основе WaveNet. Данная модель способна синтезировать речь высокого качества, принимая на вход только текст, который необходимо озвучить[11]. Реализация данной модели доступна на Github.\\nWaveNet\\nWaveNet[12] является порождающей моделью, использующей параметрический подход к синтезу речи. Её задача — восстановить распределение вероятностей звукового сигнала с помощью произведения условных вероятностей:\\n.\\nТаким образом, вероятность каждого сигналазависит только от предыдущих сигналов. Во время обучения модель оценивает данное условное распределение вероятностей, принимая на вход сигналы из обучающей выборки одновременно. На этапе генерации модель порождает выходные сигналы с помощью полученной оценки распределения вероятности последовательно — полученный моделью сигнал в момент времени подается обратно на вход для генерации последующего сигнала в момент времени . Структура модели позволяет использовать её в широком спектре задач, например, в задачах продолжения музыкального произведения по его началу, порождения голоса конкретного человека или text-to-speech синтеза.\\nОсновной идеей модели является использование причинных сверточных сетей (англ. causal convolution layers) и расширенных причинных сверточных сетей (англ. dilated causal convolution layers). Причинная сверточная сеть представляет собой несколько уровней сверточной нейронной сети, связанных между собой в порядке, который не нарушает последовательность входного сигнала, т.е. оцениваемая в момент времени вероятность сигнала не зависит от сигналов в последующие моменты времени . Причинные сверточные сети обучаются быстрее, чем рекуррентные нейронные сети, но требуют достаточно большого количества уровней для обеспечивания большого окна восприятия сигнала (англ. signal reception window) — количество предыдущих сигналов, от которых зависит оценка сигнала в текущий момент.\\nМодификация причинных сверточных сетей, расширенные причинные сверточные сети, способна увеличить окно восприятия сигнала в разы и является основной идеей модели WaveNet. Модификация заключается в применении свертки к области размерности большей, чем её длина, пропуская входные связи с некоторым шагом. Данный подход аналогичен применению пулинга или свертки с шагом большим единицы, но выходом расширенной причинной сверточной сети является последовательность размерности, равной размерности входной последовательности. Расширенные причинные сверточные сети способны достигать большего окна восприятия сигнала, используя меньшее количество уровней, при этом сохраняя вычислительную сложность причинных сверточных сетей. Структура причинных сверточных сетей изображена на Рисунке 3.\\nПолная структура модели WaveNet изображена на Рисунке 4. В качестве вокодера используется мю-закон. Модель представляет собой множество слоев сверточной нейронной сети, аналогично модели PixelCNN. Модель на вход принимает закодированную мю-законом последовательность сигналов и, опционально, некоторую дополнительную информацию, обозначаемую как вектор параметров , а на выходе возвращает распределение вероятностей для параметров мю-закона, по которым можно восстановить синтезированный сигнал. На этапе обучения входным сигналом является пример звука из обучающей выборки, который подается на все входы одновременно. На этапе генерации входом модели будут являться сигналы, порожденные ею в предыдущие моменты времени и передаваемые ей последовательно. Дополнительная информация , например, может содержать информацию о рассматриваемом тексте в задаче text-to-speech синтеза.\\nМодель представляет собой набор из блоков с остаточной связью, содержащих преобразование расширенной причинной свертки и функцию активации. Функция активации при этом аналогична функции, предложенной в модели Gated PixelCNN [13]:\\n,\\nгде— номер слоя модели, — индексы входов преобразования, — функция сигмоиды, — операция свертки, — операция покомпонентного умножения векторов и — выученные параметры свертки.\\nВ случае использования дополнительной информациимодель оценивает распределение вероятностей звукового сигнала как:\\n.\\nДля использования дополнительной информациифункция активации может использовать вектор глобально при вычислении каждой свертки как:\\n,\\nгде— выученные параметры линейной проекции. В случае, когда размерность вектора меньше, чем размерность , можно использовать upsampling-преобразование сверточных сетей, чтобы получить вектор размерности и использовать его вместо оригинального вектора . При этом будет являться операцией свертки размера 1.\\nСамый известный пример применения WaveNet для синтеза речи является технология Google Ассистент, которая использует WaveNet для генерации голосов ассистентов на различных языках. Модель позволила значительно сократить количество записей речи актеров озвучки, требуемых для создания голосовой модели[6].\\nПроблемы\\nЗадача обработки текста\\nАлгоритмы обработки текста могут не справляться с обработкой определенных частей речи, таких, как аббревиатуры, числа и гетеронимы. Произношение определенных слов также зависит от контекста их применения. Большинство систем синтеза речи по тексту не способны выделять контекст предложений и используют различные эвристические подходы с целью различить омографы (слова с одинаковым написанием, но различным произношением).\\nПреобразование текста в фонемы\\nПроцесс преобразования текста в фонемы обычно подразделяется на два подхода — словарный и основанный на правилах. Словарный подход использует словарь с записанными фонетическими представлениями слов и в процессе работы производит поиск в нем с целью конвертации слова в последовательность фонем. Основанный на правилах подход использует набор правил, которые применяются к словам или частям слов с целью выделения фонем. Оба эти подхода имеют существенные недостатки и требуют усовершенствования.\\nМультиязычный синтез\\nРаботает, но интересная задача генерации данного голоса на другом языке.\\nНесколько голосов\\nСеть перепрыгивает между голосами в середине слова.\\nСинтез в стиле\\nСейчас реализовано с помощью вариационных автоэнкодеров. Требуется пример для стиля.\\nВыразительный синтез\\nНепонятно, что речь должна отмечать выражением.\\nОценка качества\\nНа данный момент не существует единых критериев оценки качества синтезаторов речи. В каждом отдельном применении технологии синтеза речи могут быть в том числе свои критерии качества, связанные с предметной областью или используемым оборудованием. С другой стороны, ряд исследователей начали оценивать синтезаторы речи используя распространенные наборы данных для синтеза речи [14].\\nПопулярной метрикой оценки естественности речи является средняя оценка мнения (англ. mean opinion score)[15]. Она заключается в воспроизведении результатов работы синтезатора речи выборке людей, которые затем оценивают её качество по шкале от 1 до 5, в которой 1 означает \"плохое\" качество, 5 — \"идеальное\". Итоговой оценкой является среднее арифметическое всех оценок. Данная метрика страдает от субъективности и предвзятости опрашиваемых людей, в частности, в подобного рода экспериментах опрашиваемые стремятся ставить оценки, располагающиеся на всей ширине интервала оценок[16]. Из этого следует, что данная оценка не является абсолютной и её нельзя использовать для сравнения двух отдельных экспериментов кроме тех случаев, когда эксперимент поставлен особым образом, чтобы учесть данный недостаток, и даже в таком случае требуется статистический анализ данных, чтобы убедиться, что такое сравнение двух систем корректно[15].\\nМодели WaveNet, Tacotron и Tacotron 2 использовали среднюю оценку мнения для сравнения своей работы с естественным языком и другими подходами. Например, WaveNet достиг оценки 4.21 и 4.08 для американского варианта английского и путунхуа, по сравнению с оценками естественного языка 4.46 и 4.25 соответственно. Работа, описывающая модель Tacotron, сравнивала модель с другими разрабатываемыми подходами[17][18]. Tacotron смог достичь оценки в 3.82 балла для американского варианта английского, когда параметрический подход достиг 3.69, а конкатенативный - 4.09. Tacotron 2 смог достичь оценки в 4.52 балла по сравнению с оценкой записанной речи в 4.58 балла[11].\\nСм. также\\n- Нейронные сети, перцептрон\\n- Сверточные нейронные сети\\n- Рекуррентные нейронные сети\\n- Механизм внимания\\n- Распознавание речи\\nПримечания\\n- ↑ 1,0 1,1 \"ITU-T Recommendation G.711\"\\n- ↑ D. Griffin and Jae Lim, \"Signal estimation from modified short-time Fourier transform,\" ICASSP \\'83. IEEE International Conference on Acoustics, Speech, and Signal Processing, Boston, Massachusetts, USA, 1983, pp. 804-807, doi: 10.1109/ICASSP.1983.1172092.\\n- ↑ Deep Learning for Siri’s Voice: On-device Deep Mixture Density Networks for Hybrid Unit Selection Synthesis.\\n- ↑ Optimization 2018: что находится «под капотом» у Алисы.\\n- ↑ Bringing the Magic of Amazon AI and Alexa to Apps on AWS.\\n- ↑ 6,0 6,1 Martin, Taylor (May 9, 2018).\"Try the all-new Google Assistant voices right now\". CNET.\\n- ↑ Facebook’s voice synthesis AI generates speech in 500 milliseconds.\\n- ↑ 8,0 8,1 8,2 Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc Le, Yannis Agiomyrgiannakis, Rob Clark, & Rif A. Saurous. (2017). Tacotron: Towards End-to-End Speech Synthesis. arXiv:1703.10135\\n- ↑ Rupesh Kumar Srivastava, Klaus Greff, and J ̈urgen Schmidhuber. Highway networks. arXiv:1505.00387, 2015.\\n- ↑ Jonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, RJ Skerry-Ryan, Rif A. Saurous, Yannis Agiomyrgiannakis, & Yonghui Wu. (2018). Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions. arXiv:1712.05884.\\n- ↑ 11,0 11,1 Tacotron 2: Generating Human-like Speech from Text\\n- ↑ 12,0 12,1 12,2 Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, & Koray Kavukcuoglu. (2016). WaveNet: A Generative Model for Raw Audio. arXiv:1609.03499\\n- ↑ Aaron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, & Koray Kavukcuoglu. (2016). Conditional Image Generation with PixelCNN Decoders. arXiv:1606.05328\\n- ↑ Blizzard Challenge\\n- ↑ 15,0 15,1 ITU-T Recommendation P.800.2 : Mean opinion score interpretation and reporting\\n- ↑ Zielinski, Slawomir, Francis Rumsey, and Søren Bech. \"On some biases encountered in modern audio quality listening tests-a review.\" Journal of the Audio Engineering Society 56.6 (2008): 427-451.\\n- ↑ Heiga Zen, Yannis Agiomyrgiannakis, Niels Egberts, Fergus Henderson, and Przemysław Szczepa-niak. Fast, compact, and high quality LSTM-RNN based statistical parametric speech synthesizersfor mobile devices.Proceedings Interspeech, 2016\\n- ↑ Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation ofgated recurrent neural networks on sequence modeling. arXiv:1412.3555, 2014.\\nИсточники информации\\n- Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, & Koray Kavukcuoglu. (2016). WaveNet: A Generative Model for Raw Audio. arXiv:1609.03499\\n- Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc Le, Yannis Agiomyrgiannakis, Rob Clark, & Rif A. Saurous. (2017). Tacotron: Towards End-to-End Speech Synthesis. arXiv:1703.10135', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='1d17cb87-91ce-4ec9-a244-5dc2625035c8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='830a64c489897aa637e8ffd91a7867637bb969dc240a403cc5d3b4f7ef9f828f', text='Диалоговые системы\\nДиалоговые системы стремительно набирают популярность. Это связано с тем, что\\n- люди стали чаще общаться при помощи текста, используя мессенджеры [1],\\n- могие компании заинтересованы в анализе и автоматизации общения с клиентами [2],\\n- растет число «умных» бытовых предметов, которыми можно управлять [3].\\nНаиболее часто диалоговые системы используют в продажах, поддержке и маркетинге. Они используются для выполнения рутинных операций, которые можно свести к конкретному алгоритму, ищут и агрегируют данные, распространяют информацию.\\nСодержание\\n- 1 Определение\\n- 2 Целеориентированные диалоговые системы\\n- 3 Чат-ориентированные диалоговые системы\\n- 4 Существующие диалоговые системы\\n- 5 Фреймворки\\n- 6 Оценка качества модели\\n- 7 См. также\\n- 8 Примечания\\n- 9 Источники информации\\nОпределение\\nДиалоговые системы (англ. conversational agents, CAs) — компьютерные системы, предназначенные для общения с человеком. Они имитируют поведение человека и обеспечивают естественный способ получения информации, что позволяет значительно упростить руководство пользователя и тем самым повысить удобство взаимодействия с такими системами.\\nДиалоговую систему также называют разговорным искусственным интеллектом или просто ботом.\\nДиалоговая система может в разной степени являться целеориентированной системой (англ. goal/task-oriented) или чат-ориентированной (англ. chat-oriented). Как правило, чат-ориентированные системы, в отличие от целеориентированных, поддерживают большое количество доменов, но не способны различать много вопросов в рамках кажного из них.\\n|Определение:\\n|Домен (англ. domain) — область знаний, которая относится к запросу пользователя.\\nОбычно целеориентированные и чат-ориентированные системы исследуют отдельно, но на практике многие системы являются универсальными. Схема идеальной универсальной модели диалоговой системы приведена на рисунке 1. Модель является абстрактной, ее полной реализации не существует.\\nЭтапы обучения общего кодера (блок 3):\\n- обучение с моделированием языка на данных диалога,\\n- тонкая настройка на всех специфичных для задач данных.\\nОбучение блоков 4 и 5:\\n- предобучение для каждой задачи,\\n- тонкая настройка на всех специфичных для задач данных.\\nБлоки 6 и 7 обучаются на всех специфичных для задач данных.\\n|Определение:\\n|Тонкая настройка (англ. fine-turning) — подход к обучению, когда модель, обученная на большом количестве данных, повторно обучается на сравнительно небольшом количестве специфичных данных, чтобы скорректировать веса.\\nИстория диалога (блок 0) используется, чтобы обратиться к множеству внешних источников информации (блок 1). Затем формируется полный контекст диалога, который включает персональные данные пользователя, информацию из внешних источников, историю диалога (блок 2). Контекст при помощи трансформера структурируется и передается множеству компонентов, которые решают определенные задачи: в блоке 4 выполняется оценка настроения пользования (англ. sentiment), поиск именованных сущностей (NER), выделение частей речи (POS), разрешение кореферентности; в блоке 5 множество специфичных диалоговых моделей выдают свой ответ. Набор полученных ответов кодируется (блок 6) и ранжируется (блок 7) с учетом контекста.\\n|Определение:\\n|Разрешение кореферентности (англ. сoreference resolution) — задача поиска в тексте всех выражений, которые ссылаются на определенную сущность в тексте.\\nЦелеориентированные диалоговые системы\\nЗадачей целеориентированных систем является достижение определенных целей при помощи общения с пользователем. Примером цели может быть поиск книги или включение света.\\nКлассическая архитектура\\nКлассический метод построения целеориентированных систем заключается в использовании цепочки модулей (конвейера), которая изображена на рисунке 2.\\nОписание модулей:\\n- ASR. На вход поступает речь пользователя, которая затем распознается и переводится в текст. Результат работы компонента называют гипотезой, так как полученный текст может соответствовать исходному сообщению не полностью.\\n- NLU. Фраза в текстовом виде анализируется системой: определяется домен, намерение, именованные сущности. Для распознавания намерений может применяться обученный на векторном представлении фраз классификатор. Распознавание именованных сущеностей является отдельной задачей извлечения информации. Для ее решения используются формальные языки, статистические модели и их комбинации. В результате работы компонента создается формальное описание фразы — семантический фрейм.\\n- DM. Состоянием диалога или контекстом является информация, которая была получена при общении с пользователем ранее. В соответствии с текущим состоянием выбирается политика поведения системы, корректируется семантический фрейм. В качестве поставщика знаний может выступать СУБД или Web API.\\n- NLG. В соответствии с выбранным действием осуществляется генерация ответа пользователю на естественном языке. Для генерации применяются генеративные модели или шаблоны.\\n|Определение:\\n|Намерение (англ. intent) — желание пользователя в рамках произесенной фразы.\\n|Определение:\\n|Именованная сущность (англ. named entity) — слово во фразе пользователя, которое можно отнести к определенному типу.\\n|Определение:\\n|Слот (англ. named entity) — параметр запроса пользователя, ограниченный множеством допустимых значений.\\nОбычно после распознавания именованных сущностей выполняется заполнение слотов (англ. slot filling), в ходе которого каждая найденная сущность приводится к своей нормальной форме с учетом ее типа и множества возможных значений. Заполнение слотов позволяет не учитывать морфологию сущности при дальнейшей ее обработке. Простейшим подходом к нормализации сущностей является поиск с использованием расстояния Левенштейна. После определения типа сущности, она сравнивается с другими сущностями того же типа из базы данных. В качестве нормальной формы выбирается та, до которой расстояние наименьшее, либо можно выбрать несколько сущностей с наименьшим расстоянием и предоставить выбор пользователю (такой подход также применим для исправления опечаток).\\nДля получения численного представления текста используются различные языковые модели: Word2Vec, ESIM, GPT, BERT. Каждой определяется свой способ представления слов или их последовательности для наиболее точного извлечения смысловых значений. С хорошей языковой моделью достаточно около 100 примеров для хорошей классификации намерения [4].\\nСистема с классической архитектурой плохо масштабируется. Так как сценарии диалога нужно определять вручную, их становится сложно согласовывать при большом количестве.\\nНейросетевая архитектура\\nЕсли заменить каждую часть классической архитектуры искусственной нейронной сетью, то получим архитектуру изображенную на рисунке 3.\\nВходом у модели с данной архитектурой может быть компонент, который выполняет предобработку фразы пользователя и передает результаты внешним сетям (Intent Network и Belief Tracker).\\nОписание каждой части:\\n- Intent Network. Кодирующая сеть, которая преобразует последовательность токенов LSTM-сети :\\nв вектор . В качестве вектора может выступать скрытый слой\\n- Belief Tracker. В реализации используется RNN-сеть, на вход которой поступает предобработанная фраза пользователя. Дает распределение вероятностей по всем значениям определенного слота .\\n- Database Operator. Выполняет запрос к базе данных по сущностям и возвращает вектор , где единицей отмечается та запись (сущность в БД), которая соответствует запросу.\\n- Policy network. Объединяет системные модули. Выходом является вектор\\nгде матрицы , и — параметры, а — конкатенация. , который представляет системное действие. Распределение вероятностей для каждого слота пребразуется в вектор , который состоит из трех компонент: суммарная вероятность, вероятность, что пользователь выразил безразличие к слоту, и вероятность, что слот не был упомянут. Также вектор сжимается в one-hot-вектор , где каждая компонента определяет количество подходящих записей.\\n- Generation Network. Генерирует предложение, используя вектор действия и генератор языка. Предложение содержит специальные токены, которые заменяются на сущности из базы данных по указателю.\\nДанную архитектуру также называют сквозной (англ. end-to-end trainable), так как на данных обучается каждая ее часть. Модель с данной архитектурой можно обобщить на намерения, которые не наблюдались во время обучения.\\n|Классический (на основе правил)\\n|Нейросетевой\\n|Преимущества\\n|\\n|\\n|Недостатки\\n|\\n|\\nЧат-ориентированные диалоговые системы\\nДанный тип систем обычно используется чтобы занять пользователя, например, во время ожидания выполнения задачи. Система поддерживает бессодержательный, но связный диалог.\\nСистемы с ограниченными ответами\\nСистемы с ограниченными ответами (англ. retrieval/example-based) по последовательности фраз выдают наиболее подходящий ответ из списка возможных. Преимуществом таких систем является то, что ответы строго контролируются: можно удалить нежелательные шутки, нецензурные или критикующие выражения.\\nИнтерактивная система неформальных ответов (англ. informal response interactive system, IRIS) представлена на рисунке 4. Прямоугольником обозначены функциональные модули, цилиндром — базы данных. Здесь выполняется сравнение не только текущей фразы пользователя, но и вектора текущей истории диалога с другими диалогами в базе данных, что позволяет учесть контекст.\\nПервая фраза пользователя попадает в модуль инициализации, который обеспечивает приветствие пользователя и извлечение его имени. Имя пользователя используется менеджером диалога, чтобы инициализировать вектор истории диалога. Если пользователь не известен системе (его имя отуствует в Vocabulary Learning), то система инициализирует историю случайным вектором из хранилища историй. Когда инициализация заканчивается, система спрашивает пользователя, чего он хочет.\\nВ каждой новой фразе менеджер диалога при помощи модуля Dynamic replacement выполняет замену слов из словаря на плейсхолдеры (их определения, например, Иванимя), после чего выполняется токенизация и векторизация фразы. Если встречаются токены, которых нет ни в истории, ни в словаре, то они считаются неизветсными (англ. unknown vocabulary terms, OOVs). Неизвестные токены обрабатываются модулем Vocabulary learning, который получает определение от пользователя или из внешнего источника информации. Система вычисляет косинусное расстояние между текущей фразой пользователя и всеми фразами, хранимыми в базе данных. Полученное значение используется, чтобы извлечь от 50 до 100 фраз, которые могут стать ответами. Затем вычисляется та же метрика, но уже между вектором текущей истории диалога (которая включает высказывания как пользователя, так и системы) и векторами других историй . Чтобы усилить последние фразы в текущей истории, используется коэффициент забывания. Полученные метрики объединяются при помощи лог-линейной комбинации , где — настраиваемые веса, а результат используется для ранжирования потенциальных ответов. Итоговый ответ выбирается случайно среди нескольких ответов на вершине списка.\\nСистема также имеет модуль адаптации, который анализирует ответы пользователя и решает, исключить предыдущий ответ системы из множества возможных ответов, увеличить вероятность его выбора или уменьшить.\\nМодель с такой архитектурой можно обучить на субтитрах фильмов. Данные для русского языка можно найти на Толоке[7] [8].\\nСистемы с генерацией ответов\\nСистемы с генерацией ответов (англ. generation-based) генерируют ответ пословно. Такие системы более гибкие, но фильтровать их сложней. Часто для генерации диалога используются seq2seq-модели, другими вариантами являются расширенный вариационный автокодировщик или генеративно-состязательная сеть. Высокую производительность при генерации диалогов позволяют получить предобученные языковые модели на основе Трансформера.\\nСуществующие диалоговые системы\\nAliMe Assist — помощник для пользователей магазина AliExpress. Его архитектура представлена на рисунке 5. Серым цветом выделены блоки, где используются методы машинного обучения. Система состоит из 3 подсистем: поиск информации или решения, выполнение задачи для клиента и простое общение в чате. Для извлечения намерения вопрос проверяется на соответствие шаблонам при помощи бора (англ. trie-based pattern matching). Если соответствие найти не удалось, то вопрос передается классификатору, построенному на сверточной сети. На вход сети подаются вектора слов вопроса и семантических тэгов, которые относятся к нему и контексту (предыдущему вопросу). Для получения векторного представления используется FastText. Выбор CNN-сети вместо RNN основан на том, что первая сеть учитывает контекстную информацию слов (слова перед и после текущего слова) и работает быстрей. Точность классификации 40 намерений составляет 89,91%.\\nXiaolce — чат-бот, развиваемый китайским отделением Microsoft. Состоит из множества навыков, которые делятся на эмоциональные и рациональные. Имеется навык для комменирования картинок или сочинения по ним стихов. Сценарии диалога делятся на персональные и социальные. Бот старается установить эмоциональную связь с пользователем, чтобы продлить диалог с ним.\\nMicrosoft Cortana — виртуальный голосовой помощник. Состоит из можества навыков, натренированных на конкретные задачи. В отличие от классической архитектуры, где выбирается подходящий навык, здесь текст проходит через все навыки, после чего выбирается подходящий ответ. Каждый навык использует контекст (результаты обработки предыдущей фразы), сформированный всеми навыками. При таком подходе требуется больше ресурсов, но он позволяет существенно увеличить точность. Схематично процесс обработки фразы пользователя представлен на рисунке 6.\\nЯндекс Алиса — виртуальный голосовой помощник от компании Яндекс. Относится к классу чат-ориентированных систем, но имеет множество навыков, каждый из которых может быть представлен в виде целеориентированной системы. Алиса запускает навык по его активационной фразе. Фактически навык является веб-сервисом, который реализует DM и NLG модули классической архитектуры. При помщи платформы Яндекс Диалоги разработчики могут создавать свои навыки и монетизировать их, но перед публикацией навык проходит обязательную модерацию. Распознавание голоса выполняется сервисом SpeechKit.\\nСири — виртуальный помощник компании Apple. Является неотъемлемой частью iOS и доступна для большинства устройств, выпускаемых компанией. Поддерживает широкий спектр пользовательских команд, включая выполнение действий с телефоном, проверку основной информации, планирование событий и напоминаний, управление настройками устройства, поиск в интернете, взаимодействие с приложениями. Приспосабливается к каждому пользователю индивидуально, изучая его предпочтения в течение долгого времени.\\nФреймворки\\nСуществует множество фреймворков, которые значительно упрощают построение диалоговых систем. Рассмотрим самые популярные из них.\\nDeepPavlov.ai\\nОсновывается на таких библиотеках как TensorFlow, Keras и PyTorch. Включает множество компонентов, каждый из которых решает отдельную задачу диалоговых систем. Имеется модель для распознавания именованных сущностей, намерений, обработки истории диалога, анализа поведения пользователя и другие. Поведение агента диалоговой системы определяется набором навыков, каждый из которых строится из модулей. Когда агент получает фразу пользователя, специальный менеджер решает, какому навыку передать ее для обработки. Схема ядра представлена на рисунке 7. Пример использования на языке Python:\\nfrom deeppavlov.agents.default_agent.default_agent import DefaultAgent from deeppavlov.skills.pattern_matching_skill import PatternMatchingSkill from deeppavlov.agents.processors.highest_confidence_selector import HighestConfidenceSelector # Создание сконфигурированных навыков hello = PatternMatchingSkill(responses=[\\'Hello wordl! :)\\'], patterns=[\\'hi\\', \\'hello\\', \\'good day\\']) bye = PatternMatchingSkill([\\'Goodbye word! :(\\', \\'See you around.\\'], [\\'bye\\', \\'chao\\', \\'see you\\']) fallback = PatternMatchingSkill([\\'I don\\\\\\'t understand, sorry :/\\', \\'I can say \"Helo world!\" 8)\\']) # Создание менеджера, который выбирает наиболее вероятный навык skill_manager = HighestConfidenceSelector() # Создание агента HelloBot = Agent([hello, bye, fallback], skills_selector=skill_manager) # Тестирование print(HelloBot([\\'Hello!\\', \\'Boo...\\', \\'Bye.\\']))\\nRasa\\nАрхитектура схематично изображена на рисунке 8. Для передачи сообщений по каналу используются коннекторы. Имеются коннекторы для Телеграма, собственного веб-сайта, Slack, можно создавать свои коннекторы.\\nДанные для тренировки хранятся в формате YAML [11]. Имеется несколько типов тренировочных данных. Данные для NLU содержат намерения и примеры к ним. Опционально в примерах можно выделить тип сущности и ее значение или указать сентимент (настроение пользователя). Ответы бота (responses) разбиваются на именованные группы, откуда итоговый ответ выбирается случайно. Истории (stories) используются для выявления шаблонов диалога, чтобы система могла правильно реагировать на последовательности фраз пользователя, которые не были описаны явно. Каждая история описывает последовательность шагов. Шагом может быть намерение, которым определяется фраза пользователя, или действие, которым может быть группа ответов бота. Имеется возможность описать форму, чтобы пользователь мог ввести данные (например, электронную почту), и использовать ее в качестве действия. Правила похожи на истории, но они определяют последовательность шагов более строго, без применения машинного обучения.\\nОценка качества модели\\nЛучшие модели по качеству отслеживания состояния диалога (англ. dialogue state tracking):\\n|Модель\\n|Точность связок\\n|Точность слотов\\n|Особенности\\n|CHAN\\n|52.68\\n|97.69\\n|Использование контекстной иерархической сети внимания, динамическое регулирование весов различных слотов во время обучения.\\n|SAS\\n|51.03\\n|97.20\\n|Применение механизма внимания к слотам, разделение информации слотов.\\n|MERET\\n|50.91\\n|97.07\\n|Обучение с подкреплением.\\nКачество определяется по двум метрикам: точность слотов (англ. slot accuracy) — запрошенный слот верный, и точность связок (англ. joint goal accuracy) — каждый слот в стостоянии верный. Для оценки по данному криетрию обычно используется набор данных MultiWOZ.\\nЛучшие модели по качеству заполнения слотов:\\n|Модель\\n|F1\\n|Особенности\\n|Enc-dec + BERT\\n|97.17\\n|Применение кодера-декодера с языковой моделью BERT.\\n|Stack-Propagation + BERT\\n|97.0\\n|Использование намерений для заполнения слотов, обнаружение намерений на уровне токенов.\\n|Joint BERT\\n|97.0\\n|Модель заполнения слотов на основе BERT.\\nНабор данных: Snips.\\nЛучшие модели по качеству определения намерений:\\n|Модель\\n|Точность (accuracy)\\n|Особенности\\n|ELMo + BLSTM-CRF\\n|99.29\\n|Улучшение языковой модели ELMo, обучение без учителя для повышения производительности.\\n|Enc-dec + ELMo\\n|99.14\\n|Применение кодера-декодера с языковой моделью ELMo.\\n|Stack-Propagation + BERT\\n|99.0\\n|-//-\\nНабор данных: Snips.\\nСм. также\\nПримечания\\n- ↑ Jorrith Schaap, Are Messaging Apps The Next Frontier For Publishers?\\n- ↑ Юлия Фуколова, Исследование российского рынка чат-ботов\\n- ↑ Knud Lasse Lueth, State of the IoT 2018: Number of IoT devices now at 7B – Market accelerating\\n- ↑ Konstantin Savenkov, Intent Detection Benchmark by Intento\\n- ↑ Tsung-Hsien Wen, David Vandyke, A Network-based End-to-End Trainable Task-oriented Dialogue System\\n- ↑ Rafael E. Banchs, Haizhou Li, IRIS: a Chat-oriented Dialogue System based on the Vector Space Model\\n- ↑ Наборы данных Толоки\\n- ↑ Диалоги из фильмов, которые предоставлялись на соревновании Яндекс.Алгоритм 2018 (нужна регистрация)\\n- ↑ Feng-Lin Li, Minghui Qiu, AliMe Assist: An Intelligent Assistant for Creating an Innovative E-commerce Experience\\n- ↑ R. Sarikaya, P. A. Crook, AN OVERVIEW OF END–TO–END LANGUAGE UNDERSTANDING AND DIALOG MANAGEMENT FOR PERSONAL DIGITAL ASSISTANTS\\n- ↑ Формат тренировочных данных в Rasa\\nИсточники информации\\n- Лекция по подходам к построению диалоговых систем от Михаила Бурцева\\n- Семинар Multitask vs Transfer от Антона Астахова\\n- Нейронный машинный перевод с применением GPU. Вводный курс. Часть 2\\n- Tiancheng Zhao, Learning Generative End-to-end Dialog Systems with Knowledge\\n- Alibaba Clouder, Progress in Dialog Management Model Research\\n- DialogStateTracking\\n- NLP. Основы. Техники. Саморазвитие. Часть 1\\n- NLP. Основы. Техники. Саморазвитие. Часть 2: NER\\n- Fast Pattern Matching of Strings Using Suffix Tree in Java\\n- Minlie Huang, Xiaoyan Zhu, Challenges in Building Intelligent Open-domain Dialog Systems\\n- Dataset and methods survey for Task-oriented Dialogue', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='3f0f4ce1-8259-4e19-8339-347ac1450215', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ee4565c9c4ce89f6eacacd05c9b412165d1f927e3602aea46341222e07875f45', text='Уменьшение размерности\\nПод уменьшением размерности (англ. dimensionality reduction) в машинном обучении подразумевается уменьшение числа признаков набора данных. Наличие в нем признаков избыточных, неинформативных или слабо информативных может понизить эффективность модели, а после такого преобразования она упрощается, и соответственно уменьшается размер набора данных в памяти и ускоряется работа алгоритмов ML на нем. Уменьшение размерности может быть осуществлено методами выбора признаков (англ. feature selection) или выделения признаков (англ. feature extraction).\\nСодержание\\nВыбор признаков\\nМетоды выбора признаков оставляют некоторое подмножество исходного набора признаков, избавляясь от признаков избыточных и слабо информативных. Основные преимущества этого класса алгоритмов:\\n- Уменьшение вероятности переобучения;\\n- Увеличение точности предсказания модели;\\n- Сокращение времени обучения;\\n- Увеличивается семантическое понимание модели.\\nВсе методы выбора признаков можно разделить на 5 типов, которые отличаются алгоритмами выбора лишних признаков.\\nФильтры\\nФильтры (англ. filter methods) измеряют релевантность признаков на основе функции $\\\\mu$, и затем решают по правилу $\\\\kappa$, какие признаки оставить в результирующем множестве.\\nФильтры могут быть:\\n- Одномерные (англ. univariate) — функция $\\\\mu$ определяет релевантность одного признака по отношению к выходным меткам. В таком случае обычно измеряют \"качество\" каждого признака и удаляют худшие;\\n- Многомерные (англ. multivariate) — функция $\\\\mu$ определяет релевантность некоторого подмножества исходного множества признаков относительно выходных меток.\\nРаспространенными вариантами для $\\\\mu$ являются:\\n- Коэффициент ранговой корреляции Спирмена [1](англ. Spearman\\'s rank correlation coefficient): $p(x, y)=\\\\displaystyle \\\\frac{\\\\sum_{i, j}(x_{ij}-\\\\bar{x_j})(y_i-\\\\bar{y})}{\\\\sqrt{\\\\sum_{i, j}(x_{ij}-\\\\bar{x_j})^2\\\\sum_i(y_i-\\\\bar{y})^2}}$;\\n- Information gain[2]: $IG(x, y)=\\\\displaystyle -\\\\sum_{i=1}^kp(c_i)\\\\log_2{(p(c_i))}+\\\\sum_{i=1}^{n}p(t_i)\\\\sum_{j=1}^kp(c_j|t_i)log_2{(p(c_j|t_i))}$, и другие.\\nПреимуществом группы фильтров является простота вычисления релевантности признаков в наборе данных, но недостатком в таком подходе является игнорирование возможных зависимостей между признаками.\\nОберточные методы\\nОберточные методы (англ. wrapper methods) находят подмножество искомых признаков последовательно, используя некоторый классификатор как источник оценки качества выбранных признаков, т.е. этот процесс является циклическим и продолжается до тех пор, пока не будут достигнуты заданные условия останова. Оберточные методы учитывают зависимости между признаками, что является преимуществом по сравнению с фильтрами, к тому же показывают большую точность, но вычисления занимают длительное время, и повышается риск переобучения.\\nСуществует несколько типов оберточных методов: детерминированные, которые изменяют множество признаков по определенному правилу, а также рандомизированные, которые используют генетические алгоритмы для выбора искомого подмножества признаков. Среди детерминированных алгоритмов самыми простыми являются:\\n- SFS (Sequential Forward Selection) — жадный алгоритм, который начинает с пустого множества признаков, на каждом шаге добавляя лучший из еще не выбранных признаков в результирующее множество;\\n- SBS (Sequential Backward Selection) — алгоритм обратный SFS, который начинает с изначального множества признаков, и удаляет по одному или несколько худших признаков на каждом шаге.\\nПопулярным оберточным методом является SVM-RFE (SVM-based Recursive Feature Elimination), который иногда также обозначается как встроенный [3]. Этот метод использует как классификатор SVM[на 28.01.19 не создан] и работает итеративно: начиная с полного множества признаков обучает классификатор, ранжирует признаки по весам, которые им присвоил классификатор, убирает какое-то число признаков и повторяет процесс с оставшегося подмножества фичей, если не было достигнуто их требуемое количество. Таким образом, этот метод очень похож на встроенный, потому что непосредственно использует знание того, как устроен классификатор.\\nВстроенные методы\\nГруппа встроенных методов (англ. embedded methods) очень похожа на оберточные методы, но для выбора признаков используется непосредственно структуру некоторого классификатора. В оберточных методах классификатор служит только для оценки работы на данном множестве признаков, тогда как встроенные методы используют какую-то информацию о признаках, которую классификаторы присваивают во время обучения.\\nОдним из примеров встроенного метода является реализация на случайном лесе: каждому дереву на вход подаются случайное подмножество данных из датасета с каким-то случайным набор признаков, в процессе обучения каждое из деревьев решений производит \"голосование\" за релевантность его признаков, эти данные агрегируются, и на выходе получаются значения важности каждого признака набора данных. Дальнейший выбор нужных нам признаков уже зависит от выбранного критерия отбора.\\nВстроенные методы используют преимущества оберточных методов и являются более эффективными, при этом на отбор тратится меньше времени, уменьшается риск переобучения, но т.к. полученный набор признаков был отобран на основе знаний о классификаторе, то есть вероятность, что для другого классификатора это множество признаков уже не будет настолько же релевантным.\\nПравила обрезки\\nДля признаков, у которых найдено качество, можно выкинуть ненужное число признаков. От каких параметров может зависеть алгоритм обрезки:\\n- Число признаков\\n- Порог значимости признаков\\n- Интегральный порог значимости признаков\\n- Метод сломанной трости\\n- Метод локтя\\nМожет быть известно число признаков, которые нужно оставить, или выкинуть.\\nПорог значимости признаков соответствует порогу для меры, например, для корреляции. Выкидываются признаки, для которых корреляция меньше определенного порога:\\nМожет существовать интегральный порог значимости, то есть признаки отсортированы по нормированной по единице \"полезности\", и выбирается несколько признаков с наибольшей .\\nМетод сломанной трости. Есть отрезок, который мы разбиваем послучайным точкам. Если отсортировать длины подотрезков, то для -го подотрезка длина будет равна примерно:\\n, где — число признаков, которые нужно оставить.\\nТогда берутся те признаки, для которыхпревышает порог .\\nМетод локтя. Пусть есть график для признаков, отсортированных по убыванию. Берутся признаки, идущие до резкого перехода между соседними значениями. То есть берутся до порога , где — основание наиболее острого угла, образованного тремя соседними точками на графике.\\nМетод локтя можно использовать и для задачи кластеризации. Например, пусть— внутрикластерное расстояние. Тогда выбирается число кластеров, соответствующее резкому переходу между соседними значениями на графике.\\nДругие методы\\nЕсть и другие методы выбора признаков: гибридные (англ. hybrid methods) и ансамблевые (англ. ensemble methods). Гибридные методы комбинируют несколько разных методов выбора признаков, например, некоторое множество фильтров, а потом запускают оберточный или встроенный метод. Таким образом, гибридные методы сочетают в себе преимущества сразу нескольких методов, и на практике повышают эффективность выбора признаков.\\nАнсамблевые методы применяются больше для наборов данных с очень большим числом признаков. В данном подходе для начального множества признаков создается несколько подмножеств признаков, и эти группы каким-то образом объединяются, чтобы получить набор самых релевантных признаков. Это довольно гибкая группа методов, т.к. для нее можно применять различные способы выбора признаков и объединения их подмножеств.\\nПримеры кода scikit-learn\\nПример кода, реализующего функцию оценки фильтра на основе коэффициента ранговой корреляции:\\n# Импорт библиотек import pandas as pd import numpy as np # Вспомогательная функция для расчета корреляции def correlation(X, Y): return np.cov(X, Y) / np.sqrt(np.var(X) * np.var(Y))\\n# Сам фильтр на основе метрики ранговой корреляции # Аргументы X -- значения объектов датасета для какой-то фичи, Y -- метки этих объектов def measure_spearmans(X, Y): xr = pd.Series(X).rank() yr = pd.Series(Y).rank() return correlation(xr, yr)\\nПример кода, реализующего SVM-RFE wrapper:\\n# Импорт библиотек import numpy as np import pandas as pd from sklearn import svm\\n# X -- наш датасет, Y -- массив меток # N -- число признаков, которые хотим оставить, step -- сколько фичей удаляется на каждой итерации # Возвращает массив из булевых переменных размерностью 1x[число признаков], показывающий, отбрасываем признак или нет def RFE(X, Y, N, step = 10): # cache_size нужен, если набор данных большой, иначе можно опустить clfRFE = svm.SVC(kernel=\\'linear\\', cache_size=1024) featureCount = X.shape[1] featureList = np.arange(0, featureCount ) included = np.full(featureCount, True) curCount = featureCount while curCount > N: actualFeatures = featureList[included] Xnew = X[:, actualFeatures] clfRFE.fit(Xnew, Y) curStep = min(step, curCount - N) elim = np.argsort(np.abs(clfRFE.coef_[0]))[:curStep] included[actualFeatures[elim]] = False curCount -= curStep return included\\nВыделение признаков\\nДругим способом уменьшить размерность входных данных является выделение признаков. Эти методы каким-то образом составляют из уже исходных признаков новые, все также полностью описывающие пространство набора данных, но уменьшая его размерность и теряя в репрезентативности данных, т.к. становится непонятно, за что отвечают новые признаки. Все методы feature extraction можно разделить на линейные и нелинейные.\\nОдним из самых известных методов линейного выделения признаков является PCA[на 28.01.19 не создан] (Principal Component Analysis, рус. метод главных компонент). Основной идеей этого метода является поиск такой гиперплоскости, на которую при ортогональной проекции всех признаков максимизируется дисперсия. Данное преобразование может быть произведено с помощью сингулярного разложения матриц и создает проекцию только на линейные многомерные плоскости, поэтому и метод находится в категории линейных.\\nК нелинейным методам, например, могут быть отнесены методы отображающие исходное пространство признаков на нелинейные поверхности или топологические многообразия. Одним из таких алгоритмов является t-SNE[на 28.01.19 не создан] (t-distributed Stochastic Neighbor Embedding, рус. стохастическое вложение соседей с t-распределением). Данный метод состоит из двух шагов: изначально строится распределение вероятностей по всем парам точек набора данных, каждая условная вероятность $p_{j|i}$ которого означает насколько точка $X_j$ близка к точке $X_i$ при гауссовом распределении вокруг $X_i$. Данное распределение как метрику похожести использует евклидово расстояние. Алгоритм старается получить отображение из точек размерности $\\\\mathbb{R}^k$ в меньшую размерность $\\\\mathbb{R}^d$, для этого вводится еще одно распределение, описывающее насколько точки из нового пространства похожи друг на друга, но используя при этом t-распределение Стьюдента с одной степенью свободы. Как метрику похожести двух распределений используется дивергенция Кульбака-Лейблера[4], и чтобы найти точки новой размерности $d$ запускается градиентный спуск для минимизации этой величины.\\nПример кода scikit-learn\\nПример выделения признаков с помощью PCA в scikit-learn:\\n# Импорт библиотек from sklearn.decomposition import PCA from sklearn.model_selection import train_test_split\\nX = ... # загрузка X Y = ... # загрузка Y # Разделение данных на train и test Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y)\\nclf = ... # берем какой-то классификатор # Обучаем PCA для выделения 5 признаков pca = PCA(n_components=5) pca.fit(Xtrain) # Изменяем наши наборы данных под выбранные признаки Xtrain = pca.transform(Xtrain) Xtest = pca.transform(Xtest) # Обучаем классификатор и проверяем точность его работы clf.fit(Xtrain, Ytrain) print (\"Score: %.6f\" % clf.score(Xtest, Ytest))\\nПример на языке Scala\\nSBT зависимость:\\nlibraryDependencies += \"com.github.haifengl\" %% \"smile-scala\" % \"1.5.2\"\\nПример уменьшение размерности используя smile.feature.GAFeatureSelection[5]:\\nimport smile.classification._ import smile.data._ import smile.feature.GAFeatureSelection import smile.read import smile.validation.Accuracy\\n// Загрузка данных val data = read.arff(\"data/weka/segment-test.arff\", 19) val (x, y) = data.unzipInt val trainer = new GradientTreeBoost.Trainer(100) val measure = new Accuracy // Cоздание генетического алгоритма и его настройка. val selector = new GAFeatureSelection // Размер популяции - 50, количество поколений - 20 // Каждая возращаемая BitString содержит фичи и их качество. val result = selector.learn(50, 20, trainer, measure, x, y, 5) result.foreach { bits => print(100*bits.fitness) println(bits.bits.mkString(\" \")) }\\nПример на языке Java\\nПример уменьшения размерности датасета с применением\\nweka.attributeSelection.PrincipalComponents[6]\\nMaven зависимость:\\n<dependency> <groupId>nz.ac.waikato.cms.weka</groupId> <artifactId>weka-stable</artifactId> <version>3.8.0</version> </dependency>\\nimport weka.attributeSelection.PrincipalComponents; import weka.core.Instances; import weka.filters.Filter; import weka.filters.unsupervised.attribute.NumericToNominal; import java.io.BufferedReader; import java.io.FileReader;\\n// load dataset var data = new Instances(new BufferedReader(new FileReader(\"data/bank-data.arff\"))); var filter = new NumericToNominal(); filter.setInputFormat(data); data = Filter.useFilter(data, filter); // initialize the PCA-based selector var pca = new PrincipalComponents(); // dimensionality reduction is achieved through selecting enough eigenvectors to account // for some percantege of the variance in the original data pca.setVarianceCovered(0.95); pca.buildEvaluator(data); // transform the dataset data = pca.transformedData(data);\\nСм. также\\nПримечания\\nИсточники информации\\n- Sequential feature selection — курс ML Texas A&M University\\n- Feature selection — статья про Feature Selection в Wikipedia\\n- Публикация про feature selection\\n- Embedded random forest', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='71300f72-90ca-452a-a817-ef0b200adce3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8f2fe8ecc74c3efaa41a57097d738a6ccf832dbfc6454b44beb121c3878801de', text='Выброс\\nВыброс (англ. outlier) — это экстремальные значения во входных данных, которые находятся далеко за пределами других наблюдений. Например, все предметы на кухне имеют температуру около 22-25 грудусов Цельсия, а — духовка 220.\\nМногие алгоритмы машинного обучения чувствительны к разбросу и распределению значений признаков обрабатываемых объектов. Соответственно, выбросы во входных данных могут исказить и ввести в заблуждение процесс обучения алгоритмов машинного обучения, что приводит к увеличению времени обучения, снижению точности моделей и, в конечном итоге, к снижению результатов. Даже до подготовки предсказательных моделей на основе обучающих данных выбросы могут приводить к ошибочным представлениям и в дальнейшем к ошибочной интерпретации собранных данных.\\nСодержание\\n- 1 Виды выбросов\\n- 2 Причины возникновения выбросов\\n- 3 Примеры\\n- 4 Методы обнаружения и борьбы с выбросами\\n- 5 См.также\\n- 6 Примечания\\n- 7 Источники информации\\nВиды выбросов\\nНа основе размерности изучаемого массива данных выбросы подразделяют на одномерные и многомерные.\\n- Одномерные выбросы\\n- Точка является выбросом только по одной из своих координат.\\n- Многомерные выбросы\\n- Точка является выбросом сразу по нескольким координатам.\\nДругой подход классификации выбросов — по их окружению.\\n- Точечные выбросы\\n- Единичные точки, выбивающиеся из общей картины. Точечные аномалии часто используются в системах контроля транзакций для выявления мошенничества, например, когда с украденной карты совершается крупная покупка.\\n- Контекстуальные выбросы\\n- Для того, чтобы определить, является ли точка выбросом необходим контекст. Например, в Петербурге +15 градусов Цельсия. Зимой такая температура является выбросом, а летом нет.\\n- Коллективные выбросы\\n- Здесь выбросом является не точка, а группа точек. Примером таких выбросов могут служить, например, задержки поставок на фабрике. Одна задержка не является выбросом. Но если их много, значит это может стать проблемой.\\nПричины возникновения выбросов\\n- Сбой работы оборудования;\\n- Человеческий фактор;\\n- Случайность;\\n- Уникальные явления;\\n- и др.\\nПримеры\\nРис 2 показывает хорошо обученную модель, в которой присутствуют два выброса. Как видно из рисунка данная модель показала себя устойчивой к выбросам, либо же вовремя прекратила своё обучение. Обратная ситуация обстоит с Рис 3, где модель сильно переобучилась из-за присутствующих в ней выбросов.\\nМетоды обнаружения и борьбы с выбросами\\nМетоды обнаружения выбросов\\n- Экстремальный анализ данных(англ. extreme value analysis). При таком анализе не применяются какие-либо специальные статистические методы. Обычно этот метод применим для одномерного случая. Алгоритм использования таков:\\n- Визуализировать данные, используя диаграммы и гистограммы для нахождения экстремальных значений;\\n- Задействовать распределение, например Гауссовское, и найти значения, чье стандартное отклонение отличается в 2-3 раза от математического ожидания или в полтора раза от первой либо третьей квартилей;\\n- Отфильтровать предполагаемые выбросы из обучающей выборки и оценить работу модели;\\n- Аппроксимирующий метод (англ. proximity method). Чуть более сложный метод, заключающийся в применении кластеризующих методов;\\n- Использовать метод кластеризации для определения кластеров в данных;\\n- Идентифицировать и отметить центроиды каждого кластера;\\n- Соотнести кластеры с экземплярами данных, находящимися на фиксированном расстоянии или на процентном удалении от центроида соответствующего кластера;\\n- Отфильтровать предполагаемые выбросы из обучающей выборки и оценить работу модели;\\n- Проецирующие методы (англ. projections methods). Эти методы довольно быстро и просто определяют выбросы в выборке;\\n- Использовать один из проецирующих методов, например, метод главных компонент (англ. principal component analysis, PCA[1]) или самоорганизующиеся карты Кохонена(англ. self-organizing map, SOM[2]) или проекцию Саммона(англ. Sammon mapping, Sammon projection[3]), для суммирования обучающих данных в двух измерениях;\\n- Визуализировать отображение;\\n- Использовать критерий близости от проецируемых значений или от вектора таблицы кодирования (англ. codebook vector) для идентифицирования выбросов;\\n- Отфильтровать предполагаемые выбросы из обучающей выборки и оценить работу модели.\\nЛокально взвешенное сглаживание\\nЛокально взвешенное сглаживание (англ. LOcally WEighted Scatter plot Smoothing, LOWESS)[4]. Данная методика была предложена Кливлендом (Cleveland) в 1979 году для моделирования и сглаживания двумерных данных . Эта техника предоставляет общий и гибкий подход для приближения двумерных данных. Локально-линейная модель может быть записана в виде: . Эта модель может быть расширена на случай локально-квадратичной зависимости и на модель с большим числом независимых переменных. Параметры и локально линейной модели оцениваются с помощью локально взвешенной регрессии, которая присваивает объекту тем больший вес, чем более близок он к объекту t. Степень сглаживания определяется параметром сглаживания , который выбирает пользователь. Параметр указывает какая доля (англ. fraction) данных используется в процедуре. Если , то только половина данных используется для оценки и влияет на результат, и тогда мы получим умеренное сглаживание. С другой стороны, если , то используются восемьдесят процентов данных, и сглаживание намного сильнее. Во всех случаях веса данных тем больше, чем они ближе к объекту .\\nПостановка задачи\\nПусть задано пространство объектов $X$ и множество возможных ответов. Существует неизвестная зависимость , значения которой известны только на объектах обучающией выборки . Требуется построить алгоритм , аппроксимирующий неизвестную зависимость . Предполагается, что на множестве $X$ задана метрика .\\nТакже стоит определить следующее. Для вычислениядля воспользуемся методом наименьших квадратов: , где — это вес $i$-ого объекта.\\nВеса ядром[на 28.01.19 не создан], и представить в следующем виде:разумно задать так, чтобы они убывали по мере увеличения расстояния . Для этого можно ввести невозрастающую, гладкую, ограниченную функцию , называемую\\n, где $h$ — ширина окна.\\nПриравняв равной нулю производную и выразив , получаем формулу Надарая-Ватсона[5] : .\\nПроблема выбросов в этой задаче\\nБольшие случайные ошибки в значенияхсильно искажают оценку Надарая-Ватсона.\\nИдея\\nЧем больше величина невязки, тем меньше должен быть вес i-го объекта .\\nЭвристика\\nДомножить весана коэффициенты , где — ещё одно ядро, вообще говоря, отличное от .\\nПсевдокод\\nINPUT: //инициализация коэффициентов 2: do 3: for each object ; 4: calculate cross-validation estimates: //вычислить оценки скользящего контроля 5: for each object ; 6: 7: while coefficents not stabilized; //пока коэффициенты не стабилизируются- training sample; OUTPUT: coefficents ; ________________________________________________________ 1: initialization: ;\\nПример на языке R\\nВ этом примере мы попытаемся локально регрессировать и сгладить среднюю продолжительность безработицы на основе набора экономических данных из пакета $ggplot2$ языка $R$. Мы рассматриваем только первые 80 строк для этого анализа, чтобы легче было наблюдать степень сглаживания на приведенных ниже графиках.\\ndata(economics, package=\"ggplot2\") # загрузка данных economics$index <- 1:nrow(economics) # создание индексной переменной economics <- economics[1:80, ] # усечение до 80 строк для более наглядного демонстрирования loessMod10 <- loess(uempmed ~ index, data=economics, span=0.10) # 10% параметр сглаживания span loessMod25 <- loess(uempmed ~ index, data=economics, span=0.25) # 25% параметр сглаживания span loessMod50 <- loess(uempmed ~ index, data=economics, span=0.50) # 50% параметр сглаживания span\\n# получить сглаженный результат\\nsmoothed10 <- predict(loessMod10)\\nsmoothed25 <- predict(loessMod25)\\nsmoothed50 <- predict(loessMod50)\\n# Нарисовать\\nplot(economics$uempmed, x=economics$date, type=\"l\", main=\"Локально взвешенное сглаживание\", xlab=\"Дата\", ylab=\"Длительность безработицы\")\\nlines(smoothed10, x=economics$date, col=\"red\")\\nlines(smoothed25, x=economics$date, col=\"green\")\\nlines(smoothed50, x=economics$date, col=\"blue\")\\nДругие алгоритмы борьбы с выбросами\\nВ статистике методы, устойчивые к нарушениям модельных предположений о данных, называются робастными. Метод локально взвешенного сглаживания относится к робастным методам, так как он устойчив к наличию небольшого количества выбросов.\\n- Дерево принятия решения (англ. decision tree[6]). Это дерево, как и уже описанный алгоритм локально взвешенного сглаживания, относится к робастным методам;\\n- Робастная регрессия (англ. robust regression[7]). В отличие от регрессии, использующей, например, метод наименьших квадратов, в этом алгоритме не строится идеализированное предположение, что вектор ошибок распределен согласно нормальному закону. Однако на практике зачастую имеют место отклонения от этого предположения. Тогда можно применить метод наименьших модулей (англ. Least Absolute Deviation, LAD [8]) в случае, если распределение ошибок измерений подчиняется распределению Лапласа (англ. Laplace distribution [9]).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='960b681c-32fb-4d4b-8118-be2af6100e5b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8a77276530fdd8d6b38dcc528ee656db5f18cd65ecf71a2089d8a715776f94c0', text='Алгоритмы сэмплирования\\nСэмплирование (англ. data sampling) — метод корректировки обучающей выборки с целью балансировки распределения классов в исходном наборе данных. Нужно отличать этот метод от сэмплирования в активном обучении для отбора кандидатов и от сэмплирования в статистике[1] для создания подвыборки с сохранением распределения классов.\\nНеравномерное распределение может быть следующих типов:\\n- Недостаточное представление класса в независимой переменной;\\n- Недостаточное представление класса в зависимой переменной.\\nМногие модели машинного обучения, например, нейронные сети, дают более надежные прогнозы на основе обучения со сбалансированными данными. Однако некоторые аналитические методы, в частности линейная регрессия и логистическая регрессия, не получают дополнительного преимущества.\\nКогда в обучающем наборе данных доля примеров некоторого класса слишком мала, такие классы называются миноритарными (англ. minority), другие, со слишком большим количеством представителей, — мажоритарными (англ. majority). Подобные тенденции хорошо заметны в кредитном скоринге, в медицине, в директ-маркетинге.\\nСледует отметить то, что значимость ошибочной классификации может быть разной. Неверная классификация примеров миноритарного класса, как правило, обходится в разы дороже, чем ошибочная классификация примеров мажоритарного класса. Например, при классификации людей, обследованных в больнице, на больных раком (миноритарный класс) и здоровых (мажоритарный класс) лучше будет отправить на дополнительное обследование здоровых пациентов, чем пропустить людей с раком.\\nСодержание\\n- 1 Стратегии сэмплирования\\n- 2 Метод Uncertainty Sampling\\n- 3 Примеры алгоритмов\\n- 3.1 Cубдискретизация (удаление примеров мажоритарного класса)\\n- 3.1.1 Случайное удаление примеров мажоритарного класса (англ. Random Undersampling)\\n- 3.1.2 Поиск связей Томека (англ. Tomek Links)\\n- 3.1.3 Правило сосредоточенного ближайшего соседа (англ. Condensed Nearest Neighbor Rule)\\n- 3.1.4 Односторонний сэмплинг (англ. One-side sampling, one-sided selection)\\n- 3.1.5 Правило «очищающего» соседа (англ. Neighborhood cleaning rule)\\n- 3.1.6 Дополнительные\\n- 3.2 Передискретизации (увеличение числа примеров миноритарного класса)\\n- 3.3 Алгоритм Метрополиса — Гастингса\\n- 3.4 Сэмплирование по Гиббсу\\n- 3.5 Slice sampling\\n- 3.6 Комбинирование\\n- 3.7 Ансамбль сбалансированных наборов\\n- 3.1 Cубдискретизация (удаление примеров мажоритарного класса)\\n- 4 Реализации\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nСтратегии сэмплирования\\n- Cубдискретизация (англ. under-sampling) — удаление некоторого количества примеров мажоритарного класса.\\n- Передискретизации (англ. over-sampling) — увеличение количества примеров миноритарного класса.\\n- Комбинирование (англ. сombining over- and under-sampling) — последовательное применение субдискретизации и передискретизации.\\n- Ансамбль сбалансированных наборов (англ. ensemble balanced sets) — использование встроенных методов сэмплирования в процессе построения ансамблей классификаторов.\\nТакже все методы можно разделить на две группы: случайные (недетерминированные) и специальные (детерминированные).\\n- Случайное сэмплирование (англ. random sampling) — для этого типа сэмплирования существует равная вероятность выбора любого конкретного элемента. Например, выбор 10 чисел в промежутке от 1 до 100. Здесь каждое число имеет равную вероятность быть выбранным.\\n- Сэплирование с заменой (англ. sampling with replacement) — здесь элемент, который выбирается первым, не должен влиять на вторую или любую другую выборку. Математически, ковариация равна нулю между двумя выборками. Мы должны использовать выборку с заменой, когда у нас большой набор данных. Потому что, если мы используем выборку без замены, то вероятность для каждого предмета, который будет выбран, будет изменяться, и она будет слишком сложной после определенного момента. Выборка с заменой может сказать нам, что чаще встречается в наших данных.\\n- Сэмплирование без замены (англ. sampling without replacement) — здесь то, что мы выбираем первым, повлияет на второе. Выборка без замены полезна, если набор данных мал. Математически, ковариация между двумя выборками не равна нулю.\\n- Стратифицированное сэмплирование (англ. stratified sampling) — в этом типе техники мы выбираем из определенной группы объектов из всей выборки. Из каждой группы извлекается одинаковое количество объектов, хотя группы имеют разные размеры. Кроме того, существует вариант, когда количество объектов, выбранных из каждой группы, пропорционально размеру этой группы.\\nМетод Uncertainty Sampling\\nИдея: выбиратьс наибольшей неопределенностью .\\nЗадача многоклассовой классификации:\\n— ранжированные по убыванию .\\n- Принцип наименьшей достоверности (англ. least confidence):\\n- Принцип наименьшей разности отступов (англ. margin sampling):\\n- Принцип максимума энтропии (англ. maximum entropy):\\nВ случае двух классов эти три принципа эквивалентны. В случае многих классов появляются различия.\\nПримеры алгоритмов\\nCубдискретизация (удаление примеров мажоритарного класса)\\nСлучайное удаление примеров мажоритарного класса (англ. Random Undersampling)\\nЭто самый простой алгоритм. Рассчитывается число– количество мажоритарных примеров, которое необходимо удалить для достижения требуемого уровня соотношения различных классов. Затем случайным образом выбираются K мажоритарных примеров и удаляются. На рис. изображены примеры некоторого набора данных в двумерном пространстве признаков до и после использования алгоритма.\\nПоиск связей Томека (англ. Tomek Links)\\nПусть примерыи принадлежат к различным классам, – расстояние между указанными примерами. Пара называется связью Томека, если не найдется ни одного примера такого, что будет справедлива совокупность неравенств:\\nСогласно данному подходу, все мажоритарные записи, входящие в связи Томека, должны быть удалены из набора данных. Этот способ хорошо удаляет записи, которые можно рассматривать в качестве «зашумляющих». На рис.визуально показан набор данных в двумерном пространстве признаков до и после применения стратегии поиска связей Томека.\\nПравило сосредоточенного ближайшего соседа (англ. Condensed Nearest Neighbor Rule)\\nПусть– исходный набор данных. Из него выбираются все миноритарные примеры и (случайным образом) один мажоритарный. Обозначим это множество как . Все примеры из классифицируются по правилу одного ближайшего соседа. Записи, получившие ошибочную метку, добавляются во множество (рис. ). Таким образом, мы будем учить классификатор находить отличие между похожими примерами, но принадлежащими к разным классам.\\nОдносторонний сэмплинг (англ. One-side sampling, one-sided selection)\\nГлавная идея этой стратегии – это последовательное сочетание предыдущих двух, рассмотренных выше. Для этого на первом шаге применяется правило сосредоточенного ближайшего соседа, а на втором – удаляются все мажоритарные примеры, участвующие в связях Томека. Таким образом, удаляются большие «сгустки» мажоритарных примеров, а затем область пространства со скоплением миноритарных очищается от потенциального шума.\\nПравило «очищающего» соседа (англ. Neighborhood cleaning rule)\\nЭта стратегия также направлена на то, чтобы удалить те примеры, которые негативно влияют на исход классификации миноритарных классов. Для этого все примеры классифицируются по правилу трех ближайших соседей. Удаляются следующие мажоритарные примеры:\\n- получившие верную метку класса;\\n- являющиеся соседями миноритарных примеров, которые были неверно классифицированы.\\nДополнительные\\n- Under-sampling with Cluster Centroids[2] — уменьшает количество примеров мажоритарного класса, заменяя некоторые кластеры примеров мажоритарного класса их представителем (центроидом кластера).\\n- NearMiss [3] — удаляет примеры мажоритарного класса, для которых среднее расстояние до ближайших соседей (KNN) миноритарного класса является наименьшим. Также может использоваться расстояние до самых дальних соседей, либо среднее расстояние до всех соседей.\\n- Edited Nearest Neighbours[4] — удаляет примеры мажоритарного класса, если при классификации методом KNN они определяются как примеры миноритарного класса.\\nПередискретизации (увеличение числа примеров миноритарного класса)\\nДублирование примеров миноритарного класса (англ. Oversampling)\\nСамый простой метод – это дублирование примеров миноритарного класса. В зависимости от того, какое соотношение классов необходимо, выбирается количество случайных записей для дублирования.\\nSMOTE (англ. Synthetic Minority Oversampling Technique)\\nЭтот алгоритм основан на идее генерации некоторого количества искусственных примеров, которые были бы похожи на имеющиеся в миноритарном классе, но при этом не дублировали их. Для создания новой записи находят разность KNN. В данном случае необходимо и достаточно для примера получить набор из соседей, из которого в дальнейшем будет выбрана запись . Остальные шаги алгоритма KNN не требуются. Далее из путем умножения каждого его элемента на случайное число в интервале получают . Вектор признаков нового примера вычисляется путем сложения и . Алгоритм SMOTE позволяет задавать количество записей, которое необходимо искусственно сгенерировать. Степень сходства примеров и можно регулировать путем изменения числа ближайших соседей . На рис. схематично изображено то, как в двумерном пространстве признаков могут располагаться искусственно сгенерированные примеры., где , – векторы признаков «соседних» примеров и из миноритарного класса. Их находят, используя алгоритм ближайшего соседа\\nВ SMOTE (техника избыточной выборки синтетического меньшинства) мы синтезируем элементы для класса меньшинства в непосредственной близости от уже существующих элементов.\\nfrom imblearn.over_sampling import SMOTE\\nsmote = SMOTE(ratio=\\'minority\\')\\nX_sm, y_sm = smote.fit_sample(X, y)\\nВ библиотеке imblearn есть множество других методов как для недостаточной выборки (Cluster Centroids, NearMiss и т.д.), так и для избыточной выборки (ADASYN и bSMOTE).\\nASMO (англ. Adaptive Synthetic Minority Oversampling)\\nАлгоритм SMOTE имеет недостаток в том, что «вслепую» увеличивает плотность примерами в области слабо представленного класса (рис.). В случае, если миноритарные примеры равномерно распределены среди мажоритарных и имеют низкую плотность, алгоритм SMOTE только сильнее перемешает классы. В качестве решения данной проблемы был предложен алгоритм адаптивного искусственного увеличения числа примеров миноритарного класса ASMO:\\n- Если для каждого -ого примера миноритарного класса из ближайших соседей принадлежит к мажоритарному, то набор данных считается «рассеянным». В этом случае используют алгоритм ASMO, иначе применяют SMOTE (как правило, задают равным ).\\n- Используя только примеры миноритарного класса, выделить несколько кластеров (например, алгоритмом ). -средних\\n- Сгенерировать искусственные записи в пределах отдельных кластеров на основе всех классов. Для каждого примера миноритарного класса находят ближайших соседей, и на основе них (также как в SMOTE) создаются новые записи.\\nТакая модификация алгоритма SMOTE делает его более адаптивным к различным наборам данных с несбалансированными классами. Общее представление идеи алгоритма показано на рис..\\nДополнительные\\n- SMOTENC[5] — в отличие от SMOTE, работает с непрерывными признаками у примеров обучающей выборки.\\n- Borderline-SMOTE [6] — в отличие от SMOTE, для создания новых синтетических примеров используются только примеры на границе классов.\\n- SVM SMOTE - Support Vectors SMOTE[7] — вариант алгоритма SMOTE, который использует алгоритм SVM для обнаружения примеров, рядом с которыми будут создаваться новые синтетические примеры.\\nАлгоритм Метрополиса — Гастингса\\nАлгоритм позволяет семплировать любую функцию распределения. Он основан на создании цепи Маркова, то есть на каждом шаге алгоритма новое выбранное значение зависит только от предыдущего.\\n- Очередная итерация начинается с состояния\\n- Выбираем по распределению\\n- Вычисляем:\\n- С вероятностью ( , если ) , иначе\\nСэмплирование по Гиббсу\\nЭтот алгоритм является частным случаем алгоритма Метрополиса — Гастингса и назван в честь физика Джозайи Гиббса. Он замечателен тем, что для него не требуется явно выраженное совместное распределение, а нужны лишь условные вероятности для каждой переменной, входящей в распределение. Алгоритм на каждом шаге берет одну случайную величину и выбирает её значение при условии фиксированных остальных.\\nвыбираем по распределению и повторяем.\\nЭто частный случай алгоритма Метрополиса для распределений , и вероятность принятия каждого сэмпла полается равна . Поэтому сэмплирование по Гиббсу сходится, и, так как это такое же случайное блуждание по сути, верна та же квадратичная оценка. В больших размерностях может оказаться эффективнее сэмплить по несколько переменных сразу, а не по одной — например, часто бывает, что у нас двудольный граф из переменных, в которых все переменные из одной доли связаны со всеми переменными из другой доли (ну или со многими), а между собой не связаны. В такой ситуации следует зафиксировать все переменные одной доли и просэмплировать все переменные в другой доле одновременно (это можно понимать буквально — поскольку при такой структуре все переменные одной доли условно независимы при условии другой, их можно сэмплировать независимо и параллельно), потом зафиксировать все переменные второй доли и так далее.\\nSlice sampling\\nВыборка среза представляет собой тип алгоритма Монте Карло по схеме марковских цепей для выборки псевдослучайных чисел, т.е. для отбора случайных выборок из статистического распределения. Метод основан на наблюдении, что для выборки случайной величины можно равномерно выбирать из области под графиком ее функции плотности.\\nSlice sampling, в его самой простой форме, равномерно выбирается из-под кривойбез необходимости отбрасывать какие-либо точки следующими действиями:\\n- Выберите начальное значение , для которого\\n- Выберите значение равномерно между и\\n- Проведите горизонтальную линию через кривую в этой координате\\n- Выберите точку на отрезке в пределах кривой\\n- Повторите с шага , используя новое значение\\nСуть здесь заключается в том, что один из способов равномерной выборки точки из произвольной кривой — это сначала нарисовать тонкие горизонтальные срезы одинаковой высоты по всей кривой. Затем мы можем сэмплировать точку внутри кривой путем случайного выбора среза, который находится в точке или ниже кривой в позициина предыдущей итерации, а затем случайным образом выбрать позицию где-нибудь вдоль среза. Используя позицию из предыдущей итерации алгоритма, в долгосрочной перспективе мы выбираем срезы с вероятностями, пропорциональными длине их сегментов в пределах кривой. Самая сложная часть этого алгоритма — это поиск границ горизонтального среза, который включает в себя инвертирование функции, описывающей распределение, из которого производится выборка. Это особенно проблематично для мультимодальных распределений, где срез может состоять из нескольких прерывистых частей. Часто можно использовать форму выборки отклонения, чтобы преодолеть это, когда мы производим выборку из более крупного среза, который, как известно, включает в себя требуемый рассматриваемый срез, а затем отбрасываем точки за пределами желаемого среза. Этот алгоритм можно использовать для выборки из области под любой кривой, независимо от того, интегрируется ли функция в . Фактически, масштабирование функции по константе не влияет на выборочные —позиции. Это означает, что алгоритм может использоваться для выборки из распределения, функция плотности вероятности которого известна только с точностью до константы.\\nКомбинирование\\n- SMOTE [8] — сначала выполняет передискретизацию с использованием SMOTE, а потом субдискретизацию используя Tomek Links. Tomek links\\n- SMOTE [9] — последовательно использует SMOTE и Edited Nearest Neighbours. ENN\\nАнсамбль сбалансированных наборов\\n- Easy Ensemble classifier[10] — независимые классификаторы обучаются на случайных подвыборках, из которых постепенно удаляются правильно классифицирующиеся примеры мажоритарных классов.\\n- Balanced Random Forest[11] — в отличие от классического случайного леса, может работать на несбалансированных данных.\\n- Balanced Bagging[12] — в отличие от классического бэггинга, имеет дополнительный шаг субдискретизации обучающей подвыборки.\\nРеализации\\nImbalanced-learn — набор инструментов с открытым исходным кодом на Python, целью которого является предоставление широкого спектра методов для решения проблемы несбалансированного набора данных. На рис. представлена таблица реализованных в библиотеке методов.\\nПример кода для передискретизации набора данных с использованием SMOTE:\\nfrom sklearn.datasets import make_classification from sklearn.decomposition import PCA from imblearn.oversampling import SMOTE # Создание датасета X, y = makeclassification (n_classes=2, weights =[0.1, 0.9], n_features=20, n_samples=5000) Применение SMOTE over-sampling sm = SMOTE(ratio=’auto’, kind=’regular’) X_resampled , y_resampled=sm.fit_sample(X, y)\\nСм. также\\n- Метрический классификатор и метод ближайших соседей\\n- Байесовская классификация\\n- Активное обучение\\n- Виды ансамблей\\nПримечания\\n- ↑ Sampling (statistics)\\n- ↑ Show-Jane Yen, Yue-Shi Lee,Cluster-based under-sampling approaches for imbalanced data distributions, Expert Systems with Applications, Volume 36, Issue 3, Part 1, 2009, Pages 5718-5727, ISSN 0957-4174\\n- ↑ I. Mani, J. Zhang. “kNN approach to unbalanced data distributions: A case study involving information extraction,” In Proceedings of the Workshop on Learning from Imbalanced Data Sets, pp. 1-7, 2003.\\n- ↑ D. Wilson, “Asymptotic Properties of Nearest Neighbor Rules Using Edited Data,” IEEE Transactions on Systems, Man, and Cybernetrics, vol. 2(3), pp. 408-421, 1972.\\n- ↑ N. V. Chawla, K. W. Bowyer, L. O. Hall, W. P. Kegelmeyer, “SMOTE: Synthetic minority over-sampling technique,” Journal of Artificial Intelligence Research, vol. 16, pp. 321-357, 2002.\\n- ↑ H. Han, W.-Y. Wang, B.-H. Mao, “Borderline-SMOTE: A new over-sampling method in imbalanced data sets learning,” In Proceedings of the 1st International Conference on Intelligent Computing, pp. 878-887, 2005.\\n- ↑ H. M. Nguyen, E. W. Cooper, K. Kamei, “Borderline over-sampling for imbalanced data classification,” In Proceedings of the 5th International Workshop on computational Intelligence and Applications, pp. 24-29, 2009.\\n- ↑ G. E. A. P. A. Batista, A. L. C. Bazzan, M. C. Monard, “Balancing training data for automated annotation of keywords: A case study,” In Proceedings of the 2nd Brazilian Workshop on Bioinformatics, pp. 10-18, 2003.\\n- ↑ G. E. A. P. A. Batista, R. C. Prati, M. C. Monard, “A study of the behavior of several methods for balancing machine learning training data,” ACM Sigkdd Explorations Newsletter, vol. 6(1), pp. 20-29, 2004.\\n- ↑ X.-Y. Liu, J. Wu and Z.-H. Zhou, “Exploratory undersampling for class-imbalance learning,” IEEE Transactions on Systems, Man, and Cybernetics, vol. 39(2), pp. 539-550, 2009.\\n- ↑ C. Chao, A. Liaw, and L. Breiman. \"Using random forest to learn imbalanced data.\" University of California, Berkeley 110 (2004): 1-12.\\n- ↑ Hido, Shohei & Kashima, Hisashi. (2008). Roughly Balanced Bagging for Imbalanced Data. 143-152. 10.1137/1.9781611972788.13.\\nИсточники информации\\n- Oversampling and undersampling in data analysis\\n- Различные стратегии сэмплинга в условиях несбалансированности классов\\n- Lemaître, G. Nogueira, F. Aridas, Ch.K. (2017) Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning, Journal of Machine Learning Research, vol. 18, no. 17, 2017, pp. 1-5.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='d582b318-0423-4a89-91af-4a61e768879d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b751c5ba73cc62747819063b84180badcd28f1e6651ee7c5d71439c0177bb7fc', text='Известные наборы данных\\nСодержание\\n- 1 Обзор\\n- 2 Iris\\n- 3 MNIST\\n- 4 CIFAR-10\\n- 5 ImageNet\\n- 6 ADE20K\\n- 7 COCO\\n- 8 Fashion-MNIST\\n- 9 Boston Housing\\n- 10 Caltech-UCSD Birds 200 (CUB)\\n- 11 102 Category Flower\\n- 12 Visual Genome\\n- 13 CelebA\\n- 14 CityScapes\\n- 15 ICDAR\\n- 16 Pointing\\'04\\n- 17 FASSEG\\n- 18 MPI\\n- 19 См.также\\n- 20 Примечания\\nОбзор\\nДля многих алгоритмов машинного обучения требуется большое количество данных. Кроме того, что моделям нужны данные для обучения, нужно сравнивать эффективность разных моделей. Поскольку поиск хороших наборов данных и их разметка — трудная задача, на помощь приходят уже собранные и размеченные наборы данных, для которых зачастую уже опубликованы результаты каких-то алгоритмов, и можно оценить, насколько хорошо работает исследуемая модель.\\nВ этой статье рассмотрены с примерами несколько популярных наборов данных. Другие классические наборы можно посмотреть, например, на википедии[1].\\n|Набор данных\\n|Какие объекты\\n|Число объектов\\n|Число классов\\n|Доля ошибок лучшего опубликованного алгоритма\\n|Iris\\n|Данные измерений четырех параметров цветков ириса\\n|150\\n|3\\n|N/A, малый размер набора данных\\n|MNIST\\n|Рукописные цифры, черно-белые изображения 32х32 пикселя\\n|70 000\\n|10\\n|0.18% [2]\\n|CIFAR-10\\n|Фотографии объектов разных классов, цветные изображения 32х32 пикселя\\n|60 000\\n|10\\n|1.23% [3]\\n|ImageNet\\n|Фотографии с указанием классов объектов на изображении и их позиций\\n|Больше 14 миллионов\\n|Больше 21 тысячи\\n|Большое количество различных метрик, см. ImageNet Competition. 1-5% на классификацию\\n|ADE20K\\n|Фотографии с указанием семантической сегментации сущностей на них. Для каждого объекта также приведена его сегментация на части\\n|22 210 (434 826 вхождений объектов)\\n|3 169\\n|17.93% [4]\\n|Coco\\n|Фотографии сложных повседневных сцен, содержащих объекты в их естественном окружении.\\n|328 000 изображений (более 2.5 миллионов вхождений объектов)\\n|91\\n|Много метрик. Зависит, в частности, от площади, занимаемой объектом на изображении. [5]\\n|Fashion-MNIST\\n|Черно-белые фотографии различных видов одежды, 28x28 пикселей.\\n|60000 изображений + 10000 тестовых изображений\\n|10\\n|3.3% (WRN40-4 8.9M params) [6]\\n|Boston housing\\n|Данные о недвижимости в районах Бостона.\\n|506\\n|13\\n|RMSE-1.33055\\n|Caltech-UCSD Birds 200\\n|Данные о видах птиц\\n|11788\\n|200\\n|не описано\\n|102 Category Flower\\n|Данные о видах цветов\\n|8189\\n|102\\n|не описано\\n|Visual Genome\\n|Данные о связи объектов на картинке с текстом\\n|108077\\n|76340 объектов, 15626 атрибутов, 47 зависимостей\\n|Слишком много метрик [7]\\n|CelebA\\n|Изображения знаменитостей, охватывающие большие вариации поз\\n|Больше 200 тысяч\\n|202 599 изображений лиц, 10 177 уникальных личностей, 5 ориентиров, 40 бинарных атрибутов\\n|не описано\\n|Cityscapes\\n|Изображения городских улиц 50 городов с указанием семантической сегментации сущностей на них. Для каждого объекта также приведена его сегментация на части\\n|5000 изображений с разрешением 1024 * 2048, предварительно разделенных на наборы для обучения (2975), проверки (500) и тестирования (1525) + 20000 изображений с грубыми аннотациями\\n|30\\n|не описано\\n|ICDAR 2017 \"COCO Text\"\\n|набор данных, основанный на датасете \"MS COCO\"[8], где собраны обычные изображения ежедневных сцен, на которых, возможно, присутствует текст\\n|63686 изображений, 43686 — обучающая выборка,10000 — валидирующая выборка, 10000 — тестовая\\n|173589 слов\\n|не описано\\n|Pointing\\'04\\n|Изображения лиц людей с разными углами поворота и наклона\\n|15 сетов по 186 изображений в каждом\\n|93\\n|7.9% [9]\\n|FASSEG\\n|Изображения лиц людей с разными углами поворота, как в оригинале, так и в сегментированном виде\\n|Часть frontal01: 70, часть frontal02: 70, часть multipose01: 200\\n|frontal01 и frontal02 — разделяют изображение на 6 различных сегментов, multipose01 — 13 углов поворота\\n|7.73% [10] для сегментации, 22.6% [11] для определения поз\\n|MPI\\n|Изображения повседневной деятельности людей в различных позах\\n|25 тысяч\\n|410\\n|~10% [12]\\nIris\\nОписание\\nIris — небольшой набор данных для задачи классификации, опубликованный еще в 1936 году Робертом Фишером, используя данные биолога Эдгара Андерсона. В этом наборе данных представлены по 50 описаний цветков одного из трех типов — Ирис щетинистый (Iris setosa), Ирис виргинский (Iris virginica) и Ирис разноцветный (Iris versicolor).\\nДля каждого цветка измерены четыре величины — длина чашелистника (англ. sepal length), ширина чашелистника (sepal width), длина лепестка (англ. petal length), ширина лепестка (англ. petal width). Все цветки промаркированы одним из трех типов, что позволяет тестировать на нем алгоритмы классификации. Интересное наблюдение — один из классов цветков линейно отделим от двух других.\\nПример\\n|Длина чашелистника\\n|Ширина чашелистника\\n|Длина лепестка\\n|Ширина лепестка\\n|Класс\\n|5.1\\n|3.5\\n|1.4\\n|0.2\\n|setosa\\n|7.0\\n|3.2\\n|4.7\\n|1.4\\n|versicolor\\n|6.3\\n|3.3\\n|6.0\\n|2.5\\n|virginica\\nКод\\nfrom sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier from sklearn import metrics iris=load_iris() X = iris.data Y = iris.target n = len(iris.data) train = n // 2 clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0) clf.fit(X[:train], Y[:train]) expected = Y[train:] predicted = clf.predict(X[train:]) print(\"Classification report for classifier %s:\\\\n%s\\\\n\" % (clf, metrics.classification_report(expected, predicted)))\\ntype precision recall f1-score support 0 1.00 1.00 1.00 28 1 0.95 0.88 0.91 24 2 0.88 0.96 0.92 23 avg / total 0.95 0.95 0.95 75\\nMNIST\\nОписание\\nНабор данных MNIST — большой (порядка 60 000 тренировочных и 10 000 проверочных объектов, помеченных на принадлежность одному из десяти классов — какая цифра изображена на картинке) набор картинок с рукописными цифрами, часто используемый для тестирования различных алгоритмов распознавания образов. Он содержит черно-белые картинки размера 28x28 пикселей, исходно взятые из набора образцов из бюро переписи населения США, к которым были добавлены тестовые образцы, написанные студентами американских университетов. На рисунке 1 представлены примеры рукописных цифр из данного датасета.\\nРезультаты\\nНа сайте[13] MNIST можно найти список лучших результатов, достигнутых алгоритмами на это наборе данных. Так, худший из записанных результатов достигнут простым линейным классификатором (12% ошибок), а подавляющее большинство лучших результатов получены алгоритмами на основе нейронных сетей. Так, ансамбль из 35 сверточных нейронных сетей в 2012 году сумел получить всего 0.23% ошибок на наборе данных, что является очень хорошим результатом, вполне сравнимым с человеком.\\nКод\\nПростой пример, скачивающий набор данных и запускающий на нем один из классификаторов. Даже с уменьшением набора данных в сто раз и не самым подходящим классификатором точность выше половины угаданных цифр — заметно лучше, чем случайная разметка. С результатом работы данного кода можно ознакомиться на рисунке 2.\\nfrom sklearn.datasets import fetch_openml from numpy import arange import random from sklearn.tree import DecisionTreeClassifier from sklearn import datasets, svm, metrics\\nmnist = fetch_openml(\\'MNIST_784\\') indices = arange(len(mnist.data)) randidx = random.sample(list(indices), 500) mnist.data = mnist.data[randidx] mnist.target = mnist.target[randidx] X = mnist.data Y = mnist.target train = len(X)//2 clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5) clf.fit(X[:train], Y[:train]) expected = Y[train:] predicted = clf.predict(X[train:]) print(\"Classification report for classifier %s:\\\\n%s\\\\n\" % (clf, metrics.classification_report(expected, predicted)))\\ndigit precision recall f1-score support 0 0.68 0.58 0.62 26 1 0.71 0.87 0.78 23 2 0.29 0.24 0.26 25 3 0.64 0.28 0.39 25 4 0.50 0.54 0.52 28 5 0.46 0.46 0.46 24 6 0.47 0.62 0.54 24 7 0.66 0.78 0.71 27 8 0.32 0.60 0.42 15 9 0.59 0.39 0.47 33 avg/total 0.54 0.53 0.52 250\\nCIFAR-10\\nОписание\\nCIFAR-10 (Canadian Institute For Advanced Research) — еще один большой набор изображений, который обычно используется для тестирования алгоритмов машинного обучения. Он содержит 60 000 цветных картинок размером 32х32 пикселя, размеченных в один из десяти классов: самолеты, автомобили, коты, олени, собаки, лягушки, лошади, корабли и грузовики. В наборе данных по 6000 картинок каждого класса, примеры некоторых из них приведены на рисунке 3. CIFAR-10 является размеченным подмножеством заметно большего набора данных, состоящего примерно из восьмидесяти миллионов изображений.\\nРезультаты\\nС момента публикации CIFAR-10 вышло много статей, авторы которых пытаются добиться максимальной точности на этом наборе данных. В среднем более хорошие результаты показывают различные сверточные нейронные сети с различными вариантами настройки и дополнительной предобработки данных.\\nНа википедии[14] можно найти таблицу лучших публикаций с процентами ошибки на этом наборе данных. Так, лучший на сегодняшний момент алгоритм, опубликованный в мае 2018 года, допускает ошибку всего порядка 1.48%.\\nКод\\nПростой код, скачивающий CIFAR-10 из интернета и запускающий на нем стандартный классификатор.\\nfrom keras.datasets import cifar10 from sklearn.utils import shuffle\\n(x_train, y_train), (x_test, y_test) = cifar10.load_data() X, Y = shuffle(x_train, y_train) n = 1000 X, Y = X[:n], Y[:n] X, Y = X.reshape((n, -1)), Y.reshape((n,)) train = n // 2 clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5) clf.fit(X[:train], Y[:train]) expected = Y[train:] predicted = clf.predict(X[train:]) print(\"Classification report for classifier %s:\\\\n%s\\\\n\" % (clf, metrics.classification_report(expected, predicted)))\\nImageNet\\nОписание\\nБаза данных Imagenet — проект по созданию и сопровождению массивной базы данных аннотированных изображений. Аннотация изображений происходит путем краудсорсинга сообществом. Из-за этого достигается большое количество размеченных данных.\\nОсобенность данного набора данных — про каждую картинку известно несколько фактов вида \"в этом прямоугольнике есть автомобиль\" (см. рис. 4), что в совокупности с индексом по типам объектов, которые есть на изображениях, позволяет обучить алгоритм для распознавания объектов какой-то конкретной категории. На август 2017 года в ImageNet 14 197 122 изображения, разбитых на 21 841 категорию.\\nImagenet Challenge\\nВместе с публикацией набора данных стартовал конкурс ImageNet Large Scale Visual Recognition Challenge (ILSVRC[15]). В его рамках участникам предлагается достигнуть наибольшей точности при классификации набора изображений. Организаторы использовали около тысячи различных категорий объектов, которые нужно классифицировать. На примере этого конкурса хорошо видно, как в 2010-е годы люди научились заметно лучше распознавать образы на изображениях, уже в 2017 году большинство участвующих команд преодолели порог в 95% правильных ответов. История улучшения результатов представлена на рисунке 5. Эта задача, проблема компьютерного зрения, имеет огромное практическое значение во многих прикладных областях.\\nADE20K\\nОписание\\nADE20K — набор изображений с размеченными сущностями, который хорошо подходит для задачи семантической сегментации данных в компьютерном зрении, пример разметки приведен на рисунке 6. Особенность этого набора состоит в том, что кроме объектов приводится также информация об их составных частях: например, если на изображении находится человек, то в дополнение к местоположению его фигуры будет также приведено положение его глаз и носа.\\nПодобные наборы данных часто страдают от несогласованности меток при их разметке сообществом. Для ADE20K эта проблема была решена — все изображения размечал только один человек, что обусловило высокую согласованность меток.\\nСтруктура данных [16]\\nВсего в наборе данных находится 22 210 изображений, из них 20 210 составляют набор для обучения, а 2 000 — набор для проверки. Максимальный размер изображения — 4500x6000p. Минимальный — 130x96p. Средний размер изображений равен 1.5Мп. К каждому изображению прилагается его RGB-оригинал (*.jpg), сегментация на сущности (*_seg.png), несколько изображений с сегментацией на части (*_seg_N.png, где N — это число) и описание признаков на изображении (*.txt).\\nADE20K также содержит дополнительный файл на языке MATLAB, который позволяет загрузить изображения и информацию об их признаках.\\nРезультаты\\nОсновными метриками для этого набора данных являются пиксельная точность (англ. Pixel accuracy), которая состоит из доли корректно классифицированных пикселей, и индекс Жаккара. На момент создания ADE20K, лучшие алгоритмы машинного обучения давали пиксельную точность равную ~76% и индекс Жаккара равный ~0.34 на проверочном множестве[17]. Сейчас лучшей нейронной сетью для этого набора данных является ResNeSt, который позволяет достичь 82.07% пиксельной точности и индекс Жаккара 46.91%.\\nCOCO\\nОписание\\nMS COCO (англ. Common Objects in Context) — большой набор изображений. Состоит из более чем 330000 изображений (220000 — размеченных), с более чем 1.5 милионов объектов на них. Примеры изображений приведены на рисунке 7. Все объекты находятся в их естественном окружении (контексте). Изображения, как правило, содержат объекты разных классов (только 10% имеют единственный класс). Все изображения сопровождаются аннотациями, хранящихся в json формате. Подробнее о структуре аннотаций можно прочитать здесь.\\nCOCO имеет пять типов аннотаций для разных задач:\\n- Задача нахождения объектов на изображении\\n- Обнаружение ключевых точек. Обнаружение объектов и локализация их ключевых точек.\\n- Сегментация окружения (англ. Stuff Segmentation). В отличии от задачи обнаружения объектов (человек, кот, машина), здесь внимание фокусируется на том, что его окружает (трава, стена, небо). Метки классов организованы в иерархическом порядке (напр., stuff → outdoor-stuff → sky → clouds). Чтобы добиться совместимости с задачей обнаружения объектов, используются следующие идентификаторы категорий:\\n|Идентификатор\\n|Соответствие\\n|1-91\\n|категории объектов (не используются в сегментации окружения)\\n|92-182\\n|категории окружения\\n|183\\n|категория \"другое\" (выбирается для \"объектов\")\\n- Паноптическая сегментация (англ. Panoptic Segmentation) — обединение задач семантической сегментации (Сегментация изображений) и обнаружения объектов. Задача состоит в том, чтобы классифицировать все пиксели изображения на принадлежность к некоторому классу, а также определить, к какому из экземпляров данного класса они относятся.\\n- Аннотирование изображения (англ. Caption Evaluation). Генерация сопроводительной подписи к изображению.\\nРезультаты\\nРезультат задачи зависит от многих факторов. Например, для задачи обнаружения объекта, наилучшие результаты алгоритмы показывают на крупных объектах. Более подробно с метриками можно ознакомиться здесь. Приведем лишь результаты детектора ResNet (bbox) - победителя 2015 Detection Challenge. Графики, изображенные на рисунках 8 и 9, представляют из себя семейство кривых Pressision Recall для различных метрик.\\nКод\\nПример использования COCO API на python:\\n%matplotlib inline from pycocotools.coco import COCO import numpy as np import skimage.io as io import matplotlib.pyplot as plt import pylab pylab.rcParams[\\'figure.figsize\\'] = (8.0, 10.0) dataDir=\\'..\\' dataType=\\'val2017\\' annFile=\\'{}/annotations/instances_{}.json\\'.format(dataDir,dataType) coco=COCO(annFile) cats = coco.loadCats(coco.getCatIds()) nms=[cat[\\'name\\'] for cat in cats] print(\\'COCO categories: \\\\n{}\\\\n\\'.format(\\' \\'.join(nms))) nms = set([cat[\\'supercategory\\'] for cat in cats]) print(\\'COCO supercategories: \\\\n{}\\'.format(\\' \\'.join(nms))) # get all images containing given categories, select one at random catIds = coco.getCatIds(catNms=[\\'person\\',\\'dog\\',\\'skateboard\\']); imgIds = coco.getImgIds(catIds=catIds ); imgIds = coco.getImgIds(imgIds = [324158]) img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0] # load and display image # I = io.imread(\\'%s/images/%s/%s\\'%(dataDir,dataType,img[\\'file_name\\'])) # use url to load image I = io.imread(img[\\'coco_url\\']) plt.axis(\\'off\\') plt.imshow(I) plt.show()\\n# load and display instance annotations plt.imshow(I); plt.axis(\\'off\\') annIds = coco.getAnnIds(imgIds=img[\\'id\\'], catIds=catIds, iscrowd=None) anns = coco.loadAnns(annIds) coco.showAnns(anns)\\nFashion-MNIST\\nОписание\\nFashion-MNIST — это набор изображений, взятых из статей Zalando, состоящий из обучающего набора из 60000 примеров и тестового набора из 10000 примеров. Каждый пример представляет собой черно-белое изображение 28x28 (см. рис. 12), связанное с меткой из 10 классов. Создатели Fashion-MNIST предложили его в качестве прямой замены исходного набора данных MNIST, состоящего из рукописных цифр, для сравнительного анализа алгоритмов машинного обучения. Он имеет одинаковый размер изображения и структуру разделений для обучения и тестирования. Аргументировали необходимость такой замены тем, что исходный набор данных MNIST действительно хорошо отражает возможность алгоритма хоть что-то классифицировать, но если алгоритм работает на стандартном MNIST, он все равно может не сработать на других примерах данных. Также на наборе данных MNIST научились достигать слишком высоких результатов точности (97% для классических алгоритмов машинного обучения и 99.7% для сверточных нейронных сетей), в то время как MNIST не отражает современных сложных проблем компьютерного зрения. Это позволило сделать предположение о том, что набор данных MNIST слишком простой по современным меркам и его требуется заменить.\\nРезультаты\\nНа сайте[18] набора данных можно найти список лучших результатов, достигнутых алгоритмами на этом наборе данных. Так как задача классификации набора данных Fashion-MNIST сложнее, чем в случае стандартного набора MNIST, в таблице представлены только алгоритмы глубокого обучения, т.к. только для них эта задача имеет смысл. Так, худший из записанных результатов достигнут сверточной нейронной сетью с 3 сверточными слоями и одним слоем пулинга (12.4% ошибок), а подавляющее большинство лучших результатов получены боле сложными архитектурами. Лучший результат был достигнут WRN сетью и составляет всего 3.3% ошибки.\\nКод\\nПростой код, скачивающий Fashion-MNIST с использованием NumPy и запускающий на нем стандартный классификатор.\\nimport mnist_reader from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier from sklearn.utils import shuffle x_train, y_train = mnist_reader.load_mnist(\\'data/fashion\\', kind=\\'train\\') x_test, y_test = mnist_reader.load_mnist(\\'data/fashion\\', kind=\\'t10k\\') X, Y = shuffle(x_train, y_train) n = 1000 X, Y = X[:n], Y[:n] X, Y = X.reshape((n, -1)), Y.reshape((n,)) train = n // 2 clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5) clf.fit(X[:train], Y[:train]) expected = Y[train:] predicted = clf.predict(X[train:]) print(\"Classification report for classifier %s:\\\\n%s\\\\n\" % (clf, metrics.classification_report(expected, predicted)))\\nBoston Housing\\nОписание\\nBoston Housing содержит данные, собранные Службой переписи населения США (англ. U.S Census Service), касающиеся недвижимости в районах Бостона. Набор данных состоит из 13 признаков и 506 строк и также предоставляет такую информацию, как уровень преступности (CRIM), ставка налога на недвижимость (TAX), возраст людей, которым принадлежит дом (AGE), соотношение числа учащихся и преподавателей в районе (PTRATIO) и другие. Данный набор данных используется для предсказания следующих целевых переменных: средняя стоимость дома (MEDV) и уровень закиси азота (NOX).\\nРезультаты\\nДля решения задачи предсказания средней стоимости дома используется множественная линейная регрессия. Метрикой качества модели выступает корень из среднеквадратичной ошибки (англ. root-mean-square error, RMSE ). В среднем, значение RMSE на данном наборе данных находится в районе 3,5-5 в зависимости от выбранной модели. Однако на соревновании на сайте Kaggle пользователь MayankSatnalika получил результат 1.33055.\\nКод\\nПростой код, загружающий набор данных из библиотеки sklearn с использованием NumPy и Pandas и запускающий на нем алгоритм линейной регрессии.\\nimport pandas as pd import numpy as np from sklearn.datasets import load_boston from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error boston_dataset = load_boston() boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names) boston[\\'MEDV\\'] = boston_dataset.target X = pd.DataFrame(np.c_[boston[\\'LSTAT\\'], boston[\\'RM\\']], columns=[\\'LSTAT\\', \\'RM\\']) Y = boston[\\'MEDV\\'] X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5) lin_model = LinearRegression() lin_model.fit(X_train, Y_train) y_train_predict = lin_model.predict(X_train) rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))# 5.6371293350711955 y_test_predict = lin_model.predict(X_test) rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))# 5.13740078470291\\nCaltech-UCSD Birds 200 (CUB)\\nОписание\\nCaltech-UCSD Birds 200 — это набор данных, содержащий изображения птиц. Данный набор включает в себя фотографии 200 видов птиц. Большинство видов птиц, представленных в наборе данных, являются североамериканскими. Общее количество категорий птиц составляет 200. В набор данных 2010 года включены 6033 изображения, а в набор данных 2011 года — 11 788 изображений, некоторые из них приведены на рисунке 13.\\nПоиск и аннотация изображений\\nИзображения для набора данных были получены с сайта Flickr и отфильтрованы с помощью Amazon Mechanical Turk. Каждое изображение аннотировано границей области, содержащей птицу, грубой сегментацией птиц, набором меток атрибутов и текстовым описанием. Примеры аннотированных изображений представлены на рисунке 14.\\n102 Category Flower\\nОписание\\nOxford Flowers 102 — набор данных, состоящий из цветов, встречающихся в Соединенном Королевстве. Набор стоит состоит из 102 видов цветов и содержит от 40 до 258 изображений каждого вида. Примеры изображений из данного датасета приведены на рисунке 15. Цветы представлены в различных ракурсах и вариациях освещения. Кроме того, в наборе присутствуют виды цветов тяжело отличимые друг от друга. Графы соседства цветков по различным признакам представлены на рисунках 16 и 17.\\nНабор данных делится на обучающий набор, проверочный набор и тестовый наборы. Каждый обучающий и проверочный наборы состоят из 10 изображений на класс (всего 1020 изображений). Тестовый набор состоит из оставшихся 6149 изображений (минимум 20 изображений на класс).\\nVisual Genome\\nОписание\\nVisual Genome — это набор данных, связывающий изображения со словесным описанием их содержимого. Является исчерпывающим набором данных для обучения и тестирования моделей компьютерного зрения, обеспечивает обширный анализ изображений с учетом зависимостей между объектами. Это позволяет использовать набор данных для решения большого количества различных задач: поиск объектов, поиск отношений, требующих дальнейшего вывода, задачи, связанные с ответами на вопросы.\\nИзображение часто представляет сложную картину, которую невозможно полностью раскрыть одним предложением. Существующие наборы данных, такие как Flickr 30K, ориентированы на высокоточное описание всего изображения в целом. Вместо этого для каждого изображения в Visual Genome собираются более 50 описаний для разных регионов изображения, обеспечивая тем самым намного более полный набор описаний.\\nНабор данных содержит более 108К изображений, каждое из которых имеет в среднем 35 объектов, 26 атрибутов и 21 парное отношение между объектами. В данном наборе данных происходит преобразование объектов, атрибутов, отношений и словосочетаний в описаниях регионов и пар вопрос-ответ в синсеты из WordNet. Cинсет — это набор данных, элементы в котором считаются семантически эквивалентными для поиска или восстановления информации. Visual Genome является самым большим набором данных с описаниями изображений, объектов, атрибутов, отношений и пар вопрос-ответ.\\nКод\\nПример использования Visual Genome API на python:\\nimport matplotlib.pyplot as plt from matplotlib.patches import Rectangle from src import api as vg from PIL import Image as PIL_Image import requests %matplotlib inline from StringIO import StringIO ids = vg.GetImageIdsInRange(startIndex=0, endIndex=1) image_id = ids[0] image = vg.GetImageData(id=image_id) regions = vg.GetRegionDescriptionsOfImage(id=image_id) fig = plt.gcf() fig.set_size_inches(18.5, 10.5) def visualize_regions(image, regions): response = requests.get(image.url) img = PIL_Image.open(StringIO(response.content)) plt.imshow(img) ax = plt.gca() for region in regions: ax.add_patch(Rectangle((region.x, region.y), region.width, region.height, fill=False, edgecolor=\\'red\\', linewidth=3)) ax.text(region.x, region.y, region.phrase, style=\\'italic\\', bbox={\\'facecolor\\':\\'white\\', \\'alpha\\':0.7, \\'pad\\':10}) fig = plt.gcf() plt.tick_params(labelbottom=\\'off\\', labelleft=\\'off\\') plt.show() visualize_regions(image, regions[:8])\\nРезультат работы кода представлен на рисунке 18.\\nCelebA\\nОписание\\nCelebA (англ. CelebFaces Attributes Dataset) — это крупномасштабный набор данных атрибутов лиц, содержащий более 200 тысяч изображений знаменитостей (см. рис. 19). Изображения в этом наборе данных охватывают лица людей с разных ракурсов. Более подробная характеристика датасета: 10 177 уникальных личностей, 202 599 изображений лиц и 5 ориентиров, 40 бинарных аннотаций атрибутов на изображение. Эти данные были первоначально собраны исследователями из MMLAB[19], Китайского университета Гонконга.\\nНабор данных можно использовать в качестве обучающих и тестовых наборов для следующих задач компьютерного зрения: распознавание атрибутов лица, обнаружение лиц и локализация ориентиров (или части лица).\\nПример атрибутов\\nНиже приведен список бинарных атрибутов в CelebA, где отдельный атрибут — одна из характеристик лица. Более подробно со всеми атрибутами можно ознакомиться здесь\\n|Индекс атрибута\\n|Наименование\\n|Пояснение\\n|1\\n|5oClockShadow\\n|щетина, появшившаяся в течение дня\\n|2\\n|ArchedEyebrows\\n|изогнутые брови\\n|3\\n|Attractive\\n|привлекательный/ая\\n|4\\n|BagsUnderEyes\\n|мешки под глазами\\n|5\\n|Bald\\n|лысый\\n|6\\n|Bangs\\n|челка\\n|7\\n|BigLips\\n|большие губы\\n|8\\n|BigNose\\n|большой нос\\n|9\\n|BlackHair\\n|темные волосы\\n|10\\n|BlondHair\\n|блондинистые волосы\\n|11\\n|Blurry\\n|размытый\\n|12\\n|BrownHair\\n|русые волосы\\n|13\\n|BushyEyebrows\\n|густые брови\\n|14\\n|Chubby\\n|полный\\n|15\\n|DoubleChin\\n|второй подбородок\\n|16\\n|Eyeglasses\\n|очки\\n|17\\n|Goatee\\n|козлиная бородка/эспаньолка\\n|18\\n|GrayHair\\n|седые волосы\\n|19\\n|HeavyMakeup\\n|много макияжа\\n|20\\n|HighCheekBones\\n|высокие скулы\\n|21\\n|Male\\n|мужчина\\n|22\\n|MouthSlighltyOpen\\n|слегка приоткрытый рот\\n|23\\n|Mustache\\n|усы\\n|24\\n|NarrowEyes\\n|узкий разрез глаз\\n|25\\n|NoBeard\\n|отсутствет борода\\n|26\\n|OvalFace\\n|овальное лицо\\n|27\\n|PaleSkin\\n|бледная кожа\\n|28\\n|PointyNose\\n|заостренный нос\\n|29\\n|RecedingHairline\\n|залысина\\n|30\\n|RosyCheeks\\n|розовые щеки\\n|31\\n|Sideburns\\n|бакенбарды\\n|32\\n|Smiling\\n|улыбка\\n|33\\n|StraightHair\\n|прямые волосы\\n|34\\n|WavyHair\\n|волнистые волосы\\n|35\\n|WearingEarrings\\n|присутствует серьга/серьги\\n|36\\n|WearingHat\\n|присутствует шляпа\\n|37\\n|WearingLipstick\\n|накрашены губы\\n|38\\n|WearingNecklace\\n|присутствует ожерелье\\n|39\\n|WearingNecktie\\n|присутствует галстук\\n|40\\n|Young\\n|молодой/ая\\nCityScapes\\nОписание\\nCityScapes[20] — это набор данных, состоящий из разнообразных городских уличных сцен в 50 разных городах в разное время года. Данный набор хорошо подходит для задач компьютерного зрения, таких как: семантическая сегментация данных, сегментация на уровне экземпляра и вывод несоответствия стереопар. Пример изображения из данного датасета представлен на рисунке 20.\\nСтруктура данных [21]\\nВсего в наборе данных находится 25 000 изображений, из них 5000 составляют набор с более детальными аннотациями изображений с разрешением 1024 * 2048, предварительно разделенных на наборы для обучения — 2975, проверки — 500 и тестирования — 1525. Оставшиеся 20 000 изображений имеют грубые аннотации, позволяющие применять методы, использующие большие объемы данных со слабой маркировкой.\\nРезультаты\\nОсновной метрикой для этого набора данных является индекс Жаккара. Также, хорошо известно, что глобальная мера Ыеиндекса Жаккара смещена в сторону экземпляров объектов, которые покрывают большую область изображения. В уличных сценах с их сильным изменением масштаба это может быть проблематично. Чтобы решить эту проблему, создатели датасета дополнительно оценивают семантическую маркировку, используя метрику пересечения по объединению на уровне экземпляра , где , и обозначают количество истинно положительных, ложноположительных и ложно отрицательных пикселей соответственно. Сейчас лучшей нейронной сетью для этого набора данных в задаче семантической сегментации данных является DAHUA-ARI, которая позволяет достичь индекс Жаккара 85.8% и iIoU 70.6% для классов, индекс Жаккара 93.2% и iIoU 85.4% для категорий, соответственно.\\nICDAR\\nОписание\\nICDAR[22] (англ. International Conference on Document Analysis and Recognition) — это международная конференция по анализу и распознаванию текста и одноименное семейство набора данных, состоящее из фотографий (см. рис. 21, 22 и 23), на которых изображен текст на разных языках. Данные наборы создаются для соревнований RRC (англ. Robust Reading Competition), где требуется решить следующие задачи: обнаружение текста, сегментация текста, распознавание символов, сквозное распознавание, распознавание скриптов, ответы на вопросы, связанные с изображениями. Ниже приведен анализ наборов данных ICDAR2013, ICDAR2015, ICDAR2017, ICDAR2019.\\nICDAR 2013\\nICDAR 2013 \"Born Digital Images\" — датасет, который содержит изображения, извлеченные с веб-страниц и сообщений электронной почты. Текст на изображениях на английском языке. Датасет предназначен для следующих задач оптического распознавани символов: обнаружение текста, сегментация текста, распознавание символов.\\nICDAR 2013 \"Focused Scene Text\" — датасет c изображениями с текстом на вывесках, логотипах и так далее. Текст на изображениях на английском языке. Датасет предназначен для следующих задач оптического распознавани символов: обнаружение текста, сегментация текста, распознавание символов.\\n|Наименование датасета\\n|Количество объектов\\n|Количество обучающих объектов\\n|Количество тестовых объектов\\n|Количество слов\\n|Количество обучающих слов\\n|Количество тестовых слов\\n|ICDAR 2013 \"Born Digital Images\"\\n|561\\n|420\\n|141\\n|5003\\n|3564\\n|1439\\n|ICDAR 2013 \"Focused Scene Text\"\\n|462\\n|229\\n|233\\n|1943\\n|848\\n|1095\\nICDAR 2015\\nICDAR 2015 \"Born Digital Images\" — датасет, который содержит изображения, извлеченные с веб-страниц и сообщений электронной почты. Текст на изображениях на английском языке. Датасет предназначен для следующих задач оптического распознавани символов: обнаружение текста, сегментация текста, распознавание символов, сквозное распознавание .\\nICDAR 2013 \"Focused Scene Text\" — датасет c изображениями с текстом на вывесках, логотипах и так далее. Текст на изображениях на английском языке. Датасет предназначен для следующих задач оптического распознавани символов: обнаружение текста, сегментация текста, распознавание символов , сквозное распознавание.\\nICDAR 2015 \"Incidental Scene Text\" — датасет c изображениями, на которых текст попал в поле зрения камеры Google Glass случайно[23]. Текст на изображениях на английском языке. Датасет предназначен для следующих задач оптического распознавани символов: обнаружение текста, сегментация текста, распознавание символов , сквозное распознавание.\\n|Наименование датасета\\n|Количество объектов\\n|Количество обучающих объектов\\n|Количество тестовых объектов\\n|Количество слов\\n|Количество обучающих слов\\n|Количество тестовых слов\\n|ICDAR 2015 \"Born Digital Images\"\\n|561\\n|420\\n|141\\n|5003\\n|3564\\n|1439\\n|ICDAR 2015 \"Focused Scene Text\"\\n|462\\n|229\\n|233\\n|1943\\n|848\\n|1095\\n|ICDAR 2015 \"Incidental Scene Text\"\\n|1670 (1500 публичных)\\n|1000\\n|500\\n|17548\\n|-\\n|-\\nICDAR 2017\\nICDAR 2017 \"COCO-Text\" — набор данных, основанный на датасете \"MS COCO\"[24], где собраны обычные изображения ежедневных сцен, на которых, возможно, есть текст. Текст на изображениях на английском, немецком, французском и других языках. Датасет предназначен для следующих задач оптического распознавани символов: обнаружение текста, распознавание символов , сквозное распознавание.\\nICDAR 2017 \"Multi-lingual Scene Text\" — набор данных, где собраны изображения с текстом на 9 языках. Текст на изображениях на арабском, английском, немецком, бенгальском, китайском, японском, французском, корейском языках. Датасет предназначен для следующих задач оптического распознавани символов: обнаружение текста, сегментация текста.\\nICDAR 2017 \"French Street Name Signs\" — набор данных с изображениями, на которых есть названия французских улиц. Текст на изображениях на французском языке. Датасет предназначен для следующих задач оптического распознавани символов: сквозное распознавание.\\n|Наименование датасета\\n|Количество объектов\\n|Количество обучающих объектов\\n|Количество тестовых объектов\\n|Количество слов\\n|Количество обучающих слов\\n|Количество тестовых слов\\n|ICDAR 2017 \"COCO-Text\"\\n|63686\\n|43686\\n|10000 — валидирующая выборка, 10000 — тестовая\\n|173589\\n|-\\n|-\\n|ICDAR 2017 \"Multi-lingual Scene Text\"\\n|18 000\\n|-\\n|-\\n|107 547(тренировочные + валидирующие слова)\\n|-\\n|-\\n|ICDAR 2017 \"French Street Name Signs\"\\n|1 081 422, где каждое изображение содержит до 4 объектов с названией улицы\\n|-\\n|-\\n|-\\n|-\\n|-\\nICDAR 2019\\nICDAR 2019 \"COCO-Text\" — набор данных, основанный на датасете \"MS COCO\"[25], где собраны обычные изображения ежедневных сцен, на которых, возможно, есть текст. Текст на изображениях на английском, немецком, французском и других языках. Датасет предназначен для следующих задач оптического распознавани символов: сквозное распознавание.\\nICDAR 2019 \"Multi-lingual Scene Text\" — набор данных, где собраны изображения с текстом на 10 языках. Текст на изображениях на арабском, английском, деванагари, немецком, бенгальском, китайском, японском, французском, корейском языках. Датасет предназначен для следующих задач оптического распознавани символов: обнаружение текста, идентификация скрипта, сквозное распознавание.\\nICDAR 2019 \"Scene Text Visual Question Answering\" — набор данных, включающий 23 038 изображений с 31 791 парой вопросов и ответов, где ответ всегда основан на присутствующих текстовых экземплярах на изображении. Текст на изображениях на янглийском языке. Датасет предназначен для следующих задач оптического распознавани символов: ответ на вопрос, связанный с изображением.\\n|Наименование датасета\\n|Количество объектов\\n|Количество обучающих объектов\\n|Количество тестовых объектов\\n|Количество слов\\n|Количество обучающих слов\\n|Количество тестовых слов\\n|ICDAR 2019 \"COCO-Text\"\\n|63686\\n|43686\\n|10000 — валидирующая выборка, 10000 — тестовая\\n|173589\\n|-\\n|-\\n|ICDAR 2019 \"Multi-lingual Scene Text\"[26]\\n|20 000 (2 000 для каждого языка) + 277 000 сгенерированных изображения\\n|10 000\\n|10 000\\n|-\\n|-\\n|-\\n|ICDAR 2019 \"Scene Text Visual Question Answering\"\\n|23 038\\n|-\\n|-\\n|-\\n|-\\n|-\\n|-\\nPointing\\'04\\nОписание\\nPointing\\'04 [27] — база данных изображений лиц в разных положениях для 15-ти человек. Для каждого человека представлено 93 положения головы, при этом каждая фотография предложена в двух вариантах освещения и масштаба (две разные сессии). Снимки, сделанные во время первого сеанса, используются в качестве обучающих данных, а изображения из второго сеанса используются в качестве данных тестирования. 93 положения включают комбинации 13-и вариантов поворота и 7-и вариантов наклона вместе с двумя крайними случаями наклона при отсутствии поворота.\\nПример сета изображений\\nFASSEG\\nОписание\\nРепозиторий FASSEG [28] (англ. FAce Semantic SEGmentation ) состоит из двух наборов данных (Frontal01 и Frontal02) для сегментации лиц в фронтальном положении и одного набора данных (Multipose01) с лицами в нескольких определенных положениях.\\nFrontal01 содержит 70 сегментированных изображений лиц и исходные изображения RGB. Исходные лица в основном взяты из наборов данных MIT-CBCL и FEI.\\nFrontal02 — это «высокоточный» Frontal01. Он содержит те же изображения, что и Frontal01, но с гораздо более точной сегментацией.\\nMultipose01 содержит более 200 размеченных лиц в 13-ти положениях с углом поворота от -90 градусов до 90 градусов включительно. Исходные лица взяты из базы данных Pointing\\'04.\\nСегментация\\nИзображение размечается на 6 сегментов (см. рис. 30):\\n- глаза;\\n- нос;\\n- рот;\\n- волосы (вместе с бровями);\\n- фон изображения;\\n- кожа.\\nПримеры изображений\\nMPI\\nОписание\\nMPI Human Pose [29] (англ. Max Planck Institute) — это набор данных, позволяющий определять различные виды активности человека по позам на изображениях и аннотациям к ним. Набор данных включает около 25 тысяч изображений, содержащих более 40 тысяч людей с указанным положением отдельных частей тела. Изображения систематически собирались с использованием установленной таксономии повседневной деятельности человека. В целом набор данных охватывает 410 видов деятельности человека, каждое изображение снабжено меткой активности. Каждое изображение было извлечено из видео с YouTube и снабжено предшествующими и последующими кадрами без аннотации. Кроме того, для тестового набора приложены более детальные аннотации, включая сгибы частей тела и ориентации туловища и головы.\\nСтруктура датасета и примеры изображений\\nДатасет представлен двадцатью различными классами активности: езда на велосипеде, упражнения, танцы, рыбалка и охота, домашняя активность, ремонт, отдых, активность на природе, игра на музыкальных инструментах, религиозная деятельность, бег, самоуход, спорт, передвижение на транспорте, волонтерство, прогулки, активность на воде, зимние виды активности, разное.\\nКаждый класс также разделен на уникальные подклассы. Пример такого разделения приведен на рисунке 33.\\nДатасет снабжен документацией с описанием структуры объектов и методами взаимодействия с ними, всю необходимую информацию по датасету, как и сами исходники, можно получить по ссылке.\\nСм.также\\n- Общие понятия\\n- Сегментация изображений\\n- Задача нахождения объектов на изображении\\n- Оценка качества в задачах классификации и регрессии\\nПримечания\\n- ↑ https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research[1]\\n- ↑ https://arxiv.org/pdf/1805.01890.pdf[2]\\n- ↑ https://arxiv.org/pdf/1805.09501.pdf[3]\\n- ↑ https://arxiv.org/pdf/2004.08955v1.pdf\\n- ↑ http://cocodataset.org/#detection-leaderboard[4]\\n- ↑ https://github.com/zalandoresearch/fashion-mnist[5]\\n- ↑ https://arxiv.org/pdf/1602.07332.pdf [6]\\n- ↑ https://vision.cornell.edu/se3/wp-content/uploads/2019/01/ICDAR2017b.pdf\\n- ↑ https://www.researchgate.net/publication/221125207_Generalized_subspace_based_high_dimensional_density_estimation\\n- ↑ https://github.com/massimomauro/FASSEG-repository/blob/master/papers/multiclass_face_segmentation_ICIP2015.pdf\\n- ↑ https://github.com/massimomauro/FASSEG-repository/blob/master/papers/pose_estimation_by_segmentation_ICME2017.pdf\\n- ↑ http://human-pose.mpi-inf.mpg.de/#results\\n- ↑ http://yann.lecun.com/exdb/mnist/[7]\\n- ↑ https://en.wikipedia.org/wiki/CIFAR-10#Research_Papers_Claiming_State-of-the-Art_Results_on_CIFAR-10[8]\\n- ↑ http://www.image-net.org/challenges/LSVRC/[9]\\n- ↑ https://groups.csail.mit.edu/vision/datasets/ADE20K/#Description\\n- ↑ https://arxiv.org/pdf/1608.05442.pdf\\n- ↑ https://github.com/zalandoresearch/fashion-mnist\\n- ↑ http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html[10]\\n- ↑ https://www.cityscapes-dataset.com/\\n- ↑ https://www.cityscapes-dataset.com/dataset-overview/#features\\n- ↑ https://rrc.cvc.uab.es/\\n- ↑ https://rrc.cvc.uab.es/?ch=4\\n- ↑ https://vision.cornell.edu/se3/wp-content/uploads/2019/01/ICDAR2017b.pdf\\n- ↑ https://vision.cornell.edu/se3/wp-content/uploads/2019/01/ICDAR2017b.pdf\\n- ↑ https://arxiv.org/pdf/1907.00945.pdf\\n- ↑ http://crowley-coutaz.fr/FGnet/reports/Pointing04-Proceedings.pdf\\n- ↑ http://massimomauro.github.io/FASSEG-repository/\\n- ↑ http://human-pose.mpi-inf.mpg.de/', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='1c3a1be7-971f-420d-a3ed-f4b25b86d5d1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b90802e49e8ce1b47e651f59553635e50963064ba9fcc47e6eb030152f4160d7', text='Метод главных компонент (PCA)\\nМетод главных компонент (англ. Principal Components Analysis, PCA) — один из основных способов уменьшить размерность данных, потеряв наименьшее количество информации. Изобретен К. Пирсоном (англ. Karl Pearson) [1] в 1901 г. Применяется во многих областях, таких как распознавание образов, компьютерное зрение, сжатие данных и т.п. Вычисление главных компонент сводится к вычислению собственных векторов и собственных значений ковариационной матрицы исходных данных или к сингулярному разложению матрицы данных. Иногда метод главных компонент называют преобразованием Карунена-Лоэва (англ. Karhunen-Loeve) [2] или преобразованием Хотеллинга (англ. Hotelling transform).\\nСодержание\\n- 1 Формальная постановка задачи\\n- 2 Решение\\n- 3 Свойства\\n- 4 Визуализация многомерных данных\\n- 5 Пределы применимости и ограничения эффективности метода\\n- 6 Примеры кода\\n- 7 См. также\\n- 8 Примечания\\n- 9 Источники информации\\nФормальная постановка задачи\\nПусть имеется $n$ числовых признаков $f_j(x), j = 1, ... , n$. Объекты обучающей выборки будем отождествлять с их признаковыми описаниями: $x_i \\\\equiv (f_1(x_i), ..., f_n(x_i)), i = 1, ..., l$. Рассмотрим матрицу $F$, строки которой соответствуют признаковым описаниям обучающих объектов: $$F_{l \\\\times n} = \\\\begin{pmatrix} f_1(x_1) & ... & f_n(x_1)\\\\\\\\ ... & ... & ...\\\\\\\\ f_1(x_l) & ... & f_n(x_l) \\\\end{pmatrix} = \\\\begin{pmatrix} x_1\\\\\\\\ ...\\\\\\\\ x_l \\\\end{pmatrix}.$$\\nОбозначим через $z_i = (g_1(x_i), ..., g_m(x_i))$ признаковые описания тех же объектов в новом пространстве $Z = \\\\mathbb{R}^{m}$ меньшей размерности, $m < n$:\\n$$G_{l \\\\times m} = \\\\begin{pmatrix} g_1(x_1) & ... & g_m(x_1)\\\\\\\\ ... & ... & ...\\\\\\\\ g_1(x_l) & ... & g_m(x_l) \\\\end{pmatrix} = \\\\begin{pmatrix} z_1\\\\\\\\ ...\\\\\\\\ z_l \\\\end{pmatrix}.$$\\nПотребуем, чтобы исходные признаковые описания можно было восстановить по новым описаниям с помощью некоторого линейного преобразования, определяемого матрицей $U = (u_{js})_{n \\\\times m}$:\\n$$\\\\hat{f}_j(x) = \\\\sum_{s = 1}^{m} g_s(x)u_{js}, \\\\; j = 1, ..., n, \\\\; x \\\\in X,$$\\nили в векторной записи: $\\\\hat{x} = z U^T$. Восстановленное описание $\\\\hat{x}$ не обязано в точности совпадать с исходным описанием $x$, но их отличие на объектах обучающей выборки должно быть как можно меньше при выбранной размерности $m$. Будем искать одновременно и матрицу новых признаковых описаний $G$, и матрицу линейного преобразования $U$, при которых суммарная невязка $\\\\Delta^2(G, U)$ восстановленных описаний минимальна:\\n$$\\\\Delta^2(G, U) = \\\\sum_{i = 1}^{l} \\\\| \\\\hat{x}_i - x_i \\\\|^2 = \\\\sum_{i = 1}^{l} \\\\| z_i U^T - x_i \\\\|^2 = \\\\| GU^T - F \\\\|^2 \\\\to \\\\mathop{min}_{G, U},$$\\nгде все нормы евклидовы.\\nБудем предполагать, что матрицы $G$ и $U$ невырождены: $rank \\\\, G = rank \\\\, U = m$. Иначе существовало бы представление $\\\\bar{G} \\\\bar{U}^T = G U^T$ с числом столбцов в матрице $\\\\bar{G}$, меньшим $m$. Поэтому интересны лишь случаи, когда $m \\\\leq rank \\\\, F$.\\nРешение\\nИсчерпывающее решение сформулированной задачи даёт следующая теорема.\\n|Теорема:\\nЕсли, то минимум достигается, когда столбцы матрицы есть собственные векторы , соответствующие максимальным собственным значениям. При этом , матрицы и ортогональны.\\n|Доказательство:\\n|\\nЗапишем необходимые условия минимума:\\nПоскольку искомые матрицы $G$ и $U$ невырождены, отсюда следует:\\nФункционал $\\\\Delta^2(G, U)$ зависит только от произведения матриц $G U^T$, поэтому решение задачи $\\\\Delta^2(G, U) \\\\to \\\\mathop{min}_{G, U}$ определено с точностью до произвольного невырожденного преобразования $R: G U^T = (G R) (R^{-1} U^T)$. Распорядимся свободой выбора $R$ так, чтобы матрицы $U^T U$ и $G^T G$ оказались диагональными. Покажем, что это всегда возможно.\\nПусть $\\\\tilde{G} \\\\tilde{U}^T$ — произвольное решение задачи.\\nМатрица $\\\\tilde{U}^T \\\\tilde{U}$ симметричная, невырожденная, положительно определенная, поэтому существует невырожденная матрица $S_{m \\\\times m}$ такая, что $S^{-1} \\\\tilde{U}^T \\\\tilde{U} (S^{-1})^T = I_m$.\\nМатрица $S^T \\\\tilde{G}^T \\\\tilde{G} S$ симметричная и невырожденная, поэтому существует ортогональная матрица $T_{m \\\\times m}$ такая, что $T^T (S^T \\\\tilde{G}^T \\\\tilde{G} S) T = diag(\\\\lambda_1, ..., \\\\lambda_m) \\\\equiv \\\\Lambda$ — диагональная матрица. По определению ортогональности $T^T T = I_m$.\\nПреобразование $R = S T$ невырождено. Положим $G = \\\\tilde{G} R$, $U^T = R^{-1} \\\\tilde{U}^T$. Тогда\\nВ силу $G U^T = \\\\tilde{G} \\\\tilde{U}^T$ матрицы $G$ и $U$ являются решением задачи $\\\\Delta^2(G, U) \\\\to \\\\mathop{min}_{G, U}$ и удовлетворяют необходимому условию минимума. Подставим матрицы $G$ и $U$ в\\nБлагодаря диагональности $G^T G$ и $U^T U$ соотношения существенно упростятся:\\nПодставим первое соотношение во второе, получим $U \\\\Lambda = F^T F U$. Это означает, что столбцы матрицы $U$ обязаны быть собственными векторами матрицы $F^T F$, а диагональные элементы $\\\\lambda_1, ..., \\\\lambda_m$ - соответствующими им собственными значениями.\\nАналогично, подставив второе соотношение в первое, получим $G \\\\Lambda = F F^T G$, то есть столбцы матрицы $G$ являются собственными векторами $F F^T$, соответствующими тем же самым собственным значениям.\\nПодставляя $G$ и $U$ в функционал $\\\\Delta^2(G, U)$, находим:\\n= = = = = = =\\nгде $\\\\lambda_1 , ..., \\\\lambda_n$ - все собственные значения матрицы $F^T F$. Минимум $\\\\Delta^2$ достигается, когда $\\\\lambda_1, ..., \\\\lambda_m$ — наибольшие $m$ из $n$ собственных значений.Собственные векторы $u_1, ..., u_m$, отвечающие максимальным собственным значениям, называют главными компонентами.\\nСвойства\\nСвязь с сингулярным разложением\\nЕсли $m = n$, то $\\\\Delta^2(G, U) = 0$. В этом случае представление $F = G U^T$ является точным и совпадает с сингулярным разложением: $F = G U^T = V D U^T$, если положить $G = V D$ и $\\\\Lambda = D^2$. При этом матрица $V$ ортогональна: $V^T V = I_m$.\\nЕсли $m < n$, то представление $F \\\\approx G U^T$ является приближённым. Сингулярное разложение матрицы $G U^T$ получается из сингулярного разложения матрицы $F$ путём отбрасывания (обнуления) $n - m$ минимальных собственных значений.\\nПреобразование Карунена–Лоэва\\nДиагональность матрицы $G^T G = \\\\Lambda$ означает, что новые признаки $g_1, ..., g_m$ не коррелируют на объектах из обучающей выборки. Ортогональное преобразование $U$ называют декоррелирующим или преобразованием Карунена–Лоэва. Если $m = n$, то о прямое и обратное преобразование вычисляются с помощью одной и той же матрицы $U: F = G U^T$ и $G = F U$.\\nЭффективная размерность\\nГлавные компоненты содержат основную информацию о матрице $F$. Число главных компонент $m$ называют также эффективной размерностью задачи. На практике её определяют следующим образом. Все собственные значения матрицы $F^T F$ упорядочиваются по убыванию: $\\\\lambda_1 \\\\geq ... \\\\geq \\\\lambda_n \\\\geq 0$. Задаётся пороговое значение $\\\\epsilon \\\\in [0, 1]$, достаточно близкое к нулю, и определяется наименьшее целое $m$, при котором относительная погрешность приближения матрицы $F$ не превышает $\\\\epsilon$:\\n$$E(m) = \\\\frac{\\\\| G U^T - F \\\\|^2}{\\\\| F \\\\|^2} = \\\\frac{\\\\lambda_{m + 1} + ... + \\\\lambda_n}{\\\\lambda_1 + ... + \\\\lambda_n} \\\\leq \\\\epsilon .$$\\nВеличина $E(m)$ показывает, какая доля информации теряется при замене исходных признаковых описаний длины $n$ на более короткие описания длины $m$. Метод главных компонент особенно эффективен в тех случаях, когда $E(m)$ оказывается малым уже при малых значениях $m$. Если задать число $\\\\epsilon$ из априорных соображений не представляется возможным, прибегают к критерию «крутого обрыва». На графике $E(m)$ отмечается то значение $m$, при котором происходит резкий скачок: $E(m - 1) \\\\gg E(m)$, при условии, что $E(m)$ уже достаточно мало.\\nВизуализация многомерных данных\\nМетод главных компонент часто используется для представления многомерной выборки данных на двумерном графике. Для этого полагают $m = 2$ и полученные пары значений $(g_1(x_i), g_2(x_i)), i = 1, ..., l$, наносят как точки на график. Проекция на главные компоненты является наименее искаженной из всех линейных проекций многомерной выборки на какую-либо пару осей. Как правило, в осях главных компонент удаётся увидеть наиболее существенные особенности исходных данных, даже несмотря на неизбежные искажения. В частности, можно судить о наличии кластерных структур и выбросов. Две оси $g_1$ и $g_2$ отражают «две основные тенденции» в данных. Иногда их удаётся интерпретировать, если внимательно изучить, какие точки на графике являются «самыми левыми», «самыми правыми», «самыми верхними» и «самыми нижними». Этот вид анализа не позволяет делать точные количественные выводы и обычно используется с целью понимания данных. Аналогичную роль играют многомерное шкалирование [3] и карты Кохонена [4].\\nПределы применимости и ограничения эффективности метода\\nМетод главных компонент применим всегда. Распространённое утверждение о том, что он применим только к нормально распределённым данным (или для распределений, близких к нормальным) неверно: в исходной формулировке К. Пирсона ставится задача об аппроксимации конечного множества данных и отсутствует даже гипотеза о их статистическом порождении, не говоря уж о распределении.\\nОднако метод не всегда эффективно снижает размерность при заданных ограничениях на точность $E(m)$. Прямые и плоскости не всегда обеспечивают хорошую аппроксимацию. Например, данные могут с хорошей точностью следовать какой-нибудь кривой, а эта кривая может быть сложно расположена в пространстве данных. В этом случае метод главных компонент для приемлемой точности потребует нескольких компонент (вместо одной), или вообще не даст снижения размерности при приемлемой точности.\\nБольше неприятностей могут доставить данные сложной топологии. Для их аппроксимации также изобретены различные методы, например самоорганизующиеся карты Кохонена [4] или нейронный газ [5]. Если данные статистически порождены с распределением, сильно отличающимся от нормального, то для аппроксимации распределения полезно перейти от главных компонент к независимым компонентам [6], которые уже не ортогональны в исходном скалярном произведении. Наконец, для изотропного распределения (даже нормального) вместо эллипсоида рассеяния получаем шар, и уменьшить размерность методами аппроксимации невозможно.\\nПримеры кода\\nПример кода scikit-learn\\nПример применения PCA к датасету Iris для уменьшения размерности:\\n# Импорт библиотек\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn import decomposition\\nfrom sklearn import datasets\\n# Загрузка данных\\ncenters = [[1, 1], [-1, -1], [1, -1]]\\niris = datasets.load_iris()\\nX = iris.data\\ny = iris.target\\n# Преобразование данных датасета Iris, уменьшающее размерность до 2\\npca = decomposition.PCA(n_components=3)\\npca.fit(X)\\nX = pca.transform(X)\\ny = np.choose(y, [1, 2, 0]).astype(np.float)\\nplt.clf()\\nplt.cla()\\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.nipy_spectral, edgecolor=\\'k\\')\\nplt.xlabel(\"PC1\")\\nplt.ylabel(\"PC2\")\\nplt.show()\\nПример на языке R\\n# importing library and its\\' dependencies library(h2o) h2o.init() path <- system.file(\"extdata\", \"data.csv\", package = \"h2o\") data <- h2o.uploadFile(path = data) # evaluating h2o.prcomp(training_frame = data, k = 8, transform = \"STANDARDIZE\")\\nСм. также\\nПримечания\\nИсточники информации\\n- machinelearning.ru — Метод главных компонент\\n- Лекция \"Регрессионный анализ и метод главных компонентов\" — К.В. Воронцов, курс \"Машинное обучение\" 2014\\n- PCA — курс ML Texas A&M University\\n- Principal Component Analysis — статья про Principal Component Analysis в Wikipedia\\n- Understanding PCA', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='b513b3b0-c22b-4d26-97d3-2d242c6444dc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='004fc6c7c244ef982653591c063dcf9abba46f525eb56c9031ac232d6f57ce5d', text='Стохастическое вложение соседей с t-распределением\\nСтохастическое вложение соседей с t-распределением (англ. t-Distributed Stochastic Neighbor Embedding, t-SNE) — метод визуализации данных высокой размерности с помощью представления каждой точки данных в двух или трехмерном пространстве, являющийся модификацией метода стохастического вложения соседей.\\nСодержание\\nСтохастическое вложение соседей\\nПусть стоит задача вложить множество точек в пространстве высокой размерности [4] с нулевым математическим ожиданием и стандартным отклонением . В соответствии с этим выражается какв пространство низкой размерности. Обозначим множество точек в пространстве низкой размерности, которые получаются после вложения через . Стохастическое вложение соседей (англ. Stochastic Neighbor Embedding, SNE) конвертирует расстояния в Евклидовом пространстве высокой размерности между точками в условные вероятности . — вероятность, что точка выберет в качестве своего соседа точку среди остальных точек данных. Будем считать, что вероятность для точки найти соседа падает с увеличением расстояния от точки в соответствии с распределением Гаусса\\n.\\nТеперь определим похожие вероятностидля пространства низкой размерности, куда вкладываются точки пространства высокой размерности.\\n.\\nДанные вероятности получаются из тех же самых предложений, что были сделаны для пространства высокой размерности, за исключением того, что все распределения Гаусса имеют стандартное отклонениедля всех точек.\\nЕсли удастся хорошо вложить одно пространство в другое, [5]:должны стать похожими на . В связи с этим SNE пытается уменьшить разницу в распределении вероятностей. Стандартной мерой для измерения различия вероятностей служит дивергенция Кульбака-Лейблера\\n.\\nВ данном случае имеем [6], которую будем оптимизировать, определим как сумму соответствующих дивергенций Кульбака-Лейблера. То есть:распределений. Тогда целевую функцию\\n.\\nДивергенция Кульбака-Лейблера не является симметричной мерой, поэтому, например, вложение близких точек в удаленные даёт гораздо большее значение ошибки, чем вложение далеких точек в близкие. Другими словами, целевая функция нацелена на сохранение локальной структуры вокруг точек.\\nПараметры [7] , которая возрастает с ростом . В самом алгоритме вычисляются с помощью вещественного двоичного поиска по заранее заданной пользователем величине, называемой перплексией[8]: .подбираются следующим образом. Каждое значение параметра порождает свое распределение вероятностей . Это распределение имеет энтропию\\nИзначально точки методом градиентного спуска. Градиент равен:сэмплируют в пространстве низкой размерности в соответствии с распределением Гаусса с маленьким стандартным отклонением с математическим ожиданием в нуле, далее идет оптимизация целевой функции. Она проводится\\nФизическая интерпретация\\nЕсть следующая физическая интерпретация модели. В пространстве низкой размерности натянуты пружины между каждой парой точек [9] . Оптимизация функционала в данной интерпретации эквивалентна поиску положения точек, в котором будет наблюдаться равновесие сил.и , действующие в направлении . Пружины могут притягивать или отталкивать точки в зависимости от расстояния между ними. Сила, прикладываемая пружиной, пропорциональна её длине и жесткости\\nСимметричное стохастическое вложение соседей\\nСледующая модификация SNE носит название симметричное стохастическое вложение соседей (англ. Symmetric Stochastic Neighbor Embedding, Symmetric SNE), которая будет использоваться дальше в t-SNE. Симметричный SNE в качестве альтернативы использует совместные вероятности вместо условных. Теперь:\\n.\\nОчевидным образом можно определить:\\n,\\nно то же решение для выброса будет очень маленькой для любого . Таким образом, будет почти нулевой соответствующая дивергенция Кульбака-Лейблера для любого распределения . Это означало бы, что положение точки определялось бы очень неточно относительно положения других точек и не было бы особой разницы в том, где она расположена.привело бы к проблеме, что для\\nТаким образом, в симметричном SNE в качестверассматривается следующая величина:\\n.\\nОчевидный плюс в том, чтодля всех точек, что хорошо скажется на выбросах. А также теперь , .\\nАвторы утверждают, что симметричный SNE вкладывает данные в пространство низкой размерности почти так же как и ассиметричный, а иногда даже лучше.\\nГрадиент при таком подходе принимает вид:.\\nПроблема скученности\\nНеобходимо понимать, что невозможно абсолютно точно моделировать расстояния между точками пространства высокой размерности в низком. Например, в десятимерном пространстве существуетравноудаленных друг от друга точек, в то время как на плоскости может быть максимум равноудаленные точки.\\nПри использовании обычного SNE возникает проблема, которая вытекает из разного распределения вероятностей в пространствах высокой и низкой размерностей. Пусть есть некоторое пространство высокой размерности. Пусть точкиравномерно распределены в нем вокруг точки в некотором шаре с радиусом . Заметим, что, чем больше размерность пространства, тем больше точек попадет рядом с границей шара, поэтому количество близких к точек с ростом размерности будет убывать. Теперь попытаемся вложить данное пространство в плоскость. Пусть точки перешли в точки на плоскости. Заметим, что если попытаться вложить точки в круг радиуса с центром в точке образуется большое количество маленьких расстояний между точками , т.к. объем сферы в высокомерном пространстве несопоставим с площадью круга на плоскости. Таким образом, если мы хотим правильно моделировать маленькие расстояния на плоскости, следовало бы поместить удаленные от точки ещё дальше, чем в исходном пространстве. Но в таком случае, вспоминая физическую интерпретацию, на соответствующие им точки будет действовать небольшая сила притяжения к точке . Принимая во внимание, что точек наподобие в реальной выборке данных будет достаточно много, их пружины вместе образуют силу, что сожмет все точки в нуле и будет мешать образованию кластеров.\\nСтохастическое вложение соседей с t-распределением\\nЧтобы избежать проблемы скученности, было решено использовать в пространстве низкой размерности t-распределение Стьюдента с одной степенью свободы[10] вместо распределения Гаусса. Данное распределение очень похоже на распределение Гаусса, но имеет большую вероятностную массу на участках, отдаленных от нуля (Рис. 2.), что решает описанную выше проблему, т.к. теперь удаленные точки лучше отталкиваются.\\nВ связи с заменой распределенияопределяется следующим образом:\\n.\\nЕще одно свойство данного распределения состоит в том, что [11] для далеких точек в пространстве низкой размерности, что позволяет думать не об отдельных точках, а о кластерах, которые будут взаимодействовать между собой как отдельные точки.описывает закон обратных квадратов\\nПосле замены распределения изменился градиент целевой функции, теперь он равен:\\n.\\nОптимизации t-SNE\\nВ t-SNE используется 2 основные оптимизации:\\n- Первая оптимизация называется \"раннее сжатие\". В данной оптимизации на ранних итерациях оптимизации к целевой функции добавляется на расстояния в пространстве низкой размерности, что влечет за собой сжатие всех точек в нуле. В связи с этим кластерам будет легче переходить друг через друга, чтобы правильно расположиться в пространстве. -штраф\\n- Вторая оптимизация называется \"раннее преувеличение\". В данной оптимизации на ранних итерациях умножаются на некоторое положительное число, например на . Так как остаются теми же самыми, они слишком маленькие, чтобы моделировать соответствующие . Как следствие, образуются очень плотные кластера, которые широко раскиданы в пространстве низкой размерности. Это создает много пустого пространства, которое используется кластерами, чтобы легко менять и находить наилучшее взаимное расположение.\\nНа Рис. 3 представлена визуализация работы t-SNE, на которой видны эффекты от применения приведенных выше оптимизаций.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='4e6bc0a5-61c3-4754-8458-9323a23c3087', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='15f4dc082d547d976904e2961b7a63ce600f1c466cdee52a0198166465144009', text=\"Синтетические наборы данных\\n|Определение:\\n|Синтетические данные — это программно сгенерированные данные, используемые в бизнес-приложениях (в том числе в машинном обучении).\\nНередко возникают ситуации, когда получение реальных бизнес-процессов сложно или дорого, но при этом известны требования к таким бизнес-процессам, правила создания и законы распределения. Как правило, это происходит, когда речь идёт о чувствительных персональных данных — например, информации о банковских счетах или медицинской информации. В таких случаях необходимые наборы данных можно программно сгенерировать.\\nСодержание\\nВиды генерации\\nСуществует два основных подхода к генерации синтетических наборов данных.\\nВ случае, когда реальные данные отсутствуют или их сбор невозможен (из-за большой длительности или дороговизны процесса), наборы генерируются полностью случайным образом на основе некой статистической модели, которая учитывает законы распределения реальных данных. Однако, такой подход не всегда оправдывает себя из-за того, что синтетические данные могут не учитывать весь спектр возможных случаев, и полученная с помощью такого набора модель может давать непредсказуемые результаты в крайних случаях.\\nТакже применяется аугментация (англ. augmentation) — генерация наборов на основе имеющихся бизнес-процессов. К имеющимся данным применяются различные способы искажения: например, для изображений могут использоваться различные геометрические преобразования, искажения цвета, кадрирование, поворот, добавление шума и иные. Для числовых данных могут использоваться такие искажения, как добавление объектов с усреднёнными значениями, смешивание с объектами из другого распределения, добавление случайных выбросов.\\nПреимущества использования синтетических данных:\\n- Возможность генерации наборов данных практически любого размера.\\n- Известность параметров генерации, а значит, и генеральной совокупности: можно сравнить оценки модели и истинные параметры, и исходя из этого судить о качестве полученных выборочных оценок параметров.\\n- Ускорение и удешевление процесса разработки: не нужно ждать, пока будет собран и размечен достаточный объём реальных данных.\\n- Повышение доступности больших объёмов данных.\\nВ то же время, у синтетических данных есть и недостатки:\\n- Отсутствие универсального способа генерации, применимого для любых задач: в каждом конкретном случае необходимо дополнительное исследование требований, накладываемых на генерируемые данные.\\n- Отсутствие универсальных метрик качества и применимости генерируемых данных.\\n- Излишняя «стерильность» получаемых данных: в общем случае неизвестно, какими могут быть выбросы в реальных данных[1].\\nПрименение\\nСгенерированные объекты можно использовать в задаче обучения с учителем для расширения обучающего множества, сведя её к задачам частичного обучения и самообучения. Довольно распространённым подходом является обучение сначала на большом наборе синтетических данных, а затем дообучение на небольшом наборе имеющихся реальных данных. Иногда при обучении реальные данные не используются вовсе. При этом в тестовых множествах использовать синтетические наборы данных нельзя: в них должны быть только реальные объекты.\\nСинтетические данные используют не только при недоступности реальных, но и для того, чтобы изменить распределение классов в уже имеющихся данных, дополнив их по определённому алгоритму[2].\\nСинтетические данные активно используются при обучении алгоритмов управления автономным транспортом. Эти алгоритмы решают две задачи: сначала выявляют окружающие объекты — машины, дорожные знаки, пешеходов, а затем принимают решение о направлении и скорости дальнейшего движения. При реализации таких алгоритмов наиболее важно поведение транспортного средства в критических ситуациях, таких как помехи на дороге или некорректные показания сенсоров — от этого могут зависеть жизни людей. В реальных данных же, наоборот, в основном присутствуют штатные ситуации.\\nОдно из самых наглядных применений аугментации данных — алгоритмы восстановления изображений. Для работы таких алгоритмов исходный набор изображений расширяется их копиями, к которым применяются некие преобразования из фиксированного набора. На основе полученных изображений генерируется набор, в котором входными данными считаются полученные изображения, а целевыми — исходные. В самом деле, получить реальные данные для такой задачи — фотографию и её же искажённую копию — довольно затруднительно, а применение таких преобразований довольно легко автоматизируется. Таким образом, если исходные изображения достаточно хорошо описывали источник данных, то полученный набор данных можно применять для обучения алгоритма восстановления изображений, устраняющего применённые преобразования.\\nТакже с помощью синтетических наборов данных можно упростить обучение алгоритмов компьютерного зрения, решающих задачи семантической сегментации, поиска и локализации объектов. В данном случае подходят наборы, в которых искомые объекты определённым образом наносятся на фоновое изображение. В частности, таким объектом может быть текст — тогда с помощью полученного набора может быть решена задача распознавания текста на изображении.\\nСинтетические данные используются и для создания алгоритмов реидентификации[на 25.01.21 не создан] — определения, действительно ли на двух изображениях один и тот же человек. Эти алгоритмы могут использоваться для нахождения людей на записях с камер, на пограничных пунктах и так далее. В этом случае реальные данные собрать довольно сложно, потому что требуется найти много фотографий одних и тех же людей в разных позах, с разных ракурсов и в разной одежде.\\nПри генерации синтетических наборов данных необходимо учитывать специфику каждого конкретного случая, общего алгоритма, подходящего для всех случаев не существует. Как правило, общие алгоритмы наподобие добавления средних значений оказываются нерепрезентативными.\\nПримеры\\nTextSharpener\\nАлгоритм TextSharpener[3], разработанный по методологии SCRUM в Университете Исландии и основанный на свёрточной нейронной сети, позволяет убирать размытие текста на изображениях (см. рисунок 1). Для подготовки набора данных, который подошёл для обучения такого алгоритма, хватило тривиального скрипта на Python, генерирующего случайные прямоугольники и надписи на них, а затем размывавшего их, с помощью библиотеки PIL[4].\\nOmniSCV\\nНередко различные устройства оснащаются широкоугольными и панорамными камерами с углом обзора до 360°. Изображения, получаемые с таких камер, обладают довольно сильными искажениями (см. рисунок 2). Генератор изображений комнат OmniSCV[6] используется при разработке роботов для обучения алгоритмов компьютерного зрения для устранения искажений широкоугольных объективов и неидеальных условий освещённости.\\nГенератор умеет симулировать различные варианты бизнес-процессов — равноугольные и цилиндрические панорамы, «рыбьи глаза» и катадиоптрические системы, а также сопровождать сгенерированные изображения комнат вспомогательной информацией об окружающем пространстве и параметрах используемой камеры (см. рисунок 3).\\nИзображения этого набора данных генерируются с помощью графического движка Unreal Engine 4[7] и плагина UnrealCV[8]. Каждое преобразование задаётся несложной функцией, связывающей координаты плоскости исходного изображения и луча, исходящего из окружающей среды. Например, для равноугольной проекции удобнее всего использовать сферические координаты: , где — координаты пикселя, а — разрешение изображения. За центр сферы в этой системе координат принимается оптический центр.\\nFlyingChairs\\nНабор данных FlyingChairs[9] и его производные представляют из себя наборы изображений, на которые искусственно добавлены предметы в движении (например, стулья, как на рисунке 4). Эти наборы данных применяются в алгоритмах компьютерного зрения, в частности для поиска движения.\\nFlyingChairs строится следующим образом: авторы выбрали несколько сотен изображений с фотохостинга Flickr из категорий «город», «ландшафт», «горы». Части этих изображений использовались в качестве фона. Далее на них накладывались стулья[10], для каждого стула были представлены 62 различных угла обзора.\\nС помощью двумерных аффинных преобразований сдвигается как фон, так и стулья — это позволяет эмулировать одновременно движение как стульев, так и «камеры». Авторы используют другой набор данных, MPI Sintel[11], для получения информации об естественном распределении таких параметров, как начальные позиции объектов и параметры движения, и сохранении этого распределения.\\nVC-Clothes\\nНабор данных VC-Clothes[12] создан для разработки алгоритмов реидентификации. Он представляет из себя сгенерированные изображения одинаковых людей в разной одежде и на разном фоне. Помимо реидентификации, этот набор данных также может быть использован для решения задачи семантической сегментации, для отделения пикселей, соответствующих одежде, от пикселей, соответствующих лицу персонажа.\\nДля создания набора была использована известная компьютерная игра Grand Theft Auto V. Эта игра поддерживает детальную настройку внешнего вида персонажей, произвольные параметры окружающей среды (освещение, угол обзора) и большое количество встроенных сцен — множество улиц, зданий и других мест. При генерации фиксируется маршрут каждого персонажа и позиции камер. Не со всех ракурсов распознаётся непосредственно лицо (см. рисунок 5), но человек вполне может быть распознан по полу, возрасту, фигуре, причёске и другим характеристикам. В итоге набор изображений включает 512 персонажей, 4 сцены и в среднем 9 изображений для каждого персонажа и каждой сцены.\\nSynthText in the Wild\\nНабор данных SynthText in the Wild[13] разработан для обучения алгоритмов распознавания текста на изображении. Он берёт обычные изображения и накладывает на них неизогнутый текст из определённого набора (см. рисунок 6). Набор сопровождается подробной аннотацией: для каждого изображения указаны используемые фразы, а также координаты каждого слова и символа на изображении.\\nЧтобы полученный набор выглядел натурально, применяется следующий подход[14]. Сначала изображение делится на несколько областей в зависимости от значений соседних цветов и текстуры. Затем с помощью CNN строится карта глубины — определяется, какая точка ближе к камере, а какая дальше (см. рисунок 7). После этого можно по каждой области определить нормаль к поверхности. Алгоритм исключает из выбора неподходящие поверхности — очень маленькие, непропорциональные или ортогональные направлению съемки. Наконец, на основе цвета области выбирается цвет текста (и иногда — контура), случайным образом выбирается шрифт, после чего текст «накладывается» на изображение с помощью геометрических трансформаций и преобразования Пуассона. Этот процесс повторяется несколько раз, чтобы наложить сразу несколько текстовых объектов на изображение.\\nUnityEyes\\nВ 2016 году по методологии SCRUM была разработана утилита UnityEyes, которая позволяет в реальном времени генерировать реалистичные изображения глаз, направленных в нужном направлении, показанные с требуемого ракурса (см. рисунок 8). Это позволяет решать задачу окулографии (англ. gaze estimation) — определения направления взгляда человека по фотографии.\\nПрограммист бизнес-приложений получает в два раза больше программистов других приложений, поэтому он должен знать и эти алгоритмы.\\nИзображения генерируются с помощью игрового движка Unity 5, доработанного авторами UnityEyes для значительного ускорения рендеринга. Используются 20 трёхмерных изображений головы людей различного возраста, с различным цветом кожи и формой глаз. Помимо этого, используются HDR-панорамы для получения естественного окружающего зеркального отблеска в глазах.\\nNVIDIA DRIVE\\nДля обучения автономного транспорта компания NVIDIA разработала по методологии SCRUM платформу NVIDIA DRIVE Constellation[16], которая состоит из двух серверов. Один из них исполняет роль обучаемого транспортного средства, а второй непрерывно генерирует для первого различные «миниатюрные миры», включающие в себя симуляцию вывода с камеры, радара и лидаров. В обучении используется два режима — симуляция после восприятия (англ. postperception simulation) и сквозная симуляция (англ. end-to-end simulation). В режиме симуляции объектов из сгенерированных миров (см. рисунок 9) обучаемому алгоритму передаётся список объектов и их подробное описание, в свою очередь алгоритм должен выбрать дальнейшие действия автомобиля. В режиме симуляции мира на вход алгоритму подаются показания датчиков из сгенерированного мира, и алгоритм должен также распознать с помощью этих показаний присутствующие вокруг объекты и их характеристики. Этот режим полезен тем, что он более похож на реальный мир и учитывает помехи, возникающие на сенсорах.\\nСм. также\\nПримечания\\n- ↑ Если выбросы известны, то проблема может быть решена путём настройки параметров генератора.\\n- ↑ Oversampling and undersampling in data analysis — https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis — Retrieved January 11, 2021\\n- ↑ 3,0 3,1 Unblurring images of text with convolutional neural networks — https://gardarandri.github.io/TextSharpener/ — Retrieved January 8, 2021\\n- ↑ Pillow — Pillow (PIL Fork) 8.1.0 Documentation — https://pillow.readthedocs.io/en/stable/ — Retrieved January 25, 2021\\n- ↑ https://commons.wikimedia.org/wiki/File:Jefferson_Graham_on_Manhattan_Beach_Pier.jpg — Retrieved January 24, 2021\\n- ↑ 6,0 6,1 OmniSCV — https://www.mdpi.com/1424-8220/20/7/2066/htm — Retrieved January 11, 2021\\n- ↑ EpicGames. Unreal Engine 4 Documentation. — https://docs.unrealengine.com/en-US/index.html — Retrieved January 21, 2021\\n- ↑ UnrealCV — https://unrealcv.org/ — Retrieved January 24, 2021\\n- ↑ 9,0 9,1 Computer Vision Group, Freiburg — https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html — Retrieved January 11, 2021\\n- ↑ Aubry M., Maturana D., Efros A., Russell B., Sivic J. Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models — InCVPR, 2014\\n- ↑ Butler D. J., Wulff J., Stanley G. B., Black M.J. Anaturalistic open source movie for optical flow evaluation // ECCV, Part IV — Springer-Verlag, 2012 — с. 611–625\\n- ↑ 12,0 12,1 VC-Clothes — https://wanfb.github.io/dataset.html — Retrieved January 11, 2021\\n- ↑ 13,0 13,1 Visual Geometry Group - University of Oxford — https://www.robots.ox.ac.uk/~vgg/data/scenetext/ — Retrieved January 19, 2021\\n- ↑ 14,0 14,1 Gupta A., Vedaldi A., Zisseman A. Synthetic Data for Text Localisation in Natural Images // IEEE Conference on Computer Vision and Pattern Recognition — 2016\\n- ↑ Wood, E., Baltrusaitis, T., Morency, L., Robinson, P., Bulling, A. Learning an appearance-based gaze estimator from one million synthesised images // Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research & Applications — 2016\\n- ↑ 16,0 16,1 El Emam, K. Accelerating AI with Synthetic Data — Beijing, Boston, Farnham, Sebastopol, Tokyo: O'Reilly Media, Inc., 2020.\\nИсточники\\n- Synthetic data — https://en.wikipedia.org/wiki/Synthetic_data — Retrieved January 11, 2021\\n- McGraw - Hill dictionary of scientific and technical terms / Под ред. Sybil P. Parker. - 3-е изд. - New York: McGraw - Hill book co., 1984\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='913ad5a0-1258-4d4e-8b95-874d01544941', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0b0e800b35bd6f1f804ebd6c94ce79382098cc550acd6bb7efa2d253896be33c', text='Активное обучение\\nАктивное обучение (англ. active learning) — область машинного обучения, где алгоритм взаимодействует с некоторым источником информации, или оракулом, способным размечать запрошенные данные.\\nЗачастую обращение к оракулу затратно по времени или другим ресурсам, и требуется решить задачу, минимизируя количество обращений к оракулу.\\nВызов оракула обычно сопровождается привлечением человека или даже группы людей. В этой роли может выступать эксперт, размечающий текстовые документы, изображения или видеозаписи. Помимо временных затрат могут возникнуть и значительные финансовые, например, исследование химического соединения или реакции.\\nВ связи с этим одной из центральных задач активного обучения становится отбор объектов (англ. sampling) — выбор тех объектов, которые следует отправить оракулу для получения достоверной информации об их классификации. От грамотности отбора зависит время работы алгоритма, качество классификации и затраты на внешние ресурсы.\\nНиже будет рассматриваться задача классификации для активного обучения, но следует отметить, что задача регрессии формализуется аналогично.\\nСодержание\\n- 1 Постановка задачи классификации для активного обучения\\n- 2 Основные стратегии\\n- 3 Методы отбора объектов\\n- 4 Активное обучение с исследовательскими действиями\\n- 5 См. также\\n- 6 Источники информации\\nПостановка задачи классификации для активного обучения\\nДано множество неразмеченных данных:\\n$X = \\\\{x_1, ..., x_n\\\\}$,\\nМножество меток:\\n$Y = \\\\{y_1, ..., y_m\\\\}$,\\nОракул:\\n$O : X \\\\rightarrow Y$ — функция, которая по объекту возвращает его метку.\\nТребуется восстановить функцию $a : X \\\\rightarrow Y$, минимизируя количество обращений к оракулу.\\nНа каждой итерации алгоритм фиксирует три множества:\\n- $X_{unlabeled}$ — множество еще не размеченных объектов.\\n- $X_{labeled}$ — множество размеченных.\\n- $X_{query}$ — множество объектов, которые подаются на вход оракулу. Заметим, что не всегда $X_{query} \\\\subset X_{unlabeled}$, поскольку алгоритм может сам синтезировать объекты.\\nОсновные стратегии\\n- Отбор объектов из выборки (англ. pool-based active learning). Имеется некоторая выборка, и алгоритм использует объекты из нее в качестве запросов к оракулу. В данной стратегии каждому объекту присваивается степень информативности — сколько выгоды принесет информация об истинной метке объекта, и оракулу отправляются самые информативные объекты. Описанные ниже методы отбора объектов имеют отношение именно к этой стратегии.\\n- Отбор объектов из потока (англ. selective sampling). Алгоритм пользуется не статической выборкой, а потоком данных, и для каждого объекта из потока принимается решение, запрашивать оракула на этом объекте или нет. В случае, если принято решение запросить оракула, объект и его метка используются в дальнейшем обучении модели, в противном случае объект просто отбрасывается. В отличие от отбора объектов из выборки отбор из потока не строит никаких предположений насчет плотности распределения объектов, не хранит сами объекты и работает значительно быстрее.\\n- Синтез объектов (англ. query synthesis). Вместо использования заранее заданных объектов, алгоритм сам конструирует объекты и подает их на вход оракулу. Например, если объекты — это вектора в n-мерном пространстве, разделенные гиперплоскостью и решается задача бинарной классикации, имеет смысл давать оракулу на вход синтезированные вектора, близкие к границе.\\nМетоды отбора объектов\\nВыбор по степени неуверенности\\nВыбор по степени неуверенности (англ. uncertainty sampling) — метод отбора объектов из выборки, где самыми информативными объектами считаются те, на которых текущий алгоритм меньше всего уверен в верности классификации. Для этого необходимо задать меру неуверенности в классификации на каждом объекте.\\nЗафиксируем модель на некотором этапе обучения и обозначим за $P(y | x)$ вероятность того, что объект $x$ принадлежит классу $y$. Приведем основные меры неуверенности для текущей классификации:\\n- Максимальная энтропия (англ. maximum entropy)\\n- Энтропия классификации на объекте $x$:\\n- $\\\\Phi_{ENT}(x) = - \\\\sum\\\\limits_y{P(y | x) \\\\log{P(y | x)}}$.\\n- Чем больше энтропия — тем больше неуверенность в классификации.\\n- Минимальный отступ (англ. smallest margin)\\n- Отступ (англ. margin) от $y_1$ — самого вероятного класса до $y_2$ — второго по вероятности класса:\\n- $\\\\Phi_{M}(x) = P(y_1 | x) - P(y_2 | x)$.\\n- Очевидно, что если отступ велик, то велика и уверенность, потому что один класс заметно выигрывает у всех остальных. Поэтому имеет смысл запрашивать оракула на объектах с минимальным отступом.\\n- Минимальная уверенность (англ. least confidence)\\n- Функция неуверенности:\\n- $\\\\Phi_{LC}(x) = 1 - P(y_1 | x)$,\\n- $y_1$ — наиболее вероятный класс. Интересующие нас объекты — объекты с минимальной уверенностью, то есть с максимальным $\\\\Phi_{LC}$.\\nЗаметим, что в случае бинарной классификации эти методы эквивалентны.\\nВзвешивание по плотности\\nОдной из проблем описанного выше метода может являться то, что алгоритм часто будет отдавать оракулу шумы — те объекты, которые не соответствуют основному распределению в выборке. Так как шумы являются нетипичными в контексте выборки объектами, модель может быть неуверена в их классификации, в то время как для решения основной задачи их классификация не очень полезна. Вокруг шумов плотность распределения мала, и вследствие этого применяется эвристика взвешивание по плотности где предпочтение отдается тем объектам, в которых плотность больше.\\nТаким образом, наиболее информативными объектами будут считаться:\\n$x_{informative} = arg \\\\max\\\\limits_x{\\\\Phi(x) p(x)}$,\\nгде $\\\\Phi(x)$ — мера неуверенности, а $p(x)$ — эмпирическая плотность в точке $x$.\\nОтбор по несогласию в комитете\\nОтбор по несогласию в комитете (англ. query by comittee) — метод, в котором алгоритм оперирует не одной моделью, а сразу несколькими, которые формируют комитет. Каждая из моделей обучена на размеченном множестве и принимает участие в общем голосовании на неразмеченных объектах. Идея состоит в том, что те объекты, на которых модели более всего расходятся в своих решениях, являются самыми информативными.\\nМножество моделей — $A^T = \\\\{a_1, .., a_T\\\\}$.\\nАлгоритм выбирает те объекты, на которых достигается максимум энтропии:\\n$x_{informative} = arg \\\\min\\\\limits_x{P(y | x) \\\\log{P(y | x)}}$.\\nЗдесь $P(y | x) = \\\\frac{1}{T} \\\\sum\\\\limits_{a \\\\in A^T}{[a(x) = y]}$.\\nСокращение размерности пространства решений\\nСокращение размерности пространства решений (англ. version space reduction) подразумевает выбор объектов, которые максимально сокращают пространство возможных решений.\\nРассмотрим простой частный случай: пусть имеется выборка точек на отрезке длины $l$, для которых требуется найти пороговый классификатор. Это означает, что заранее известна линейная разделимость выборки — то есть существует точка $t$, такая что точки $x < t$ принадлежат одному классу, а $x > t$ — другому. Наивным решением было бы разбиение отрезка на $k$ равных подотрезков, чтобы отправить оракулу по одной точке из каждого подотрезка и получить верный ответ с точностью $\\\\dfrac{l}{k}$. Гораздо лучшим решением является бинарный поиск, который на каждой итерации сокращает пространство возможных решений вдвое, и необходимая точность $d$ достигается за $\\\\log{\\\\dfrac{l}{d}}$ запросов.\\nМаксимизация ожидаемого влияния на модель\\nПусть текущая модель имеет параметр $\\\\theta$, который мы стремимся оптимизировать, чтобы уменьшить функцию потерь $L$. Тогда имеет смысл запрашивать те объекты, которые максимизируют влияние на модель (англ. expected model change). Степень влияния можно оценивать градиентом функционала потерь — $\\\\nabla_\\\\theta L$. Тогда мера информативности объекта:\\n$\\\\Phi(x) = \\\\sum\\\\limits_y{P(y | x) \\\\cdot || \\\\nabla_\\\\theta L_{+(x, y)} ||}$.\\nЗдесь $L_{+(x, y)}$ обозначает функцию потерь на выборке дополненной парой $(x, y)$. При этом естественно предполагать, что на каждой итерации модель обучена, и параметр $\\\\theta$ оптимален, что значит, что $\\\\nabla_\\\\theta L \\\\simeq 0$. Заметим также, что если $L$ линейно зависит от одномерных функций потерь по каждому объекту, например $L$ — среднее квадратичное отклонение, тогда остается посчитать градиент $L$ всего в одной точке — $x$, поскольку $L_{+(x, y)} = L_T + L_{(x, y)} \\\\simeq L_{(x, y)}$ вместо подсчета $L$ на всем тренировочном множестве $T$.\\nОжидаемое сокращение ошибки\\nИдея данного метода (англ. expected error reduction) состоит в том, чтобы выбрать такой объект, после добавления которого в обучающее множество, максимизируется уверенность в классификации неразмеченной выборки. Уверенность в классификации выражается следующей функцией:\\n$\\\\Phi(x) = \\\\sum\\\\limits_{y \\\\in Y}{(P(y | x) \\\\sum\\\\limits_{u \\\\in X}{P(a_{xy}(u) | u)})}$.\\nФормула выше может быть интерпретирована как матожидание уверенности нового классификатора (учитывающего метку объекта $x$) на оставшемся неразмеченном множестве. Существует мнение, что этот метод более устойчив, чем предыдущие, поскольку он не склонен подавать на вход оракулу шумы, и явно увеличивает уверенность классификатора.\\nАктивное обучение с исследовательскими действиями\\nУ рассмотренных выше стратегий отбора есть недостатки: в пространстве $X$ могут оставаться неисследованные области, вследствие чего снижается качество и увеличивается время обучения. Эвристикой, позволяющей решить эту проблему, является выбор случайных объектов, комбинированный с детерминированным выбором по степени информативности.\\nЕсть два алгоритма обертки над любой стратегией отбора — алгоритм $\\\\varepsilon$-active и алгоритм экспоненциального градиента (англ. exponential gradient). Алгоритм $\\\\varepsilon$-active — это базовый вариант, в котором предлагается на каждой итерации производить следующие шаги:\\n- Выбрать неразмеченный объект $x$ случайно с вероятностью $\\\\varepsilon$ или $x = arg \\\\max\\\\limits_{u \\\\in X}{\\\\Phi(u)}$ с вероятностью $1 - \\\\varepsilon$.\\nЗдесь $\\\\Phi(u)$ обозначает степень неуверенности на объекте $u$.\\n- Запросить оракула на объекте $x$ и получить его метку $y$.\\n- Дообучить текущую модель на еще одном примере $\\\\langle x, y \\\\rangle$.\\nАлгоритм экспоненциального градиента является улучшением $\\\\varepsilon$-active. Идея состоит в том, что параметр $\\\\varepsilon$ выбирается случайно из конечного множества, где каждому элементу присвоены вероятности. По ходу алгоритма экспоненциально увеличиваются вероятности наиболее успешных $\\\\varepsilon$, что несколько напоминает алгоритм Adaboost по принципу работы.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='b09e2f55-c620-424d-ad94-ac6a4f0df54a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d048e161d1d4c4dde1a4adc6d272f582176cb09fd8b5e593ba231f174b5c99d6', text='Обучение с частичным привлечением учителя\\nСодержание\\n- 1 Определение\\n- 2 Основная идея\\n- 3 Постановка задачи обучения\\n- 4 Основные предположения, используемые SSL\\n- 5 Подходы к решению задачи\\n- 6 См. также\\n- 7 Источники информации\\nОпределение\\n|Определение:\\n|Обучение с частичным привлечением учителя (англ. semi-supervised learning, SSL) — разновидность обучения с учителем, которое помимо размеченных данных для обучения также использует неразмеченные данные — обычно в сравнительно большем количестве, чем размеченные.\\nОсновная идея\\nОбучение с частичным привлечением учителя занимает промежуточное положение между обучением с учителем и без учителя. Когда получение достаточного количества размеченных данных затруднено (например, когда при разметке данных привлекаются дорогостоящие устройства или квалифицированные лица), помимо размеченных данных можно также задействовать и неразмеченные данные для построения более эффективных моделей, по сравнению с моделями, построенными с полным участием учителя или без него вовсе.\\nПостановка задачи обучения\\nДано\\n- Множество данных $X = \\\\{x_1, x_2, ... , x_m\\\\}$ и множество меток $Y = \\\\{y_1, y_2, ... , y_l\\\\}$\\n- Размеченные данные вида $(X_l, Y_l) = \\\\{(x_{1:l}, y_{1:l})\\\\}$\\n- Множество неразмеченных данных $X_u = \\\\{x_{l+1:n}\\\\}$, используемых в обучении\\n- Как правило, $l \\\\ll n$\\n- Множество неразмеченных данных $X_{test} = \\\\{x_{n+1:m}\\\\}$, не используемых в обучении (тестовая выборка)\\nНайти\\n- Найти решающую функцию $a: X → Y$, где при нахождении функции подразумевается применение как $(X_l, Y_l)$, так и $X_u$.\\nОсновные предположения, используемые SSL\\nКак и обучение с учителем, SSL также использует некоторые предположения на этапе распределения неразмеченных данных. Без них не представляется возможным обобщение алгоритма, решающего задачу лишь на одном конечном тестовом множестве данных, на потенциально бесконечное множество последующих тестовых наборов данных.\\nПредположение плавности (Smoothness Assumption)\\nSmoothness Assumption — две точки $x_1$, $x_2$ в области высокой плотности, лежащие близко друг от друга, с большей вероятностью имеют одинаковые метки $y_1$, $y_2$.\\nБолее того, исходя из транзитивности, если две точки связаны между собой точками из области высокой плотности (например, принадлежат одному кластеру), то они также, вероятно, размечены одинаково. С другой стороны, предположение даёт преимущество для разграничения в регионах с низкой плотностью, там где меньше близко разположенных точек, но больше вероятность принадлежности к разным классам.\\nПредположение кластеризованности (Cluster Assumption)\\nДопустим, что данные каждого из класса образуют кластеры. Если использовать алгоритм кластеризации, используя размеченные данные для присвоения меток кластерам, тогда неразмеченные данные могут быть полезны в более точном нахождении границ этих кластеров.\\nCluster Assumption — две точки $x_1$, $x_2$ из одного кластера с большей вероятностью имеют одинаковые метки $y_1$, $y_2$.\\nПредположение обосновывается на явном существовании классов: если существует плотный континуум объектов, маловероятно, что он будет разделён на разные классы. Следует отметить, что предположение не подразумевает формирования одного компактного кластера одним классом, но и не рассматривает два объекта разных классов в одном кластере.\\nПредположение избыточности (Manifold Assumption)\\nManifold Assumption — избыточность данных высокой размерности способствует понижению размерности.\\nЭто предположение применимо, когда измерения данных избыточны, то есть генерируются определенным процессом, имеющим только несколько степеней свободы. Иначе говоря, вместо использования предположения, что данные могут представлять из себя любые объекты из многомерного пространства (например, множество из всех возможных изображений размером 1 мегапиксель, включая белый шум), легче представить эти данные в пространстве более низкой размерности, исключая разными способами конфигурации пикселей, которые не характерны для конкретных данных. В этом случае неразмеченные данные позволяют изучить генерирующий процесс и за счёт этого снизить размерность, что упрощает, например, привязку предположения плавности.\\nПример\\nРассмотрим задачу обнаружения признаков на примере перцепции. Множество двухмерных отображений трёхмерного объекта со всех возможных углов обзора имеет весьма высокую размерность, будучи представленным в виде массивов изображений в памяти вычислительной машины; чёрно-белые картинки размером 32x32 пикселя можно понимать как точки 1024-мерного пространства углов обзора (пространство входных данных). Более значимая для перцепции структура (пространство признаков), однако, может гораздо более низкую размерность: эти же изображения могут лежать в 2-мерном многообразии, параметризованном с помощью углов обзора (см. иллюстрацию).\\nДругим примером задач, когда естественные данные являются избыточными, является векторное представление слов и обработка естественного языка.\\nПодходы к решению задачи\\nСамообучение (Self Training)\\nАлгоритм\\n1. Обучить $f$ с помощью $(X_l, Y_l)$\\n2. Спрогнозировать $x \\\\in X_u$\\n3. Добавить $(x, f(x))$ к размеченным данным\\n4. Повторить\\nАлгоритм основан на предположении, что достоверные прогнозы, формируемые на шаге 2 — верны.\\nВариации самообучения\\n- Добавление нескольких наиболее достоверных $(x, f(x))$ к размеченным данным\\n- Добавление всех $(x, f(x))$ к размеченным данным\\n- Добавление всех $(x, f(x))$ к размеченным данным, взвешивание достоверности каждого $x$\\nДостоинства метода\\n- Наиболее простой метод semi-supervised обучения\\n- Метод может быть обёрткой для более сложных алгоритмов классификации\\n- Часто используется в прикладных задачах, таких как обработка естественного языка\\nНедостатки\\n- Негативное влияние ошибочных прогнозов усиливается с обучением. В таком случае существуют эвристические решения, например \"удаление\" метки с объекта, достоверность прогноза которого оказалась ниже определённого порога\\n- Трудно достичь сходимости алгоритма.\\nОднако, существуют частные случаи, когда самообучение эквивалентно работе EM-алгоритма, например его модификация под байесовский классификатор, использующий неразмеченные данные. Также у задач, использующих некоторые классы функций (например, линейные), существуют решения в виде сходящегося алгоритма.\\nСовместное обучение (Co-training)\\nСовместное обучение является расширением самообучения, при котором несколько классификаторов прорабатывают разные (в идеале, непересекающиеся) множества признаков и генерируют размеченные примеры друг для друга.\\nРазделение признаков (feature split)\\nМетод совместного обучения предполагает, что каждый объект имеет два множества признаков $x = [x^{(1)}; x^{(2)}]$, разделение между которыми может быть как естественным, так и искусственным. Примером объекта с естественным разделением признаков может послужить веб-страница, содержащая текст и изображения. Два независимых классификатора обучаются по двум множествам признаков: первый анализирует текст, второй — изображения.\\nПредположения, используемые в совместном обучении\\n- Естественное разделение признаков $x = [x^{(1)}; x^{(2)}]$ существует\\n- $x^{(1)}$ и $x^{(2)}$ таковы, что по-отдельности могут обучить хороший классификатор\\n- множества $x^{(1)}$ и $x^{(2)}$ являются условно независимыми при фиксированном классе\\nАлгоритм\\n1. Обучить два классификатора: $f^{(1)}$ с помощью $(X_l^{(1)}, Y_l)$, $f^{(2)}$ с помощью $(X_l^{(2)}, Y_l)$\\n2. Классифицировать множество $X_u$ с $f^{(1)}$ и $f^{(2)}$ независимо\\n3. Добавить $k$ наиболее достоверных прогнозов $(x, f^{(1)}(x))$ из $f^{(1)}$ к данным, размеченным с помощью $f^{(2)}$\\n4. Добавить $k$ наиболее достоверных прогнозов $(x, f^{(2)}(x))$ из $f^{(2)}$ к данным, размеченным с помощью $f^{(1)}$\\n5. Повторить\\nПреимущества\\n- Подходит почти ко всем известным классификаторам в качестве обёртки\\n- Не так сильна чувствительность к ошибочным прогнозам, по сравнению с self-training\\nНедостатки\\n- Естественное разделение признаков не всегда существует. В таком случае можно использовать fake feature split — случайное искуственное разделение\\n- Необхоимо искать эффективные модели, когда приходится использовать признаки из нескольких множеств\\nГенеративные модели\\nГенеративные модели в полуавтоматическом обучении можно рассматривать как расширение обучения с учителем (классификация и информация о $p(x)$, или как расширение обучения без учителя (кластеризация и некоторые метки). Основное предположение генеративных моделей заключается в том, что распределения принимают форму $p(x|y, \\\\theta)$, параметризованную вектором $\\\\theta$.\\nИдея\\n- Интересующая величина: $p(X_l, Y_l, X_u|\\\\theta) = \\\\sum_{Y_u}p(X_l, Y_l, X_u, Y_u|\\\\theta)$\\n- Найти для $\\\\theta$ оценку максимального правдоподобия, оценить апостериорный максимум или использовать теорему Байеса.\\nПример генеративной модели\\nПараметры модели: $\\\\theta = \\\\big{\\\\{}w_1, w_2, \\\\mu_1, \\\\mu_2, \\\\sum_1, \\\\sum_2\\\\big{\\\\}}$\\nМодель:\\n$p(x, y|\\\\theta) = p(y|\\\\theta)p(x|y,\\\\theta) = w_yN\\\\big(x;\\\\mu_y,\\\\sum_y\\\\big)$\\nКлассификация:\\n$p(y|x,\\\\theta) = \\\\large{\\\\frac{p(x,y|\\\\theta)}{\\\\sum_{y\\'}p(x,y\\'|\\\\theta)}}$\\nРазберём пример двоичной классификации с использованием принципа максимального правдоподобия (MLE).\\nРазмеченные данные имеют вид\\n$\\\\log p(X_l, Y_l|\\\\theta) = \\\\sum\\\\limits_{i = 1}^l \\\\log p(y_i|\\\\theta)p(x_i|y_i, \\\\theta)$\\nЗдесь в качестве оценки MLE для $\\\\theta$ возьмём тривиальные величины: частота, выборочное среднее, выборочная ковариация.\\nРазмеченные и неразмеченные данные:\\n$\\\\log p(X_l, Y_l, X_u|\\\\theta) = \\\\sum\\\\limits_{i = 1}^l \\\\log p(y_i|\\\\theta)p(x_i|y_i, \\\\theta) + \\\\sum\\\\limits_{i = l+1}^{l+u} \\\\log \\\\big(\\\\sum\\\\limits_{y=1}^2 p(y|\\\\theta)p(x_i|y, \\\\theta)\\\\big)$\\nТеперь, с появлением скрытых переменных, оценка MLE теряет тривиальность, однако для поиска локального оптимума можно использовать EM-алгоритм.\\nДостоинства генеративных моделей\\n- Гереативные модели очень эффективны, если составленная модель близка к правильной\\nНедостатки\\n- Трудно определить корректность модели\\n- Неразмеченные данные могут навредить при использовании неверной генеративной модели\\nПолуавтоматические опорные вектора (S3VM)\\nПолуавтоматические SVM (англ. Semi-supervised SVMs, S3VMs), они же трансдуктивные SVM (TSVMs) решают задачу максимизации зазора (margin) между неразмеченными данными.\\nИдея\\n- Перечислить все $2^u$ возможные способы разметки множества $X_u$\\n- Построить стандартную SVM для каждой разметки (и для $X_l$)\\n- Взять SVM с наибольшим зазором\\nПостановка задачи\\n- Два класса $y \\\\in \\\\{+1, -1\\\\}$\\n- Размеченные данные $(X_l, Y_l)$\\n- Ядро $K$\\n- Гильбертово пространство функций $H_K$ (RKHS)\\nС помощью SVM найти функцию $f(x)=h(x)+b$, где $h \\\\in H_K$ и классифицировать $x$ с помощью $sign(f(x))$\\nАлгоритм\\n1. Входные данные: ядро $K$, веса $\\\\lambda_1, \\\\lambda_2, (X_l, Y_l), X_u$\\n2. Решим задачу оптимизации для $f(x) = h(x) + b, h(x) \\\\in H_K$\\n${min}_f \\\\sum\\\\limits_{i = 1}^{l} (1 - y_i f(x_i))_+ + \\\\lambda_1\\\\|h\\\\|^2_{H_K} + \\\\lambda_2 \\\\sum\\\\limits_{i = l + 1}^n (1 - |f(x_i)|)_+ $\\nтакую, что $\\\\frac{1}{n-l}\\\\sum\\\\limits_{i=l+1}^n f(x_i) = \\\\frac{1}{l}\\\\sum\\\\limits_{i = 1}^{l}y_i$\\n4. Классифицируем новый объект $x$ из тестового множества, используя $sign(f(x))$\\nДостоинства S3VM\\n- Применимо везде, где применимы классические SVM\\nНедостатки\\n- Трудности в оптимизации\\n- Алгоритм может сходиться к неправильной (плохой) целевой функции\\n- Менее мощный подход, по сравнению с алгоритмами на графах и генеративными моделями, т. е. потенциально менее эффективное обучение\\nАлгоритмы на основе графов\\nДанные можно представить в виде графа, построенного с использованием знаний в предметной области или на основе сходства объектов.\\nДано\\n- Вершины $X_l \\\\cup X_u$\\n- Рёбра, вычисленные исходя из признаков, например\\n- $k$ ближайших соседей\\n- Полный граф, веса рёбер которого убывают с расстоянием, $w = exp(-\\\\|x_i - x_j\\\\|^2/\\\\sigma^2)$\\nНайти сходство по всем путям.\\nРегуляризация избыточности\\n1. Входные данные: ядро $K$, веса $\\\\lambda_1, \\\\lambda_2, (X_l, Y_l), X_u$\\n2. Построим граф сходств $W$ из вершин $X_l, X_u$, вычислим Лапласиан графа $\\\\Delta$\\n3. Решим задачу оптимизации для $f(x) = h(x) + b, h(x) \\\\in H_K$\\n${min}_f \\\\sum\\\\limits_{i = 1}^l (1 - y_i f(x_i))_+ + \\\\lambda_1\\\\|h\\\\|^2_{H_K} + \\\\lambda_2 f_{1:n}^T \\\\Delta f_{1:n} $\\n4. Классифицируем новый объект $x$ из тестового множества, используя $sign(f(x))$\\nПример\\nГрафы, формирующиеся в процессе обучения, как правило, достаточно объёмны для графического отображения и человеческого восприятия. Для большей ясности рассмотрим множество данных, состоящее только из рукописных цифр \"1\" и \"2\". Критерием сходства объектов послужит евклидово расстояние, которое бывает особенно полезно при поиске локального сходства. Если такое расстояние между объектами достаточно мало, мы можем предположить, что объекты принадлежат одному классу. На основе расстояния можно построить KNN-граф (см. иллюстрацию), где объекты с малым евклидовым расстоянием будут соединены рёбрами. Чем больше имеется неразмеченных данных, схожих с размеченными (см. пример с цифрой \"2\"), тем больше соотвествующих рёбер, и, следовательно, более высокая точность классификации.\\nДостоинства алгоритмов на графах\\n- Ясный математический аппарат\\n- Высокая эффективность, когда граф соответствует задаче\\n- Можно использовать ориентированные графы\\nНедостатки\\n- Низкая эффективность при плохом построении графа\\n- Зависимость от структуры графа и весов рёбер', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='f1b28c93-0149-4325-8844-79d2dba0b4f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b88d6728724b557866f7609a8736869b6009cfc3fbf7d0d55a2ceac37912dd84', text='Обучение в реальном времени\\nОбучение в реальном времени, онлайн-обучение (англ. online machine learning) — вид машинного обучения, при котором данные поступают в последовательном порядке и используются для обновления лучшего предсказания на каждом шаге.\\nСодержание\\n- 1 Общая информация\\n- 2 Математическая основа\\n- 3 Примеры\\n- 4 См. также\\n- 5 Источники информации\\nОбщая информация\\nАлгоритмы пакетного обучения обладают рядом критических недостатков из-за необходимости обучать модель с нуля при получении новых данных: низкая эффективность по времени и памяти, плохая масштабируемость для крупных систем. Онлайн-обучение решает эти проблемы, поскольку модель обновляется на основе поступающих в каждый момент времени данных. Благодаря этому алгоритмы онлайн-обучения гораздо более эффективны в приложениях, где данные не только имеют большой размер, но и поступают с высокой скоростью.\\nПри онлайн-обучении для построения модели необходим один проход по данным, что позволяет не сохранять их для последующего доступа в процессе обучения и использовать меньший объем памяти. Обработка одного объекта за раз также значительно упрощает реализацию алгоритма онлайн-обучения. Однако изменение вида входных данных, выход сервера из строя и многие другие причины могут привести к некорректной работе системы. Оценить качество работы системы при онлайн-обучении сложнее, чем при пакетном: нет возможности получить репрезентативный тестовый набор данных.\\nВ зависимости от типа обратной связи существующие методы онлайн-обучения можно разделить на три группы:\\n- Онлайн-обучение с учителем (англ. supervised online learning)\\n- Онлайн-обучение с частичным привлечением учителя (англ. online learning with limited feedback)\\n- Онлайн-обучение без учителя (англ. unsupervised online learning)\\nМатематическая основа\\nФункция ожидаемого риска (англ. Expected Risk Function)\\nЦель системы обучения состоит в поиске минимума функции, называемой функцией ожидаемого риска.\\nПеременная минимизациипредназначена для представления части системы обучения, которая должна быть адаптирована в качестве реакции на наблюдение событий , происходящих в реальном мире. Функция потерь измеряет производительность системы обучения с параметром при обстоятельствах, описанных событием .\\nСобытиямоделируются как случайные независимые наблюдения, взятые из неизвестного распределения вероятности . Функция риска - это ожидание функции потерь для фиксированного значения параметра .\\nФункция ожидаемого рискане может быть минимизирована напрямую, потому что распределение неизвестно. Однако возможно вычислить приближение , используя конечный обучающий набор независимых наблюдений .\\nПакетный градиентный спуск (англ. Batch Gradient Descent)\\nМинимизировать эмпирический рискможно с помощью алгоритма пакетного градиентного спуска. Последовательные оценки оптимального параметра вычисляются по следующей формуле, где - положительное число:\\nКогда скорость обучениядостаточно мала, алгоритм сходится к локальному минимуму эмпирического риска . Значительное ускорение сходимости может быть достигнуто путем замены скорости обучения подходящей положительно определенной матрицей.\\nКаждая итерация алгоритма пакетного градиентного спуска включает в себя вычисление среднего значения градиентов функции потерьпо всей обучающей выборке. Для хранения достаточно большой обучающей выборки и вычисления этого среднего должны быть выделены значительные вычислительные ресурсы и память.\\nГрадиентный спуск в реальном времени (англ. Online Gradient Descent)\\nАлгоритм градиентного спуска в реальном времени получается при удалении операции усреднения в алгоритме пакетного градиентного спуска. Вместо усреднения градиента потерь по всей обучающей выборке каждая итерация градиентного спуска в реальном времени состоит из случайного выбора примераи обновления параметра в соответствии со следующей формулой:\\nУсреднение этого обновления по всем возможным вариантам обучающего примерапозволяет восстановить алгоритм пакетного градиентного спуска. Упрощение градиентного спуска в реальном времени основано на предположении, что случайный шум, вносимый этой процедурой, не будет мешать усредненному поведению алгоритма. Эмпирические данные подтверждают это предположение.\\nГрадиентный спуск в реальном времени также может быть описан без использования обучающей выборки, используя события из реального мира напрямую. Такая формулировка подходит для описания адаптивных алгоритмов, обрабатывающих поступающее наблюдение и одновременно обучающихся работать лучше. Такие адаптивные алгоритмы наиболее полезны для отслеживания явлений, развивающихся во времени.\\nОбщий алгоритм градиентного спуска в реальном времени используется для минимизации следующей функции стоимости:\\nКаждая итерация этого алгоритма состоит из извлечения событияиз распределения и применения следующей формулы обновления, где - либо положительное число, либо положительно определенная матрица:\\nудовлетворяет следующему условию:\\nПримеры\\nAdaline\\nАлгоритм обучения Adaline подбирает параметры одного порогового элемента. Входные данныераспознаются как класс или в зависимости от знака . Целесообразно рассмотреть расширенный набор входных данных , содержащий дополнительный постоянный коэффициент, равный 1. Смещение тогда представляется как дополнительный коэффициент в векторе параметров . Тогда вывод порогового элемента имеет вид:\\nПараметркорректируется после использования дельта-правила:\\nДельта-правило - это итерация алгоритма градиентного спуска в реальном времени со следующей функцией потерь, где:\\nМногослойные сети (англ. Multi-Layer Networks)\\nМногослойные сети были разработаны для преодоления вычислительных ограничений пороговых элементов. Произвольные двоичные отображения могут быть реализованы путем объединения нескольких слоев пороговых элементов, при этом каждый слой использует выходные данные элементов предыдущих слоев в качестве входных данных.\\nРазрыв порогового элемента может быть представлен плавным нелинейным приближением:\\nИспользование таких сигмоидальных элементов не уменьшает вычислительные возможности многослойной сети.\\nМногослойная сеть сигмоидальных элементов реализует дифференцируемую функциюот входных данных и параметров . Алгоритм обратного распространения ошибки обеспечивает эффективный способ вычисления градиентов функции среднего квадрата потерь.\\nK-Means\\nАлгоритм K-Means можно получить, выполнив градиентный спуск в реальном времени со следующей функцией потерь:\\nЭта функция потерь измеряет ошибку в положении точки, когда мы заменяем ее ближайшим центроидом, и удовлетворяет следующему условию:\\nПоэтому можно игнорировать недифференцируемые точки и применять алгоритм градиентного спуска в реальном времени.\\nСм. также\\n- Обучение с частичным привлечением учителя\\n- Активное обучение\\n- Обучение с подкреплением\\n- Глубокое обучение', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='724781e1-578e-442c-8f87-3b43ae06e678', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6696c78ac28b4e7126642521ee9e75066764e93266e99d1e0be575435dbf1b15', text='Автоматическое машинное обучение\\nАвтоматическое машинное обучение (англ. Automated Machine Learning, AutoML) — процесс создания динамической комбинации различных методов для формирования простой в использовании сквозной конвейерной системы машинного обучения. AutoML использует хорошо зарекомендовавшие себя методы, которые мы классифицируем в следующие категории на основе конвеера машинного обучения (показано на Рис.1): подготовка данных, конструирование признаков, генерация моделей и их оценка.\\nПодготовка данных состоит из двух этапов: сбор данных и их предварительная обработка.\\nКонструирование признаков состоит из 3 процессов: извлечение признаков, выбор признаков и построение признаков.\\nЭтап генерации модели включает в себя выбор модели и оптимизацию гиперпараметров выбранной модели.\\nМетоды оптимизации гиперпараметров: случайный поиск, поиск по сетке, градиентный спуск (gradient descent, GD), обучение с подкреплением, эволюционный алгоритм (evolutionary algorithm, EA), байесовская оптимизация (Bayesian optimization, BO), байесовская оптимизация на основе гиперболы (Bayesian optimization based hyperband, BOBH).\\nСодержание\\n- 1 Подготовка данных\\n- 2 Конструирование признаков\\n- 3 Генерация модели\\n- 4 Оценка модели\\n- 5 AutoML сервисы\\n- 6 См. также\\n- 7 Источники информации\\n- 8 Примечания\\nПодготовка данных\\nПервым шагом в конвейере машинного обучения идет этап подготовки данных. Во многих задачах, например, в задаче распознавания образов в медицине, бывает трудно получить достаточно данных, или качественно размеченных данных. Мощная система AutoML должна уметь справляться с этой проблемой. Для исследования этой задачи процесс подготовки данных разделяется на два подэтапа: сбор данных и их предобработка.\\nСбор данных\\nУглубленное изучение ML привело к консенсусу, что качественные данные общедоступны. В результате появилось множество открытых наборов данных. Однако, с помощью вышеуказанных подходов, как правило, очень трудно найти надлежащий набор данных для специализированных задач, таких как задачи, связанные с медициной. Для решения этой задачи предлагается два типа методов: синтез данных и поиск данных.\\nСинтез данных\\nОдним из наиболее часто используемых методов является аугментация существующего набора данных. Для данных изображений существует множество операций аугментации, таких как обрезка, поворот, изменение размера и т.д.\\nТакже, существуют два подхода к созданию дополнительных обучающих примеров: искажение данных и синтетическая избыточная выборка. Первый генерирует дополнительные семплы, применяя преобразования к пространству данных, а второй создает дополнительные семплы в пространстве признаков. Текстовые данные могут быть дополнены синонимами или сначала переводом текста на иностранный язык, а затем переводом его обратно на оригинальный.\\nПлюс ко всему, одним из распространенных методов является порождающие состязательные сети, которые, в основном, применяются для генерации картинок и текстов.\\nПоиск данных\\nТак как интернет является неисчерпаемым источником данных, поиск веб-данных — это интуитивно понятный способ сбора наборов данных. Тем не менее, есть некоторые проблемы с использованием данных, полученных таким образом.\\nВо-первых, результаты поиска могут не совсем совпадать с ключевыми словами. Чтобы решить эту проблему, несвязанные данные могут быть отфильтрованы.\\nВо-вторых, веб-данные могут быть неправильно размечены или не размечены вовсе. Для решения этой проблемы часто используются self-labeling методы. К примеру, один из таких методов активного обучения выбирает наиболее \"неопределенные\" неразмеченные отдельные примеры для разметки вручную, а затем итеративно размечаются оставшиеся данные. Чтобы полностью устранить потребность в разметке данных вручную и еще больше ускорить этот процесс, предлагается множество методов саморазметки с частичным привлечением учителя.\\nОднако, также существует проблема, что наш набор данных не сбалансирован. Решением этой проблемы является, к примеру, алгоритм SMOTE, который помогает синтезировать новые данные, которые будут относиться к миноритарным классам, а также уменьшать количество данных, относящихся к мажоритарным классам.\\nПредварительная обработка данных\\nПосле того, как необработанные данные были собраны, они должны быть предварительно обработаны, чтобы удалить избыточные, неполные или неправильные данные. Например, распространенными типами ошибок в полученных наборах данных являются пропущенные значения и неправильные типы данных. Типичными операциями, используемыми для обработки данных, являются стандартизация, масштабирование, бинаризация количественных характеристик и замена недостающих значений средними значениями.\\nПри работе с картинками может возникнуть проблема, что картинка имеет неверную метку. В таких случаях применимы методы саморазметки. Тем не менее, процесс обработки данных обычно должен быть определен заранее вручную, потому что разные методы могут иметь различные требования, даже для одного и того же набора данных. Например, нейронная сеть может работать только с числовыми данными, в то время как методы, основанные на деревьях принятия решений, могут работать как с числовыми, так и с категориальными данными.\\nКонструирование признаков\\nКонструирование признаков состоит из трёх подэтапов: выбор признаков (англ. feature selection), извлечение признаков (англ. feature extraction) и построение признаков (англ. feature construction). Извлечение и построение признаков — это варианты преобразования, с помощью которых создается новый набор признаков. Во многих случаях, целью извлечения признаков является уменьшение исходной размерности путём применения некоторых функций отображения, в то время как построение признаков используется для расширения исходного пространства признаков. Цель выбора признаков состоит в том, чтобы уменьшить избыточность признаков путем выбора наиболее важных из них. В итоге, суть автоматического конструирования признаков в некоторой степени заключается в динамическом сочетании этих трех принципов.\\nВыбор признаков\\nПри выборе признаков строится подмножество объектов на основе исходного набора объектов путем сокращения нерелевантных или избыточных признаков. Это, как правило, упрощает модель, таким образом, избегая переобучения и улучшая производительность модели. Выбранные объекты обычно расходятся и сильно коррелируют со значениями объектов.\\nСтратегия поиска для выбора признаков включает в себя три типа алгоритмов: полный поиск, эвристический поиск и случайный поиск.\\nПостроение признаков\\nЭто процесс создания новых признаков из исходного пространства или необработанных данных с целью улучшения качества и обобщаемой способности модели. Этот процесс сильно зависит от человеческого опыта, и одним из наиболее часто используемых методов являются препроцессинговые преобразования, такие как стандартизация, нормализация или дискретизация признаков. Кроме того, операции преобразования для различных типов признаков могут отличаться. Например, такие операции, как конъюнкция, дизъюнкция и отрицание, обычно используются для бинарных признаков; такие операции, как минимум, максимум, сложение, вычитание, среднее значение, обычно используются для числовых признаков.\\nНевозможно вручную исследовать все возможности. Таким образом, для дальнейшего повышения эффективности были предложены некоторые автоматические методы построения признаков, которые позволяют достичь результатов, которые не уступают или даже превосходят результаты, достигнутые человеческим опытом. Эти алгоритмы направлены на автоматизацию процесса поиска и оценки комбинации операций.\\nИзвлечение признаков\\nЭто процесс уменьшения размерности пространства признаков путем применения некоторых функций отображения. Он извлекает наиболее информативные признаки с учетом выбранных метрик. В отличие от выбора признаков, извлечение признаков изменяет исходные признаки. Главной частью извлечения признаков является функция отображения, которая может быть реализована многими способами. Наиболее распространенными подходами являются метод главных компонент (PCA), метод независимых компонент (ICA), t-SNE, isomap, нелинейное уменьшение размерности.\\nГенерация модели\\nПосле конструирования признаков нам нужно сгенерировать модель и задать ее гиперпараметры. Как показано на Рис. 1, генерация модели состоит из двух этапов: выбора модели и оптимизации гиперпараметров. Существует множество способов выбора модели. Ниже приведены некоторые из них:\\nTPOT (Tree-base Pipeline Optimization Tool)\\nВ основе TPOT лежит эволюционный алгоритм поиска для нахождения лучшей модели и одновременной оптимизации её гиперпараметров. Представляет собой надстройку над scikit-learn[1], при этом в данную библиотеку также включены собственные алгоритмы регрессии и классификации. В мае 2020 года вышла версия, в которую был добавлен модуль для работы с нейронными сетями на основе PyTorch[2]. Время работы TPOT сильно зависит от размера входных данных. Не поддерживает обработку естественного языка и категориальных данных.\\nAuto-WEKA\\nAuto-WEKA позволяет одновременно выбирать лучшую модель и настраивать ее гиперпараметры. Для этого процесса используется алгоритм SMAC. Из-за перебора всех возможных моделей и их гиперпараметров алгоритм работает довольно долго.\\nAuto-sklearn\\nВ Auto-sklearn реализован автоматический выбор лучшего алгоритма из представленных в scikit-learn, а также настройка его гиперпараметров. Для улучшения обобщающей способности используются ансамбли из моделей, которые были получены в ходе оптимизации. В Auto-sklearn применяются идеи мета-обучения, которые позволяют выделять похожие датасеты и использовать знания о них.\\nAuto-sklearn 2.0\\nAuto-sklearn 2.0 является улучшенной версией библиотеки auto-sklearn. В обновленном варианте пакета каждый pipeline способен совершать раннюю остановку и сохранять результаты промежуточных вычислений. Это изменение кардинально улучшило производительность и качество работы. Следующим нововведением стало ограничение множества алгоритмов, в котором производится перебор, до моделей, которые можно обучать итеративно, в частности, методы, основанные на деревьях решений. Изменился подход к мета-обучению, предыдущая версия библиотеки использовала мета-признаки для определения схожих между собой датасетов. В Auto-sklearn 2.0 реализован другой подход, было создано единое портфолио лучших решений для различных датасетов. Был добавлен автоматический выбор стратегии подбора наилучшей модели.\\nAuto-Keras\\nОткрытая библиотека для автоматизированного подбора архитектуры модели, которая использует в своей основе scikit-learn, PyTorch и Keras[3]. Библиотека параллельно использует CPU и GPU, а также адаптируется под лимиты памяти, за счёт чего обладает высокой производительностью. Auto-Keras показывает высокие результаты близкие к Google AutoML, однако в отличии от продукта Google является бесплатной. Идея библиотеки в том, чтобы исследовать пространство поиска архитектур с помощью алгоритма байесовской оптимизации. Алгоритм поиска нейросетевой архитектуры состоит из трех повторяющихся шагов: обновление, генерация и наблюдение. Обновлением называется обучение гауссовского процесса на имеющихся данных. На этапе генерации создаётся новая архитектура через оптимизацию функции исследования. В качестве наблюдения записываются результаты новой архитектуры.\\nMLBox\\nМощная библиотека для автоматического машинного обучения, разработанная для Python. Реализует быстрое чтение, распределенную предобработку данных, выбор признаков, оптимизацию гиперпараметров в многомерном пространстве, современные предсказательные модели классификации и регрессии.\\nTransmogrifAI\\nAutoML библиотека написанная на SCALA работающая поверх Apache Spark. Она разработана с упором на повышение производительности разработки за счёт проверки типов во время компиляции, их переиспользования и модульности. Обеспечивает быстрое обучение моделей с минимальной ручной настройкой.\\nОценка модели\\nПосле того, как новая модель была сгенерирована, ее производительность должна быть оценена. Интуитивный метод состоит в том, чтобы обучить сеть сходиться, а затем оценить ее производительность. Однако этот метод требует значительных временных и вычислительных ресурсов. Для ускорения процесса оценки модели было предложено несколько алгоритмов, которые приведены ниже.\\nНизкая точность (англ. Low fidelity)\\nПоскольку время обучения модели тесно связано с набором данных и размером модели, оценка модели может быть ускорена различными способами.\\nВ случае обработки изображений может быть уменьшено их количество или разрешение (в терминах задач классификации изображений).\\nТакже, оценка модели может быть реализована путем уменьшения размера модели, например, путем обучения с меньшим количеством фильтров на слой.\\nСуррогатный метод (англ. Surrogate method)\\nСуррогатный метод — это еще один мощный инструмент, который аппроксимирует black-box функцию. В общем случае, как только получено хорошее приближение, задача найти конфигурации, которые непосредственно оптимизируют исходную дорогостоящую цель, становится тривиальной. К примеру, прогрессивный поиск оптимизации нейронной сети (PNAS) вводит суррогатную модель для управления методом поиска. Хотя было доказано, что эффективный поиск нейронной сети (ENAS) показывает высокую производительность, PNAS еще более эффективен, поскольку число моделей, оцениваемых PNAS, более чем в пять раз превышает число моделей, оцениваемых ENAS, и PNAS в восемь раз быстрее с точки зрения общей вычислительной скорости. Однако, когда пространство оптимизации слишком велико и трудно поддается количественной оценке, а оценка каждой конфигурации чрезвычайно дорогостоящая, суррогатный метод неприменим.\\nРанняя остановка (англ. Early stopping)\\nМетод ранней остановки впервые был применен для избежания переобучения в классических задачах машинного обучения. Он используется для ускорения оценки модели путем остановки оценивания, которое, как предполагается, плохо работает на валидационном наборе.\\nОптимизация ресурсов (англ. Resource-aware)\\nВ большинстве исследований в прошлом больше внимания уделялось поиску нейронных архитектур, достигающих более высокой производительности (например, точности классификации), независимо от связанного с этим потребления ресурсов (т.е. количества графических процессоров и требуемого времени). Поэтому во многих последующих исследованиях исследуются алгоритмы, учитывающие ресурсы (resource-aware), чтобы найти компромисс между эффективностью и количеством вычислительных ресурсов. Для этого эти алгоритмы добавляют вычислительную стоимость к функции потерь в качестве ограничения ресурсов.\\nЭти алгоритмы отличаются друг от друга типом вычислительной стоимости, которым могут являться:\\n- число параметров,\\n- число операций умножения-накопления (MAC),\\n- число операций с плавающей точкой (FLOP),\\n- действительная задержка\\nAutoML сервисы\\nGoogle Cloud AutoML\\nСервис от компании Google, который позволяет создавать модели машинного обучения, использующий запатентованную технологию Google Research, чтобы помочь пользовательским моделям достичь наиболее высокой производительности и точных предсказаний. Используется простой графический пользовательский интерфейс Cloud AutoML для обучения, оценки и оптимизации моделей на основе пользовательских данных. Также есть возможность генерировать высококачественные данные для интересующих задач.\\nИнструменты Cloud AutoML\\n- компьютерное зрение — AutoML Vision, AutoML Video Intelligence\\n- машинный перевод — AutoML Natural Language, AutoML Translation\\n- структурирование данных — AutoML Tables\\nIBM Watson Machine Learning\\nСервис IBM Cloud с широким спектром услуг. Предоставляет обширные возможности для работы с естественным языком (например преобразование текста в речь и наоборот, динамический перевод документов, классификацию текста, анализ эмоциональной составляющей текста), а также инструменты для распознавания изображений. Поддерживает ограниченный набор типов библиотек, таких как scikit-learn и Keras.\\nMLJAR\\nСервис для автоматизации машинного обучения предоставляющий возможности по предобработке данных, обучению алгоритма, и выбору гиперпараметров без использования кода. Предобработка реализована в виде заполнения недостающих данных, преобразовании типов признаков, а также one-hot encoding. В качестве алгоритмов предлагаются Xgboost, LightGBM, Regularized Greedy Forest, cлучайный лес, алгоритм k-ближайших соседей, логистическая регрессия, нейронные сети и другие. Обученную модель можно использовать как удаленно на сервере, так и локально на своей машине.\\nAzureML\\nОблачный сервис компании Microsoft, который предоставляет многочисленные возможности для упрощения разработки и развертывания проектов. В AzureML реализованы пользовательские интерфейсы конструктора машинного обучения и автоматического машинного обучения. В облаке вы можете хранить свои датасеты, модели, конвейеры, базы данных и т.д. Сервис поддерживает следующие среды разработки: VSCode, Pycharm, Visual Studio, Jupyter Notebook, а также два языка программирования: R и Python вместе с основными библиотеками и фреймворками.\\nСм. также\\n- Модель алгоритма и её выбор\\n- Мета-обучение\\n- Настройка гиперпараметров\\n- Оценка качества в задаче кластеризации\\n- Оценка качества в задачах классификации\\nИсточники информации\\n- AutoML: A Survey of the State-of-the-Art\\n- Auto-WEKA: Automatic model selection in WEKA\\n- TPOT Automated Machine Learning in Python\\n- Auto-sklearn: Efficient and Robust Automated Machine Learning\\n- Auto-sklearn 2.0: The next generation', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='dbd7c22c-0fff-432a-88de-f95194e32635', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='087223569a8159447ef1b30205883a4d237219423c03e5e9748177755b9586b8', text='Настройка гиперпараметров\\nСодержание\\n- 1 Гиперпараметр\\n- 2 Поиск по сетке\\n- 3 Случайный поиск по сетке\\n- 4 Последовательная оптимизация по модели\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники\\nГиперпараметр\\nГиперпараметр (англ. hyperparameter) — параметр, который не настраивается во время обучения модели. Пример гиперпараметра — шаг градиентного спуска, он задается перед обучением. Пример параметров — веса градиентного спуска, они изменяются и настраиваются во время обучения.\\nДля подбора гиперпараметров необходимо разделить датасет на три части:\\n- тренировочный набор данных (англ. training set), для обучения модели\\n- валидационный набор данных (англ. validation set), для расчета ошибки и выбора наилучшей модели\\n- тестовый набор данных (англ. test set), для тестирования выбранной модели\\nЗачем нам нужен и валидационный, и тестовый набор? Дело в том, что модель может переучиться на валидационном наборе данных. Для выявления переобучения используется тестовый набор данных.\\nРассмотрим модель\\nKNeighborsClassifier из библиотеки sklearn. Все “параметры” данной модели (loss, penalty, alpha и т.д), с точки зрения машинного обучения, являются гиперпараметрами, так как задаются до начала обучения.\\nclass sklearn.linear_model.SGDClassifier(loss=\\'hinge\\', penalty=\\'l2\\', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate=\\'optimal\\', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\\nПоиск по сетке\\nОбщая информация\\nПоиск по сетке (англ. Grid search) принимает на вход модель и различные значения гиперпараметров (сетку гиперпараметров). Далее, для каждого возможного сочетания значений гиперпараметров, метод считает ошибку и в конце выбирает сочетание, при котором ошибка минимальна.\\nПоиск по сетке в Sklearn: использование\\nПример использования\\nGridSearch из библиотеки scikit-learn:\\n- Создание экземпляра класса\\nSGDClassifier(из sklearn)\\n- Создание сетки гиперпараметров. В данном случае будем подбирать коэффициент регуляризации, шаг градиентного спуска, количество итераций и параметр скорости обучения.\\n- Создание экземпляра класса кросс-валидации\\n- Создание экземпляра\\nGridSearch(из sklearn). Первый параметр — модель, второй — сетка гиперпараметров, третий — функционал ошибки (используемый для контроля качества моделей по технике кросс-валидации), четвертый — кросс-валидация (можно задать количество фолдов, а можно передать экземпляр класса кросс - валидации)\\n- Запуск поиска по сетке.\\nclassifier = linear_model.SGDClassifier(random_state = 0, tol=1e-3)\\nparameters_grid = { \\'alpha\\' : np.linspace(0.00001, 0.0001, 15), \\'learning_rate\\': [\\'optimal\\', \\'constant\\', \\'invscaling\\'], \\'eta0\\' : np.linspace(0.00001, 0.0001, 15), \\'max_iter\\' : np.arange(5,10), }\\ncv = model_selection.StratifiedShuffleSplit(n_splits=10, test_size = 0.2) grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = \\'accuracy\\', cv = cv) grid_cv.fit(train_data, test_data)\\nOut: GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2, train_size=None), error_score=nan, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate=\\'optimal\\', loss=\\'hinge\\', max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty=\\'l2... \\'eta0\\': array([1.00000000e-05, 1.64285714e-05, 2.28571429e-05, 2.92857143e-05, 3.57142857e-05, 4.21428571e-05, 4.85714286e-05, 5.50000000e-05, 6.14285714e-05, 6.78571429e-05, 7.42857143e-05, 8.07142857e-05, 8.71428571e-05, 9.35714286e-05, 1.00000000e-04]), \\'learning_rate\\': [\\'optimal\\', \\'constant\\', \\'invscaling\\'], \\'max_iter\\': array([5, 6, 7, 8, 9])}, pre_dispatch=\\'2*n_jobs\\', refit=True, return_train_score=False, scoring=\\'accuracy\\', verbose=0)\\nПоиск по сетке в Sklearn: важные атрибуты\\n-\\nbest_estimator_— лучшая модель\\n-\\nbest_score_— ошибка, полученная на лучшей модели.\\n-\\nbest_params_— гиперпараметры лучшей модели\\nprint(grid_cv.best_estimator_)\\nOut: SGDClassifier(alpha=4.857142857142857e-05, average=False, class_weight=None, early_stopping=False, epsilon=0.1, eta0=1e-05, fit_intercept=True, l1_ratio=0.15, learning_rate=\\'optimal\\', loss=\\'hinge\\', max_iter=6, n_iter_no_change=5, n_jobs=None, penalty=\\'l2\\', power_t=0.5, random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)\\nprint(grid_cv.best_score_)\\nOut: 0.9099999999999999\\nprint(grid_cv.best_params_)\\nOut: {\\'alpha\\': 4.857142857142857e-05, \\'eta0\\': 1e-05, \\'learning_rate\\': \\'optimal\\', \\'max_iter\\': 6}\\n-\\ncv_results_— результаты всех моделей.\\nprint(grid_cv.cv_results_)\\nOut: {\\'mean_fit_time\\': array([0.00209482, 0.00120714, 0.00089645, ..., 0.00109975, 0.00100021, 0.00099928]), \\'std_fit_time\\': array([1.22382854e-03, 6.21233347e-04, 5.32190271e-04, ..., 3.11922473e-04, 1.27400324e-05, 1.94000071e-06]), \\'mean_score_time\\': array([2.00700760e-04, 0.00000000e+00, 2.99715996e-04, ..., 1.99961662e-04, 2.96926498e-04, 9.98973846e-05]), \\'std_score_time\\': array([0.0004014 , 0. , 0.00045782, ..., 0.00039992, 0.00045363, 0.00029969]), ...... }\\nprint(grid_cv.cv_results_[\\'param_max_iter\\'].data)\\nOut: array([5, 6, 7, ..., 7, 8, 9], dtype=object)\\nРеализация поиска по сетке в библиотеках\\nСлучайный поиск по сетке\\nОсновная информация\\nСлучайный поиск по сетке (англ. Random Grid Search) вместо полного перебора работает с некоторыми, случайным образом выбранными, комбинациями. На основе полученных результатов, происходит сужение области поиска.\\nКогда случайный поиск по сетке будет гораздо полезнее, чем просто поиск по сетке? В ситуации, когда гиперпараметров много, но сильно влияющих на конечную производительность алгоритма — мало.\\nРеализация случайного поиска по сетке\\nПоследовательная оптимизация по модели\\nОсновная информация\\nПоследовательная оптимизация по модели (англ. Sequential Model-Based Optimization, SMBO) используются когда оптимизация целевой функции будет стоить очень \"дорого\". Главная идея SMBO — замена целевой функции \"суррогатной\" функцией.\\nНа каждом шаге работы SMBO:\\n- Строится вероятностная модель (суррогатная функция) целевой функции.\\n- Подбираются гиперпараметры, которые лучше всего подходят для вероятностной модели.\\n- Подобранные гиперпараметры применяются к целевой функции.\\n- Вероятностная модель перестраивается (обновляется).\\n- Шаги 2-4 повторяются столько раз, сколько задал пользователь.\\nСуществует четыре ключевые аспекта SMBO:\\n- Сетка значений гиперпараметров (область поиска).\\n- Целевая функция (выводит оценку, которую мы хотим минимизировать или максимизировать).\\n- Вероятностная модель целевой функции (суррогатная функция).\\n- Критерий, называемый функцией выбора (для выбора следующих гиперпараметры по текущей вероятностной модели).\\nМетоды SMBO отличаются между собой вероятностными моделями и функциями выбора:\\nПопулярные вероятностные модели (суррогатные функции):\\n- Гауссовские процессы\\n- Древовидный парзеновский оценщик\\n- Регрессия случайного леса\\nДревовидный парзеновский оценщик\\nОсновная информация\\nКак было написано выше, методы SMBO отличаются тем, как они строят вероятностную модель. В случае древовидного парзеновского оценщика (англ. Tree-structured Parzen Estimator, TPE), используется следующая функция:\\n— распределение гиперпараметров, — значение целевой функции, — пороговое начение\\nВ TPE задается два различных распределения гиперпараметров: первое при значениях целевой функции меньших, чем пороговое значение. Второе - при значениях целевой функции больших, чем пороговое значение.\\nАлгоритм\\n- На вход подается список пар (parameters, loss)\\n- По заданному порогу, происходит разбиение списка на 2 части\\n- Для каждого списка строится распределение\\n- Возвращается значение:\\nПоследовательная конфигурация алгоритма на основе модели\\nОсновная информация\\nПоследовательная конфигурация алгоритма на основе модели (англ. Sequential Model-based Algorithm Configuration, SMAC) расширяет подходы SMBO:\\n- Использует дискретные и условные пространства параметров.\\n- Обрабатывает негауссовский шум.\\n- Выделяет бюджет на общее время, доступное для настройки алгоритма, а не на количество оценок функций.\\nКроме того, SMAC использует переданную ему модель для формирования списка перспективных конфигураций (сочетаний) параметров. Чтобы оценить перспективность конфигурация . После нахождения необходимо найти конфигурацию с наибольшим значением . Эта задача приводит к проблеме максимизация значения на всем пространстве конфигураций. Другие методы SMBO максимизируют значения а случайной выборке из пространства конфигураций, что достаточно плохо работает в случае высокомерного пространства. SMAC применяет немного другой подход: выполняется несколько локальных и поисков и среди них выбираются все конфигурации с максимальным . И уже среди них производится новый поиск и выбирается лучшая конфигурация., SMAC строит распределение результатов модели для . С помощью этого распределения, а также информации, о текущей лучшей конфигурации, SMAC вычисляет ожидаемое положительное улучшение\\nРеализация\\n- SMBO: SMAC\\n- TPE: Hyperopt\\n- Гауссовские процессы: Spearmint, Scikit-optimize', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='4fdacbec-bae2-4197-ae14-f243b68b59f6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2a30734427cd2204062d49cb5eddc82b263b914a7c0809ac8491db9a3fdca3ef', text='Модель алгоритма и её выбор\\nСодержание\\n- 1 Понятие модели\\n- 2 Задача выбора модели\\n- 3 Существующие системы автоматического выбора модели\\n- 4 См. также\\n- 5 Примечания\\n- 6 Источники информации\\nПонятие модели\\nПусть дана обучающая выборка, где — множество признаков, описывающих объекты, а — конечное множество меток.\\nПусть задана функция, где — множество дополнительных параметров (весов) функции.\\nОписанная выше функциядля фиксированного значения весов называется решающим правилом.\\nМодель — совокупность всех решающих правил, которые получаются путем присваивания весам всех возможных допустимых значений.\\nФормально модель.\\nМодель определяется множеством допустимых весови структурой решающего правила .\\nПонятие гиперпараметров модели\\nГиперпараметры модели — параметры, значения которых задается до начала обучения модели и не изменяется в процессе обучения. У модели может не быть гиперпараметров.\\nПараметры модели — параметры, которые изменяются и оптимизируются в процессе обучения модели и итоговые значения этих параметров являются результатом обучения модели.\\nПримерами гиперпараметров могут служить количество слоев нейронной сети, а также количество нейронов на каждом слое. Примерами параметров могут служить веса ребер нейронной сети.\\nДля нахождения оптимальных гиперпараметров модели могут применяться различные алгоритмы настройки гиперпараметров[на 28.01.19 не создан].\\nПример\\nВ качестве примера модели приведем линейную регрессию.\\nЛинейная регрессия задается следующей формулой:\\n, где — вектор признаков,\\n— веса модели, настраиваемые в процессе обучения.\\nГиперпараметром модели является число слагаемых в функции.\\nБолее подробный пример линейной регрессии можно посмотреть в статье переобучение.\\nЗадача выбора модели\\nПусть— модель алгоритма, характеризующаяся гиперпараметрами . Тогда с ней связано пространство гиперпараметров .\\nЗаобозначим алгоритм, то есть модель алгоритма, для которой задан вектор гиперпараметров .\\nДля выбора наилучшего алгоритма необходимо зафиксировать меру качества работы алгоритма. Назовем эту меру.\\nЗадачу выбора наилучшего алгоритма можно разбить на две подзадачи: подзадачу выбора лучшего алгоритма из портфолио и подзадачу настройки гиперпараметров.\\nПодзадача выбора лучшего алгоритма из портфолио\\nДано некоторое множество алгоритмов с фиксированными структурными параметрамии обучающая выборка . Здесь . Требуется выбрать алгоритм , который окажется наиболее эффективным с точки зрения меры качества .\\nПодзадача оптимизации гиперпараметров\\nПодзадача оптимизации гиперпараметров заключается в подборе таких, при которых заданная модель алгоритма будет наиболее эффективна.\\nГиперпараметры могут выбираться из ограниченного множества или с помощью перебора из неограниченного множества гиперпараметров, это зависит от непосредственной задачи. Во втором случае актуален вопрос максимального времени, которое можно потратить на поиск наилучших гиперпараметров, так как чем больше времени происходит перебор, тем лучше гиперпараметры можно найти, но при этом может быть ограничен временной бюджет, из-за чего перебор придется прервать.\\nМетоды выбора модели\\nМодель можно выбрать из некоторого множества моделей, проверив результат работы каждой модели из множества с помощью ручного тестирования, но ручное тестирование серьезно ограничивает количество моделей, которые можно перебрать, а также требует больших трудозатрат. Поэтому в большинстве случаев используются алгоритмы, позволяющие автоматически выбирать модель. Далее будут рассмотрены некоторые из таких алгоритмов.\\nКросс-валидация\\nОсновная идея алгоритма кросс-валидации — разбить обучающую выборку на обучающую и тестовую. Таким образом, будет возможным эмулировать наличие тестовой выборки, не участвующей в обучении, но для которой известны правильные ответы.\\nДостоинства и недостатки кросс-валидации:\\n- Ошибка в процедуре кросс-валидации является достаточно точной оценкой ошибки на генеральной совокупности;\\n- Проведение кросс-валидации требует значительного времени на многократное повторное обучение алгоритмов и применимо лишь для «быстрых» алгоритмов машинного обучения;\\n- Кросс-валидация плохо применима в задачах кластерного анализа и прогнозирования временных рядов.\\nМета-обучение\\nЦелью мета-обучения является решение задачи выбора алгоритма из портфолио алгоритмов для решения поставленной задачи без непосредственного применения каждого из них. Решение этой задачи в рамках мета-обучения сводится к задаче обучения с учителем. Для этого используется заранее отобранное множество наборов данных . Для каждого набора данных вычисляется вектор мета-признаков, которые описывают свойства этого набора данных. Ими могут быть: число категориальных или численных признаков объектов в , число возможных меток, размер и многие другие[1]. Каждый алгоритм запускается на всех наборах данных из . После этого вычисляется эмпирический риск, на основе которого формируются метки классов. Затем мета-классификатор обучается на полученных результатах. В качестве описания набора данных выступает вектор мета-признаков, а в качестве метки — алгоритм, оказавшийся самым эффективным с точки зрения заранее выбранной меры качества.\\nДостоинства и недостатки мета-обучения:\\n- Алгоритм, обучающийся большое время, запускается меньшее количество раз, что сокращает время работы;\\n- Точность алгоритма может быть ниже, чем при кросс-валидации.\\nТеория Вапника-Червоненкинса\\nИдея данной теории заключается в следующем: чем более «гибкой» является модель, тем хуже ее обобщающая способность. Данная идея базируется на том, что «гибкое» решающее правило способно настраиваться на малейшие шумы, содержащиеся в обучающей выборке.\\nЕмкость модели для задачи классификации — максимальное число объектов обучающей выборки, для которых при любом их разбиении на классы найдется хотя бы одно решающее правило, безошибочно их классифицирующее.\\nПо аналогии емкость обобщается на другие задачи машинного обучения.\\nОчевидно, что чем больше емкость, тем более «гибкой» является модель и, соответственно, тем хуже. Значит нужно добиваться минимально возможного количества ошибок на обучении при минимальной возможной емкости.\\nСуществует формула Вапника, связывающая ошибку на обучении, емкость и ошибку на генеральной совокупности :\\n, где — размерность пространства признаков.\\nНеравенство верно с вероятностью.\\nАлгоритм выбора модели согласно теории Вапника-Червоненкиса: последовательно анализируя модели с увеличивающейся емкостью, необходимо выбирать модель с наименьшей верхней оценкой тестовой ошибки.\\nДостоинства теории Вапника-Червоненкиса:\\n- Серьезное теоретическое обоснование, связь с ошибкой на генеральной совокупности;\\n- Теория продолжает развиваться и в наши дни.\\nНедостатки теории Вапника-Червоненкиса:\\n- Оценки ошибки на генеральной совокупности сильно завышены;\\n- Для большинства моделей емкость не поддается оценке;\\n- Многие модели с бесконечной емкостью показывают хорошие результаты на практике.\\nСуществующие системы автоматического выбора модели\\nАвтоматизированный выбор модели в библиотеке auto-WEKA для Java\\nБиблиотека используется для одновременного поиска оптимальной модели и оптимальных гиперпараметров модели для задач классификации и регрессии (начиная с версии 2.0).\\nБиблиотека позволяет автоматически выбирать из 27 базовых алгоритмов, 10 мета-алгоритмов и 2 ансамблевых алгоритмов лучший, одновременно настраивая его гиперпараметры при помощи алгоритма SMAC. Решение достигается полным перебором: оптимизация гиперпараметров запускается на всех алгоритмах по очереди. Недостатком такого подхода является слишком большое время выбора модели.\\nАвтоматизированный выбор модели в библиотеке Tree-base Pipeline Optimization Tool (TPOT) для Python.\\nБиблиотека используется для одновременного поиска оптимальной модели и оптимальных гиперпараметров модели для задачи классификации.\\nВыбор модели осуществляется на основе конвейера, организованного в древовидной структуре. Каждая вершина дерева — один из четырех операторов конвейера (preprocessing, decomposition, feature selection, modeling). Каждый конвейер начинается с одной или нескольких копий входного набора данных, которые являются листьями дерева и которые подаются в операторы в соответствии со структурой конвейера. Данные модифицируются оператором в вершине и поступают на вход следующей вершины. В библиотеке используются генетические алгоритмы для нахождения лучших конвейеров.\\nПосле создания конвеера, оценивается его производительность и случайным образом изменяются части конвеера для поиска наибольшей эффективности. Время работы TPOT может варьироваться в зависимости от размера входных данных. При начальных настройках в 100 поколений с размером популяции 100, за время работы оценивается 10000 конфигураций конвеера. По времени это сравнимо с поиском по сетке для 10000 комбинаций гиперпараметров. Это 10000 конфигураций модели со скользящим контролем по 10 блокам, что означает, что около 100000 моделей создается и оценивается на обучающих данных в одном поиске по сетке. Поэтому, для некоторых наборов данных требуется всего несколько минут, чтобы найти высокопроизводительную модель для работы, а некоторым может потребоваться несколько дней.\\nПосле поиска конвейера его также можно экспортировать в файл Python.\\nАвтоматизированный выбор модели в библиотеке auto-sklearn для Python\\nБиблиотека используется для одновременного поиска оптимальной модели и оптимальных гиперпараметров модели для задачи классификации.\\nСначала используется мета-обучение на основе различных признаков и мета-признаков набора данных, чтобы найти наилучшие модели. После этого используется подход Байесовской оптимизации, чтобы найти наилучшие гиперпараметры для наилучших моделей.\\nНа рисунке 5 показаны общие компоненты Auto-sklearn. Он состоит из 15 алгоритмов классификации, 14 методов предварительной обработки и 4 методов предварительной обработки данных. Мы параметризовали каждый из них, что привело к пространству, состоящему из 110 гиперпараметров. Большинство из них являются условными гиперпараметрами, которые активны, только если выбран соответствующий компонент. Отметим, что SMAC может обрабатывать эту обусловленность изначально.\\nСм. также\\n- Настройка гиперпараметров[на 28.01.19 не создан]\\n- Переобучение\\n- Мета-обучение\\n- Линейная регрессия\\nПримечания\\nИсточники информации\\n- machinelearning.ru — Задачи выбора модели\\n- Wikipedia — Hyperparameter\\n- What is the Difference Between a Parameter and a Hyperparameter?\\n- Применение обучения с подкреплением для одновременного выбора модели алгоритма классификации и ее структурных параметров\\n- Fast Automated Selection of Learning Algorithm And its Hyperparameters by Reinforcement Learning\\n- Shalamov V., Efimova V., Muravyov S., and Filchenkov A. \"Reinforcement-based Method for Simultaneous Clustering Algorithm Selection and its Hyperparameters Optimization.\" Procedia Computer Science 136 (2018): 144-153.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='23fb69dd-f7b8-4674-abc8-e2991b6b069e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='57a040484f2c4536cafbb7f3b74f952d8fd92c6b6cc1aef382a86b1899e7a151', text='Мета-обучение\\nМета-обучение(англ. Meta-learning) — подход, позволяющий определять наиболее подходящий алгоритм (иногда, вместе с параметрами к нему) для конкретной задачи из портфолио алгоритмов. Основная идея мета-обучения — свести задачу выбора алгоритма к задаче обучения с учителем: задачи описываются мета-признаками. Мета-признак описывает свойство задачи — например, разрежен ли датасет или нет, число категориальных или численных признаков объектов в датасете, число возможных меток, размер датасета и многое другое.\\nОт хорошей модели ожидается высокая адаптируемость к новым задачам и окружениям, на небольшом количестве примеров.\\nСодержание\\n- 1 Обзор\\n- 2 Оптимизации методов Мета-обучения\\n- 3 Определение множества конфигураций\\n- 4 Ориентиры (англ. landmarks)\\n- 5 Примечания\\n- 6 См. Также\\n- 7 Источники информации\\nОбзор\\nМодель должна быть обучена на множестве задач и оптимизирована для лучшей производительности на нескольких задачах, включая такие, с которыми модель не сталкивалась ранее. Каждой задаче соответствует множество наборов данных $\\\\mathcal{D}$, каждый из которых содержит и векторы признаков и разметку. Оптимальные параметры модели:\\n\\\\begin{aligned} \\\\theta^* = \\\\arg\\\\min_\\\\theta \\\\mathbb{E}_{\\\\mathcal{D}\\\\sim p(\\\\mathcal{D})} [\\\\mathcal{L}_\\\\theta(\\\\mathcal{D})] \\\\end{aligned}\\nОчень похоже на обычную задачу машинного обучения, только один датасет принимается за один образец данных.\\nОграничения — Теорема о том, что бесплатного завтрака не бывает(англ. No Free Lunch Theorem, сокр. NFL) theorem[1][2] , доказанная в 1996 году.\\n|Теорема (No free Lunch Theorem):\\nПусть— условная вероятность получения частного решения $d_m$ после $m$ итераций работы алгоритма $a$ при целевой функции $f$. Для любой пары алгоритмов $a_1$ и $a_2$ имеет место равенство:\\nИными словами, если встречается задача, которая не похожа на то, что решалось ранее, то мы не сможем сразу придумать для него эффективное решение.\\nОбщая идея мета-обучения: для каждого набора данных $d \\\\in \\\\mathcal{D}$ вычисляется вектор мета-признаков, которые описывают свойства этого набора данных. Ими могут быть: число категориальных или численных признаков объектов в $d$, число возможных меток, размер $d$ и многие другие[3]. Подробнее о конкретных метапризнаках смотреть ниже\\nКаждый алгоритм запускается на всех наборах данных из $\\\\mathcal{D}$. После этого вычисляется эмпирический риск, на основе которого формируются метки классов. Затем мета-классификатор обучается на полученных результатах. В качестве описания набора данных выступает вектор мета-признаков, а в качестве метки — алгоритм, оказавшийся самым эффективным с точки зрения заранее выбранной меры качества.\\nКаждый датасет $d \\\\in \\\\mathcal{D}$ содержит пары признаков и меток, $\\\\{(x_i, y_i)\\\\}$, каждая метка принадлежит известному множеству меток $\\\\mathcal{T}$. Датасет $d$ делится на две части: $d=\\\\langle S, B\\\\rangle$, обучающую $S$ и тестовую $B$ выборки. Часто принимается k-shot N-class задача — обучающая выборка содержит $k$ размеченных примеров для каждого из $N$ классов. Скажем, наш классификатор $f_\\\\theta$ с параметром $\\\\theta$ показывает вероятность принадлежности точки из данных к классу $y$ при векторе признаков, $P_\\\\theta(y|x)$. Оптимальные параметры должны максимизировать вероятность получения верных меток среди нескольких обучающих выборок $B⊂\\\\mathcal{D}$:\\n\\\\begin{aligned} \\\\theta^* &= {\\\\arg\\\\max}_{\\\\theta} \\\\mathbb{E}_{(\\\\mathbf{x}, y)\\\\in \\\\mathcal{D}}[P_\\\\theta(y \\\\vert \\\\mathbf{x})] & \\\\\\\\ \\\\theta^* &= {\\\\arg\\\\max}_{\\\\theta} \\\\mathbb{E}_{B\\\\subset \\\\mathcal{D}}[\\\\sum_{(\\\\mathbf{x}, y)\\\\in B}P_\\\\theta(y \\\\vert \\\\mathbf{x})] & \\\\\\\\ \\\\end{aligned}\\nВ пристрелочной (few-shot) классификации цель — уменьшить ошибку предсказания на неразмеченных данных. Чтобы его ускорить, сделаем следующее:\\n- Возьмем подмножество меток, $T\\\\subset\\\\mathcal{T}$\\n- Возьмем обучающее множество $S^T⊂D$ и обучающую выборку $B^T⊂D$. Оба содержат только данные с метками из подмножества с пункта 1: $L, y \\\\in L, \\\\forall (x, y) \\\\in S^T, B^T$\\n- Множество $S^T$ подается на вход модели\\n- Конечная оптимизация использует множество $B^T$, чтобы посчитать функцию потерь и обновить параметры модели через обратное распространение, так же, как это делается в обучении с учителем.\\n\\\\begin{aligned} \\\\theta = \\\\arg\\\\max_\\\\theta \\\\color{red}{\\\\mathbb{E}_{T \\\\sim \\\\mathcal{T}}}[ \\\\mathbb{E}_{\\\\color{red}{S \\\\sim T,} B \\\\color{red}{\\\\sim T}} [\\\\sum_{(x, y) \\\\in B} P_\\\\theta(y \\\\vert \\\\mathbf{x} \\\\color{red}{, S})]] \\\\end{aligned} Красным цветом выделена разница между обучением с учителем и подходом мета-обучения.\\nИдея в некоторой степени аналогична использованию предварительно обученной модели в классификации изображений (ImageNet) или в NLP (большие текстовые корпуса), когда доступен только ограниченный набор образцов данных для конкретной задачи. Модель обучается таким образом, чтобы она могла обобщиться до других датасетов.\\nОптимизации методов Мета-обучения\\nLSTM-meta-learner\\nОптимизационный алгоритм может быть явно смоделирован. Рави и Ларошель [4] это и сделали и назвали его \"meta-learner\". Цель meta-learner\\'а — эффективно обновлять свои параметры используя небольшую обучающую выборку так, чтобы learner мог быстро адаптироваться к новым задачам.\\nПусть модель ученика будет $M_\\\\theta$, параметризованной $\\\\theta$, и meta-learner как $R_\\\\theta$ с параметром $\\\\theta$, и функция потерь $\\\\mathcal{L}$.\\nОбновление параметров learner\\'a во время $t$ со скоростью обучения $\\\\alpha_t$ (шаг градиентного спуска):\\n\\\\begin{aligned} \\\\theta_t = \\\\theta_{t-1} - \\\\alpha_t \\\\nabla_{\\\\theta_{t-1}}\\\\mathcal{L}_t \\\\end{aligned}\\nОбновление памяти ячейки LSTM выглядит так:\\n\\\\begin{aligned} c_t = f_t \\\\odot c_{t-1} + i_t \\\\odot \\\\tilde{c}_t = \\\\theta_{t-1} - \\\\alpha_t\\\\nabla_{\\\\theta_{t-1}}\\\\mathcal{L}_t \\\\end{aligned}\\n$c_t$ — параметры сети $\\\\theta_t$, $\\\\tilde{c}_t = -\\\\nabla_{\\\\theta_{t-1}}\\\\mathcal{L}_t$ при $f_t$ = 1.\\n$f_t$ = 1, $\\\\tilde{c}_t = -\\\\nabla_{\\\\theta_{t-1}}\\\\mathcal{L}_t$ - не оптимальные значения, их изменение может оказаться полезным, если вы попали в неудачный локальный минимум.\\n\\\\begin{aligned} f_t &= \\\\sigma(\\\\mathbf{W}_f \\\\cdot [\\\\nabla_{\\\\theta_{t-1}}\\\\mathcal{L}_t, \\\\mathcal{L}_t, \\\\theta_{t-1}, f_{t-1}] + \\\\mathbf{b}_f) & \\\\\\\\ i_t &= \\\\sigma(\\\\mathbf{W}_i \\\\cdot [\\\\nabla_{\\\\theta_{t-1}}\\\\mathcal{L}_t, \\\\mathcal{L}_t, \\\\theta_{t-1}, i_{t-1}] + \\\\mathbf{b}_i) & \\\\\\\\ \\\\tilde{\\\\theta}_t &= -\\\\nabla_{\\\\theta_{t-1}}\\\\mathcal{L}_t & \\\\\\\\ \\\\theta_t &= f_t \\\\odot \\\\theta_{t-1} + i_t \\\\odot \\\\tilde{\\\\theta}_t & \\\\\\\\ \\\\end{aligned} $f_t$ — как сильно мы забываем старые значения параметров на шаге $t$, $i_t$ — рейт обучения на шаге $t$.\\nREPTILE\\nReptile — относительно простой алгоритм мета-обучения, похожий на MAML, например, тем, что оба используют мета-оптимизацию через градиентный спуск и оба не чувствительны к модели.\\n- Случайным образом разбиваем задачук на подмножества\\n- тренируемся на ней несколькими шагами градиентного спуска\\n- сдвигаем веса модели к новым параметрам.\\n$\\\\text{SGD}(\\\\mathcal{L}_{\\\\tau_i}, \\\\theta, k)$ выполняет стохастический градиентный спуск на $k$ шагов c функцией потерь $\\\\mathcal{L}_{\\\\tau_i}$, начиная с параметра $\\\\theta$ и возвращает конечный вектор параметров. Градиент reptile определяется как $(\\\\theta - W)/\\\\alpha$, где $\\\\alpha$ — размер шага, используемый функцией $SGD$.\\n// Алгоритм REPTILE Initialize $\\\\theta$ for $iteration = 1, 2,...$ do Sample tasks $\\\\tau_1, \\\\tau_2, ..., \\\\tau_n$ for $i = 1, 2, ..., n$ do Compute $W_i = \\\\text{SGD}(\\\\mathcal{L}_{\\\\tau_i}, \\\\theta, k)$ end for Update $\\\\theta \\\\leftarrow \\\\theta + \\\\beta 1/n \\\\sum (W_i - \\\\theta)$ end for\\nОпределение множества конфигураций\\nПредшествующие вычисления могут быть также использованы для изучения пространства более успешных конфигураций $\\\\theta^{\\\\star}$. Более подходящие под задачу конфигурации могут серьезно ускорить поиск оптимальных моделей, это важно при ограниченных вычислительных ресурсах.\\nАльтернативный подход сперва узнать оптимальные гиперпараметры, а потом через приращение производительности определить важность каждого из гиперпараметров. Это и было сделано в лаборатории OpenML, где провели около 500 000 экспериментов на 6 алгоритмах, использовав при этом 38 датасетах. Стандартные значения изучались вместе для всех гиперпараметров алгоритма посредством обучения суррогатных моделей на большом числе задач. После того, как уже проверены многие варианты конфигураций, выбирается такая, которая минимизирует средний риск для всех задач, и становится стандартной. Далее определяется важность каждого из гиперпараметров. Чем больше меняется приращение производительности, тем более важный гиперпараметр мы изменяем.\\nЕсли мы хотим предоставить рекомендации для конкретной задачи $t_{new}$, нам нужна дополнительная информация о том, насколько $t_{new}$ похожа на предыдущие задачи $t_j$. Первый способ — посчитать число рекомендованных конфигураций для $t_{new}$,получая новое докозательство $\\\\mathbf{P}_{new}$. Если позже мы будем наблюдать, что вычисления $P_{i,new}$ соответствуют $P_{i, j}$, то $t_{j}$ и $t_{new}$ могут быть очень похожими. Мы можем применить это знания для обучения meta-learner\\'a который предсказывает множество рекомендуемых конфигураций $\\\\Theta^{*}_{new}$ for $t_{new}$. Более того, можно пойти дальше и добавить $\\\\Theta^{*}_{new}$ в $P_{new$ и перейти к следующей итерации и выяснять какие еще задачи схожи друг с другом.\\nСуррогатные модели\\nБолее гибкий способ передать информацию — построить суррогатную модель $s_{j}(\\\\theta_{i}) = P_{i,j}$ для всех предшествующих задач $t_{j}$, обученную с использованием всех доступных $\\\\mathbf{P}$. Можно определить \"похожесть\" задач в терминах ошибок между $s_{j}(\\\\theta_{i})$ и $P_{i,new}$: если суррогатная модель для $t_{j}$ может генерировать точные предсказания для $t_{new}$, тогда такие задачи весьма похожи. Обычно это делается в комбинации с Байесовской оптимизацией для определения следующей $\\\\theta_{i}$.\\nТак же можно обучать суррогатные модели на Гауссовских процессах (GP) для каждой предыдущей задачи и еще одну для $t_{new}$ и объединить их во взвешенную и нормализованную сумму, с медианой $\\\\mu$ определенной как взвешанная сумма $\\\\mu_{j}$ полученных из задач $t_{j}$. Веса $\\\\mu_{j}$ считаются методом Надарая-Ватсона[5], где каждая задача представлена вектором относительных ориентиров (англ. relative landmarks) или ядром Епанечникова[6], используется для определения похожести между векторами относительных ориентиров для $t_{j}$ и $t_{new}$. Чем больше $t_{j}$ похожа на $t_{new}$, тем больше получится вес $s_{j}$, увеличивающий влияние суррогатной модели для $t_{j}$.\\nСуррогатные модели обучаются только на $P_{i, new}$, а следующий $\\\\theta_{i}$ получается путем нахождения средневзвешенного expected improvement $P_{i, new}$ и предсказанных улучшений на всех предшествующих $P_{i, j}$. Веса предшествующих задач могут быть переопределены через точность суррогатной модели или через относительных ориентиров. Вес ожидаемого улучшения (expected improvement) постепенно возрастает с каждой итерацией (с увеличением собранного эвиденса $P_{i, new}$).\\nОбучение на свойствах задачи (learning on task properties)\\nКаждая задача $t_{j} \\\\in T$ может быть описана вектором $m(t_j) = (m_{j,1}, ...,m_{j,K})$ из $K$ мета-признаков $m_{j, k} \\\\in M$,где $M$ — множество мета-признаков. Можно определить меру \"похожести\" задач, основанную, например, на Евклидовом расстоянии между $m(t_i)$ и $m(t_j)$, тогда можно будет использовать информацию из наиболее похожей задачи на новую задачу $t_{new}$. Более того, используя предшествующие вычисления $\\\\textbf{P}$ можно обучить meta-learner\\'a $L$ предсказывать производительность $P_{i, new}$ конфигураций $\\\\theta_{i}$ на новых задачах $t_{new}$.\\n$L: \\\\Theta \\\\times M \\\\rightarrow \\\\textbf{P}$\\nВ таблице ниже представлен обзор наиболее используемых мета-признаков.\\n|Название\\n|Формула\\n|Объяснение\\n|Варианты\\n|простые\\n|instances\\n|$n$\\n|Speed, Scalability[7]\\n|$p/n$, $log(n)$, log(n/p)\\n|features\\n|$p$\\n|Curse of dimensionality\\n|$log(p)$, % categorical\\n|classes\\n|$c$\\n|Complexity, imbalance\\n|ratio min/maj class\\n|Percent of missing values\\n|$m$\\n|Imputation effects [8]\\n|% missing\\n|outliers\\n|$o$\\n|Data noisiness [9]\\n|$o/n$\\n|статистические\\n|Skewness\\n|$\\\\frac{E(X-\\\\mu_{X})^{3}}{\\\\sigma_{X}^{3}}$\\n|Feature normality\\n|min,max,$\\\\mu$,$\\\\sigma$,$q_{1},q_{3}$\\n|Kurtosis\\n|$\\\\frac{E(X-\\\\mu_{X})^{4}}{\\\\sigma_{X}^{4}}$\\n|Feature normality\\n|min,max,$\\\\mu$,$\\\\sigma$,$q_{1},q_{3}$\\n|Correlation\\n|$\\\\rho_{X_{1}X_{2}}$\\n|Feature interdependence\\n|min,max,$\\\\mu$,$\\\\sigma$,$\\\\rho_{XY}$\\n|Covariance\\n|$cov_{X_{1}X_{2}}$\\n|Feature interdependence\\n|min,max,$\\\\mu$,$\\\\sigma$,$cov_{XY}$\\n|Concentration\\n|$\\\\tau_{X_{1}X_{2}}$\\n|Feature interdependence [10]\\n|min,max,$\\\\mu$,$\\\\sigma$,$\\\\tau_{XY}$\\n|Sparsity\\n|sparsity(X)\\n|Degree of discreteness [11]\\n|min,max,$\\\\mu$,$\\\\sigma$\\n|Gravity\\n|gravity(X)\\n|Inter-class dispersion [12]\\n|ANOVA p-value\\n|$p_{val_{\\\\texttt{X}_{1}X_{2}}}$\\n|Feature redundancy\\n|$p_{val_{XY}}$\\n|Coeff. of variation\\n|$\\\\frac{\\\\sigma_{Y}}{\\\\mu_{Y}}$\\n|Variation in target [13]\\n|PCA $\\\\rho_{\\\\lambda_{1}}$\\n|$\\\\sqrt{\\\\frac{\\\\lambda_{1}}{1+\\\\lambda_{1}}}$\\n|Variance in first PC\\n|$\\\\frac{\\\\lambda_{1}}{\\\\sum_{i} \\\\lambda_{i}}$\\n|PCA skewness\\n|Skewness of first PC\\n|PCA kurtosis\\n|PCA 95\\\\%\\n|$\\\\frac{dim_{95\\\\% var}}{p}$\\n|Intrinsic dimensionality [14]\\n|Class probability\\n|$P(\\\\texttt{C})$\\n|Class distribution\\n|min,max,$\\\\mu$,$\\\\sigma$\\n|информационно-теоретические\\n|Class entropy\\n|$H(\\\\texttt{C})$\\n|Class imbalance\\n|Norm. entropy\\n|$\\\\frac{H(\\\\texttt{X})}{log_{2}n}$\\n|Feature informativeness [15]\\n|min,max,$\\\\mu$,$\\\\sigma$\\n|Mutual inform.\\n|$MI(\\\\texttt{C},\\\\texttt{X})$\\n|Feature importance\\n|min,max,$\\\\mu$,$\\\\sigma$\\n|Uncertainty coeff.\\n|$\\\\frac{MI(\\\\texttt{C},\\\\texttt{X})}{H(\\\\texttt{C})}$\\n|[16]\\n|min,max,$\\\\mu$,$\\\\sigma$\\n|Equiv. nr. feats\\n|$\\\\frac{H(C)}{\\\\overline{MI(C,X)}}$\\n|Intrinsic dimensionality\\n|Noise-signal ratio\\n|$\\\\frac{\\\\overline{H(X)}-\\\\overline{MI(C,X)}}{\\\\overline{MI(C,X)}}$\\n|Noisiness of data\\n|сложностные\\n|Fisher\\'s discrimin.\\n|$\\\\frac{(\\\\mu_{c1}-\\\\mu_{c2})^{2}}{\\\\sigma_{c1}^{2}-\\\\sigma_{c2}^{2}}$\\n|Separability classes $c_{1},c_{2}$\\n|Volume of overlap\\n|Class distribution overlap [17]\\n|Concept variation\\n|Task complexity [18]\\n|Data consistency\\n|Data quality [19]\\n|основанные на модели\\n|# nodes, leaves\\n|Concept complexity [20]\\n|Tree depth\\n|Branch length\\n|Concept complexity\\n|min,max,$\\\\mu$,$\\\\sigma$\\n|Nodes per feature\\n|Feature importance\\n|min,max,$\\\\mu$,$\\\\sigma$\\n|Leaves per class\\n|Class complexity [21]\\n|min,max,$\\\\mu$,$\\\\sigma$\\n|Leaves agreement\\n|Class separability [22]\\n|min,max,$\\\\mu$,$\\\\sigma$\\n|Information gain\\n|Feature importance\\n|min,max,$\\\\mu$,$\\\\sigma$, gini\\n|ориентиры (landmarks)\\n|Landmarker(1NN)\\n|$P(\\\\theta_{1NN},t_{j})$\\n|Data sparsity [23]\\n|Landmarker(Tree)\\n|$P(\\\\theta_{Tree},t_{j})$\\n|Data separability\\n|Stump,RandomTree\\n|Landmarker(Lin)\\n|$P(\\\\theta_{Lin},t_{j})$\\n|Linear separability\\n|Lin.Discriminant\\n|Landmarker(NB)\\n|$P(\\\\theta_{NB},t_{j})$\\n|Feature independence\\n|[24]\\n|Relative LM\\n|$P_{a,j} - P_{b,j}$\\n|Probing performance [25]\\n|Subsample LM\\n|$P(\\\\theta_{i},t_{j},s_{t})$\\n|Probing performance [26]\\nНепрерывные признаки $X$ и таргет $Y$ имеют медиану $\\\\mu_{X}$, стандартное отклонение $\\\\sigma_{X}$ и дисперсию $\\\\sigma^{2}_{X}$. Категориальные признаки $\\\\texttt{X}$ и класс $\\\\texttt{C}$ имеют категориальные значения $\\\\pi_{i}$, условные вероятности $\\\\pi_{i|j}$, совместные вероятности $\\\\pi_{i,j}$, предельные вероятности $\\\\pi_{i+}=\\\\sum_{j}\\\\pi_{ij}$ и энтропию $H(\\\\texttt{X})=-\\\\sum_{i}\\\\pi_{i+}log_{2}(\\\\pi_{i+})$.\\nМногие мета-признаки вычисляются по одиночным признакам или их комбинации, и должны быть агрегированы через min, max, $\\\\mu$, $\\\\sigma$, квартили или гистограммы.\\nВо время вычисления похожести задач важно нормализовать все мета-признаки, использовать отбор признаков [27] или использовать уменьшение размерности (например, principal component analisys — PCA).\\nОриентиры (англ. landmarks)\\nОриентиры — один из подходов для описания задач мета-обучения. В отличие от предшественников, использовавших только статистические метрики, ориентиры стараются определить расположение конкретной задачи мета-обучения в пространстве всех задач обучения, измеряя производительность некоторых простых и эффективных алгоритмов. Таким образом, можно сказать, что алгоритм обучения сам характеризуют задачу.\\nОтносительные ориентиры\\nПервая мера для вычисления \"похожести\" задач вычисляла попарно разницу в производительности, так же называемую \"relative landmarks\" $RL_{a,b,j} = P_{a,j} - P_{b,j}$ между двумя конфигурациями $\\\\theta_{a}$ и $\\\\theta_{b}$ на конкретной задаче $t_{j}$.\\nЛинейный дискриминант\\nЛинейный дискриминант (англ. linear discriminant) $P(\\\\theta_{Lin},t_{j})$ можно понимать как группировка и разделение категорий соответствующих конкретным признакам. Линейный дискриминант обычно ищет линейную комбинацию признаков, которая лучше всего разделит классы. Результат — линия, плоскость или гиперплоскость, зависит от числа комбинированных признаков.\\nНаивный Байесовский лэндмарк\\nНаивный Байесовский лэндмарк $P(\\\\theta_{NB},t_{j})$ [28] — вероятностный классификатор, основанный на теореме Байеса. Называется наивным потому что предполагается, что все атрибуты независимы друг от друга.\\n1NN\\nElite 1-nearest neighbor $P(\\\\theta_{1NN},t_{j})$ [29] kNN c $k = 1$. Elite — вариация основного метода, но в этом случае на вход kNN подается предварительно отобранное множество самых информативных примеров (у них минимлаьная разница приращения информации (information gain).Помогает установить, является ли задача релевантной, если похожи их атрибуты.\\nПримечания\\n- ↑ Wolpert and Macready, 1996\\n- ↑ Giraud-Carrier and Provost, 2005\\n- ↑ Datasets meta-feature description for recommending feature selection algorithm\\n- ↑ Ravie & Larochelle, Optimization as a model for a few-shot learning, 2017\\n- ↑ Nadaraya-Watson estimator\\n- ↑ V. A. Epanechnikov, Non-Parametric Estimation of a Multivariate Probability Density\\n- ↑ Donald Michie, David J. Spiegelhalter, Charles C. Taylor, and John Campbell. Machine Learning, Neural and Statistical Classification, 1994\\n- ↑ A. Kalousis. Algorithm Selection via Meta-Learning. PhD thesis, University of Geneva, Department of Computer Science, 2002\\n- ↑ Peter J. Rousseeuw and Mia Hubert. Robust statistics for outlier detection. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 2011.\\n- ↑ Alexandros Kalousis and Melanie Hilario. Model selection via meta-learning: a comparative study.Intl Journ. on Artificial Intelligence Tools, 2001.\\n- ↑ Mostafa A. Salama, Aboul~Ella Hassanien, and Kenneth Revett. Employment of neural network and rough set in meta-learning, 2013.\\n- ↑ Shawkat Ali and Kate~A. Smith-Miles. On learning algorithm selection for classification. Applied Soft Computing, 2006.\\n- ↑ C. Soares, P. Brazdil, and P. Kuba. A meta-learning method to select the kernel width in support vector regression, 2004.\\n- ↑ R ́emi Bardenet, M ́aty ́as Brendel, Bal ́azs K ́egl, and Michele Sebag. Collaborative hyperparameter tuning. In Proceedings of ICML 2013, pages 199–207, 2013\\n- ↑ Ciro Castiello, Giovanna Castellano, and Anna~Maria Fanelli. Meta-data: {C}haracterization of input features for meta-learning, pages 457 -- 468, 2005.\\n- ↑ Feature importance A. Agresti. Categorical Data Analysis. Wiley Interscience, 2002.\\n- ↑ Tin Kam Ho and Mitra Basu. Complexity measures of supervised classification problems. Pattern Analysis and Machine Intellig, 2002.\\n- ↑ R. Vilalta. Understanding accuracy performance through concept characterization and algorithm analysis. ICML Workshop on Recent Advances in Meta-Learning and Future Work, 1999.\\n- ↑ C K\\\\ddot{o}pf and I Iglezakis. Combination of task description strategies and case base properties for meta-learning, 2002.\\n- ↑ Y Peng, P Flach, C Soares, and P Brazdil. Improved dataset characterisation for meta-learning, 2002.\\n- ↑ Andray Filchenkov and Arseniy Pendryak. Dataset metafeature description for recommending feature selection. In \\\\emph{ISMW FRUCT}, pages 11--18, 2015.\\n- ↑ Bernhard Pfahringer, Hilan Bensusan, and Christophe G. Giraud-Carrier. Meta-learning by landmarking various learning algorithms.In \\\\emph{17th International Conference on Machine Learning (ICML), 2000.\\n- ↑ Bernhard Pfahringer, Hilan Bensusan, and Christophe G. Giraud-Carrier. Meta-learning by landmarking various learning algorithms.In \\\\emph{17th International Conference on Machine Learning (ICML)}, pages 743 -- 750, 2000.\\n- ↑ Daren Ler, Irena Koprinska, and Sanjay Chawla. Utilizing regression-based landmarkers within a meta-learning framework for algorithm selection. \\\\emph{Technical Report 569. University of Sydney}, pages 44--51, 2005.\\n- ↑ J F\\\\ddot{u}rnkranz and J Petrak. An evaluation of landmarking variants. \\\\emph{ECML/PKDD 2001 Workshop on Integrating Aspects of Data Mining, Decision Support and Meta-Learning}, pages 57--68, 2001.\\n- ↑ Taciana AF Gomes, Ricardo BC Prudencio, Carlos Soares, Andre LD Rossi and Andre Carvalho. Combining meta-learning and search techniques to select parameters for support vector machines, 2012.\\n- ↑ L Todorovski and S Dzeroski. Experiments in meta-level learning with ILP. Lecture Notes in Computer Science, 1704:98–106, 1999.\\n- ↑ Daren Ler, Irena Koprinska, and Sanjay Chawla. Utilizing regression-based landmarkers within a meta-learning framework for algorithm selection. \\\\emph{Technical Report 569. University of Sydney}, pages 44--51, 2005.\\n- ↑ Bernhard Pfahringer, Hilan Bensusan, and Christophe G. Giraud-Carrier. Meta-learning by landmarking various learning algorithms.In \\\\emph{17th International Conference on Machine Learning (ICML)}, pages 743 -- 750, 2000.\\nСм. Также\\nИсточники информации\\n- https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html#define-the-meta-learning-problem\\n- https://arxiv.org/pdf/1810.03548.pdf\\n- https://www.ml4aad.org/wp-content/uploads/2018/09/chapter2-metalearning.pdf\\n- https://openreview.net/pdf?id=rJY0-Kcll\\n- https://www1.maths.leeds.ac.uk/~charles/statlog/whole.pdf\\n- https://www.fruct.org/publications/ainl-fruct/files/Fil.pdf', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='6bb03001-2738-4973-a058-0cf80647daf3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ecc2c5491d01d0652a0d5a1ac8282262ec908c98a97719faf739a46389cde269', text='Поиск архитектуры нейронной сети\\n|Определение:\\n|Поиск архитектуры нейронной сети (англ. Neural Architecture Search, NAS) — это процесс автоматизации проектирования архитектуры нейронной сети. Другими словами, это процесс поиска лучшей структуры модели машинного обучения. Система NAS получает на вход набор данных и тип задачи (классификация, регрессия и т.д.), и на выходе дает архитектуру модели. Полученная архитектура будет работать лучше остальных архитектур для данного типа задачи при обучении на предоставленном наборе данных.\\nNAS можно рассматривать как часть автоматического машинного обучения (англ. AutoML). NAS существенно пересекается с оптимизацией гиперпараметров. Чтобы из всех возможных архитектур найти нужную, NAS следует стратегии поиска, которая максимизирует производительность.\\nСодержание\\n- 1 Принцип работы\\n- 2 См. также\\n- 3 Примечания\\n- 4 Источники информации\\nПринцип работы\\nМетоды для NAS классифицируются по трем категориям: пространство поиска (англ. Search Space), стратегия поиска (англ. Search Strategy) и стратегия оценки эффективности (англ. Performance Estimation Strategy). Схематичный принцип работы NAS отображен на рисунке 1.\\nПространство поиска (англ. Search Space)\\nПространство поиска определяет, какую нейронную архитектуру в принципе может обнаружить система NAS. Это может быть цепочечная архитектура (рисунок 2, слева), в которой выход уровня [1] (рисунок 2, справа).подается как вход уровня . Или это может быть сложная ветвистая архитектура с пропусками соединений\\nВ некоторых случаях используют спроектированный вручную каркас архитектуры (макроархитектуру), состоящий из повторяющихся ячеек (англ. motifs/blocks/cells). В таких случаях каркас является фиксированным, а задача NAS заключается в поиске архитектуры самих ячеек. Такой тип поиска известен как микро-поиск (англ. cell-search) (рисунок 3).\\nПредварительные знания о типичных свойствах архитектур могут уменьшить размер пространства поиска и упростить поиск. Тем не менее, они также могут помешать человеку найти новые архитектурные ячейки, которые выходят за рамки современных человеческих знаний.\\nНаиболее часто используемые типы архитектур для NAS[2]:\\n- полные архитектуры (англ.entire structures)\\n- прогрессивные архитектуры (англ. progressive structures)\\n- архитектуры, основанные на ячейках (англ. cell-based structures)\\n- архитектуры, основанные на морфизме (англ. morphism-based structures)\\nСтратегия поиска (англ. Search Strategy)\\nСтратегия поиска подробно описывает, как исследовать пространство поиска, которое часто экспоненциально велико или даже неограниченно. Она включает в себя классический компромисс между разведкой и эксплуатацией, поскольку, с одной стороны, желательно найти быстро работающие архитектуры, с другой стороны, следует избегать преждевременного схождения.\\nДля изучения пространства нейронных архитектур можно использовать множество различных стратегий поиска, включая случайный поиск, байесовскую оптимизацию, эволюционные методы, обучение с подкреплением и методы на основе градиента.\\nСравнение методов стратегий поиска\\nЛучшие результаты на сегодняшний день показывает NAS с использованием стратегии байесовской оптимизации[3] (рисунок 4).\\nБайесовская оптимизация (англ. Bayes Optimization, BO) использует алгоритм для построения вероятностной модели целевой функции, а затем использует эту модель, чтобы выбрать наиболее перспективные гиперпараметры и оценивает выбранные гиперпараметры на истинной целевой функции. Таким образом, байесовская оптимизация может итеративно обновлять вероятностную модель, ведя учет оценок прошлых результатов.\\nBANANAS (англ. Bayesian optimization with neural architectures for NAS)\\nСложностью применения байесовской оптимизации в NAS является обязательное наличие функции расстояния между различными архитектурами нейросети. Чтобы обойти этот момент, был разработан BANANAS — алгоритм, использующий специальную кодировку (англ. path encoding) для кодирования входных архитектур и получающий на выходе вероятностные распределения (рисунок 5).\\nАлгоритм BANANAS:\\n- Выбираются случайных архитектур из пространства поиска.\\n- Итерационно проводится обучение ансамбля мета-нейронных сетей на выбранных архитектурах. Каждая сеть ансамбля является сетью прямой связи с полностью связанными слоями, каждому слою дается случайная инициализация весов и случайный порядок обучающего набора. Используемая функция ошибки — вариация MAPE (англ. Mean Absolute Percentage Error).\\n- Далее формируется набор архитектур-кандидатов посредством случайных изменений лучших архитектур после обучения.\\n- Для каждой архитектуры-кандидата определяется значение переданной на вход функции сбора независимой выборки Томпсона (англ. ITS acquisition function).\\n- Для архитектуры-кандидата с минимальным значением функции сбора определяется значение целевой вероятностной функции.\\nСтратегия оценки эффективности (англ. Performance Estimation Strategy)\\nЦелью NAS обычно является поиск архитектуры, обеспечивающей высокую точность прогнозов. Определением этой точности занимается процесс оценки эффективности. Самый простой вариант — выполнить стандартное обучение и проверку архитектуры данных, но это, к сожалению, вычислительно дорого и ограничивает количество архитектур, которые можно изучить. Поэтому многие недавние исследования направлены на разработку методов, способных снизить стоимость оценки эффективности и увеличить скорость. Уже разработанные методы:\\n- Сокращение качества оценки — более высокая скорость достигается сокращением набора данных.\\n- Экстраполяция прямой обучения — функция оценки может быть экстраполирована после всего нескольких обучающих итераций.\\n- Наследование / Сетевые морфизмы — параметры модели не ищутся каждый раз, они наследуются по каким-либо правилам.\\n- Модели One-Shot / Распределение веса — обучается только одна модель, далее ее веса/параметры используются остальными моделями.\\nСм. также\\n- Автоматическое машинное обучение\\n- Настройка гиперпараметров\\n- Обучение с подкреплением\\n- Модель алгоритма и её выбор\\n- Эволюционные алгоритмы\\nПримечания\\n- ↑ англ. Multi-branch neural networks with branch control, пример: multi-branch network\\n- ↑ Источник: \"AutoML: A Survey of the State-of-the-Art\", стр.2\\n- ↑ Cоответствующее исследование.\\nИсточники информации\\n- AutoML: A Survey of the State-of-the-Art Xin He, Kaiyong Zhao, Xiaowen Chu\\n- Bayesian Optimization with Neural Architectures for Neural Architecture Search, Colin White, Willie Neiswanger, Yash Savani\\n- Medium Towards Data Science - Neural Architecture Search (NAS) - The Future Of Deep Learning\\n- Neural Architecture Search: A Survey', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='f236881b-1fe8-4c5d-871b-d054d0f247d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a21f5ded601f49102fd591b2162fc79d0d74a630b58f21f763061494961143a8', text='Обучение с подкреплением\\n|Определение:\\n|Обучение с подкреплением (англ. reinforcement learning) — способ машинного обучения, при котором система обучается, взаимодействуя с некоторой средой.\\nСодержание\\n- 1 Обучение с подкреплением\\n- 2 Алгоритмы\\n- 3 Задача о многоруком бандите (The multi-armed bandit problem)\\n- 4 Q-learning\\n- 5 Ссылки\\nОбучение с подкреплением\\nВ обучении с подкреплением существует агент (agent) взаимодействует с окружающей средой (environment), предпринимая действия (actions). Окружающая среда дает награду (reward) за эти действия, а агент продолжает их предпринимать.\\nАлгоритмы с частичным обучением пытаются найти стратегию, приписывающую состояниям (states) окружающей среды действия, одно из которых может выбрать агент в этих состояниях.\\nСреда обычно формулируется как марковский процесс принятия решений (МППР) с конечным множеством состояний, и в этом смысле алгоритмы обучения с подкреплением тесно связаны с динамическим программированием. Вероятности выигрышей и перехода состояний в МППР обычно являются величинами случайными, но стационарными в рамках задачи.\\nПри обучении с подкреплением, в отличии от обучения с учителем, не предоставляются верные пары \"входные данные-ответ\", а принятие субоптимальнх решений (дающих локальный экстремум) не ограничивается явно. Обучение с подкреплением пытается найти компромисс между исследованием неизученных областей и применением имеющихся знаний (exploration vs exploitation). Баланс изучения-применения при обучении с подкреплением исследуется в задаче о многоруком бандите.\\nФормально простейшая модель обучения с подкреплением состоит из:\\n- множества состояний окружения (states) ;\\n- множества действий (actions) ;\\n- множества вещественнозначных скалярных \"выигрышей\" (rewards).\\nВ произвольный момент времениагент характеризуется состоянием и множеством возможных действий . Выбирая действие , он переходит в состояние и получает выигрыш . Основываясь на таком взаимодействии с окружающей средой, агент, обучающийся с подкреплением, должен выработать стратегию , которая максимизирует величину в случае МППР, имеющего терминальное состояние, или величину:\\n- ,\\nдля МППР без терминальных состояний (где— дисконтирующий множитель для \"предстоящего выигрыша\").\\nТаким образом, обучение с подкреплением особенно хорошо подходит для решения задач, связанных с выбором между долгосрочной и краткосрочной выгодой.\\nПостановка задачи обучения с подкреплением\\n— множество состояний среды\\nИгра агента со средой:\\n- инициализация стратегии и состояния среды ;\\n- для всех\\n:\\n- агент выбирает действие ;\\n- среда генерирует награду и новое состояние ;\\n- агент корректирует стратегию .\\nЭто марковский процесс принятия решений (МППР), если,\\nМППР называется финитным, если,\\nАлгоритмы\\nТеперь, когда была определена функция выигрыша, нужно определить алгоритм, который будет использоваться для нахождения стратегии, обеспечивающей наилучший результат.\\nНаивный подход к решению этой задачи подразумевает следующие шаги:\\n- опробовать все возможные стратегии;\\n- выбрать стратегию с наибольшим ожидаемым выигрышем.\\nПервая проблема такого подхода заключается в том, что количество доступных стратегий может быть очень велико или бесконечно. Вторая проблема возникает, если выигрыши стохастические — чтобы точно оценить выигрыш от каждой стратегии потребуется многократно применить каждую из них. Этих проблем можно избежать, если допустить некоторую структуризацию и, возможно, позволить результатам, полученным от пробы одной стратегии, влиять на оценку для другой. Двумя основными подходами для реализации этих идей являются оценка функций полезности и прямая оптимизация стратегий.\\nПодход с использованием функции полезности использует множество оценок ожидаемого выигрыша только для одной стратегии(либо текущей, либо оптимальной). При этом пытаются оценить либо ожидаемый выигрыш, начиная с состояния , при дальнейшем следовании стратегии ,\\n- ,\\nлибо ожидаемый выигрыш, при принятии решенияв состоянии и дальнейшем соблюдении ,\\n- ,\\nЕсли для выбора оптимальной стратегии используется функция полезности, то оптимальные действия всегда можно выбрать как действия, максимизирующие полезность.\\nЕсли же мы пользуемся функцией, необходимо либо иметь модель окружения в виде вероятностей , что позволяет построить функцию полезности вида\\n- ,\\nлибо применить т.н. метод исполнитель-критик, в котором модель делится на две части: критик, оценивающий полезность состояния, и исполнитель, выбирающий подходящее действие в каждом состоянии.\\nИмея фиксированную стратегию, оценить при можно просто усреднив непосредственные выигрыши. Наиболее очевидный способ оценки при — усреднить суммарный выигрыш после каждого состояния. Однако для этого требуется, чтобы МППР достиг терминального состояния (завершился).\\nПоэтому построение искомой оценки принеочевидно. Однако, можно заметить, что образуют рекурсивное уравнение Беллмана:\\n- ,\\nПодставляя имеющиеся оценки обучения с временными воздействиями (temporal difference (TD) learning). В простейшем случае и состояния, и действия дискретны и можно придерживаться табличных оценок для каждого состояния.и применяя метод градиентного спуска с квадратичной функцией ошибок, мы приходим к алгоритму\\nДругие похожие методы: Адаптивный эвристический критик (Adaptive Heuristic Critic, AHC), SARSA и Q-обучение (Q-learning).\\nЗадача о многоруком бандите (The multi-armed bandit problem)\\nФормулировка\\n— множество возможных действий (ручек автомата),\\n— неизвестное распределение награды ,\\n— стратегия агента в момент .\\nИгра агента со средой:\\n- инициализация стратегии ;\\n- для всех\\n:\\n- агент выбирает действие (ручку) ;\\n- среда генерирует награду ;\\n- агент корректирует стратегию .\\n— средняя награда в t играх\\n, — ценность действия .\\nУ нас есть автомат —-рукий бандит, на каждом шаге мы выбираем за какую из ручек автомата дернуть, т.е. множество действий .\\nВыбор действияна шаге влечет награду при этом есть случайная величина, распределение которой неизвестно.\\nСостояние среды у нас от шага к шагу не меняется, а значит множество состоянийтривиально, ни на что не влияет, поэтому его можно проигнорировать.\\nДля простоты будем полагать, что каждому действию соответствует некоторое распределение, которое не меняется со временем. Если бы мы знали эти распределения, то очевидная стратегия заключалась бы в том, чтобы подсчитать математическое ожидание для каждого из распределений, выбрать действие с максимальным математическим ожиданием и теперь совершать это действие на каждом шаге.\\nПроблема в том, что распределения неизвестны, однако можно оценить математическое ожидание некоторой случайной величиныc неизвестным распределением. Для экспериментов , оценка математического ожидания это среднее арифметическое результатов экспериментов:\\n,\\nЗадача является модельной для понимания конфликта между exploitation-exploration.\\nЖадные и -жадные стратегии (greedy & -greedy)\\nЖадная (greedy) стратегия\\n- — сколько раз было выбрано действие ,\\n- — текущая оценка математического ожидания награды для действия .\\nНа каждом шаге\\n- Выбираем действие с максимальной оценкой математического ожидания:\\n- ,\\n- Выполняем действие и получаем награду ;\\n- Обновляем оценку математического ожидания для действия :\\n- ,\\n- .\\nВ чем проблема?\\nПусть у нас есть \"двурукий\" бандит. Первая ручка всегда выдаёт награду равную 1, вторая всегда выдаёт 2. Действуя согласно жадной стратегии мы дёрнем в начале первую ручку, так как в начале оценки математических ожиданий равны нулю, увеличим её оценку до. В дальнейшем всегда будем выбирать первую ручку, а значит на каждом шаге будем получать на 1 меньше, чем могли бы.\\nВ данном случае достаточно попробовать в начале каждую из ручек вместо того, чтобы фокусироваться только на одной. Но если награда случайная величина, то единичной попытки будет не достаточно. Поэтому модифицируем жадную стратегию следующим образом:\\n-жадная ( -greedy) стратегия\\nВведем параметр.\\nНа каждом шаге\\n- Получим значение — случайной величины равномерно распределенной на отрезке ;\\n- Если , то выберем действие случайно и равновероятно, иначе как в жадной стратегии выберем действие с максимальной оценкой математического ожидания;\\n- Обновляем оценки так же как в жадной стратегии.\\nЕсли, то это обычная жадная стратегия. Однако если , то в отличии от жадной стратегии на каждом шаге с вероятностью присходит \"исследование\" случайных действий.\\nСтратегия Softmax\\nОсновная идея алгоритма softmax — уменьшение потерь при исследовании за счёт более редкого выбора действий, которые небольшую награду в прошлом. Чтобы этого добиться для каждого действия вычисляется весовой коэффициент на базе которого происходит выбор действия. Чем больше, тем больше вероятность выбора :\\n,\\n— параметр, с помощью которого можно настраивать поведение алгоритма.\\nПристратегия стремится к равномерной, то есть softmax будет меньше зависеть от значения выигрыша и выбирать действия более равномерно (exploration).\\nПристратегия стремится к жадной, то есть алгоритм будет больше ориентироваться на известный средний выигрыш действий (exploitation).\\nЭкспонента используется для того, чтобы данный вес был ненулевым даже у действий, награда от которых пока нулевая.\\nЭвристика: параметримеет смысл уменьшать со временем.\\nМетод UCB (upper confidence bound)\\nПредыдущие алгоритмы при принятии решения используют данные о среднем выигрыше. Проблема в том, что если действие даёт награду с какой-то вероятностью, то данные от наблюдений получаются шумные и мы можем неправильно определять самое выгодное действие.\\nАлгоритм верхнего доверительного интервала (upper confidence bound или UCB) — семейство алгоритмов, которые пытаются решить эту проблему, используя при выборе данные не только о среднем выигрыше, но и о том, насколько можно доверять значениям выигрыша.\\nТакже как softmax в UCB при выборе действия используется весовой коэффициент, который представляет собой верхнюю границу доверительного интервала (upper confidence bound) значения выигрыша:\\n,\\n— бонусное значение, которые показывает, насколько недоисследовано действие по сравнению с остальными.\\nДоказательство здесь\\nВ отличие от предыдущих алгоритмов UCB не использует в своей работе ни случайные числа для выбора действия, ни параметры, которыми можно влиять на его работу. В начале работы алгоритма каждое из действий выбирается по одному разу (для того чтобы можно было вычислить размер бонуса для всех действий). После этого в каждый момент времени выбирается действие с максимальным значением весового коэффициента.\\nНесмотря на это отсутствие случайности результаты работы этого алгоритма выглядят довольно шумно по сравнению с остальными. Это происходит из-за того, что данный алгоритм сравнительно часто выбирает недоисследованные действия.\\nQ-learning\\nНа основе получаемого от среды вознаграждения агент формирует функцию полезности, что впоследствии дает ему возможность уже не случайно выбирать стратегию поведения, а учитывать опыт предыдущего взаимодействия со средой. Одно из преимуществ -обучения — то, что оно в состоянии сравнить ожидаемую полезность доступных действий, не формируя модели окружающей среды. Применяется для ситуаций, которые можно представить в виде МППР.\\nТаким образом, алгоритм это функция качества от состояния и действия:\\n- ,\\nПеред обучениеминициализируется случайными значениями. После этого в каждый момент времени агент выбирает действие , получает награду , переходит в новое состояние , которое может зависеть от предыдущего состояния и выбранного действия, и обновляет функцию . Обновление функции использует взвешенное среднее между старым и новым значениями:\\n- ,\\nгдеэто награда, полученная при переходе из состояния в состояние , и это скорость обучения ( ).\\nАлгоритм заканчивается, когда агент переходит в терминальное состояние.\\nAлгоритм Q-learning\\n- — множество состояний,\\n- — множество действий,\\n- — функция награды,\\n- — функция перехода,\\n- — learning rate (обычно 0.1), чем он выше, тем сильнее агент доверяет новой информации,\\n- — discounting factor, чем он меньше, тем меньше агент задумывается о выгоде от будущих своих действий.\\nfun Q-learning(): for : for : Q(s, a) = rand() while Q is not converged: s = while s is not terminal: a = r = R(s, a) s\\' = T(s, a) s = s\\' return Q\\nСсылки\\n- Wikipedia: Reinforcement learning\\n- Sutton, Richard S., and Andrew G. Barto. Introduction to reinforcement learning. Vol. 135. Cambridge: MIT press, 1998.\\n- Sutton R. S., Barto A. G. Reinforcement learning: An introduction. – 2011.\\n- Обучение с подкреплением\\n- Многорукий бандит\\n- Задача о многоруком бандите\\n- Обучение с подкреплением (Reinforcement Learning) К.В.Воронцов\\n- Обзор книги «Bandit Algorithms for Website Optimization»\\n- Q-learning\\n- An introduction to Q-Learning: reinforcement learning', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='54f7cdce-173c-4854-9b0a-995a1a7c7f7a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='641d7d32248a36e49bf14fc90de5940f177fc2710959ec561ab8d99c77705d5f', text='Методы policy gradient и алгоритм асинхронного актора-критика\\nВ алгоритме Q-learning агент обучает функцию полезности действия . Стратегия агента определяется согласно текущим значениям с использованием жадного, -жадного или softmax подхода. Однако существуют методы, которые позволяют оптимизировать стратегию напрямую. Такие алгоритмы относятся к классу алгоритмов policy gradient.\\nСодержание\\n- 1 Простой policy gradient алгоритм (REINFORCE)\\n- 2 Преимущества и недостатки policy gradient по сравнению с Q-learning\\n- 3 Усовершенствования алгоритма\\n- 4 Алгоритм актора-критика с преимуществом (англ. Advantage Actor Critic, A2C)\\n- 5 См. также\\n- 6 Ссылки\\nПростой policy gradient алгоритм (REINFORCE)\\nРассмотрим Марковский процесс принятия решений (МППР), имеющий терминальное состояние. Задача — максимизировать сумму всех выигрышей, где T — шаг, на котором произошел переход в терминальное состояние.\\nБудем использовать буквудля обозначения некоторого сценария — последовательности состояний и произведенных в них действий: . Будем обозначать сумму всех выигрышей, полученных в ходе сценария, как .\\nНе все сценарии равновероятны. Вероятность реализации сценария зависит от поведения среды, которое задается вероятностями перехода между состояниями, распределением начальных состояний и поведения агента, которое определяется его стохастической стратегией . Вероятностное распределение над сценариями, таким образом, задается как\\n- ,\\nМы предполагаем, что вероятности переходов между состояниями агенту неизвестны, то есть у агента нет модели поведения окружающей среды (model-free learning).\\nНам нужно выбрать такой набор параметров агента, задающий , чтобы максимизировать матожидание суммы полученных выигрышей:\\n- ,\\nПусть мы хотим максимизировать функциюметодом градиентного подъема. Для этого нам необходимо уметь рассчитывать ее градиент:\\n- ,\\nМы не можем подсчитатьнапрямую, потому что в выражение для входят вероятности переходов между состояниями, которые агенту неизвестны. Однако, так как\\n- ,\\nто мы можем заменитьна :\\n- ,\\nРассмотрим:\\n- ,\\nТогда:\\n- ,\\nПодставляя в определение:\\n- ,\\nЗаметим, что в получившееся выражение дляуже не входят напрямую значения и , которые нам неизвестны. Таким образом, если у нас есть в наличии сценарий и соответствующее ему значение , мы можем вычислить величину . Значит, если у нас есть выборка из уже известных сценариев , полученная из распределения , то мы можем приблизить посчитать приблизительное значение по методу Монте-Карло — вычислив выборочное среднее случайной величины:\\n- ,\\nОсталось понять, как получить несмещенную выборку сценариевиз вероятностного распределения . Однако это очень просто — нам всего лишь нужно зафиксировать параметр и провзаимодействовать со средой, так как распределение задает именно вероятность реализации сценария при взаимодействии агента с фиксированной стратегией со средой.\\nТаким образом, оптимизироватьможно с помощью следующего простого алгоритма (REINFORCE):\\n- Прогнать сценариев со стратегией ;\\n- Посчитать среднее арифметическое ;\\n- ;\\n- Если не сошлись к экстремуму, повторить с пункта 1.\\nИнтуитивное объяснение принципа работы\\n— это вероятность того, что будет реализован сценарий при условии параметров модели , т. е. функция правдоподобия. Нам хочется увеличить правдоподобие \"хороших\" сценариев (обладающих высоким ) и понизить правдоподобие \"плохих\" сценариев (с низким ).\\nВзглянем еще раз на полученное определение градиента функции полного выигрыша:\\n- ,\\nДвигаясь вверх по этому градиенту, мы повышаем логарифм функции правдоподобия для сценариев, имеющих большой положительный.\\nПреимущества и недостатки policy gradient по сравнению с Q-learning\\nПреимущества:\\n- Легко обобщается на задачи с большим множеством действий, в том числе на задачи с непрерывным множеством действий;\\n- По большей части избегает конфликта между эксплуатацией (exploitation) и исследованием (exploration), так как оптимизирует напрямую стохастическую стратегию ;\\n- Имеет более сильные гарантии сходимости: если Q-learning гарантированно сходится только для МППР с конечными множествами действий и состояний, то policy gradient, при достаточно точных оценках (т. е. при достаточно больших выборках сценариев), сходится к локальному оптимуму всегда, в том числе в случае бесконечных множеств действий и состояний, и даже для частично наблюдаемых Марковских процессов принятия решений (ЧНМППР, англ. partially observed Markov decision process, POMDP).\\nНедостатки:\\n- Очень низкая скорость работы — требуется большое количество вычислений для оценки\\nпо методу Монте-Карло, так как:\\n- для получения всего одного семпла требуется произвести взаимодействий со средой;\\n- случайная величина имеет большую дисперсию, так как для разных значения могут очень сильно различаться, поэтому для точной оценки требуется много семплов;\\n- cемплы, собранные для предыдущих значений , никак не переиспользуются на следующем шаге, семплирование нужно делать заново на каждом шаге градиентного спуска.\\n- В случае конечных МППР Q-learning сходится к глобальному оптимуму, тогда как policy gradient может застрять в локальном.\\nДалее мы рассмотрим способы ускорения работы алгоритма.\\nУсовершенствования алгоритма\\nОпорные значения\\nЗаметим, что если- константа относительно , то\\n- ,\\nтак как\\n- ,\\nТаким образом, изменениена константу не меняет оценку . Однако дисперсия зависит от :\\n- ,\\nпоэтому, регулируя, можно достичь более низкой дисперсии, а значит, более быстрой сходимости метода Монте-Карло к истинному значению . Значение называется опорным значением. Способы определения опорных значений будут рассмотрены далее, в рамках рассмотрения алгоритма актора-критика (Actor-Critic).\\nИспользование будущего выигрыша вместо полного выигрыша\\nРассмотрим еще раз выражение для градиента полного выигрыша:\\n- ,\\nТак как в момент времениот действия зависят только для , это выражение можно переписать как\\n- ,\\nВеличина— будущий выигрыш (reward-to-go) на шаге в сценарии\\nАлгоритм актора-критика с преимуществом (англ. Advantage Actor Critic, A2C)\\nИз предыдущего абзаца:\\n- ,\\nЗдесь— оценка будущего выигрыша из состояния при условии действия , которая базируется только на одном сценарии . Это плохое приближение ожидаемого будущего выигрыша — истинный ожидаемый будущий выигрыш выражается формулой\\n- ,\\nТакже, в целях уменьшения дисперсии случайной величины, введем опорное значение для состояния, которое назовем ожидаемой ценностью (value) этого состояния. Ожидаемая ценность состояния — ожидаемый будущий выигрыш при совершении некоторого действия в этом состоянии согласно стратегии :\\n- ,\\nТаким образом, вместо ожидаемого будущего выигрыша при оценкебудем использовать функцию преимущества (advantage):\\n- ,\\nПреимущество действияв состоянии — величина, характеризующая то, насколько выгоднее в состоянии выбрать именно действие .\\nИтого:\\n- ,\\nКак достаточно точно и быстро оценить? Сведем задачу к оценке :\\n- ,\\n- ,\\nТеперь нам нужно уметь оценивать. Мы можем делать это, опять же, с помощью метода Монте-Карло — так мы получим несмещенную оценку. Но это будет работать не существенно быстрее, чем обычный policy gradient. Вместо этого заметим, что при фиксированных и выполняется:\\n- ,\\nТаким образом, если мы имеем некоторую изначальную оценкудля всех , то мы можем обновлять эту оценку путем, аналогичным алгоритму Q-learning:\\n- ,\\nЗдесь— коэффициент обучения (learning rate) для функции ценности. Такой пересчет мы можем производить каждый раз, когда агент получает вознаграждение за действие. Так мы получим оценку ценности текущего состояния, не зависящую от выбранного сценария развития событий , а значит, и оценка функции преимущества не будет зависеть от выбора конкретного сценария. Это сильно снижает дисперсию случайной величины , что делает оценку достаточно точной даже в том случае, когда мы используем всего один сценарий для ее подсчета:\\n- ,\\nНа практике же мы можем аппроксимироватьна каждом шаге (в онлайне), основываясь на всего одном действии каждый раз. Алгоритм в итоге будет следующим:\\n- производим действие , переходим в состояние и получаем вознаграждение ;\\n- ;\\n- ;\\n- ;\\n- ;\\n- Если не сошлись к экстремуму, повторить с пункта 1.\\nТакой алгоритм называется алгоритмом актора-критика с преимуществом (Advantage Actor-Critic). Актором здесь называется компонента, которая оптимизирует стратегию, а критиком — компонента, которая подсчитывает ценности состояний . Актор определяет дальнейшее действие, а критик оценивает, насколько то или иное действие выгодно, основываясь на функции преимущества (advantage).\\nАлгоритм актора-критика считается гибридным, так как актор работает в соответствии с принципом policy gradient, а критик работает аналогично алгоритму Q-routing.\\nАсинхронный актор-критик (англ. Asynchronous Advantage Actor-Critic, A3C)\\nПроблема с обучением с подкреплением в онлайне заключается в том, что данные, поступающие на вход алгоритму обучения, сильно скоррелированы: каждое следующее состояние непосредственно зависит от предпринятых агентом действий. Обучение на сильно скоррелированных данных приводит к переобучению. Таким образом, для того, чтобы успешно обучить стратегию, обобщаемую на большое количество состояний среды, нам все еще необходимо обучаться на эпизодах из различных сценариев.\\nОдним из способов достичь этого является запуск множества агентов параллельно. Все агенты находятся в разных состояниях и выбирают различные конкретные действия согласно стохастической стратегии, тем самым достигается устранение корреляции между наблюдаемыми данными. Однако все агенты используют и оптимизируют один и тот же набор параметров .\\nИдея алгоритма асинхронного актора-критика заключается в том, чтобы запуститьагентов параллельно, при этом на каждом шаге каждый из агентов рассчитывает обновления для значений и . Однако, вместо того, чтобы просто продолжить работу, каждый агент обновляет и , общие для всех агентов. Перед обработкой каждого нового эпизода агент копирует текущие глобальные значения параметра и использует его, чтобы определить собственную стратегию на этот эпизод. Агенты не ждут, пока остальные агенты завершат обработку своих эпизодов, чтобы обновить глобальные параметры (отсюда асинхронный). Поэтому пока один из агентов обрабатывает один эпизод, глобальное значение может изменяться вследствие действий других агентов.\\nРеализация асинхронного актора-критика на основе нейронных сетей\\nВ большинстве современных исследований стратегияи функция ценности задаются с помощью нейросетей. Каждая из функций может в принципе использовать отдельную нейросеть, но на практике чаще всего применяется совмещенная нейросеть с двумя выходными слоями — для стратегии и для функции ценности. Такой подход, как правило, приводит к лучшим результатам, так как функция ценности, вообще говоря, зависит от текущей стратегии.\\nРеализация алгоритма асинхронного актора-критика инициализирует глобальную нейросеть (master network) и запускает N дочерних процессов (workers), в каждом из которых агент взаимодействует со средой. Нейросеть каждого агента является копией материнской нейросети. Перед началом каждого эпизода веса из материнской нейросети заново копируются в нейросеть агента. Градиенты, посчитанные по агентской нейросети, применяются в итоге к материнской.\\nСм. также\\nСсылки\\n- Williams, Ronald J. \"Simple statistical gradient-following algorithms for connectionist reinforcement learning.\" Machine learning 8.3-4 (1992): 229-256.\\n- Sutton, Richard S., et al. \"Policy gradient methods for reinforcement learning with function approximation.\" Advances in neural information processing systems. 2000.\\n- Policy Gradients. CS 294-112: Deep Reinforcement Learning, Sergey Levine.\\n- Actor-Critic Algorithms. CS 294-112: Deep Reinforcement Learning, Sergey Levine.\\n- Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='48ec81dd-0836-49bb-b00b-1b85994dfcd6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='be834fcdb927eb82c91baabc069866d45e54bbabb8aec9df969d370a87d1e612', text='Обзор библиотек для машинного обучения на Python\\nСодержание\\n- 1 Scikit-learn\\n- 1.1 Описание\\n- 1.2 Примеры кода\\n- 1.2.1 Линейная регрессия\\n- 1.2.2 Логистическая регрессия\\n- 1.2.3 Перцептрон\\n- 1.2.4 Метрический классификатор и метод ближайших соседей\\n- 1.2.5 Дерево решений и случайный лес\\n- 1.2.6 Обработка естественного языка\\n- 1.2.7 Кросс-валилация и подбор параметров\\n- 1.2.8 Метод опорных векторов (SVM)\\n- 1.2.9 EM-алгоритм\\n- 1.2.10 Уменьшение размерности\\n- 2 Tensorflow\\n- 3 Keras\\n- 4 Другие библиотеки для машинного обучения на Python\\n- 5 См. также\\n- 6 Примечания\\nScikit-learn\\nОписание\\nScikit-learn[1] — библиотека машинного обучения на языке программирования Python с открытым исходным кодом. Содержит реализации практически всех возможных преобразований, и нередко ее одной хватает для полной реализации модели. В данной библиотеки реализованы методы разбиения датасета на тестовый и обучающий, вычисление основных метрик над наборами данных, проведение Кросс-валидация[на 28.01.19 не создан]. В библиотеке также есть основные алгоритмы машинного обучения: линейной регрессии[на 28.01.19 не создан] и её модификаций Лассо, гребневой регрессии, опорных векторов[на 28.01.19 не создан], решающих деревьев и лесов и др. Есть и реализации основных методов кластеризации. Кроме того, библиотека содержит постоянно используемые исследователями методы работы с признаками: например, понижение размерности методом главных компонент[на 28.01.19 не создан]. Частью пакета является библиотека imblearn[2], позволяющая работать с разбалансированными выборками и генерировать новые значения.\\nПримеры кода\\nЛинейная регрессия\\n# Add required imports import matplotlib.pyplot as plt import numpy as np from sklearn import datasets from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score\\nЗагрузка датасета:\\ndiabetes = datasets.load_diabetes() # Use only one feature diabetes_X = diabetes.data[:, np.newaxis, 2]\\nРазбиение датасета на тренировочный и тестовый:\\n# Split the data into training/testing sets x_train = diabetes_X[:-20] x_test = diabetes_X[-20:] # Split the targets into training/testing sets y_train = diabetes.target[:-20] y_test = diabetes.target[-20:]\\nПостроение и обучение модели:\\nlr = LinearRegression() lr.fit(x_train, y_train) predictions = lr.predict(x_test)\\nОценка алгоритма:\\n# The mean squared error print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predictions)) # Explained variance score: 1 is perfect prediction print(\\'Variance score: %.2f\\' % r2_score(y_test, predictions))\\n> Mean squared error: 2548.07 Variance score: 0.47\\nПостроение графика прямой, получившейся в результате работы линейной регрессии:\\nplt.scatter(x_test, y_test, color=\\'black\\') plt.plot(x_test, predictions, color=\\'blue\\', linewidth=3) plt.xticks(()) plt.yticks(()) plt.show()\\nЛогистическая регрессия\\nЗагрузка датасета:\\nfrom sklearn.datasets import load_digits digits = load_digits()\\nВывод первых трех тренировочных данных для визуализации:\\nimport numpy as np import matplotlib.pyplot as plt plt.figure(figsize=(20,4)) for index, (image, label) in enumerate(zip(digits.data[0:3], digits.target[0:3])): plt.subplot(1, 3, index + 1) plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray) plt.title(\\'Training: %i\\\\n\\' % label, fontsize = 20)\\nРазбиение датасета на тренировочный и тестовый:\\nfrom sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)\\nПостроение и обучение модели:\\nfrom sklearn.linear_model import LogisticRegression lr = LogisticRegression() lr.fit(x_train, y_train) predictions = lr.predict(x_test)\\nОценка алгоритма:\\nscore = lr.score(x_test, y_test) print(\"Score: %.3f\" % score)\\n> Score: 0.953\\nПерцептрон\\nЗагрузка датасета:\\nfrom sklearn import datasets iris = datasets.load_iris() X = iris.data y = iris.target\\nРазбиение датасета на тренировочный и тестовый:\\nfrom sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\\nТрансформация признаков:\\nfrom sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(X_train) X_train = scaler.transform(X_train) X_test = scaler.transform(X_test)\\nПостроение и обучение модели:\\nfrom sklearn.neural_network import MLPClassifier mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000) mlp.fit(X_train, y_train.values.ravel()) predictions = mlp.predict(X_test)\\nОценка алгоритма:\\nfrom sklearn.metrics import classification_report, confusion_matrix print(confusion_matrix(y_test,predictions)) print(classification_report(y_test,predictions))\\n> [[ 7 0 0] [ 0 8 1] [ 0 2 12]] precision recall f1-score support 0 1.00 1.00 1.00 7 1 0.80 0.89 0.84 9 2 0.92 0.86 0.89 14 micro avg 0.90 0.90 0.90 30 macro avg 0.91 0.92 0.91 30 weighted avg 0.90 0.90 0.90 30\\nМетрический классификатор и метод ближайших соседей\\nДерево решений и случайный лес\\nОбработка естественного языка\\nЗагрузка датасета:\\nfrom sklearn import fetch_20newsgroups twenty_train = fetch_20newsgroups(subset=\\'train\\', shuffle=True, random_state=42)\\nВывод первых трех строк первого тренивочного файла и его класса:\\nprint(\"\\\\n\".join(twenty_train.data[0].split(\"\\\\n\")[:3])) print(twenty_train.target_names[twenty_train.target[0]])\\n> From: lerxst@wam.umd.edu (where\\'s my thing) Subject: WHAT car is this!? Nntp-Posting-Host: rac3.wam.umd.edu rec.autos\\nПостроение и обучение двух моделей. Первая на основе Байесовской классификации[на 28.01.19 не создан], а вторая использует метод опорных векторов:\\nfrom sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer from sklearn.naive_bayes import MultinomialNB text_clf1 = Pipeline([ (\\'vect\\', CountVectorizer()), (\\'tfidf\\', TfidfTransformer()), (\\'clf\\', MultinomialNB()), ]) from sklearn.linear_model import SGDClassifier text_clf2 = Pipeline([ (\\'vect\\', CountVectorizer()), (\\'tfidf\\', TfidfTransformer()), (\\'clf\\', SGDClassifier(loss=\\'hinge\\', penalty=\\'l2\\', alpha=1e-3, random_state=42, max_iter=5, tol=None)), ]) text_clf1.fit(twenty_train.data, twenty_train.target) text_clf2.fit(twenty_train.data, twenty_train.target)\\nОценка алгоритмов:\\ntwenty_test = fetch_20newsgroups(subset=\\'test\\', shuffle=True, random_state=42) docs_test = twenty_test.data predicted1 = text_clf1.predict(docs_test) predicted2 = text_clf2.predict(docs_test) print(\"Score: %.3f\" % np.mean(predicted1 == twenty_test.target)) print(\"Score: %.3f\" % np.mean(predicted2 == twenty_test.target))\\n> Score for naive Bayes: 0.774 Score for SVM: 0.824\\nКросс-валилация и подбор параметров\\nВозьмем предыдущий пример с обработкой естественного языка и попробуем увеличить точность алгоритма за счет кросс-валидации и подбора параметров:\\nfrom sklearn.model_selection import GridSearchCV parameters = { \\'vect__ngram_range\\': [(1, 1), (1, 2)], \\'tfidf__use_idf\\': (True, False), \\'clf__alpha\\': (1e-2, 1e-3), } gs_clf = GridSearchCV(text_clf2, parameters, cv=5, iid=False, n_jobs=-1) gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target) print(\"Best score: %.3f\" % gs_clf.best_score_) for param_name in sorted(parameters.keys()): print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\\n> Best score: 0.904 clf__alpha: 0.001 tfidf__use_idf: True vect__ngram_range: (1, 2)\\nМетод опорных векторов (SVM)\\nЗагрузка датасета:\\nfrom sklearn import datasets iris = datasets.load_iris()\\nРазбиение датасета на тестовый и тренировочный:\\nfrom sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=0)\\nПостроение и обучение модели:\\nclf = svm.SVC(kernel=\\'linear\\', C=1.0) clf.fit(x_train, y_train) predictions = clf.predict(x_test)\\nОценка алгоритма:\\nfrom sklearn.metrics import classification_report, confusion_matrix print(confusion_matrix(y_test,predictions)) print(classification_report(y_test,predictions))\\n> [[13 0 0] [ 0 15 1] [ 0 0 9]] precision recall f1-score support 0 1.00 1.00 1.00 13 1 1.00 0.94 0.97 16 2 0.90 1.00 0.95 9 micro avg 0.97 0.97 0.97 38 macro avg 0.97 0.98 0.97 38 weighted avg 0.98 0.97 0.97 38\\nEM-алгоритм\\nimport numpy as np import matplotlib.pyplot as plt from matplotlib.colors import LogNorm from sklearn import mixture n_samples = 300 # generate random sample, two components np.random.seed(0) # generate spherical data centered on (20, 20) shifted_gaussian = np.random.randn(n_samples, 2) + np.array([20, 20]) # generate zero centered stretched Gaussian data C = np.array([[0., -0.7], [3.5, .7]]) stretched_gaussian = np.dot(np.random.randn(n_samples, 2), C) # concatenate the two datasets into the final training set X_train = np.vstack([shifted_gaussian, stretched_gaussian]) # fit a Gaussian Mixture Model with two components clf = mixture.GaussianMixture(n_components=2, covariance_type=\\'full\\') clf.fit(X_train) # display predicted scores by the model as a contour plot x = np.linspace(-20., 30.) y = np.linspace(-20., 40.) X, Y = np.meshgrid(x, y) XX = np.array([X.ravel(), Y.ravel()]).T Z = -clf.score_samples(XX) Z = Z.reshape(X.shape) CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=1000.0), levels=np.logspace(0, 3, 10)) CB = plt.colorbar(CS, shrink=0.8, extend=\\'both\\') plt.scatter(X_train[:, 0], X_train[:, 1], .8) plt.title(\\'Negative log-likelihood predicted by a GMM\\') plt.axis(\\'tight\\') plt.show()\\nУменьшение размерности\\nTensorflow\\nОписание\\nTensorflow[3] — библиотека, разработанная корпорацией Google для работы с тензорами, используется для построения нейронных сетей. Поддержка вычислений на видеокартах имеет поддержку языка программирования C++. На основе данной библиотеки строятся более высокоуровневые библиотеки для работы с нейронными сетями на уровне целых слоев. Так, некоторое время назад популярная библиотека Keras стала использовать Tensorflow как основной бэкенд для вычислений вместо аналогичной библиотеки Theano. Для работы на видеокартах NVIDIA используется библиотека cuDNN. Если вы работаете с картинками (со сверточными нейросетями), скорее всего, придется использовать данную библиотеку.\\nПримеры кода\\nСверточная нейронная сеть\\nРеализация сверточной нейронной сети для классификации цифр из датасета MNIST:\\nfrom __future__ import division, print_function, absolute_import import tensorflow as tf # Import MNIST data from tensorflow.examples.tutorials.mnist import input_data mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True) # Training Parameters learning_rate = 0.001 num_steps = 200 batch_size = 128 display_step = 10 # Network Parameters num_input = 784 # MNIST data input (img shape: 28*28) num_classes = 10 # MNIST total classes (0-9 digits) dropout = 0.75 # Dropout, probability to keep units # tf Graph input X = tf.placeholder(tf.float32, [None, num_input]) Y = tf.placeholder(tf.float32, [None, num_classes]) keep_prob = tf.placeholder(tf.float32) # dropout (keep probability) # Create some wrappers for simplicity def conv2d(x, W, b, strides=1): # Conv2D wrapper, with bias and relu activation x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=\\'SAME\\') x = tf.nn.bias_add(x, b) return tf.nn.relu(x) def maxpool2d(x, k=2): # MaxPool2D wrapper return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=\\'SAME\\') # Create model def conv_net(x, weights, biases, dropout): # MNIST data input is a 1-D vector of 784 features (28*28 pixels) # Reshape to match picture format [Height x Width x Channel] # Tensor input become 4-D: [Batch Size, Height, Width, Channel] x = tf.reshape(x, shape=[-1, 28, 28, 1]) # Convolution Layer conv1 = conv2d(x, weights[\\'wc1\\'], biases[\\'bc1\\']) # Max Pooling (down-sampling) conv1 = maxpool2d(conv1, k=2) # Convolution Layer conv2 = conv2d(conv1, weights[\\'wc2\\'], biases[\\'bc2\\']) # Max Pooling (down-sampling) conv2 = maxpool2d(conv2, k=2) # Fully connected layer # Reshape conv2 output to fit fully connected layer input fc1 = tf.reshape(conv2, [-1, weights[\\'wd1\\'].get_shape().as_list()[0]]) fc1 = tf.add(tf.matmul(fc1, weights[\\'wd1\\']), biases[\\'bd1\\']) fc1 = tf.nn.relu(fc1) # Apply Dropout fc1 = tf.nn.dropout(fc1, dropout) # Output, class prediction out = tf.add(tf.matmul(fc1, weights[\\'out\\']), biases[\\'out\\']) return out # Store layers weight & bias weights = { # 5x5 conv, 1 input, 32 outputs \\'wc1\\': tf.Variable(tf.random_normal([5, 5, 1, 32])), # 5x5 conv, 32 inputs, 64 outputs \\'wc2\\': tf.Variable(tf.random_normal([5, 5, 32, 64])), # fully connected, 7*7*64 inputs, 1024 outputs \\'wd1\\': tf.Variable(tf.random_normal([7*7*64, 1024])), # 1024 inputs, 10 outputs (class prediction) \\'out\\': tf.Variable(tf.random_normal([1024, num_classes])) } biases = { \\'bc1\\': tf.Variable(tf.random_normal([32])), \\'bc2\\': tf.Variable(tf.random_normal([64])), \\'bd1\\': tf.Variable(tf.random_normal([1024])), \\'out\\': tf.Variable(tf.random_normal([num_classes])) } # Construct model logits = conv_net(X, weights, biases, keep_prob) prediction = tf.nn.softmax(logits) # Define loss and optimizer loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( logits=logits, labels=Y)) optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) train_op = optimizer.minimize(loss_op) # Evaluate model correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1)) accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) # Initialize the variables (i.e. assign their default value) init = tf.global_variables_initializer() # Start training with tf.Session() as sess: # Run the initializer sess.run(init) for step in range(1, num_steps+1): batch_x, batch_y = mnist.train.next_batch(batch_size) # Run optimization op (backprop) sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.8}) if step % display_step == 0 or step == 1: # Calculate batch loss and accuracy loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0}) print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\\ \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\\ \"{:.3f}\".format(acc)) print(\"Optimization Finished!\") # Calculate accuracy for 256 MNIST test images print(\"Testing Accuracy:\", \\\\ sess.run(accuracy, feed_dict={X: mnist.test.images[:256], Y: mnist.test.labels[:256], keep_prob: 1.0}))\\n> Step 1, Minibatch Loss= 41724.0586, Training Accuracy= 0.156 Step 10, Minibatch Loss= 17748.7500, Training Accuracy= 0.242 Step 20, Minibatch Loss= 8307.6162, Training Accuracy= 0.578 Step 30, Minibatch Loss= 3108.5703, Training Accuracy= 0.766 Step 40, Minibatch Loss= 3273.2749, Training Accuracy= 0.727 Step 50, Minibatch Loss= 2754.2861, Training Accuracy= 0.820 Step 60, Minibatch Loss= 2467.7925, Training Accuracy= 0.844 Step 70, Minibatch Loss= 1423.8140, Training Accuracy= 0.914 Step 80, Minibatch Loss= 1651.4656, Training Accuracy= 0.875 Step 90, Minibatch Loss= 2105.9263, Training Accuracy= 0.867 Step 100, Minibatch Loss= 1153.5090, Training Accuracy= 0.867 Step 110, Minibatch Loss= 1751.1400, Training Accuracy= 0.898 Step 120, Minibatch Loss= 1446.2119, Training Accuracy= 0.922 Step 130, Minibatch Loss= 1403.7135, Training Accuracy= 0.859 Step 140, Minibatch Loss= 1089.7897, Training Accuracy= 0.930 Step 150, Minibatch Loss= 1147.0751, Training Accuracy= 0.898 Step 160, Minibatch Loss= 1963.3733, Training Accuracy= 0.883 Step 170, Minibatch Loss= 1544.2725, Training Accuracy= 0.859 Step 180, Minibatch Loss= 977.9219, Training Accuracy= 0.914 Step 190, Minibatch Loss= 857.7977, Training Accuracy= 0.930 Step 200, Minibatch Loss= 430.4735, Training Accuracy= 0.953 Optimization Finished! Testing Accuracy: 0.94140625\\nKeras\\nОписание\\nKeras[4] — библиотека для построения нейронных сетей, поддерживающая основные виды слоев и структурные элементы. Поддерживает как рекуррентные, так и сверточные нейросети, имеет в своем составе реализацию известных архитектур нейросетей (например, VGG16). Некоторое время назад слои из данной библиотеки стали доступны внутри библиотеки Tensorflow. Существуют готовые функции для работы с изображениями и текстом. Интегрирована в Apache Spark с помощью дистрибутива dist-keras. Данная библиотека позволяет на более высоком уровне работать с нейронными сетями. В качестве библиотеки для бэкенда может использоваться как Tensorflow, так и Theano.\\nПримеры кода\\nСверточная нейронная сеть\\nРеализация сверточной нейронной сети для классификации текста:\\nfrom __future__ import print_function from keras.preprocessing import sequence from keras.models import Sequential from keras.layers import Dense, Dropout, Activation from keras.layers import Embedding from keras.layers import Conv1D, GlobalMaxPooling1D from keras.datasets import imdb # set parameters: max_features = 5000 maxlen = 400 batch_size = 32 embedding_dims = 50 filters = 250 kernel_size = 3 hidden_dims = 250 epochs = 2 (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) print(len(x_train), \\'train sequences\\') print(len(x_test), \\'test sequences\\')\\n> 25000 train sequences 25000 test sequences\\nprint(\\'Pad sequences (samples x time)\\') x_train = sequence.pad_sequences(x_train, maxlen=maxlen) x_test = sequence.pad_sequences(x_test, maxlen=maxlen) print(\\'x_train shape:\\', x_train.shape) print(\\'x_test shape:\\', x_test.shape)\\n> Pad sequences (samples x time) x_train shape: (25000, 400) x_test shape: (25000, 400)\\nmodel = Sequential() model.add(Embedding(max_features, embedding_dims, input_length=maxlen)) model.add(Dropout(0.2)) model.add(Conv1D(filters, kernel_size, padding=\\'valid\\', activation=\\'relu\\', strides=1)) model.add(GlobalMaxPooling1D()) model.add(Dense(hidden_dims)) model.add(Dropout(0.2)) model.add(Activation(\\'relu\\')) model.add(Dense(1)) model.add(Activation(\\'sigmoid\\')) model.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\']) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\\n> Train on 25000 samples, validate on 25000 samples Epoch 1/2 25000/25000 [==============================] - 136s 5ms/step - loss: 0.4107 - acc: 0.7923 - val_loss: 0.2926 - val_acc: 0.8746 Epoch 2/2 25000/25000 [==============================] - 136s 5ms/step - loss: 0.2294 - acc: 0.9082 - val_loss: 0.3200 - val_acc: 0.8652\\nДругие библиотеки для машинного обучения на Python\\nВспомогательные библиотеки\\n- NumPy[5] — библиотека, добавляющая поддержку больших многомерных массивов и матриц вместе с большой библиотекой высокоуровневых математических функций для операций с этими массивами. Данная библиотека предоставляет реализации вычислительных алгоритмов (в виде функций и операторов), оптимизированные для работы с многомерными массивами. В результате любой алгоритм, который может быть выражен в виде последовательности операций над массивами (матрицами) и реализованный с использованием NumPy, работает так же быстро, как эквивалентный код, выполняемый в MATLAB[6];\\n- SciPy[7] — открытая библиотека высококачественных научных инструментов для языка программирования Python. SciPy содержит модули для оптимизации, интегрирования, специальных функций, обработки сигналов, обработки изображений, генетических алгоритмов, решения обыкновенных дифференциальных уравнений и других задач, обычно решаемых в науке и при инженерной разработке;\\n- Pandas[8] — библиотека Python, которая является мощным инструментом для анализа данных. Пакет дает возможность строить сводные таблицы, выполнять группировки, предоставляет удобный доступ к табличным данным и позволяет строить графики на полученных наборах данных при помощи библиотеки Matplotlib;\\n- Matplotlib[9] — библиотека Python для построения качественных двумерных графиков. Matplotlib является гибким, легко конфигурируемым пакетом, который вместе с NumPy, SciPy и IPython[10] предоставляет возможности, подобные MATLAB.\\n- Autograd - Библиотека автодифференциирования функций на numpy. ПОзволяет делать простые нейросети и оптимизацию научных расчётов. Для тяжёлого лучше использовать GPU-библиотеки.\\n- JAX - улучшенный autograd.\\n- Tensor shape annotation lib - позволяет назначить измерениям тензора человекочитаемые метки\\nБиблиотеки для глубокого обучения\\n- Tenzorflow[11] - открытая программная библиотека для машинного обучения, разработанная компанией Google для решения задач построения и тренировки нейронной сети с целью автоматического нахождения и классификации образов, достигая качества человеческого восприятия. Широко применяется в бизнес-приложениях.\\n- PyTorch[12] — библиотека для глубокого обучения, созданная на базе Torch[13] и развиваемая компанией Facebook. Две ключевые функциональности данной библиотеки — тензорные вычисления с развитой поддержкой ускорения на GPU (OpenCL) и глубокие нейронные сети на базе системы autodiff;\\n- Theano[14] — расширение языка программирования Python, позволяющее эффективно вычислять математические выражения, содержащие многомерные массивы. Библиотека предоставляет базовый набор инструментов для конфигурации нейронных сетей и их обучения. Наибольшее признание данная библиотека получила в задачах машинного обучения при решении задач оптимизации. Она позволяет использовать возможности GPU без изменения кода программы, что делает ее незаменимой при выполнении ресурсоемких задач;\\n- Caffe[15] — фреймворк для обучения нейронных сетей, созданный университетом Беркли. Как и Tensorflow, использует cuDNN для работы с видеокартами NVIDIA;\\n- Microsoft Cognitive Toolkit (CNTK)[16] — фреймворк от корпорации Microsoft, предоставляющий реализации архитектур различных нейронных сетей.\\n- plaidml - ещё одна библиотека на OpenCL, умеющая компилировать граф в оптимизированные кастомные ядра OpenCL.\\nБиблиотеки для обработки естественного языка\\n- NLTK[17] — пакет библиотек и программ для символьной и статистической обработки естественного языка, написанных на языке программирования Python;\\n- Gensim[18] — инструмент для автоматической обработки языка, основанный на машинном обучении. В Gensim реализованы алгоритмы дистрибутивной семантики word2vec и doc2vec, он позволяет решать задачи тематического моделирования и выделять основные темы текста или документа.\\nБиблиотеки для градиентного бустинга\\n- Xgboost[на 28.01.19 не создан][19] — библиотека с реализацией градиентного бустинга, которая для выбора разбиения использует сортировку и модели, основанные на анализе гистограмм;\\n- LightGBM[20] — фреймворк с реализацией градиентного бустинга от корпорации Microsoft. Является частью проекта Microsoft DMTK, посвященного реализации подходов машинного обучения для .Net;\\n- CatBoost[21] — библиотека с градиентным бустингом от компании Яндекс, в которой реализуется особый подход к обработке категориальных признаков, основанный на подмене категориальных признаков статистиками на основе предсказываемого значения.\\nСм. также\\n- Примеры кода на Scala\\n- Примеры кода на R[на 28.01.19 не создан]\\n- Примеры кода на Java\\nПримечания\\n- ↑ Библиотека scikit-learn\\n- ↑ Библиотека imbalanced-learn\\n- ↑ Библиотека Tensorflow\\n- ↑ Библиотека Keras\\n- ↑ Библиотека NumPy\\n- ↑ MATLAB\\n- ↑ Библиотека SciPy\\n- ↑ Библиотека Pandas\\n- ↑ Библиотека Matplotlib\\n- ↑ IPython Notebook\\n- ↑ https://www.tensorflow.org\\n- ↑ Библиотека PyTorch\\n- ↑ Torch\\n- ↑ Библиотека Theano\\n- ↑ Библиотека Caffe\\n- ↑ Библиотека CNTK\\n- ↑ Библиотека NLTK\\n- ↑ Библиотека Gensim\\n- ↑ Библиотека Xgboost\\n- ↑ Библиотека LightGBM\\n- ↑ Библиотека CatBoost', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='aa840f37-07a2-4736-9e9d-f48bdbd7ca4d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7a102c34f448e4529f06e63b06dcd1c6b037e2304559f8e33bcf598c9310cea5', text='Многопоточность в машинном обучении\\nДля применения машинного обучения на практике часто нужно обработать большое количество данных и на это уходит много времени. Использование многопоточности и других видов параллелизма позволяет значительно ускорить вычисления, иногда даже без изменения самого алгоритма.\\nСледует выделить следующие виды параллелизма:\\n- Параллелизм на уровне инструкций (англ. instruction-level parallelism, ILP[1]): несколько инструкций исполняются одновременно.\\n- Параллелизм типа одна инструкция множество данных (англ. single instruction, multiple data, SIMD[2]): одна операция применяется к множеству данных.\\n- Многопоточный параллелизм: несколько независимых рабочих потоков взаимодействуют через абстракцию совместно используемой памяти.\\n- Распределенные вычисления: несколько независимых рабочих компьютеров взаимодействуют по сети (MLlib[3] на Spark, Mahout[4] на Hadoop).\\nСодержание\\n- 1 Идеи используемые для ускорения вычислений в машинном обучении\\n- 1.1 Параллелизм для ускорения линейной алгебры\\n- 1.2 Параллелизм в оптимизации гиперпараметров\\n- 1.3 Параллелизм кросс-валидации\\n- 1.4 Параллелизм GPU[7]\\n- 1.5 Параллелизм в стохастическом градиентном спуске\\n- 1.6 Параллелизм в методе k ближайших соседей\\n- 1.7 Параллелизм в методе опорных векторов\\n- 1.8 Параллелизм в линейной регрессии\\n- 2 См. также\\n- 3 Примечания\\n- 4 Источники информации\\nИдеи используемые для ускорения вычислений в машинном обучении\\nПараллелизм для ускорения линейной алгебры\\nМногие операции линейной алгебры, например, векторное сложение, произведение матриц и вычисление нормы состоят из большого количества независимых операций. Поэтому можно сильно повысить их производительность как за счёт ILP и SIMD параллелизма для маленьких данных, так и за счёт многопоточности для больших данных. От ускорения линейной алгебры особенно выигрывают нейронные сети, так как большую часть времени их работы занимает умножение матриц.\\nНекоторые действия, выполняемые в цикле, можно записать как операции над матрицами, полученными повторением матриц меньшей размерности. Например, сложение каждой строки матрицы с вектором — это сложение двух матриц, в одной из которых повторяются строки. Бродкастинг (англ. broadcasting[5][6]) позволяет выполнять операции с аргуметами разных размерностей, неявно приводя их к одной. При этом из пользовательского кода исчезают циклы, а задача оптимизации переходит к разработчику библиотеки, который может обеспечить лучший параллелизм операций за счет доступа к внутренностям библиотеки.\\nПримеры оптимизаций:\\n- Высоко оптимизированные тензорные библиотеки для арифметики.\\n- Алгоритмы в терминах матричных операций, а не векторных операций, насколько это возможно.\\n- Бродкастинг вместо циклов.\\n- Распараллеленные реализации некоторых специальных операций (таких как свертки для сверточных сетей).\\nПараллелизм в оптимизации гиперпараметров\\nДля параллельной оптимизации гиперпараметров можно использовать поиск по решётке или случайный поиск в которых мы можем оценить параметры независимо. Такая оптимизации часто встречаются в библиотеках машинного обучения.\\nПараллелизм кросс-валидации\\nПолная кросс-валидация, k-fold, t×k-fold, Leave-One-Out легко распараллеливаются на несколько потоков, каждый из которых работает на своем разбиении данных\\nПараллелизм GPU[7]\\nГрафические процессоры позволяют применять одну и ту же операцию параллельно к десяткам тысяч элементов за счет большого числа потоков.\\nФреймворки машинного обучения, такие как TensorFlow, PyTorch и MxNet используют эти возможности через библиотеки от компаний производителей графических ускорителей и открытые фреймворки:\\n- CUDA[8] — язык параллельного программирования/вычислительная платформа для вычислений общего назначения на графическом процессоре\\n- cuBLAS[9] — библиотека представляет собой реализацию базовых подпрограмм линейной алгебры (англ. Basic Linear Algebra Subprograms, BLAS) поверх среды выполнения CUDA.\\n- OpenCL[10] — фреймворк для написания компьютерных программ, связанных с параллельными вычислениями на различных графических и центральных процессорах, а также программируемых пользователем вентильных матрицах (ППВМ, англ. field-programmable gate array, FPGA[11]).\\nПример перемножения матриц на C с использованием cuBLAS:\\nvoid gpu_blas_mmul(cublasHandle_t &handle, const float *A, const float *B, float *C, const int m, const int k, const int n) { int lda = m, ldb = k, ldc = m; const float alf = 1; const float bet = 0; const float *alpha = &alf; const float *beta = &bet; // Do the actual multiplication cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, n, k, alpha, A, lda, B, ldb, beta, C, ldc); }\\nПример перемножения матриц на питоне с использованием PyCUDA:\\nimport pycuda.gpuarray as gpuarray import numpy as np import skcuda.linalg as linalg # --- Initializations import pycuda.autoinit linalg.init() A = np.array(([1, 2, 3], [4, 5, 6])).astype(np.float64) B = np.array(([7, 8, 1, 5], [9, 10, 0, 9], [11, 12, 5, 5])).astype(np.float64) A_gpu = gpuarray.to_gpu(A) B_gpu = gpuarray.to_gpu(B) C_gpu = linalg.dot(A_gpu, B_gpu) print(np.dot(A, B)) print(C_gpu)\\nНаивная реализация перемножения матриц на OpenCL:\\n// First naive implementation __kernel void myGEMM1(const int M, const int N, const int K, const __global float *A, const __global float *B, __global float *C) { // Thread identifiers const int globalRow = get_global_id(0); // Row ID of C (0..M) const int globalCol = get_global_id(1); // Col ID of C (0..N) // Compute a single element (loop over K) float acc = 0.0f; for (int k = 0; k < K; k++) { acc += A[k * M + globalRow] * B[globalCol * K + k]; } // Store the result C[globalCol * M + globalRow] = acc; }\\nПараллелизм в стохастическом градиентном спуске\\nМожно запустить внешний цикл стохастического градиентного спуска (SGD) параллельно в пуле потоков и использовать конструкции синхронизации, такие как блокировки, чтобы предотвратить состояние гонки. Однако из-за накладных расходов на синхронизацию ускорение может получиться маленьким.\\nЕще более интересная идея называется асинхронным SGD или Hogwild[12]. SGD запускается параллельно в несколько потоков без какой-либо синхронизации. Теперь состояния гонки могут возникнуть, но во многих случаях это хорошо, потому что они просто немного изменяют шум и ошибки уже присутствующие из-за случайного выбора градиента.\\nПараллелизм в методе k ближайших соседей\\nОсновное время работы метода k ближайших соседей составляет поиск ближайших соседей. Так как расстояния до разных объектов независимы, то можно разбить объекты на группы, параллельно решить задачу во всех группах, а потом объединить результат[13]. Альтернативный подход — параллельная сортировка всех объектов, например, с использованием битонной сортировки[14].\\nПараллелизм в методе опорных векторов\\nВычислительная сложность метода опорных векторов заключается в минимизации квадратичной функции. Первый вариант распараллеливания задачи — добавление параллелизма в алгоритм в явном виде, например, параллельная оптимизация большего количества переменных в SMO[15]. Второй подход — запись алгоритма через матричные операции, которые легко параллелизируемы, например, можно обновлять вектор из оптимизируемых параметров через умножение на матрицы[16].\\nПараллелизм в линейной регрессии\\nПри использовании метода наименьших квадратов поиск коэффициентов регрессии сводится к нахождению псевдообратной матрицы. Хотя псевдообратную матрицу можно вычислить через обратную и для этого существуют параллельные алгоритмы, такой подход остается непрактичным. Более популярный способ, основанный на сингулярном разложении, можно сделать параллельным, если в процессе использовать метод Якоби для собственных значений и на каждом шаге обрабатывать несколько строк и столбцов[17]. Также можно использовать параллельный алгоритм для QR-разложения как это сделано в ScaLAPACK[18].\\nСм. также\\n- Стохастический градиентный спуск\\n- Кросс-валидация\\n- Настройка гиперпараметров\\n- Метод опорных векторов (SVM)\\n- Метрический классификатор и метод ближайших соседей\\nПримечания\\n- ↑ ILP\\n- ↑ SIMD\\n- ↑ MLlib\\n- ↑ Mahout\\n- ↑ Broadcasting — NumPy v1.19 Manual\\n- ↑ Broadcasting (GNU Octave (version 6.1.0))\\n- ↑ GPU\\n- ↑ CUDA\\n- ↑ cuBLAS\\n- ↑ OpenCL\\n- ↑ Программируемая пользователем вентильная матрица\\n- ↑ Feng Niu, Benjamin Recht, Christopher Re, Stephen J. Wright (2011) HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent\\n- ↑ Ahmed S. J. Abu Hammad (2019) Implementation of a Parallel K-Nearest Neighbor Algorithm Using MPI\\n- ↑ Nikos Sismanis, Nikos P. Pitsianis, Xiaobai Sun (2012) Parallel Search of k-Nearest Neighbors with Synchronous Operations\\n- ↑ Dominik Brugger (2006) Parallel Support Vector Machines\\n- ↑ Fei Sha, Yuanqing Lin, Lawrence K. Saul, Daniel D. Lee (2006) Multiplicative Updates for Nonnegative Quadratic Programming\\n- ↑ Handbook of Parallel Computing and Statistics: Parallel Algorithms for the Singular Value Decomposition\\n- ↑ ScaLAPACK — Linear Least Squares Problems', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='59b17dac-2203-4a14-bf40-3c6c34eb867f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a1896b72a17d1106ae4651fa5c866c4aab2df4139bbf6b158c6ea9d6861a846f', text='Примеры кода на Java\\nСодержание\\n- 1 Популярные библиотеки\\n- 2 Основные особенности использования Java для задач машинного обучения\\n- 3 Примеры кода\\n- 3.1 Вариации регрессии\\n- 3.2 Метрический классификатор и метод ближайших соседей\\n- 3.3 Классификация при помощи MLP\\n- 3.4 Рекуррентные нейронные сети\\n- 3.5 Долгая краткосрочная память\\n- 3.6 Метод опорных векторов\\n- 3.7 Деревья решений, случайный лес\\n- 3.8 Бустинг, Ada-boost\\n- 3.9 EM-алгоритм\\n- 3.10 Уменьшение размерности\\n- 3.11 Байесовская классификация\\n- 4 См. также\\n- 5 Примечания\\nПопулярные библиотеки\\n-\\nWeka[1] — популярная библиотека, написанная на языке\\nJavaи содержащая в себе множество алгоритмов машинного обучения для задач анализа данных. Предоставляет инструменты для решения задач классификации, кластеризации данных, регрессионного анализа и др. Основные возможности\\nWekaможно сгруппировать в 3 категории: инструменты пре-процессинга данных, алгоритмы машинного обучения и инструменты оценки модели. Инструменты пре-процессинга в\\nWekaназываются фильтрами,\\nWekaсодержит фильтры для дискретиации, нормализации, уменьшения размерности, трансформации и комбинирования признаков.\\nWeka Machine Learning Toolkitсодержит алгоритмы классификации, регрессии, кластеризации. Реализованы следующие алгоритмы обучения: деревья решений, метод опорных векторов,\\nMLP, логистическая регрессия, Байесовские сети, и др., мета-алгоритмы включают в себя: бэггинг, бустинг, стекинг, алгоритмы выбора признаков: PCA[на 28.01.19 не создан], фильтрующие методы, основанные на information gain, коэффициенте корреляции Пирсона и\\nOneRклассификаторе.\\n-\\nSmile[2] —\\nJavaфреймворк для машинного обучения, анализа естественного языка, линейной алгебры и визуализации данных.\\nSmileпокрывает все основные аспекты машинного обучения и предоставляет высокопроизводительные алгоритмы и структуры данных.\\n-\\ndeeplearning4j[3] —\\nJavaбиблиотека для глубокого обучения, создания рекуррентых (в том числе распределенных) нейронных сетей.\\nОсновные особенности использования Java для задач машинного обучения\\nВ отличие от\\nPython,\\nJava не обладает столь обширной экосистемой, ориентированной на решение задач машинного обучения и анализа данных. Большинство имеющихся инструментов являются узко специализированными (по сравнению, например, с\\nscikit-learn[4]) и хуже документированы. Ввиду более низкой популярности языка в сфере\\nML большинство онлайн курсов и обучающих материалов ориентированы на\\nPython. Однако, несмотря на вышеперечисленные факторы,\\nJava остается\\nпопулярной альтернативой, особенно при необходимости интеграции с существующими\\nJVM проектами. Также к достоинствам\\nJava можно отнести статическую типизацию (и как следствие уменьшенную вероятность ошибок времени исполнения) и заметно более развитую поддержку в IDE.\\nПримеры кода\\nДля работы с приведенными ниже примерами необходим\\nJDK версии не ниже 10 и система сборки\\nMaven.\\nКаждый пример структурирован следующим образом:\\n-\\nMavenзависимость на необходимые библиотеки\\n- Список необходимых\\nimportдиректив\\n- Код примера с комментариями\\nВариации регрессии\\nЛинейная регрессия\\nЛогистическая регрессиия\\nГребневая регрессия (ридж-регрессия)\\nЛассо-регрессия\\nМетрический классификатор и метод ближайших соседей\\nКлассификация при помощи MLP\\nРекуррентные нейронные сети\\nДолгая краткосрочная память\\nМетод опорных векторов\\nДеревья решений, случайный лес\\nБустинг, Ada-boost\\nEM-алгоритм\\nПример кластеризации с применением\\nweka.clusterers.EM[5]\\n<dependency> <groupId>nz.ac.waikato.cms.weka</groupId> <artifactId>weka-stable</artifactId> <version>3.8.0</version> </dependency>\\nimport weka.clusterers.ClusterEvaluation; import weka.clusterers.EM; import weka.core.Instances; import java.io.BufferedReader; import java.io.FileReader; import java.util.Random;\\n//load data var data = new Instances(new BufferedReader(new FileReader(\"data/bank-data.arff\"))); // new instance of clusterer var model = new EM(); // build the clusterer model.buildClusterer(data); System.out.println(model); var logLikelihood = ClusterEvaluation.crossValidateModel(model, data, 10, new Random(1));', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='ba427b4b-5e70-4c26-917c-25f82fc7f100', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='98057f470faebd4f97e7dd357521acf8413f915b6106a37b1d755213e7345b64', text='Примеры кода на R\\nСодержание\\n- 1 Особенности написания кода на R\\n- 2 Описание известных пакетов\\n- 3 Примеры алгоритмов\\n- 3.1 Задачи регрессии\\n- 3.2 Метод главных компонент\\n- 3.3 Деревья решений, случайный лес\\n- 3.4 Наивный Бейесовский классификатор\\n- 3.5 Метод опорных векторов\\n- 3.6 Бустинг\\n- 3.7 Кластеризация\\n- 4 См. также\\n- 5 Примечания\\nОсобенности написания кода на R\\nЯзык R изначально создавался как язык программирования для работы с графикой и статистической обработки данных. Поэтому он отличается большим количеством реализованных статистических алгоритмов, на основе которых можно создавать модели и алгоритмы машинного обучения.\\nЯзык постоянно расширяется за счёт новых библиотек (пакетов). Для импорта одного пакета необходимо прописать в файле следующие строки:\\ninstall.packages(\"packageName\") require(\"packageName\")\\nДля того чтобы импортировать пакет с его зависимостями в код следует включить следующие строки:\\nlibrary(\"packageName\")\\nОписание известных пакетов\\nДля языка\\nR написано много пакетов, каждый из которых предназначен для решения определенного круга проблем. Например, для обработки данных или реализации основных алгоритмов. В статье представлено несколько наиболее часто используемых пакетов.\\nПакеты для обработки данных\\nPipelearner\\nПакет\\nPipelearner[1] предоставляет базовые возможности для разбиения набора данных на блоки для обучения моделей. В основе пакета лежит концепция работы конвейера.\\nПринцип работы очень прост и описывается 3 шагами:\\n- Инициализация\\n- Функция\\npipelearner()инициализирует новый объект, который используется в следующих функциях обработки. На этом этапе необходимо указать датасет, с которым производится работа. Также можно указать набор обучающих моделей и предсказываемую модель данных.\\n- Функция\\n- Настройка\\n- Для настройки есть 3 основных функции:\\n-\\nlearn_cvpairs()отвечает за кросс-валидацию. Функция генерирует набор пар из тестовой и обучающей выборки на основе входного датасета.\\n- В качестве ядра разделения можно использовать\\ncrossv_mc(случайные разбиения),\\ncrossv_kfold(k-fold кросс-валидация) или\\ncrossv_loo(leave-one-out разбиения) из пакета\\nmodelr[2]. Но если данных способов недостаточно, можно написать свою функцию разбиения.\\n-\\nlearn_curves()служит для настройки кривых обучения. Используется метод увеличивающихся пропорций относительно начала датасета.\\n- Например, вызов\\nlearn_curves(.5, .75, 1)создаст сценария работы: в первом будет взята первая половина выбоки, во втором — первые объектов, и в третьем — вся выборка. Авторы пакета утверждают, что брать случайные объекты выборки не имеет смысла, потому что выборка уже случайно разбита с помощью\\nlearn_cvpairs().\\n-\\nlearn_models()предназначен для добавления новых обучающих моделей.\\n- Обучение\\n- С помощью функции\\nlearn()все сконструированные ранее модели обучаются и выдается таблица результатов работы\\n- С помощью функции\\nВ итоге работа с пакетом выглядит приблизительно следующим образом:\\n# Load the dependencies library(pipelearner) library(dplyr) iris %>% # Use iris dataset pipelearner() %>% # Initialize a blank pipelearner object learn_cvpairs(crossv_mc, n = 50) %>% # Creating 50 random cross-validation pairs learn_curves(seq(.5, 1, by = .1)) %>% # Copy each cv-pair to be fitted in sample size proportions of .5 to 1 in increments of .1. learn_models(lm, Sepal.Width ~ .*.) %>% # Use regression modell learn_models(rpart::rpart, Sepal.Width ~ .) %>% # Use decision tree modell learn() # Fit all models on all partitions and return the results\\nПакет хорошо документирован, все непонятные моменты можно прояснить, просто изучив структуру объекта на каждом этапе работы алгоритма.\\nMICE\\nПакет\\nMICE[3] используется для заполнения пропущенных значений в данных. При этом нет необходимости думать о типах значений: для каждого из них в пакете предусмотрено заполнение по умолчанию.\\nПринцип работы основан на методе множественного восстановления[4]. Пропущенные данные заполняются не один, а несколько раз. После этого, каждый из полученных наборов обучается на определенной модели. Затем, результаты агрегируются и выдаются итоговые параметры модели.\\nСтандартный процесс работы выглядит так:\\n# Load the dependencies library(mice) # Impute the missing data m times imp <- mice(nhanes, m = 5) # Analize completed datasets using linear model fit <- with(imp, lm(chl ~ bmi + age)) # Combine parameter estimates est <- pool(fit) # Print summary of estimation summary(est)\\nGgplot2\\nДанный пакет[5] используется для отрисовки данных и графиков.\\nПакеты с реализованными алгоритмами машинного обучения\\nCaret\\nВ данном пакете [6] представлены модели для регрессии и классификации, а также большая часть популярных метрик. В настоящее время имеется возможность использовать более 180 различных алгоритмов.\\nОсновная функция в составе\\nCaret — функция\\ntrain(). Параметры обучения в ней задаются аргументом\\ntrControl, а оценка качества модели — аргументом\\nmetric.\\nОтличительными особенностями\\nCaret является универсальность используемых команд, наличие автоматического подбора гиперпараметров для алгоритмов, в также наличие параллельных вычислений.\\nParty\\nПакет\\nParty [7] содержит в себе инструменты для рекурсивного разбиения данных на классы. В пакета также доступна расширяемая функциональность для визуализации древовидных регрессионных моделей.\\nОсновная функция пакета —\\nctree(), которая используется для создания деревьев решения для таких задач регрессии как номинальные, порядковые, числовые а также многовариантные переменные отклика. На основе деревьев условного вывода\\ncforest() предоставляет реализацию случайных лесов Бреймана. Функция\\nmob() реализует алгоритм рекурсивного разделения на основе параметрических моделей (например, линейных моделей, GLM или регрессии выживания), использующих тесты нестабильности параметров для выбора разделения.\\nRandomForest\\nRandomForest [8] — пакет с реализацией алгоритма случайного леса. Используется для решения задач регрессии и классификации, а также для поиска аномалий и отбора предикторов.\\nClusterR\\nПакет\\nClusterR [9] состоит из алгоритмов кластеризации на основе центроидов (метод K-средних (k-means), mini-batch-kmeans, k-medoids) и распределений (GMM). Кроме того, пакет предлагает функции для:\\n- проверки результатов,\\n- построения графика результатов, используя метрики\\n- прогнозирования новых наблюдения,\\n- оценки оптимального количества кластеров для каждого алгоритма\\nE1071\\nПакет [10] содержит в себя функции для анализа классов, кратковременного преобразование Фурье, нечеткой кластеризации, реализации метода опорных векторов, вычисления кратчайшего пути, а также реализации наивного байесовского классификатора.\\nMlr\\nВ пакете\\nMlr [11] представлены модели для регрессии, классификации, кластеризации и анализа выживаемости, а также широкие возможности для оценки качества (в том числе функции для анализа ROC-кривых).\\nЕсть поддержка параллельных вычислений и конвейерных операций.\\nH2O\\nВ пакете\\nH20 [12] представлены линейные модели, такие как градиентный бустинг, метод главных компонент (PCA), GLRM, метод k ближайших соседей, случайный лес, наивный байесовский классификатор. Сильная сторона этой библиотеки — работа с большими объемами данных и поддержка многопоточных вычислений. Однако в ней нет возможности задавать параметры используемых алгоритмов\\nПримеры алгоритмов\\nВ интернете много хороших примеров реализации алгоритмов на\\nR, но среди них хотелось бы особо отметить один учебник[13] c портала coderlessons.com. В нем представлена реализация основных алгоритмов в порядке, удобном для изучения.\\nЗадачи регрессии\\nЛинейная регрессия\\n# reading data data <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # evaluating linear regression model model <- lm(data$x ~ data$y) # getting summary print(summary(model)) # visualizing data plot(data$y, data$x) lines(data$y, predict(fit), col = \\'red\\')\\nМножественная регрессия\\n# reading data rdata <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # evaluating regression model model <- lm(target ~ x + y + z, data = rdata) # getting summary print(summary(model))\\nЛогистическая регрессия\\nЛогистическая регрессия – это модель регрессии, в которой переменная ответа принимает значения 0 или 1 (True или False). Реализация на языке\\nR представлена в следующем фрагменте:\\n# reading data rdata <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # evaluating model model = glm(formula = target ~ x + y + z, data = rdata, family = binomial) # printing summary print(summary(model))\\nМетод главных компонент\\n# importing library and its\\' dependencies library(h2o) h2o.init() path <- system.file(\"extdata\", \"data.csv\", package = \"h2o\") data <- h2o.uploadFile(path = data) # evaluating h2o.prcomp(training_frame = data, k = 8, transform = \"STANDARDIZE\")\\nДеревья решений, случайный лес\\nДеревья решений\\nДля создания деревьев решений в\\nR используется функция\\nctree() из пакета\\nparty.\\n# importing package install.packages(\"party\") # reading data rdata <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # evaluating model output.tree <- ctree(target ~ x + y + z, data = rdata) # plotting results plot(output.tree)\\nСлучайный лес\\nДля создания случайного леса необходимо импортировать пакет\\nrandomForest\\n# importing packages install.packages(\"party\") install.packages(\"randomForest\") # reading data rdata <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # creating the forest output.forest <- randomForest(target ~ x + y + z, data = rdata) # getting results print(output.forest)\\nНаивный Бейесовский классификатор\\n# importing package and it\\'s dependencies library(e1071) # reading data data <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # splitting data into training and test data sets index <- createDataPartition(y = data$target, p = 0.8, list = FALSE) training <- data[index,] testing <- data[-index,] # create objects x and y for predictor and response variables x <- training[, -9] y <- training$target # training model model <- train(x, y, \\'nb\\', trControl = trainControl(method = \\'cv\\', number = 10)) # predicting results predictions <- predict(model, newdata = testing)\\nМетод опорных векторов\\n# importing package and its\\' dependencies library(caret) #reading data data <- read.csv(\"input.csv\", sep = \\',\\', header = FALSE) # splitting data into train and test sets index <- createDataPartition(y = data$target, p = 0.8, list = FALSE) training <- data[index,] testing <- data[-index,] # evaluating model fit <- train(target ~ x + y + z, data = train_flats, method = \"svmRadial\", trControl = trainControl(method = \"repeatedcv\", number = 10, repeats = 3)) # printing parameters print(fit)\\nБустинг\\n# loading libraries install.packages(\"mlr\") library(mlr) # loading data train <- read.csv(\"input.csv\") test <- read.csv(\"testInput.csv\") # loading GBM getParamSet(\"classif.gbm\") baseLearner <- makeLearner(\"classif.gbm\", predict.type = \"response\") # specifying parameters controlFunction <- makeTuneControlRandom(maxit = 50000) # specifying tuning method cvFunction <- makeResampleDesc(\"CV\", iters = 100000) # definig cross-validation function gbmParameters<- makeParamSet( makeDiscreteParam(\"distribution\", values = \"bernoulli\"), makeIntegerParam(\"n.trees\", lower = 100, upper = 1000), # number of trees makeIntegerParam(\"interaction.depth\", lower = 2, upper = 10), # depth of tree makeIntegerParam(\"n.minobsinnode\", lower = 10, upper = 80), makeNumericParam(\"shrinkage\", lower = 0.01, upper = 1) ) # tunning parameters gbmTuningParameters <- tuneParams(learner = baseLearner, task = trainTask, resampling = cvFunction, measures = acc, par.set = gbmParameters, control = controlFunction) # creating model parameters model <- setHyperPars(learner = baseLearner, par.vals = gbmTuningParameters) # evaluating model fit <- train(model, train) predictions <- predict(fit, test)\\nКластеризация\\nДля реализации алгоритма кластеризации k-средних используется пакет\\nClusterR. В нем реализовано 2 функции:\\nKMeans_arma() и\\nKMeans_rcpp(). В примере далее рассмотрена реализация с использованием функции\\nKMeans_arma().\\n# importing package and its\\' dependencies library(ClusterR) # reading data data <- read.csv(\"data.csv\") # evaluating model model <- KMeans_arma(data, clusters = 2, n_iter = 10, seed_mode = \"random_subset\", verbose = T, CENTROIDS = NULL) # predicting results predictions <- predict_KMeans(test_data, model)\\nСм. также\\n- Примеры кода на Scala\\n- Примеры кода на Java\\n- Примеры кода на Kotlin\\n- Обзор библиотек для машинного обучения на Python\\nПримечания\\n- ↑ Pipelearner github repository\\n- ↑ Modelr github repository\\n- ↑ MICE package documentation\\n- ↑ Multiple Imputation\\n- ↑ Ggplot2 main info page\\n- ↑ Caret guide book\\n- ↑ party package main info page\\n- ↑ RandomForest package main info\\n- ↑ ClusterR documentation\\n- ↑ 1071 package documentation\\n- ↑ Mlr package documentation\\n- ↑ H20 main info page\\n- ↑ Учебник по R', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='d55a0dc1-dd10-4ddc-aae7-0fa87aa61c7b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8d0ed689f1854ec1cde8309b0d354d36f153ea327a96ee2cef7753dcf52ba8fc', text='Примеры кода на Scala\\nСодержание\\n- 1 Популярные библиотеки\\n- 2 Примеры кода\\n- 2.1 Линейная регрессия\\n- 2.2 Вариации регрессии\\n- 2.3 Логистическая регрессия\\n- 2.4 Классификация при помощи MLP\\n- 2.5 Рекуррентные нейронные сети\\n- 2.6 Долгая краткосрочная память\\n- 2.7 Обработка естественного языка\\n- 2.8 Метрический классификатор и метод ближайших соседей\\n- 2.9 Метод опорных векторов\\n- 2.10 Дерево решений и случайный лес\\n- 2.11 Байесовская классификация\\n- 2.12 EM-алгоритм\\n- 2.13 Бустинг, AdaBoost\\n- 2.14 Уменьшение размерности\\n- 3 Примечания\\nПопулярные библиотеки\\n- Breeze[1] — библиотека, которая копирует реализует идеи строения структур данных из MATLAB[2] и NumPy[3]. Breeze позволяет быстро манипулировать данными и позволяет реализовать матричные и векторные операции, решать задачи оптимизации, обрабатывать сигналы устройств;\\n- Epic[4] — часть ScalaNLP, позволяющая парсить и обрабатывать текст, поддерживающая использование GPU. Так же имеет фрэймворк для предсказаний текста;\\n- Smpile[5] — развивающийся проект, похожий на scikit-learn[6], разработанный на Java и имеющий API для Scala. Имеет большой набор алгоритмов для решения задач классификации, регрессии, выбора фичей и другого;\\n- Apache Spark MLlib[7] — построенная на Spark[8] имеет большой набор алгоритмов, написанный на Scala;\\n- DeepLearning.scala [9] — набор инструментов для глубокого обучения[10]. Позволяет создавать динамические нейронные сети, давая возможность параллельных вычеслений.\\nПримеры кода\\nЛинейная регрессия\\nSbt зависимость:\\nlibraryDependencies += \"org.apache.spark\" %% \"spark-core\" % \"2.4.0\" libraryDependencies += \"org.apache.spark\" %% \"spark-mllib\" % \"2.4.0\" % \"runtime\"\\nПример линейной регрессии c применением org.apache.spark.ml.regression.LinearRegression[11]:\\nval training = spark.read.format(\"libsvm\") .load(\"linear_regression.txt\") val lr = new LinearRegression() .setMaxIter(10) .setRegParam(0.3) .setElasticNetParam(0.8) val lrModel = lr.fit(training)\\nВывод итоговых параметров модели:\\nprintln(lrModel.coefficients) println(lrModel.intercept) val trainingSummary = lrModel.summary println(trainingSummary.totalIterations) println(trainingSummary.objectiveHistory.mkString(\",\")) trainingSummary.residuals.show() println(trainingSummary.rootMeanSquaredError) println(trainingSummary.r2)\\nВариации регрессии\\nSbt зависимость:\\nlibraryDependencies += \"com.github.haifengl\" %% \"smile-scala\" % \"1.5.2\"\\nПример ридж и лассо регрессии c применением smile.regression[12]:\\nimport smile.data.{AttributeDataset, NumericAttribute} import smile.read import smile.regression.{LASSO, RidgeRegression, lasso, ridge}\\nval data: AttributeDataset = read.table(\"regression.txt\", delimiter = \" \", response = Some((new NumericAttribute(\"class\"), 0))) val x: Array[Array[Double]] = data.x() val y: Array[Double] = data.y() val ridgeRegression: RidgeRegression = ridge(x, y, 0.0057) val lassoRegression: LASSO = lasso(x, y, 10) println(ridgeRegression) println(lassoRegression)\\nЛогистическая регрессия\\nSbt зависимость:\\nlibraryDependencies += \"org.apache.spark\" %% \"spark-core\" % \"2.4.0\" libraryDependencies += \"org.apache.spark\" %% \"spark-mllib\" % \"2.4.0\" % \"runtime\"\\nПример логистической регрессии c применением spark.mllib.classification[13]:\\nimport org.apache.spark.mllib.classification.{LogisticRegressionModel, LogisticRegressionWithLBFGS} import org.apache.spark.mllib.evaluation.MulticlassMetrics import org.apache.spark.mllib.regression.LabeledPoint import org.apache.spark.mllib.util.MLUtils\\nval data = MLUtils.loadLibSVMFile(sc, \"logisticRegresion.txt\") val splits = data.randomSplit(Array(0.6, 0.4), seed = 11L) val training = splits(0).cache() val test = splits(1) val model = new LogisticRegressionWithLBFGS() .setNumClasses(10) .run(training)\\nval predictionAndLabels = test.map { case LabeledPoint(label, features) => val prediction = model.predict(features) (prediction, label) } val metrics = new MulticlassMetrics(predictionAndLabels) val accuracy = metrics.accuracy println(accuracy)\\nКлассификация при помощи MLP\\nSbt зависимость:\\nlibraryDependencies += \"com.github.haifengl\" %% \"smile-scala\" % \"1.5.2\"\\nПример классификации c применением smile.classification.mlp[14]:\\nimport smile.classification.NeuralNetwork.{ActivationFunction, ErrorFunction} import smile.data.{AttributeDataset, NumericAttribute} import smile.read import smile.classification.mlp import smile.plot.plot\\nval data: AttributeDataset = read.table(\"iris.csv\", delimiter = \",\", response = Some((new NumericAttribute(\"class\"), 2))) val x: Array[Array[Double]] = data.x() val y: Array[Int] = data.y().map(_.toInt) val mlpModel = mlp(x, y, Array(2, 10, 2), ErrorFunction.LEAST_MEAN_SQUARES, ActivationFunction.LOGISTIC_SIGMOID) plot(x, y, mlpModel)\\nРекуррентные нейронные сети\\nПример кода, с использованием библиотеки DeepLearning.scala\\n// Задание слоёв\\ndef tanh(x: INDArrayLayer): INDArrayLayer = {\\nval exp_x = hyperparameters.exp(x)\\nval exp_nx = hyperparameters.exp(-x)\\n(exp_x - exp_nx) / (exp_x + exp_nx)\\n}\\ndef charRNN(x: INDArray, y: INDArray, hprev: INDArrayLayer): (DoubleLayer, INDArrayLayer, INDArrayLayer) = {\\nval hnext = tanh(wxh.dot(x) + whh.dot(hprev) + bh)\\nval yraw = why.dot(hnext) + by\\nval yraw_exp = hyperparameters.exp(yraw)\\nval prob = yraw_exp / yraw_exp.sum\\nval loss = -hyperparameters.log((prob * y).sum)\\n(loss, prob, hnext)\\n}\\n// Определение структуры\\nval batches = data.zip(data.tail).grouped(seqLength).toVector\\ntype WithHiddenLayer[A] = (A, INDArrayLayer)\\ntype Batch = IndexedSeq[(Char, Char)]\\ntype Losses = Vector[Double]\\ndef singleBatch(batch: WithHiddenLayer[Batch]): WithHiddenLayer[DoubleLayer] = {\\nbatch match {\\ncase (batchseq, hprev) => batchseq.foldLeft((DoubleLayer(0.0.forward), hprev)) {\\n(bstate: WithHiddenLayer[DoubleLayer], xy: (Char, Char)) =>\\n(bstate, xy) match {\\ncase ((tot, localhprev), (x, y)) => {\\ncharRNN(oneOfK(x), oneOfK(y), localhprev) match {\\ncase (localloss, _, localhnext) => {\\n(tot + localloss, localhnext)\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n// Определение одного шага обучения\\ndef initH = INDArrayLayer(Nd4j.zeros(hiddenSize, 1).forward)\\ndef singleRound(initprevloss: Losses): Future[Losses] =\\n(batches.foldLeftM((initprevloss, initH)) {\\n(bstate: WithHiddenLayer[Losses], batch: Batch) =>\\nbstate match {\\ncase (prevloss, hprev) => singleBatch(batch, hprev) match {\\ncase (bloss, hnext) => bloss.train.map {\\n(blossval: Double) => {\\nval nloss = prevloss.last * 0.999 + blossval * 0.001\\nval loss_seq = prevloss :+ prevloss.last * 0.999 + blossval * 0.001\\n(loss_seq, hnext)\\n}\\n}\\n}\\n}\\n}).map {\\n(fstate: WithHiddenLayer[Losses]) =>\\nfstate match {\\ncase (floss, _) => floss\\n}\\n}\\ndef allRounds: Future[Losses] = (0 until 2048).foldLeftM(Vector(-math.log(1.0 / vocabSize) * seqLength)) {\\n(ploss: Losses, round: Int) => {\\nsingleRound(ploss)\\n}\\n}\\n// Обучение сети\\ndef unsafePerformFuture[A](f: Future[A]): A = Await.result(f.toScalaFuture, Duration.Inf)\\nval losses = unsafePerformFuture(allRounds)\\nДолгая краткосрочная память\\nОсновная статья: Долгая краткосрочная память.\\nПример реализации LSTM на основе DeepLearning4j[15] и ND4J[16]\\nОбработка естественного языка\\nОсновная статья: Обработка естественного языка: Пример кода на языке Scala.\\nМетрический классификатор и метод ближайших соседей\\nОсновная статья: Метрический классификатор и метод ближайших соседей: Пример на языке Scala.\\nМетод опорных векторов\\nОсновная статья: Метод опорных векторов (SVM)[на 28.01.19 не создан].\\nSBT зависимость:\\nlibraryDependencies += \"com.github.haifengl\" %% \"smile-scala\" % \"1.5.2\"\\nПример классификации датасета и вычисления F1 меры[17] используя smile.classification.svm[18]:\\nimport smile.classification._ import smile.data._ import smile.plot._ import smile.read import smile.validation.FMeasure\\nval iris: AttributeDataset = read.table(\"iris.csv\", delimiter = \",\", response = Some((new NumericAttribute(\"class\"), 2))) val x: Array[Array[Double]] = iris.x() val y: Array[Int] = iris.y().map(_.toInt) val SVM = svm(x, y, new GaussianKernel(8.0), 100) val predictions: Array[Int] = x.map(SVM.predict) val f1Score = new FMeasure().measure(predictions, y) plot(x, y, SVM)\\nДерево решений и случайный лес\\nОсновная статья: Дерево решений и случайный лес: Пример на языке Scala.\\nБайесовская классификация\\nОсновная статья: Байесовская классификация.\\nSBT зависимость:\\nlibraryDependencies += \"com.tsukaby\" %% \"naive-bayes-classifier-scala\" % \"0.2.0\"\\nПример классификации используя smile.classification.cart[19]:\\n// Создание модели val bayes = new BayesClassifier[String, String]() // Задание соотвествия категория - слово bayes.learn(\"technology\", \"github\" :: \"git\" :: \"tech\" :: \"technology\" :: Nil) bayes.learn(\"weather\", \"sun\" :: \"rain\" :: \"cloud\" :: \"weather\" :: \"snow\" :: Nil) bayes.learn(\"government\", \"ballot\" :: \"winner\" :: \"party\" :: \"money\" :: \"candidate\" :: Nil) // Тестовые примеры val unknownText1 = \"I use git\".split(\" \") val unknownText2 = \"Today\\'s weather is snow\".split(\" \") val unknownText3 = \"I will vote for that party\".split(\" \") // Классификация println(bayes.classify(unknownText1).map(_.category).getOrElse(\"\")) // technology println(bayes.classify(unknownText2).map(_.category).getOrElse(\"\")) // weather println(bayes.classify(unknownText3).map(_.category).getOrElse(\"\")) // government\\nEM-алгоритм\\nОсновная статья: EM-алгоритм[на 28.01.19 не создан].\\nSBT зависимость:\\nlibraryDependencies += \"com.github.haifengl\" %% \"smile-scala\" % \"1.5.2\"\\nПример классификации используя smile.clustering.kmeans[20]:\\nimport smile.clustering._ import smile.data._ import smile.plot._ import smile.read\\nval iris: AttributeDataset = read.table(\"iris.csv\", delimiter = \",\", response = Some((new NumericAttribute(\"class\"), 2))) val x: Array[Array[Double]] = iris.x() val kMeans: KMeans = kmeans(x, k = 6, maxIter = 1000) val y = kMeans.getClusterLabel plot(x, y, \\'.\\', Palette.COLORS)\\nБустинг, AdaBoost\\nОсновная статья: Бустинг, AdaBoost: Пример на языке Scala.\\nУменьшение размерности\\nОсновная статья: Уменьшение размерности: Пример на языке Scala.\\nПримечания\\n- ↑ Breeze\\n- ↑ MATLAB, structures\\n- ↑ ;NumPy wiki\\n- ↑ ScalaNLP, Epic\\n- ↑ Smile, Statistical Machine Intelligence and Learning Engine\\n- ↑ scikit-learn\\n- ↑ Apache Spark MLlib\\n- ↑ Apache Spark\\n- ↑ DeppLearning.scala\\n- ↑ Глубокое обучение\\n- ↑ Spark, LinearRegression\\n- ↑ Smile, Regression\\n- ↑ Spark, Logistic Regression\\n- ↑ Smile, MLP\\n- ↑ DeepLearning4j\\n- ↑ ND4J\\n- ↑ F1 мера\\n- ↑ Smile, SVM\\n- ↑ Naive bayes classifier, Scala\\n- ↑ Smile, K-Means', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='3bd8042f-9462-4190-8a7b-6a76d80b49c6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4cf79104602321c2a01ac9edc1dfb7483ec6b5c724ad0fe561dcb76e826d3d37', text='Примеры кода на Kotlin\\nСодержание\\nПопулярные библиотеки\\n- Kotlin-statistics[1] — библиотека с набором функций-расширений для работы с коллекциями, необходимыми в задачах статистики, такими как mode, median, range, variance, standardDeviation, geometricMean и др. Также, библиотека предоставляет расширения для трансформации коллекций, агрегации, сэмплинга данных. Есть реализации алгоритмов классификации, регрессии. Библиотека поддается расшерению API, за счет объявления своих расшерений, реализация которых может использовать Apache Math. Библиотека не содержит собственной реализации структур данных - все опреации производятся над стандартными интерфейсами (Sequence, Iterable и т.п.), функционал которых расширен благодаря механизму фнкций-расширения в Kotlin[2]. Нет встроенной поддержки визуализации данных, но можно использовать TornadoFX, работающий со стандартными коллекциями.\\n- KMath[3] — аналог numpy: поддержка алгебраических структур, массиво-подобных коллекций, гистограмм и т.д. На текущий момент 19.04.20 находится в разработке.\\n- SMILE[4] — JVM фреймворк, для которого помимо официального API[5] на Kotlin существуют расширения SMILE-NLP-KT[6]. Фреймворк используется для решения различных задач машинного обучения, таких как: классификация, регрессия, кластеризация, использование генетических алгоритмов, KNN, вывод отсутствующих значений набора данных, обработку естественных языков. Есть встроенная поддержка визуализации данных, средств для чтения и нормализации данных различных форматов (csv, apache arrow, json, jdbc).\\nТак как Kotlin интеропабилен с Java, то помимо поддерживающих для Kotlin библиотек можно использовать библиотеки для Java, например:\\n- Deeplearning4j[7] — DSL на Java для конфигурации глубоких нейронных сетей. Библиотека поддерживает распределенные вычисления, используя Apache Spark. Помимо реализаций алгоритмов машинного обучения, библиотека содержит классы для загрузки и нормализации данных.\\nТакже есть возможность[8] работы с NumPy.\\nПримеры кода\\nПримеры кода написаны на kotlin 1.3.71 для JVM, с использованием kotlin-statistics\\nGradle зависимость:\\nrepositories { maven { url \\'https://jitpack.io\\' } } dependencies { implementation \\'com.github.thomasnield:kotlin-statistics:-SNAPSHOT\\' }\\nЛинейная регрессия\\nПример линейной регрессии c применением Kotlin-statistics:\\nfun main() { val r = sequenceOf( 1.0 to 3.0, 2.0 to 6.0, 3.0 to 9.0, 4.0 to 11.8 ).simpleRegression() println(r.slope) // 2.9400000000000004 println(r.meanSquareError) // 0.006000000000000227 println(r.predict(5.0)). // 14.8 }\\nБайесовская классификация\\nОсновная статья: Байесовская классификация.\\nПример классификации при помощи Наивного Байесовского Классификатора:\\nimport org.nield.kotlinstatistics.toNaiveBayesClassifier class Email(val message: String, val isSpam: Boolean) fun main() { val emails = listOf( Email(\"Hey! If you really want to enlarge your ML scores click here\", isSpam = true), Email(\"Earn 50 more points for ML just by visiting this site!\", isSpam = true), Email(\"Still have F grade? Professional help with ML right here\", isSpam = true), Email(\"Hey, I left my phone at home. Email me if you need anything.\", isSpam = false), Email(\"Stay At Home: COVID-19 news\", isSpam = false), Email(\"Please see attachment for notes on today\\'s meeting.\", isSpam = false), Email(\"JetBrains license certificate\", isSpam = false), Email(\"Your Education Pack expires soon \", isSpam = false) ) val nbc = emails.toNaiveBayesClassifier( featuresSelector = { it.message.splitWords().toSet() }, categorySelector = { it.isSpam } ) val spamInput = \"your grade is still so bad, but I can help you to get more scores\".splitWords().toSet() require(nbc.predict(spamInput) == true) { spamInput } val legitInput = \"Thank you for placing the order \".splitWords().toSet() require(nbc.predict(legitInput) == false) { legitInput } } fun String.splitWords(): Sequence<String> = this.split(Regex(\"\\\\\\\\s\")) .asSequence() .map { it.replace(Regex(\"[^A-Za-z]\"), \"\") } .map { it.toLowerCase() } .filter { it.isNotEmpty() }\\nКластеризация\\nОсновная статья: Кластеризация.\\nПример кластеризации с DBSCAN:\\nimport org.nield.kotlinstatistics.dbScanCluster import kotlin.math.pow import kotlin.math.sin inline fun <V> IntProgression.mapDouble(mapper: (Double) -> V) = this.map { mapper(it.toDouble()) } data class Point(val coordinates: Pair<Double, Double>, val cluster: Int) fun main() { val firstCluster = (1..100 step 1) .mapDouble { x -> Point(x to x / 2, cluster = 1) } val secondCluster = (1..80 step 3) .mapDouble { x -> Point(x to (x / 12).pow(2) + 20, cluster = 2) } val thirdCluster = (60..150 step 1) .mapDouble { x -> Point(x to 10 * sin(x / 5) + 15, cluster = 3) } val points = firstCluster + secondCluster + thirdCluster val clusters = points.dbScanCluster( xSelector = { (coords) -> coords.first }, ySelector = { (coords) -> coords.second }, maximumRadius = 5.0, minPoints = 1 ) val pointsWithMatchedClusters = clusters.withIndex() .flatMap { (clusterIdx, matched) -> matched.points.map { p -> p to clusterIdx + 1 } } require(clusters.size == 3) { clusters.size } val pointsWithMismatchedCluster = pointsWithMatchedClusters.filterNot { (p, cluster) -> cluster == p.cluster } require(pointsWithMismatchedCluster.isEmpty()) { pointsWithMatchedClusters } }\\nПример работы с матрицами\\nПример использования средств языка и методов стандартной библиотеки для работы с матрицами\\ntypealias Vector = List<Double> typealias Matrix = List<Vector> class MatrixBuilder { private var matrixWidth: Int? = null private val _result: MutableList<Vector> = mutableListOf() val result: Matrix = _result operator fun invoke(vararg vector: Double) = addVector(vector.toList()) operator fun invoke(vararg vector: Number) = addVector(vector.map { it.toDouble() }) private fun addVector(vectorList: List<Double>) { _result.add(vectorList) if (matrixWidth != null) { require(vectorList.size == matrixWidth) { \"Vector size must be the same among all builder invocations: $vectorList, $_result\" } } else { matrixWidth = vectorList.size } } } fun matrix(builder: MatrixBuilder.() -> Unit): Matrix = MatrixBuilder().apply(builder).result fun main() { val multiplied = matrix { this(1, 2, 3, 4) this(1, 2, 3, 4) this(1, 2, 3, 4) } * matrix { this(5, 6) this(7, 8) this(9, 10) this(11, 12) } multiplied .transpose() .print() } fun Matrix.transpose(): Matrix = this.asSequence() .map { it.withIndex() } .flatten() .groupBy({ it.index }, { it.value }) .values .toList() operator fun Matrix.times(other: Matrix): Matrix { val (rows1, cols1) = this.size() val (_, cols2) = other.size() return (0 until rows1).map { i -> (0 until cols2).map { j -> (0 until cols1).fold(0.0) { s, k -> s + this[i][k] * other[k][j] } } } } fun Matrix.size(): Pair<Int, Int> = this.size to this.first().size fun Pair<Int, Int>.zeroMatrix(): Matrix = List(this.first) { List(this.second) { 0.0 } } fun Matrix.print() = println(this.joinToString(separator = \"\\\\n\") { it.joinToString(separator = \" \") }) fun List<Matrix>.sum(): Matrix { val n = this.size val (rowsCount, colCount) = this[0].size() return (0 until rowsCount).map { i -> (0 until colCount).map { j -> (0 until n).fold(0.0) { s, k -> s + this[k][i][j] } } } }', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='5120d37a-2863-403c-8b9c-1f1d5b5270fd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2141d520757f16e1e32bc95b164702a418a783689634379b263d76cc2e753796', text='Примеры кода на Kotlin в Jupyter Notebook\\nСодержание\\nKotlin и Data Science\\nKotlin - это прагматичный, статически типизированный JVM язык, который поддерживает написание кода как в ООП, так и в функциональном стилях, а также компилируется в различные платформы: JVM, JS, Native. Благодаря статической типизации, Котлин более производителен в больших проектах, по сравнению с Python, а также позволяет избежать Runtime errors. Сравним аналогичные примеры кода на Python и Kotlin:\\nPython:\\nimport numpy as np # ... a = np.ones((3, 3), dtype=int) * 3 b = np.random.random((3, 3)) b *= a # Success a *= b # TypeError at runtime\\nKotlin:\\n// ... val a = ones<Int>(3, 3) * 3 val b = Random.random(3, 3) b *= a // Success a *= b // Compilation error: //Type mismatch: inferred type is KtNDArray<Double> but KtNDArray<Int> was expected\\nТакже Котлин имеет имеет такую особенность дизайна языка, как null-safety и предоставляет такие операторы, как: safe call operator, elvis operator, not-null assertion operator, что позволяет ему быть более типобезопасным, по сравнениюc с Python:\\nvar a: String = \"abc\" a = null // compilation error var b: String? = \"abc\" b = null // ok\\nПомимо функционального синтаксиса и конструкций, Котлин также предоставляет набор математических и machine learning библиотек, а также инструментов для Data Science, в том числе, интегрированность с Jupyter Notebook.\\nУстановка Kotlin в Jupyter Notebook\\nKernel в Jupyter Notebook - это вычислительный движок, который исполняет код в данном документе и запускается автоматически при запуске ассоциированного с ним Jupyter Notebook документа. Они существуют для разных языков, например, ipython kernel исполняет Pythod код, а Kotlin kernel - Kotlin код в Jupyter Notebook. Именно Kotlin kernel позволяет писать и запускать код в Jupyter Notebook, а также использовать библиотеки и фреймворки, написанные на Java и Kotlin.\\nНа данный момент, установить Kotlin kernel можно только через conda:\\nconda install kotlin-jupyter-kernel -c jetbrains\\nОбратите внимание, что Kotlin Jupyter требует установленной Java 8:\\napt-get install openjdk-8-jre\\nПоддерживаемые библиотеки\\n- kotlin-statistics - предоставляет расширения для функций для подсчета статистики. Поддерживает основные list/sequence/array functions, slicing operators (countBy, simpleRegressionBy, etc), binning operations, discrete PDF sampling, naive bayes classifier, clustering, linear regression, и другое\\n- kmath - поддерживает алгебраические структуры и операторы, математические выражения, гистограммы, потоковые операции, обертки над commons-math и koma, и другое. Вдохновлена numpy\\n- Krangl - предоставляет функционал для обработки данных в функциональном стиле(filter, transform, aggregate, reshape и др.) Вдохновлена pandas\\n- lets-plot - Мультиплатформенная библиотека для создания графиков из данных. Может использоваться не только в JVM, но также JS and Python.\\n- kravis - библиотека для визуализации данных.\\n- klaxon $-$ Котлин JSON парсер\\n- spark $-$ Фреймворк для распределённой обработки неструктурированных и слабоструктурированных данных\\n- gral $-$ Java библиотека для отображения графиков\\n- koma $-$ Котлин библиотека для научных вычислений\\n- numpy $-$ Kотлин обертка над Python NumPy\\n- exposed $-$ Kотлин SQL фреймворк\\n- mysql $-$ MySql JDBC\\nДобавление зависимостей\\nПо умолчанию возможно добавлять зависимости из следующих репозиториев:\\nСпособы подключения зависимости:\\n@file:Repository(\"https://jcenter.bintray.com\") @file:DependsOn(\"com.beust:klaxon:5.0.1\") import com.beust.klaxon.*\\nИли коротким способом:\\n%use klaxon\\nТакже можно указать конкретную версию зависимости:\\n%use krangl(0.10)\\nМожно указать свойства library descriptor (обязательно использовать именованные аргументы):\\n%use spark(scala=2.11.10, spark=2.4.2)\\nПодключить несколько библиотек одним выражением:\\n%use lets-plot, krangl, mysql(8.0.15)\\nРабота с JSON\\nПример парсинга датасета в формате JSON с Котлин библиотекой Klaxon:\\n%use klaxon import java.io.*\\ndata class User( val age: Int, val firstName: String =\"\", val lastName: String =\"\", val eyeColor: String )\\nval users = Klaxon().parseArray<User>(File(\"users.json\").readText())!! users.count()\\nФункциональный стиль с библиотекой krangl\\nПримеры обработки данных в функциональном стиле с Kotlin stdlib:\\nusers.filter{it.eyeColor == \"green\"}\\nusers.groupBy { user -> user.eyeColor } .mapValues { mapEntry -> mapEntry.value.map { user -> user.firstName} }\\nПримеры обработки данных в функциональном стиле с krangl\\nИспользуемые функции:\\n- addColumn $-$ добавление новой вычисленной по заданной функции колонки\\n- filter $-$ подвыборка строк по заданному условию:\\ndf.filter { it[\"age\"] eq 23 } df.filter { it[\"weight\"] gt 50 } df.filter({ it[\"last_name\"].isMatching { startsWith(\"Do\") }})\\n- sortedBy $-$ сортировка, можно передавать множество значений, которые будут учитываться в сортировке в соответствующем порядке\\ndf.sortedBy(\"age\", \"weight\") df.sortedByDescending(\"age\")\\n- select и remove $-$ подвыборка строк\\ndf.select2 { it is IntCol } // functional style column selection df.select(\"last_name\", \"weight\") // positive selection df.remove(\"weight\", \"age\") // negative selection df.select({ endsWith(\"name\") }) // selector mini-language\\nОбработка строк:\\nfun readFromJsonString(s: String) = s.removePrefix(\"JsonArray(value=[\") .removeSuffix(\"])\") .split(\\',\\') .dropLastWhile{it.isEmpty()} .toList()\\nval channels = DataFrame .fromJson(\"channels.json\") .addColumn(\"groups\") { it[\"groups\"].map<String>{value -> readFromJsonString(value)}}\\nval modifiedChannels = channels .addColumn(\"count\"){it[\"groups\"].map<List<*>>{it.count()}} .filter{it[\"score\"] gt 50} .filter{it[\"age (y)\"] lt 40} .select(\"name\", \"score\", \"count\", \"groups\") .sortedByDescending(\"score\")\\nБольше примеров с ипользованием библиотеки krangl - https://github.com/Kotlin/kotlin-jupyter/blob/master/samples/Krangl.ipynb\\nПостроение графиков\\nLets-plot\\nПодробнее о настройках и параметрах графиков в Lets-plot: https://github.com/JetBrains/lets-plot-kotlin/blob/master/docs/guide/user_guide.ipynb\\nlets_plot(eyes) + stat_count() + ggsize(500,300)\\nval rand = java.util.Random()\\nval data = mapOf<String, Any>( \"rating\" to List(200) { rand.nextGaussian() } + List(200) { rand.nextGaussian() * 1.5 + 1.5 }, \"cond\" to List(200) { \"A\" } + List(200) { \"B\" } ) var p = lets_plot(data) p += geom_density(color=\"dark_green\", alpha=.3) {x=\"rating\"; fill=\"cond\"} p + ggsize(500, 250)\\nlets_plot(mapOf( \"date\" to usages.select(\"DateTime\").collectAsList().map{(it[0] as Timestamp).getTime()}, \"usage\" to usages.select(\"users\").collectAsList().map{it[0]} )) + geom_bar(stat = Stat.identity){x = \"date\"; y = \"usage\"; fill =\"usage\"} + scale_x_datetime() + scale_fill_hue()+ qqsize(800, 400)\\nБиблиотека Kravis\\nПодробнее - https://github.com/holgerbrandl/kravis\\n%use kravis, krangl val sleepData = DataFrame.fromJson(\"data.json\"). .addColumn(\"rem_proportion\") { it[\"sleep_rem\"] / it[\"sleep_total\"] } .plot(x = \"sleep_total\", y = \"rem_proportion\", color = \"vore\", size = \"brainwt\") .geomPoint(alpha = 0.7) .guides(size = LegendType.none) .title(\"Correlation between dream and total sleep time\")\\nБиблиотека Gral\\nИсточники\\n- Kotlinlang — Официальный сайт языка Kotlin\\n- Kotlin For Python Developers Documentation — Документация языка Kotlin для разработчиков на Python\\n- kotlin-jupyter on GitHub\\n- Примеры kotlin-jupyter\\n- KotlinConf 2019: Using Kotlin for Data Science', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='1a4fb0b2-941e-44fd-b914-e670f78e8605', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8610a4989a05ed83eb26373b01f410809b96aec85e704923bf6feb68f625063b', text='Машинное обучение на мобильных телефонах\\nМашинное обучение, как известно, очень тесно связано с нашей жизнью, и во многих областях используются разные модели машинного обучения. Эти модели нужно где-то запускать и сохранять. Самый простой выход из ситуации — сервер, на котором будет находиться наша модель, и который будет принимать запросы. Однако, что, если мы находимся в глухом лесу и у нас нет доступа к Интернету? Что, если мы не хотим хранить свои данные на чужих серверах? У нас нет своих серверов для машинного обучения, но мобильные телефоны есть почти у каждого. Давайте рассмотрим машинное обучение на телефонах.\\nСодержание\\n- 1 Задачи машинного обучения на телефонах\\n- 2 Запуск моделей машинного обучения на мобильных телефонах\\n- 3 Вес современных нейронных сетей\\n- 4 Процессоры\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nЗадачи машинного обучения на телефонах\\nКастомизация\\nКонечно же, самое первое, что может прийти в голову про применение машинного обучения на телефонах — это кастомизация. Подбор музыки, новостей, любого контента — все это достигается с помощью машинного обучения. Приложение получает ваши персональные данные и, используя данные старых пользователей, показывает вам то, что понравилось людям с наиболее подходящими данными. Однако такая работа связана с очень большими вычислениями, и, чаще всего, выполняется на сторонних серверах. Самая частая модель для классификации изображений — CNN, однако порой такая классификация является излишней.\\nПример приложения:\\n- Spotify\\n- TikTok\\nРаспознавание фото, текста и видео\\nРаспознавание фото и видео на мобильных телефонах мало чем отличается от обычных компьютерных методов, только цели немного другие. Например, некоторые мобильные телефоны распознают владельца через Face ID с помощью фронтальной камеры. Есть приложения для определения возраста, пола.\\nЕсли же рассмотреть распознавание текста, то и у него тоже есть большое количество применений — сканирование чеков, кредитные карты, документы, переводить в реальном времени иностранные слова.\\nСуществует несколько известных библиотек для работы с изображениями в мобильных приложениях: Tesseract[1], OpenCV[2], Mobile Vision Google[3], ML Kit[4]. Изображения легко передавать через сеть, так что можно обрабатывать их и на веб-серверах.\\nПример приложения:\\n- Google Lens\\nРаспознавание звука\\nРаспознавание звука и его парсинг тоже очень важная задача машинного обучения. Голосовые помощники, голосовой ввод, умные дома — все это нужно для нашей жизни.\\nДля распознавания речи есть библиотека pocketsphinx[5]\\nПример приложения:\\n- Shazam\\n- Google Assistant\\nАнализ данных с сенсоров\\n|Приложение\\n|Датчик\\n|Распознавание человеческой активности\\n|Акселерометр\\n|Гироскоп\\n|Магнитометр\\n|Монитор сердечного ритма\\n|Распознавание жестов\\n|Акселерометр\\n|Гироскоп\\n|Распознавание падений\\n|Акселерометр\\n|Гироскоп\\n|Датчики близости\\n|Распознавание аварий\\n|Акселерометр\\n|Приемник GPS\\n|Распознавание условий окружающей среды\\n|Датчик окружающего света\\n|Датчик влажности\\n|Термометр\\n|Датчик давления\\n|Приемник GPS\\n|Распознавание стресса\\n|Микрофон\\n|Электрокардиограф\\n|Монитор сердечного ритма\\n|Датчик проводимости кожи\\n|Распознавание эмоций\\n|Микрофон\\n|Камера\\n|Электрокардиограф\\n|Монитор сердечного ритма\\n|Датчик проводимости кожи\\nТелефон получает данные об окружающем мире с помощью специальных датчиков и сенсоров. В мире их существует огромное количество, и, к сожалению, большинство из них работает недостаточно точно. Но это исправляет машинное обучение, уточняя данные с сенсоров. Это важно для людей с опасными для жизни болезнями, например, может произойти сердечный приступ, и процессор лучше любого человека скажет, что это он, и, считав местоположение с навигатора, вызовет скорую помощь в тот же момент.\\nПример приложения:\\n- Карты Google\\n- Gravity Screen\\nНавигация\\nНавигационные приложения можно значительно улучшить, если интегрировать в них алгоритмы по распознаванию фото и видео. К примеру, если приложение подключается к камере в автомобиле, оно может анализировать ситуацию на дороге и предупреждать водителя в случае возможной опасности. Так можно распознавать пробки, дорожные знаки по ограничению скорости, агрессивное поведение окружающих водителей и другие характеристики дорожного движения.\\nПример приложения:\\n- Карты Google\\nЗапуск моделей машинного обучения на мобильных телефонах\\nДля запуска глубоких моделей необходимо наличием мощных вычислительных ресурсов и большого объема учебных данных. Поэтому построение модели может осуществляться с помощью высокопроизводительных центральных (англ. central processing unit, CPU[6]) и графических (англ. graphics processing unit, GPU[7]) процессоров, а после построения ее можно запустить на мобильном устройстве с гораздо меньшей вычислительной мощностью на CPU, интегральных схемах специального назначения (англ. Application specific integrated circuit, ASIC), программируемых пользователем вентильных матриц (англ. Field programmable gate array, FPGA) или мобильных GPU. На рисунках 1-4 представлены модели взаимодействия с соответcтвующими вычислительными устройствами.\\nCPU\\nХотя процессоры могут быть неудачным решением для построения современных моделей глубокого обучения, когда учебные данные очень большие, они являются приемлемым вариантом для обучения или адаптации моделей к небольшим объемам данных, а также для развертывания предварительно построенных моделей глубокого обучения. Очевидным преимуществом развертывания глубокого обучения на CPU является то, в отличие от других типов вычислительных устройств ими оснащен любой современный телефон или планшет. Кроме того, мобильные устройства часто поставляются с мощными процессорами и имеют широкий выбор встроенных датчиков. Это означает отсутствие дополнительных затрат на аппаратное обеспечение и таким образом обеспечение большего количества приложений ИИ для потенциально огромного рынка. Real-time приложения могут быть развернуты на стандартном процессоре с минимальными затратами или без дополнительных усилий. Кроме того CPU в современных мобильных устройствах столь же мощны, как и в компьютерах, что позволяет эффективно использовать их для данных целей.\\nGPU\\nGPU — графический процессор, который по своему устройству является процессором с несколькими тысячами маленьких ядер. За счет этого достигается большая степень параллельности, что позволяет производить на GPU более эффективные вычисления с матрицами и тензорами, нежели на CPU. На данный момент существует множество мобильных GPU от разных производителей, например одной из самых заметных систем смартфонов на чипе (SoC) является чип Qualcomm Snapdragon.\\nFPGA\\nВ то время как CPU создан для вычислений общего назначения, а ASIC сделана исключительно для специфических вычислений, FPGA находится между ними. FPGA могут быть (повторно) запрограммированы (\"перепрошиты\") для эффективного выполнения многих специфических задач. На базовом уровне FPGA используют схемы flip-flop для реализации последовательных логических функций и поиска таблиц. Логические функции реализуются посредством программируемой памяти, которая также контролирует соединения коммутационных цепей, таким образом, FPGA не нужно явно выполнять логическую операцию после того, как она запрограммирована. Современные FPGA, как правило, используют SoC подход для интеграции ядра процесса, коммуникационного ядра, и память на одной микросхеме. FPGA вендоры, такие как Xilinx и Altera, создали множество программного обеспечения для облегчения программирования на FPGA. В то время как традиционное программирование для FPGA требует знаний о цифровых схемах и языка описания оборудования (HDL), сейчас оно движется в сторону создания схем высокого уровня (HLS). Существует пять основных категорий инструментов HLS, но для мобильного глубокого обучения наиболее актуален фреймворк параллельных вычислений OpenCL. OpenCL — это язык основанный на C и являющийся открытой, стандартизированной основой для ускорения алгоритмов. Программы, написанные на OpenCL, могут быть выполнены на GPU, DSP и FPGA. OpenCL можно рассматривать как open source версию CUDA.\\nASIC и TPU\\nASIC — интегральная схема конкретно под поставленную задачу. Примером можем служить интегральная схема реализующая необходимую нейросеть. За счёт этого, энергопотребление становится меньше, а скорость работы операций выше по сравнению с CPU, GPU и FPGA. Также, большинство вычислительных узлов может работать параллельно, только зависимости по данным и неравномерность вычислений на разных уровнях сети могут помешать постоянно задействовать все ALU. Самым большим недостатком является потеря настраиваемости сети, так как настрока параметров будет связана с изменением интегральной схемы. На текущее время, существует множество ASIC, разработанных для нейронных сетей, например TPU разработанная Google специально для нейросетевого машинного обучения.\\nСравнение\\nКак упоминалось в предыдущих подразделах, CPU и GPU являются вычислительными платформами общего назначения, предлагая таким образом большую гибкость. Начальное алгоритмическое обучение модели должно использовать CPU и GPU для получения предварительного представления о достижимой производительности. CPU и GPU поддерживают вычисления с полной точностью и могут быть использованы для моделей с интенсивными вычислениями, что часто означает более высокую точность прогнозирования. Однако, GPU и CPU более энергозатратны. ASIC могут быть гораздо более энергоэффективными, так как аппаратное обеспечение изготовлено специально для некоторых вычислений. Тем не менее, проектирование и разработка микросхем ASIC может занять очень много времени. Таким образом, ASIC используется только тогда, когда модель фиксирована и требуются низкие затраты энергии. FPGA предлагает компромисс между энергопотреблением, точностью прогнозирования и скоростью разработки системы.\\nВес современных нейронных сетей\\nВ нынешних реалиях глубокие нейронные сети могут весить порядка сотен мегабайт, в то же время современные фреймворки, например, MobileNet позволяют строить нейросети значительно меньшего размера при небольшой потере точности, такие сети отлично подходят для мобильных устройств. Результаты использования MobileNet приведены в сравнении с другими нейросетями приведены в таблице ниже.\\n|Модель\\n|Размер входа\\n|Размер параметров\\n|Размер признаков\\n|Метод\\n|Флопс\\n|Тип модели\\n|Набор данных\\n|rfcn-res50-pascal\\n|600 x 850\\n|122 MB\\n|1 GB\\n|r-fcn\\n|79 GFLOPS\\n|resnet50\\n|pascal VOC\\n|rfcn-res101-pascal\\n|600 x 850\\n|194 MB\\n|2 GB\\n|r-fcn\\n|117 GFLOPS\\n|resnet101\\n|pascal VOC\\n|ssd-pascal-vggvd-300\\n|300 x 300\\n|100 MB\\n|116 MB\\n|ssd\\n|31 GFLOPS\\n|vvgd\\n|pascal VOC\\n|ssd-pascal-vggvd-512\\n|512 x 512\\n|104 MB\\n|337 MB\\n|ssd\\n|91 GFLOPS\\n|vvgd\\n|pascal VOC\\n|ssd-pascal-mobilenet-ft\\n|300 x 300\\n|22 MB\\n|37 MB\\n|ssd\\n|1 GFLOPS\\n|mobilenets\\n|pascal VOC\\n|aster-rcnn-vggvd-pascal\\n|600 x 850\\n|523 MB\\n|600 MB\\n|faster-rcnn\\n|172 GFLOPS\\n|vvgd\\n|pascal VOC\\nПроцессоры\\nИз-за медлительности телефонов развитие машинного обучения на них началось совсем недавно. Раньше все данные хранились на серверах компаний, выбор модели был очень широк, и, с точки зрения безопасности, это было плохо. Однако теперь IT-гиганты, такие, как Google, переходят на модель федеративного обучения[8]. Понятно, что обычный телефон не может себе позволить обучаться на моделях, которые потребляют много ресурсов, таких как, например, нейронные сети. Однако существуют модели, которые потребляют очень малое количество памяти и времени на обучение. В основном именно они используются, когда нет соединения с сервером.\\nОднако машинное обучение стало настолько актуальным, что производители процессоров задумались о том, что бы создавать процессоры, некоторые чипы которых заточены под задачи машинного обучения.\\nСуществует огромное число процессоров для огромного числа задач, начиная от задачи линейной регрессии до задач глубокого обучения.\\nВот примеры таких процессоров — Qualcomm Neural Processing SDK[9], Huawei Ai[10], NeuroPilot SDK[11], CoreML SDK[12]\\nQualcomm Neural Processing SDK\\nЭтот процессор заточен под работу с аудио и видео: распознавание речи, обработку изображений, очистку картинки от шума и подобное.\\n|Область применения\\n|Пример использования\\n|Генератор текста\\n|Преобразование данных в текст\\n|Распознавание речи\\n|Голосовые системы\\n|Чат-боты\\n|Программы, способные общаться с людьми\\n|Биометрика\\n|Идентификация и анализ здоровья людей\\n|Обработка естественного языка\\n|Понимание структуры и значения фраз\\n|Распознавание эмоций\\n|Считывание информации с лица\\n|Распознавание изображений\\n|Подсчет числа обьектов на картинке\\nРазработчики данного процессора делают упор на сверточные сети, однако там встречаются почти все известные модели машинного обучения. Обеспечивает аппаратное ускорение ML-моделей на связке DSP + GPU + CPU для Snapdragon чипов. Далее приведен листинг на языке C++, который принимает объект класса выборки, преобразует их в модель и сохраняет их в файл:\\n#include \"zdl.h\" void executeNetwork(std::unique_ptr<zdl::SNPE::SNPE>& snpe, std::unique_ptr<zdl::DlSystem::ITensor>& input, std::string OutputDir, int num) { static zdl::DlSystem::TensorMap outputTensorMap; snpe->execute(input.get(), outputTensorMap); zdl::DlSystem::StringList tensorNames = outputTensorMap.getTensorNames(); //Проходимся по всем объектам и выводим их имена std::for_each( tensorNames.begin(), tensorNames.end(), [&](const char* name) { std::ostringstream path; path << OutputDir << \"/\" << \"Result_\" << num << \"/\" << name << \".raw\"; auto tensorPtr = outputTensorMap.getTensor(name); SaveITensor(path.str(), tensorPtr); }); } void SaveITensor(const std::string& path, const zdl::DlSystem::ITensor* tensor) { ... std::ofstream os(path, std::ofstream::binary); if (!os) { std::cerr << \"Failed to open output file for writing: \" << path << \"\\\\n\"; std::exit(EXIT_FAILURE); } for ( auto it = tensor->cbegin(); it != tensor->cend(); ++it ) { float f = *it; if (!os.write(reinterpret_cast<char*>(&f), sizeof(float))) { std::cerr << \"Failed to write data to: \" << path << \"\\\\n\"; std::exit(EXIT_FAILURE); } } }\\nHuawei Ai\\nЭтот процессор заточен под компьютерное зрение, распознавание речи и интерпретацию естественного языка.\\nКак можно заметить по картинке, здесь нет никакого обучения, мы берем уже обученную модель и пользуемся ею. Огромное количество классов, предназначенных для различных задач. HiAI SDK дает доступ к заточенному под операции над матрицами NPU. Таким образом, оптимизируются нейронные сети, которые используют матрицы.\\nПример кода на Java, распознающего, одинаковые ли люди изображены на картинке.\\nimport com.huawei.hiai.vision.face.FaceComparator;// Класс для сравнивания лиц import com.huawei.hiai.vision.visionkit.face.FaceCompareResult;// Класс результата сравнивания лиц if (!AiEngineMgr.isAsync) { resultCode = mFaceComparator.faceCompare(image1, image2, mFaceCompareResult, null); } else { mFaceComparator.faceCompare(image1, image2, null, new VisionCallback<FaceCompareResult>() { @Override public void onResult(FaceCompareResult faceCompareResult){ mFaceCompareResult = faceCompareResult; resultCode = 0; } @Override public void onError(int i){ resultCode = i; HopeCVLog.d(temp_Log,\"onError: \"+i); } @Override public void onProcessing(float v){ } }); } try { Float confidence = mFaceCompareResult.isSamePerson(); boolean samePerson = mFaceCompareResult.getSocre(); } catch (Exception e) { e.printStackTrace(); }\\nNeuroPilot SDK\\nПроцессор заточен под отслеживание поз множества людей, идентификацию множества объектов, семантическую сегментацию, обработку изображений. NeuroPilot SDK позволяет решать ML-задачи с помощью APU + GPU. APU заточен под модели глубоких нейронных сетей. Обеспечивает аппаратное ускорение для свертки, полносвязных нейронных сетей (то есть нейронных сетей без дропаута), функции активации.\\nУ данной разработки есть три пути развития:\\n- чип NeuroPilot Micro, представляющий собой микрокомпьютер, оптимизированный под задачи машинного обучения. Его возможности ограничены $10^6$ операциями, мегабайтами памяти. В качестве такого чипа так же можно использовать обычные схематические конструкторы, такие как Arduino[13] (конечно же, их скорость будет ниже на порядок).\\n- телефон или телефонный чип, на который загружено специальное ПО. Возможности ограничены примерно $10^8 - 10^9$ операциями и гигабайтами памяти.\\n- удаленное серверное управление. По словам авторов, количество операций и памяти почти безграничны.\\nВ своем основании использует TFLite модели, лучше всего подходит TensorFlow и Keras. Можно писать программы прямо на нем, они будут успешно оптимизироваться.\\nCoreML SDK\\nСоздан для классификации объектов, звуков, движений, текста, табличных данных, обладает рекомендательной системой. Работает на NPU. Пример использования для картинок.\\nДанное программное обеспечение сильно разделено. У нас есть специальная MLModel, которая изначально принимает изображения, и сохраняет их в компактном виде, сохраняя там же уже натренированную сеть (см. рисунок 5). Затем данный пакет передается уже программе, и она обрабатывает его. Пример кода на Swift:\\nimport UIKit import CoreML import Vision import ImageIO DispatchQueue.main.async { guard let results = request.results else { self.classificationLabel.text = \"Unable to classify image.\\\\n\\\\(error!.localizedDescription)\" return } let classifications = results as! [VNClassificationObservation] if classifications.isEmpty { self.classificationLabel.text = \"Nothing recognized.\" } else { // Display top classifications ranked by confidence in the UI. let topClassifications = classifications.prefix(2) let descriptions = topClassifications.map { classification in // Formats the classification for display; e.g. \"(0.37) cliff, drop, drop-off\". return String(format: \" (%.2f) %@\", classification.confidence, classification.identifier) } self.classificationLabel.text = \"Classification:\\\\n\" + descriptions.joined(separator: \"\\\\n\") } }\\nДля работы с кодом и результатами у Apple есть рекомендуется программа XCode (пример работы см. рисунок 6)\\nСм. также\\n- Машинное обучение в медицине\\n- Модель алгоритма и её выбор\\n- Глубокое обучение\\n- Распознавание речи\\n- Компьютерное зрение\\nПримечания\\nИсточники информации\\n- azoft.ru - о применении машинного обучения.\\n- habr.com - железо и процессоры.\\n- researchgate.net - Deep Learning on Mobile Devices, Yunbin Deng\\n- habr.com - аппаратное ускорение нейронных сетей\\n- habr.com - краткий обзор и пример на CoreML.\\n- habr.com - распознавание изображений.\\n- habr.com - использование ML Kit.\\n- habr.com - использование Pocketsphinx.\\n- osp.ru - глубинный анализ данных с сенсоров.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='d64c0b3f-a00d-4f30-8aeb-bf790b5d988b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9fb49e70f2aeb36ba6c7b4643f921cc9d7428fdb2329af61f28efdc122d5987f', text='Анализ социальных сетей\\nРассмотрим анализ социальных сетей в свете сбора данных про их пользователей. Правовые и морально-этические аспекты сбора и использования персональных данных в рамках данного обзора рассматриваться не будут.\\nСодержание\\n- 1 Задачи анализа социальных сетей\\n- 2 Общая информация\\n- 3 Сбор данных\\n- 4 Обработка данных\\n- 5 Большая пятерка\\n- 6 Связь показателей Большой пятерки с характеристиками из социальных сетей\\n- 7 Музыка и характер[1]\\n- 8 Психотипы\\n- 9 Предсказание поведения пользователя и оптимизация взаимодействия с ним\\n- 10 Примеры использования данных социальных сетей\\n- 11 Оценка надёжности и платёжеспособности кандидатов на получение кредитов\\n- 12 См. Также\\n- 13 Примечания\\n- 14 Источники Информации\\nЗадачи анализа социальных сетей\\nАнализ социальных сетей представляет из себя ряд отдельных задач, выполняющихся поэтапно.\\n- Задача сбора данных.\\n- Анкетных данных.\\n- Адресов.\\n- Интересов.\\n- Задача анализа достоверности данных.\\n- Задача индексации данных.\\n- Задача классификации данных.\\n- Задача предсказания поведения пользователей.\\nОбщая информация\\nИнформация в социальных сетях отличается от информации, полученной из баз данных, с которой обычно работают системы анализа и машинного обучения, своей спецификой. Прежде всего следует учитывать, что под пользователями социальных сетей понимаются виртуальные личности, созданные реальными людьми. В связи с этим информация в социальных сетях формируется пользователем в рамках создания виртуального образа с учетом конфиденциальности и представлениях о безопасности конкретного человека. Таким образом, вопрос достоверности данных, получаемых для дальнейшего анализа, становится весьма актуальным. Следовательно любые данные из социальных сетей должны обрабатываться с дополнительным параметром, характеризующим вероятность их достоверности. Хотя мы и видим настойчивые попытки владельцев и модераторов сетей идентифицировать пользователей и требовать от них доказательства их реальности, но практика показывает, что нередки случаи использования людьми сразу нескольких аккаунтов в рамках одной социальной сети. Это происходит из-за того, что пользователи стараются физически обособить свои различные интересы, по-разному раскрывающие их личность. Как правило, такие аккаунты имеют разные характеристики, интересы, круги общения. Люди иногда являются пользователями сразу нескольких соцсетей, соответственно заводят аккаунты в каждой из них. Данные одного человека в разных соцсетях могут дополнять друг друга, тем самым дать более полную информацию о нем. Кроме того, не следует забывать о фейковых аккаунтах и ботах, создаваемых для введения в заблуждение людей и искажения статистической информации аналитических систем. Таким образом, идентификация пользователя, включающая в себя группировку разных аккаунтов одного реального человека и исключения фейков является важной задачей анализа данных социальных сетей.\\nСбор данных\\nПервым этапом работы с соцсетями является собственно сбор данных. Первое — парсинг и семантический анализ данных, оставленных в соцсетях виртуальными пользователями. Прежде всего это личные данные:\\n- Фамилия, имя, отчество.\\n- Контактные данные.\\n- Анкетные данные.\\nСледует отметить, что для владельцев соцсетей есть дополнительные возможности для получения информации о пользователе, недоступные для внешних аналитиков такие как:\\n- IP-адреса.\\n- Геолокация.\\n- Характеристика устройства.\\nКроме того, важно зафиксировать кто является друзьями и подписчиками пользователя и на кого пользователь сам подписан. Анализируются:\\n- Группы, в которых пользователь участвует.\\n- Их тематика.\\n- Активность пользователя в них, его сообщения.\\n- Комментарии к чужим сообщениям.\\nНемаловажное значение имеют данные с собственных страниц пользователя:\\n- Подписчики этих страниц.\\n- Тематика страницы.\\n- Размещаемый на них контент.\\n- Фотографии и собственные видеозаписи.\\n- Комментарии пользователя и подписчиков.\\nСбор данных осуществляется на постоянной основе. Данные пополняются по мере появления новой информации.\\nОбработка данных\\nПосле сбора данных идет индексация и обработка данных, выделяющих существенную информацию для дальнейшей обработки. Делается это с целью уменьшения объема хранимых данных и приведения их в вид, удобный для дальнейшей обработки и анализа. Любые личные данные, адрес и контактные данные крайне важны как для сопоставления виртуальных пользователей с реальными личностями, так и для выявления разных аккаунтов одного и того же человека. Верификация этих данных происходит путем сравнения анкетных данных, оставленных этим пользователем, с информацией из разных независимых источников. Это такие как:\\n- IP-адреса пользователя.\\n- Геолокация и временной пояс пользователя.\\n- Время оставляемых им сообщений.\\nМогут быть использованы существующие базы персональных данных реальных людей: базы паспортов; фотографий; прописок; автовладельцев; налоговых; имущественных. В свете появления новых технологий поиска людей по их изображениям, перспективным является анализ достоверности фотографии, представленной пользователем. Достоверность фотографии может быть подтверждена путем сравнения ее с лицами, представленными на других фотографиях и видеозаписях аккаунта. Также осуществляется поиск по фотографиям и видеозаписям, выложенным в аккаунтах друзей. Поиск точной копии фотографий в интернете может помочь избежать фейков, либо найти другие аккаунты этого же пользователя.\\nПомимо идентификаторов и названий страниц и групп пользователя производится семантический анализ сообщений в группах с целью определения их тематики. Достоверность этой информации тем выше, чем дольше существует активность в этой группе. Во внимание берутся:\\n- посты;\\n- комментарии;\\n- лайки;\\n- дизлайки;\\n- анализируются ссылки на группу в тематических контентах;\\n- интересы других пользователей этих групп;\\nТаким образом формируется список интересов анализируемого пользователя. Достоверность этого списка подтверждается наличием постов и комментариев на данную тематику, а также выявлением круга его знакомых, интересующихся данной тематикой. Данным, получившим подтверждение из независимых источников, присваивается коэффициент достоверности больший, чем данным, подтверждение которым пока найти не удалось. Данные, замеченные в фальсификации, получают негативный коэффициент достоверности. Эти данные исключаются из дальнейшей обработки, а пользователю снижается его общий коэффициент доверия.\\nСобранные таким образом характеристики пользователей вполне пригодны для выбора целевых аудиторий для эффективного продвижения рекламы и коммерческих предложений.\\nЭта технология хоть и использует сейчас современные компьютерные методы сбора и обработки данных является по сути классическим \"пещерным\" маркетингом.\\nКоличество собираемых данных может быть расширено за счет анализа реакции клиентов на обращения к тем или иным темам. Например, относительное количество кликов на показанную пользователю рекламу. Это может несколько увеличить эффективность взаимодействия с пользователем.\\nПринципиально новый подход к взаимодействию с пользователем возможен благодаря использованию более широкого анализа характеристик его личности. Фундаментальную теорию такого анализа можно почерпнуть из смежных наук, таких как классическая и современная психология. На житейском уровне мы привыкли разделять характеры людей по дихотомии:\\n- Рефлексивные — это меланхолики и флегматики.\\n- Активные — это холерики и сангвиники.\\nБольшая пятерка\\nАкадемическая психология использует Большую пятёрку — диспозициональная (от англ. disposition — предрасположенность) модель личности человека, отражающей восприятие людей друг другом. В соответствии с названием, модель предполагает, что личность человека включает в себя пять общих и относительно независимых черт. В ней используют показатели:\\n- Экстраверсии (противоположность — интроверсия).\\n- Доброжелательности - дружелюбия, способности прийти к согласию (противоположность - конфликтность).\\n- Добросовестности - сознательности (противоположность - несознательность).\\n- Нейротизма (противоположный полюс — эмоциональная стабильность).\\n- Открытости опыту (интеллект), (противоположность - замкнутость и закрытость к коммуникации и опыту).\\nЗначение личностных моделей во многом определяется их способностью предсказывать поведение индивида. Существует много исследований на эту тему. В частности, Cuperman and Ickes (2009) изучали поведенческие корреляты Большой пятёрки в контексте межличностного взаимодействия участников исследования. Было показано, что Большая пятёрка может предсказывать не только определённые формы поведения, но и реакции партнёра по общению. Например, было обнаружено, что с увеличением нейротизма возрастает число взглядов партнёра на такого человека. Cuperman and Ickes (2009) также показали, что личностные черты партнёров в диаде могут взаимодействовать между собой. Например, было показано, что удовлетворённость от общения зависит от степени экстраверсии (интроверсии) партнёров таким образом, что она возрастает по мере сходства партнёров по этому параметру.\\nМетодами машинного обучения можно выявить дополнительные закономерности для моделей Большой пятерки уже непосредственно исходя из нужд конкретных задач.\\nСвязь показателей Большой пятерки с характеристиками из социальных сетей\\nМетоды машинного обучения могут быть использованы для соотнесения пользователей сети с моделями личности Большой пятерки. Осуществляется это с использованием заранее определенных закономерностей. Рассмотрим для примера соотношение между типами характеров из Большой пятерки с характерами из социальных сетей:\\nВысокая экстраверсия\\nХарактеристики:\\n- Цветовые предпочтения фотографий (горячие оттенки).\\n- Большое количество групп, в которые человек вступает.\\n- Большое количество фотографий, размещенное на странице.\\n- Большое число записей на стене и комментариев, число замен аватаров , число слов в рубрике «обо мне».\\n- Большое количество друзей.\\n- Большое количество записей на стене сделанных пользователем,\\n- Большое количество записей на стене сделанных другими пользователями.\\n- Большое количество портретов.\\n- Большое количество фото пользователя с другими людьми.\\n- Большое количество аватаров.\\n- Большое количество лайков на фото.\\n- Большое число связей (лидер мнений), частое использование соцсети (большое количество логинов).\\n- Использование в качестве основного канала переписки мессенджера ФБ.\\n- Большое количество обновления статуса.\\n- Много оставленных комментариев у других пользователей.\\n- Большое количество других людей на фотографиях.\\n- Превалирование среди друзей лиц противоположного пола.\\n- Большое количество понравившихся страниц на ФБ.\\n- Указанные контакты (тел, почта, адрес).\\n- Большое количество юмористического контента и видео.\\n- Большое количество отмеченных мест и геолокаций.\\n- Большое количество поздравлений с праздниками.\\n- Портрет/Селфи – превалирует селфи.\\n- Большое количество фотографий вне дома.\\n- Активная лицевая экспрессия на фото, особенно на аватаре.\\n- Большое количество непостановочных, неожиданных фотографий с активными занятиями спортом, тусовками и прочее.\\n- Большое количествр подарков в ВК.\\nЛингвистика постов:\\n- Активная лингвистика cо словами, символизирующими активность, разговорчивость, энергичность, авантюризм, общение, встречи и прочее.\\n- Положительные конструкции предложений, без частицы «не».\\n- Слова с коннотациями возможности (могу, можно, возможно), желания (хочу), намерения (намереваюсь), способности (способен).\\n- Сравнительные степени без негативных сравнений «лучше», «больше», «громче», «быстрее», «значительнее».\\n- Положительные формулировки и номинализации (решение, задача, умение).\\n- Глаголы с положительной окраской (получить, решить, создать, добавить, изучить).\\nНизкая экстраверсия\\nХарактеристики:\\n- Абстрактные аватары.\\n- Игра в онлайн игры в соцсети.\\n- Цветовые предпочтения в фотографиях (черно-белые и холодные цвета).\\n- Малое количество групп, в которые пользователь вступил.\\n- Маленькое количество фотографий, которое пользователь разместил на странице – высчитывалось количество фотографий в год (2 и менее).\\n- Закрытый профиль и/или крайне мало заполненный профиль.\\n- Малое количество друзей и явные признаки фэйковости аккаунта.\\n- Отсутствие записей пользователя на стене и/или их крайне ограниченное количество. (репосты не считаются).\\n- Отсутствие записей других пользователей на стене, закрытая к комментариям стена.\\n- Отсутствие портретов и селфи, фотографии преимущественно неживых объектов.\\n- Редкое использование соцсети (малое количество логинов).\\n- Отсутствие комментариев на страницах друзей и интересных групп.\\n- Редкая переписка с использованием мессенджеров соцсетей.\\n- Долгий ответ на сообщения, отсутствие инициативы в сообщениях.\\n- Друзья преимущественно своего пола.\\n- Неуказанные контакты и невозможность отправить сообщение на страницу. Превалирующее количество технического контента в аккаунте.\\n- Пользователь не поздравляет никого с Днем Рождения в соцсети и сам мало получает таких поздравлений.\\n- Такое же относительно праздников.\\n- Неотмеченные геолокации и отсутствие чек-инов.\\n- Большое количество фотографий в помещении, отсутствие людей на фото.\\n- Скупая и сдержанная лицевая экспрессия на лице аватара и других фото.\\n- Фотографии исключительно постановочные и отредактированные.\\n- Нет экспрессивных фотографий.\\nВ лингвистике часто используются:\\n- Негативные конструкции предложений с частицей «не». – слова с коннотациями необходимости (нужно – не нужно), долженствования (должны – не должны) и обязательств (обязан – не обязан).\\n- Сравнительные степени с негативной коннотацией «не хуже», «не плохо», «не меньше», «незначительно».\\n- Проблемные формулировки и номинализации (проблема, сложность, затруднение).\\n- Глаголы с негативной окраской (избежать, избавиться, исключить, выбросить, помешать).\\n- Частые ссылки на негативный опыт и прошлое время.\\n- Критичные высказывания и скепсис по поводу актуальных задач, планов и решений.\\nВысокая доброжелательность\\nХарактеристики:\\n- Большое число друзей.\\n- На фотографиях большое количество менее статусных людей, дети, животные, растения.\\n- Присутствие темы благотворительности и помощи.\\n- Преимущественно пастельные тона на фотографиях.\\n- Умеренное количество групп, интересов, не связанных с активным спортом и экстремальным времяпрепровождением.\\n- Отсутствие обсуждения политики и политического контента и лайкание его.\\n- Раскрытая информация о семье и родственниках.\\nОсобенности лингвистики постов:\\n- Конструкции с пассивным залогом и сослагательным наклонением («нас поставили в известность», «хорошо было бы, если б»).\\n- Частые обращения, предполагающие ролевые и иерархичные отношения («с вашего позволения», «если Вас не затруднит», «не были бы Вы столь любезны?»).\\n- Подчеркнутое использование уменьшительно-ласкательных форм.\\n- Излишняя доверчивость к внешней информации и комментариям без желания ее детализировать.\\n- Избегание использования повелительного наклонения и требований.\\nНизкая доброжелательность\\nХарактеристики:\\n- Небольшое число друзей.\\n- Значительное количество контента, связанного с агрессивностью и экстримом: бои без правил, война, насилие.\\n- Большое количество политического контента.\\n- Горячие тона фотографий.\\n- Фотографии связанные со спортом и конкуренцией.\\n- Большое количество сведений, связанных с употреблением крепкого алкоголя.\\n- Большое количество мата и бранных слов.\\nОсобенности лингвистики постов:\\n- Ссылки на себя как на источник размышлений и принятия решений.\\n- Конструкции с активным залогом и изъявительным наклонением («я решу», «я прочитаю и приму решение»).\\n- Частые обращения, предполагающие ролевые и иерархичные отношения с позиции силы («Вам следовало бы», «Вы должны были сделать», «Для того, чтобы все было правильно, Вам нужно»).\\n- Модальные операторы желания и возможности применительно к себе (хочу, могу, желаю) и модальные операторы долженствования и необходимости (должен, обязан, вынужден) применительно к другим.\\n- Недоверие и скепсис к внешним источникам информации с постоянным желанием ее перепроверить.\\n- Не стесняется использовать повелительное наклонение и прямые требования.\\nВысокая добросовестность\\nХарактеристики:\\n- Минимальное количество загруженных фотографий в сеть, число лайков на портрет.\\n- Минимальное время, проведенное в соцсети.\\n- Указанные контакты и сведения о себе.\\n- Полностью указанный образовательный и трудовой путь.\\n- Редкая смена статуса соцсети либо его стабильное отсутствие.\\n- Гарантированное отсутствие сведений об онлайн-играх.\\n- Большое количество геотегов и чек-иннов.\\n- Большое количество информационного постинга (длинна поста более 300 знаков). Страница, с исключительно профессиональным контентом.\\n- Большое количество фотографий из семейного контекста (с семьей, с детьми).\\nОсобенности лингвистики личного постинга:\\n- Слова с коннотациями необходимости (нужно – не нужно), долженствования (должны – не должны) и обязательств (обязан – не обязан).\\n- Конструкции с пассивным залогом и сложносочиненными предложениями («мне была предоставлена информация о том, что…», «если бы мы владели полной информацией, то решение было бы принято»).\\n- Перечисления («во-первых», «во-вторых», «в-третьих»), разделения (первый шаг, второй шаг и так далее) и последовательности (в начале, потом, в конце).\\n- Причинно-следственные связи и слова-связки, указывающие на них (поэтому, следовательно, так как, исходя из, если – то).\\nНизкая добросовестность\\nХарактеристики:\\n- Большое количество фото с пользователя с животными, абстрактные аватары, аватары на которых изображен другой человек,\\n- Очевидно фэйковая информация в профиле (например – возраст 120 лет).\\n- Полностью скрытый профиль и отсутствие личных сведений пользователя.\\n- Большое количество агрессивного и юмористического контента.\\n- Большое количество проведенного времени в онлайн играх.\\n- Преимущественно короткие сообщение в ленте.\\n- Большое количество мата и бранных слов.\\nВысокий нейротизм\\nХарактеристики:\\n- Высокая частота использования стены для коммуникаций.\\n- Большое количество портретов,\\n- Большое количество фотографий пользователя с другими людьми.\\n- Фотографии преимущественно черно-белой гаммы.\\n- Частая смена аватаров.\\n- Высокое число лайков на портрет.\\n- Большое число друзей.\\n- Большое количество мата и бранных слов.\\n- Частая смена статуса.\\n- Частое упоминание политических, межгендерных и сексуальных тем в личном постинге.\\nНизкий нейротизм\\nХарактеристики:\\n- Минимальное время, проведенное в соцсетях.\\n- Небольшое количество логинов.\\n- Полное отсутствие в той или иной соцсети.\\n- Присутствие в небольшом количестве преимущественно профессиональных группах и пабликах.\\n- Баланс между статусными и нестатусными фотографиями.\\n- Заполненность, но немногословность профиля.\\n- Минимальное количество загруженных фотографий в сеть, число лайков на портрет.\\n- Минимальное время, проведенное в соцсети.\\n- Указанные контакты и сведения о себе.\\n- Полностью указанный образовательный и трудовой путь.\\n- Редкая смена статуса соцсети либо его стабильное отсутствие.\\n- Гарантированное отсутствие сведений об онлайн-играх.\\n- Большое количество геотегов и чек-иннов.\\n- Большое количество информационного постинга (длинна поста более 300 знаков). Страница, с исключительно профессиональным контентом.\\n- Большое количество фотографий из семейного контекста (с семьей, с детьми).\\nВысокая открытость опыту\\nХарактеристики:\\n- Большое число друзей.\\n- Большое количество записей на стене сделанных пользователем.\\n- Большое количество фото пользователя с другими людьми.\\n- Использование широкого спектра функций социальных сетей.\\n- Частая игра в онлайн игры.\\n- Высокое разнообразие контекстов на фотографиях и в постах.\\n- Большое количество групп и интересов.\\n- Большое количество отправленных комментариев.\\nНизкая открытость опыту\\nХарактеристики:\\n- Закрытый профиль.\\n- Малое количество друзей.\\n- Эпизодическое ведение страницы.\\n- Частое упоминание политических, межгендерных и сексуальных тем в личном постинге.\\n- Отсутствие фотографий, лайков и дополнительных сведений о пользователе\\nМузыка и характер[1]\\nАнализ саундтреков из аккаунтов пользователей позволяет сделать выводы об их музыкальных предпочтениях. А используя наработанные коррелянты можно судить о характере пользователя.\\nНапример, считается:\\nэкстраверты в целом чаще слушают музыку и их музыкальные предпочтения более разнообразны, однако они более склонны к поп, хип-хоп, сценической и современной-хитовой музыке. Экстраверты мало слушают музыку, которая «старше их по возрасту»: т.е. экстраверт 1990 года рождения практически не будет слушать музыку, вышедшую раньше своего рождения.\\nУ интровертов это наблюдается в разы чаще. Экстраверты чаще слушают музыку в качестве фона. При этом, - доказано, что экстраверты по сравнению с интровертами, чаще слушают музыку со словами, чем без слов. Интроверты практически не слушают современные хиты из топ-10, а начинают их слушать (и покупать) спустя почти год после их выхода.\\n«Доброжелательные» люди имеют четко ограниченный набор любимых песен и предпочитают не расширять этот список. Кстати, так же поступают и люди с невысокими показателями «открытости опыту». Доброжелательные люди достоверно чаще предпочитают спокойную, ретро и релакс-музыку, а менее доброжелательные – панк и рэп. Удивительно, но шансон, в русском понимании этого направления, оказался, что больше связан с закрытостью к опыту, а не к сниженной доброжелательности.\\n«Добросовестность» незначительно коррелирует с хитами 90-х песен на своем языке, сниженная добросовестность слабо коррелирует с прослушиванием рэпа и отсутствием музыкальных предпочтений. Более добросовестные люди достоверно реже слушают музыку.\\nНейротизм, или эмоциональная неустойчивость, более характерна для людей, прослушивающих музыку печальной и негативной тематики. Уровень нейротизма несколько коррелирует со стремлением многократно слушать одно и то же музыкальное произведение.\\nОткрытость опыту значимо коррелирует с популярной музыкой и современными хитами. Низкие показатели открытости опыта наблюдаются у поклонников андеграунда и шансона.\\nВерно и обратное. С помощью приведенных выше закономерностей на основании типов характеров пользователей возможно сделать вывод об его музыкальных предпочтениях, о музыке, которая ему будет комфортна и будет им востребована.\\nПсихотипы\\nПсихотипология оперирует конкретными психотипами, такими как:\\n- Истероидный психотип.\\n- Эпилептоидный психотип.\\n- Паранойяльный психотип.\\n- Эмотивный психотип.\\n- Шизоидный психотип.\\n- Гипертимный психотип.\\n- Депрессивно-печальный психотип.\\n- Тревожно-мнительный психотип.\\nПредсказание поведения пользователя и оптимизация взаимодействия с ним\\nСуществуют обоснованные и детерминированные признаки для всех этих психотипов и моделей личности, согласно которым пользователи социальных сетей с достаточной степенью достоверности могут быть к ним причислены. Задача эта вполне решаема с помощью современных методов машинного обучения. Компьютерный анализ текстов, поиск в них заранее определенных паттернов и сигнатур, стиля речи и особенности общения, характерных для тех или иных психотипов пользователя, его эмоциональные реакции и комментарии на чужие тексты, внешний вид и мимика на его фотографиях с высокой достоверностью могут быть причислены к одному из вышеперечисленных психотипов. Кроме того, для каждого из этих психотипов досконально изучены их поведенческие особенности, позволяющие прогнозировать их поведение в зависимости от возникающей ситуации. Сформированные таким образом предварительные данные несут в себе достаточный потенциал для эффективного решения ставящихся перед нами задач воздействия на реальных людей. Это увеличивает вероятность положительного результата воздействия на сформированные кластеры пользователей, независимо от того, какой области это касается, будь то коммерческие предложения, политология, социальные опросы или социальные исследования.\\nЭти технологии вполне современны и активно используются в данный момент [2] [3] [4]. Возможности наработок смежных гуманитарных дисциплин для воздействия на людей не ограничиваются только использованием психотипов в качестве дополнительных характеристик личности. Например, использование давно отработанной технологии: нейролингвистического программирования может дать более существенные и эффективные результаты. Правда для этого следует несколько видоизменить характер сбора и анализа данных. Помимо семантического анализа текстов пользователя предполагается проведение их частотного, лингвистического и стилистического анализа. Обращение к конкретному пользователю или группам пользователей должны быть автоматически составлены с такими же характеристиками речи, с использованием их словарного запаса, стилистических оборотов и с учетом привычных для них объемов текста, завершенные конкретным призывом к действию. Особенностями вышеперечисленных методик является:\\n- Заранее определенный и ограниченный перечень возможных характеристик пользователей соцсетей.\\n- Автоматический сбор данных с целью назначения пользователю тех или иных характеристик.\\n- Прогнозирование и оптимизация реакции пользователя на наш с ним контакт.\\nСледует отметить, что возможности машинного обучения значительно шире реализации описанных выше технологий. В частности, представляется возможным осуществление недоступных ранее схем обратной связи. Рассмотрим существующую совокупность интересных нам людей, полностью удовлетворяющих нашим требованиям. Например: покупатели, купившие наш уникальный товар, избиратели, поддержавшие наше общественное движение. Методом машинного обучения возможен анализ активности, характерной для этих людей в социальных сетях, и выявление кластеров параметров, характерных этой совокупности людей. При этом, найденные кластеры могут не иметь ни вербального, ни логического обоснования и вообще их количество заранее не определено. Например, вполне может выясниться, что люди купившие ваш дорогой, уникальный товар по непонятной причине одновременно интересуются рыбалкой, делают одинаковые грамматические ошибки, часто используют букву “Ж”. Это совокупное свойство не имеет названия и не может быть объяснено логически, но может помочь в поиске дополнительных клиентов. Разумеется такие гипотезы, найденные компьютером, нуждаются в проверке и в подтверждении.\\nПримеры использования данных социальных сетей\\nКлассическим примером использования данных о пользователях является реклама и маркетинг. Предприниматели предпочитают осуществлять целевое рекламное воздействие на своих потенциальных клиентов. С этой целью выявляется группа пользователей, соответствующая определенным характеристикам. Таким как:\\n- Проявление заинтересованности в предлагаемой продукции.\\n- Соответствующая платежеспособность.\\n- Положительное реагирование на рекламные предложения.\\nОценка надёжности и платёжеспособности кандидатов на получение кредитов\\nС этой задачей ежедневно сталкиваются все банки, занимающиеся выдачей кредитов. Необходимость в автоматизации этого процесса назрела давно, ещё в 1960–1970-е годы, когда в США и других странах начался бум кредитных карт.\\nЛица, запрашивающие у банка заём, – это объекты, а вот признаки будут отличаться в зависимости от того, физическое это лицо или юридическое. Признаковое описание частного лица, претендующего на кредит, формируется на основе данных анкеты, которую оно заполняет. Затем анкета дополняется некоторыми другими сведениями о потенциальном клиенте, которые банк получает по своим каналам. Часть из них относятся к бинарным признакам (наличие телефонного номера), другие — к порядковым (образование, должность), большинство же являются количественными (величина займа, общая сумма задолженностей по другим банкам, возраст, количество членов семьи, доход, трудовой стаж) или номинальными (имя, название фирмы-работодателя, профессия, адрес).\\nДля машинного обучения составляется выборка, в которую входят кредитополучатели, чья кредитная история известна. Все заёмщики делятся на классы, в простейшем случае их 2 – «хорошие» заёмщики и «плохие», и положительное решение о выдаче кредита принимается только в пользу «хороших».\\nБолее сложный алгоритм машинного обучения, называемый кредитным скорингом, предусматривает начисление каждому заёмщику условных баллов за каждый признак, и решение о предоставлении кредита будет зависеть от суммы набранных баллов. Во время машинного обучения системы кредитного скоринга вначале назначают некоторое количество баллов каждому признаку, а затем определяют условия выдачи займа (срок, процентную ставку и остальные параметры, которые отражаются в кредитном договоре). Но существует также и другой алгоритм обучения системы – на основе прецедентов.\\nСм. Также\\nПримечания\\n- ↑ Филатов, А. В. Заметки профайлера / А. В. Филатов. -Москва: Издательские решения, 2019. -522.\\n- ↑ Social Multimedia Influencer Discovery Marketplace\\n- ↑ Прогнозирование кредитоспособности клиентов на основе методов машинного обучения\\n- ↑ Психотипы для таргетирования рекламы\\nИсточники Информации\\n- somin.ai\\n- Филатов, А. В. Заметки профайлера / А. В. Филатов. -Москва: Издательские решения, 2019. -522.\\n- Cuperman R., Ickes W. Big Five predictors of behavior and perceptions in initial dyadic interactions: Personality similarity helps extraverts and introverts, but hurts “disagreeables” //Journal of personality and social psychology. – 2009. – Т. 97. – №. 4. – С. 667.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='0bf300bc-adf9-407e-a93e-d2b41c972355', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cf59f4037ed1444376201ec81e07ad704468c178c91b849c712c9df8bdf3319d', text='Машинное обучение в медицине\\nМашинное обучение в медицине используют очень активно, находя все больше областей для его применения. Сейчас в медицине используют почти все виды машинного обучения: обучение с учителем, без учителя, с частичным привлечением учителя, с подкреплением. Наиболее активно машинное обучение в медицине используют для решения проблем по диагностике заболеваний и дизайну лекарств. Эти задачи относят к обучению с учителем или с частичным привлечением учителя. Кроме того, машинное обучение стали применять в персонализированной медицине и генерации данных различных исследований для анонимизации данных пациентов. В этих задачах сейчас все больше применяют обучение с подкреплением и обучение без учителя, в частности, генеративные состязательные сети. Машинное обучение в медицине начали изучать еще в 2000-ых и оно продолжает активно развиваться и в наши дни.\\nСодержание\\n- 1 Диагностика заболеваний по результатам рентгенологических и УЗИ исследований\\n- 2 Персонализированная медицина\\n- 3 Поиск лекарств\\n- 4 См. также\\n- 5 Примечания\\n- 6 Источники информации\\nДиагностика заболеваний по результатам рентгенологических и УЗИ исследований\\nДиагностика по изображению\\nВ диагностике заболеваний есть большое количество задач, которые можно решить при помощи машинного обучения, а в частности, при помощи анализа результатов различных исследований, таких как рентген, УЗИ или МРТ. В основном задача любой модели сводится к предсказанию, болен ли человек сейчас. В зависимости от целей исследования используют разные типы классификации: обычную (рис. 1), мультиклассовую или вероятностную (рис. 2).\\nДля решения таких задач чаще всего используют глубокое обучение. Модели на вход подается картинка с рентгенологическим или ультразвуковым исследованием пациента, и по ним предсказывают наличие болезни. Обычно внутри таких моделей-классификаторов лежат сверточные нейронные сети, а иногда к ним добавляется механизм внимания. За основу берутся state-of-the-art модели в области сверточных нейронных сетей, такие как GoogLeNet[3], при этом точность предсказаний превышает 90%. Такие модели учатся на размеченных тренировочных наборах данных, поэтому их можно отнести к обучению с учителем. Большое распространение такие классификаторы получили в предсказании злокачественности новообразований, классификации заболеваний легких, подборе дозы контраста при проведении МРТ.\\nПрименения\\nМногие модели учатся не только определять, есть ли опухоль на данном образце, но и локализировать ее (рис. 3). Таким образом, необходимо решить задачу сегментации изображения, то есть выделения каких-то ее наиболее важных частей. Технически задача не сильно отличается от предыдущей и решается все теми же сверточными нейронными сетями.\\nПоскольку точность предсказаний у описанных выше моделей достаточно высока, их стали применять на практике. Сейчас ведутся исследования по внедрению таких моделей в УЗИ-аппараты для того, чтобы быстрее и точнее определять местоположение и злокачественность опухоли. Кроме того, такие модели стали применять в направленной лучевой терапии, когда злокачественная опухоль облучается различными видами частиц. Известно, что эти частицы уничтожают не только раковые, но и здоровые клетки. Именно поэтому активно внедряются модели, которые могут подсказать аппарату точное направление облучения. Также сверточные сети стали использовать для определения дозы контрастного вещества при МРТ[5].\\nГенерация результатов исследований\\nДля обучения сверточных нейронных сетей необходимо большое количество данных, которые очень часто достаточно тяжело или даже невозможно получить из-за запрета на использование данных исследований без согласия пациента. Поэтому сейчас для получения достаточно больших датасетов стали применять генеративные состязательные сети (GAN).\\nЗадачу таких GAN можно разделить на две: генерация результатов исследований здоровых пациентов и пациентов с патологиями. В случае второй задачи важно, чтобы сгенерированные изображения правильно определялись именно по типу патологии.\\nОсновная проблема, с которой сталкиваются такие модели — необходимость очень точно определять границы объекта на сгенерированном изображении, а также не допускать размытости. Эти две проблемы долгое время не получалось решить без большого количества реальных данных, вследствие чего не было возможным применение сгенерированных изображений на практике.\\nСильно улучшить поведение моделей удалось путем использования метрики Вассерштейна[на 09.01.21 не создан]. Интуитивно, если каждая мера измеряет распределение «грунта» по метрическому пространству, то расстояние Вассерштейна измеряет минимальную стоимость преобразования одного распределения грунта в другое, при этом предполагается, что стоимость прямо пропорциональна количеству грунта и расстоянию, на которое его надо перетащить. Использование такой метрики в GAN помогло сильно улучшить поведение моделей при генерации данных МРТ исследований. Одной из моделей, в которых стали применять метрику Вассерштейна для генерации изображений исследований, стала 3D-alpha-WGAN (рис. 4).\\nПерсонализированная медицина\\nПерсонализированная медицина (англ. personalized medicine) — новая организационная модель построения медицинской помощи пациентам, которая основывается на подборе индивидуальных лечебных, диагностических и превентивных средств, оптимально подходящих по биохимическим, физиологическим и генетическим особенностям организма.\\nОсновная цель нового направления в медицине заключается в персонализации и оптимизации профилактических мероприятий и лечения пациентов для исключения негативных последствий и осложнений, проявляющихся из-за индивидуальных особенностей. Основные отрасли медицины, где применяются новые принципы — онкология, фармация и фармакогеномика. Последняя занимается изучением реакций организма на медицинские препараты в зависимости от индивидуальных наследственных факторов.\\nЭкспрессия генов и анализ транскриптомных данных\\nМногие модели ориентируются на данные экспрессии генов[8] (в широком смысле — процесс получения белка из последовательности ДНК). Известно, что от количества некоторых белков напрямую зависит возможность клеток становиться раковыми, а также порождать другие заболевания. Совокупность изменений в большом количестве различных белков может приводить к заболеванию. Именно поэтому модели персонализированной медицины основываются на данных экспрессии. Часто в качестве основы используют сверточные нейронные сети (рис. 5), располагая гены, отвечающие за похожие по своей функции белки, рядом друг с другом.\\nПрямой анализ экспрессии генов — трудная и дорогостоящая задача, поэтому часто обращаются к транскриптомным данным. Транскриптом — совокупность всех молекул РНК[9], которые присутствовали в клетке после завершения процесса трансрипции (получение РНК с матрицы ДНК). Транскриптом включает в себя матричную РНК (мРНК) — РНК, с которой впоследствии транслируются белки, и некодирующую РНК, которая, в свою очередь, не используется для получения белков. Транскриптомные данные чаще всего получают с помощью РНК-секвенирования (англ. RNA-seq) или ДНК-микрочипов (англ. DNA-microarray). С помощью специальных процедур из взятой у пациента пробы выделяют мРНК, которая затем наносится на ДНК-микрочип, где цепочки мРНК зацепляются, образуя двухцепочечные молекулы. Число цепочек, зацепившихся за определенный участок ДНК-микрочипа, определяет интенсивность свечения этого участка при сканировании. Так косвенно определяют экспрессию каждого из генов. Следующая проблема, с которой сталкиваются исследователи — слишком большое количество генов (например, у человека их около 28000). Вследствие этого очень тяжело обучать модели, поэтому приходится прибегать к уменьшению размерности.\\nУменьшение размерности при работе с данными экспрессии генов\\nДля уменьшения размерности в случае биологических данных применяются методы, основным критерием которых становится их скорость. Поскольку количество генов очень велико, чаще всего нет возможности опробовать встроенные и оберточные методы, поэтому используют фильтры.\\nОдним из примеров моделей, основанных на фильтрах является модель MeLiF[11] (рис. 6), которая берет несколько фильтров с соответствующими функциями измерения релевантности признака , после чего строит новую меру значимости как , где — набор вещественных коэффициентов. После получения новой меры значимости происходит оценка модели на лучших выбранных признаках, которая состоит в полном цикле тренировки и тестирования. В случае удовлетворительного результата алгоритм завершается, возвращая текущий набор признаков, иначе — возвращается снова к получению новой меры на признаках.\\nМедицинская карта\\nДругая задача — предсказать, заболеет ли человек в будущем. Для этого часто используется электронная медицинская карта пациента, и на вход сети подаются данные о пациенте, результаты исследований, его генеалогическое древо и другая медицинская информация. Основываясь на полученных данных, модель должна предсказать вероятность того, что человек может заболеть каждой болезнью из приведенного набора. Если вероятность хотя бы по одному из маркеров превышает некоторое значение — такая модель рекомендует пациенту обратиться к специалисту и относит его в группу высокого риска по этому параметру. В свою очередь специалист может подтвердить или же опровергнуть опасения модели, отдавая ей результат — права модель или нет. Таким образом, эта проблема относится к классу задач обучения с подкреплением. С точки зрения архитектуры моделей — в таких задачах часто используют метод опорных векторов (SVM) или глубокое обучение.\\nПоиск лекарств\\nПоиск лекарств (англ. drug discovery, drug design) — процесс поиска новых лекарственных средств, часто основанный на знаниях о биологической мишени (целевом белке, с которым должно взаимодействовать лекарственное вещество). При поиске новых лекарственных средств часто прибегают к помощи машинного обучения в таких задачах, как предсказание молекулярных свойств потенциальной молекулы лекарства, формы какого-либо белка, активности взаимодействия между веществами.\\nПредсказание молекулярных свойств\\nОдна из главных задач машинного обучения при поиске новых лекарств — сужение круга их поиска. Чаще всего фармацевтические компании имеют на руках библиотеки с огромным количеством веществ, которые они потенциально могут синтезировать и опробовать в качестве лекарства. Но обычно размеры этих библиотек составляют тысячи молекул, поэтому синтезировать и проверить каждую из них не представляется возможным. В этом случае прибегают к предсказанию некоторых свойств этих молекул, которые точно определяют, может ли молекула быть использована как лекарство. Для предсказания свойств молекул обычно используют молекулярный граф (рис. 7) — графическое представление молекулы (ее атомов и связей).\\nПервые нейронные сети для предсказания молекулярных свойств использовали Моргановские фингерпринты (англ. Morgan fingerpints), которые для каждого атома в молекуле выделяли всех его соседей на каком-то определенном расстоянии (которое является гиперпараметром) и смотрели на наличие такой подструктуры в молекуле (рис. 8). Получался аналог оne-hot кодирования. Впоследствии этот метод был несколько усовершенствован, и стали смотреть не на наличие подструктуры, а на то, сколько раз она встречается в молекуле. Прорыв в этой области случился с появлением сети NeuralFingerprints [13], которая является примером одной из первых попыток применения графовых нейронных сетей в предсказании свойств молекул.\\nNeuralFingerprints принимает один гиперпараметр — максимальное расстояние, которое нужно учитывать при просмотре соседей каждого атома. После этого для каждого расстояния для каждого атома суммируются атомные представления его соседей на текущем расстоянии. Таким образом, получается векторное представление текущего атома фиксированной длины, которая равна количеству свойств у одного атома. Каждый элемент такого представления умножается на обучаемый параметр, уникальный для номера свойства и текущего рассматриваемого расстояния. После этого применяется функция активации к полученному ранее вектору, умноженному на вес, отвечающий за текущее расстояние. Полученные результаты для каждого из атомов на каждом из расстояний суммируются и получается результирующий вектор свойств для молекулы. Таким образом, в этой сети обучаемые параметры — веса для каждого из свойств атомов на каждом расстоянии (, где — индекс номера свойства (в модели их всего 5), — индекс для текущего расстояния) и веса для каждого из расстояний ( , где — индекс для текущего расстояния). Псевдокод представлен ниже.\\nfunction neuralFingerptint(molecule, R, H, W): # R - максимальное расстояние, H - матрица весов размера len(molecule) f = array[len(molecule), 0] for a in molecule: r[a] = g(a) R, W - вектор весов размера R# записываем свойства для каждого атома for L = 1 to R: for a in molecule: neighbors = neighbors(a) # смотрим соседей на расстоянии L от текущего атома a v = r[a] + sum(r[i] for i in neighbors) # суммируем вектора соседей и вектор текущего атома r[a] = σ(v H[a][L]) # изменяем представление текущего атома i = softmax(r[a] W[L]) # получаем вектор для текущего атома и расстояния f = f + i # добавляем его к ответу return f\\nЭта сеть была одной из первых в этой области, и сейчас используется как базовый метод в множестве статей. В основу новых методов и сейчас чаще всего ложатся графовые нейронные сети. Подходы графовых нейронных сетей адаптируют под молекулярный граф путем поиска элементов на расстоянии не более, чем N (где N является гиперпараметром), или последовательным рассмотрением каждой вершины и усреднением полученных значений.\\nПредсказание формы белка\\nСеквенирование[15] — процесс получения нуклеотидной последовательности из молекулы ДНК. Из нуклеотидной последовательности можно получить аминокислотную последовательность, которая, в свою очередь, кодирует любой белок в организме.\\nПредсказание формы белка — другая очень важная задача машинного обучения в фармацевтике. С возникновением технологий секвенирования ДНК у сообщества появилась возможность быстро и достаточно качественно прочитывать белковые последовательности, но получать пространственную структуру полученных белков экспериментально все еще очень трудоемко и дорого. Тем не менее, знать пространственную структура белка очень важно, поскольку от нее сильно зависят типы соединений, которые могут связаться (прореагировать) с этим белком. Например, при подборе потенциальной вакцины, необходимо точно знать форму антитела, чтобы понимать, сможет ли это соединение захватить мишень (вирус, бактерию, белок).\\nПредсказание формы белков основано на нейронных сетях, которые как вход используют очень длинную аминокислотную последовательность (размер алфавита ограничен — всего различных аминокислот 20), а на выходе должны предсказать значения торсионных углов[16] между аминокислотами. В декабре 2020 года DeepMind (исследовательское подразделение Google) заявили, что решили проблему пространственной структуры белка[17]. Авторы модели утверждают, что значение метрики глобального расстояния (англ. global distance test) в их сети AlphaFold2 (рис. 9) превысило 90%. Метрика глобального расстояния — это метрика, которая вычисляется для каждой аминокислоты как процент атомов углерода из главной цепи белка, которые в сгенерированном белке расположены не более чем на расстоянии какого-то определенного количества ангстрем от соответствующего атома углерода в исходном белке. Обычно это значение берется равным 1, 2, 4 или 8 ангстрем (10-10м).\\nГенерация молекулярных структур\\nЕще одна задача, которая есть сейчас в мире машинного обучения — генерировать новые молекулы, которые могут потенциально быть лекарствами. В отличие от подхода с анализом уже существующих библиотек лекарств, такай метод исключает возможность \"пропустить\" хорошо походящее вещество из-за того, что оно не было включено в библиотеку для анализа.\\nДля кодирования молекулярной структуры существует специальная нотация SMILES (Simplified Molecular Input Line Entry System, с англ. — «система упрощённого представления молекул в строке ввода») — система правил для однозначного описания состава и структуры молекулы химического вещества с использованием строки символов (рис. 10). Таким образом, задача моделей состоит в генерации строки, правильной с точки зрения SMILES. Стоит отметить, что есть возможность сгенерировать правильные SMILES-строки с точки зрения синтаксиса, но не правильные по валентности[20] (например, атом углерода не может иметь валентность больше, чем 4, но можно сгенерировать SMILES, где валентность углерода — 5.)\\nДля генерации молекулярных структур используют генеративные состязательные сети (рис. 11). Общую идею подхода можно описать так — предлагается генерировать различные молекулярные структуры в формате SMILES-строки (это делает генератор), а уже потом проверять, действительно ли их можно использовать как лекарство и насколько сложно их синтезировать (это делает дискриминатор — пытается отличить сгенерированный SMILES от настоящего).\\nДискриминатор обычно проверяет схожесть с лекарственными средствами (по набору физических свойств, таких как растворимость[21], гидрофильность[22], липофильность[23]) и синтезируемость молекулы с данной SMILES-строкой (по валентностям атомов, кратности связей, заряду молекулы). Таким образом, задача генератора — сгенерировать такую строку SMILES для молекулы, чтобы дискриминатор не отличил ее от настоящей. Архитектура дискриминатора чаще всего остается очень похожей на архитектуру обычной сети, предсказывающей молекулярные свойства. В качестве дискриминатора часто используются графовые или сверточные нейронные сети. Для генератора же обычно используют механизм долгой краткосрочной памяти.\\nСм. также\\n- Нейронные сети, перцептрон\\n- Глубокое обучение\\n- Графовые нейронные сети\\n- Компьютерное зрение\\n- Обучение с подкреплением\\nПримечания\\n- Protein structure prediction\\n- Википедия: Персонализированная медицина\\n- 7 Applications of Machine Learning in Pharma and Medicine\\n- Ascent of machine learning in medicine\\n- Глубокое машинное обучение (искусственный интеллект) в ультразвуковой диагностике\\n- Википедия: Метрика Васерштейна\\nИсточники информации\\n- ↑ Seetha J, Raja S. S. Brain Tumor Classification Using Convolutional Neural Networks. Biomed Pharmacol J 2018;11(3).\\n- ↑ CoroNet: A deep neural network for detection and diagnosis of COVID-19 from chest x-ray images, 2020\\n- ↑ Szegedy et al., Going Deeper with Convolutions, 2015\\n- ↑ Zhiyun Xue et al., Gender Detection from Spine X-ray Images Using Deep Learning, 2018\\n- ↑ Lundervold et al., An overview of deep learning in medical imaging focusing on MRI, 2019\\n- ↑ Generation of 3D Brain MRI Using Auto-Encoding Generative Adversarial Networks\\n- ↑ Convolutional neural network models for cancer type prediction based on gene expression\\n- ↑ Википедия: Экспрессия генов\\n- ↑ Википедия: РНК\\n- ↑ Сметанников Иван Борисович, Метод и алгоритмы выбора признаков в предсказательном моделировании фенотипических характеристик на основе транскриптомных данных\\n- ↑ Smetannikov et al., MeLiF: Filter Ensemble Learning Algorithm for Gene Selection\\n- ↑ Adrià Cereto-Massagué et al., Molecular fingerprint similarity search in virtual screening, 2015\\n- ↑ Duvenaud et al., Convolutional Networks on Graphs for Learning Molecular Fingerprints, 2015\\n- ↑ Wikipedia: AlphaFold\\n- ↑ Википедия: Секвенирование\\n- ↑ Торсионные углы\\n- ↑ Фундаментальная «проблема белка» решена\\n- ↑ Википедия: SMILES\\n- ↑ Evgeny Putin et al., Reinforced Adversarial Neural Computer for de Novo Molecular Design, 2018\\n- ↑ Википедия: Валентность\\n- ↑ Википедия: Растворимость\\n- ↑ Википедия: Гидрофильность\\n- ↑ Википедия: Липофильность', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='f8d48143-06bb-4948-a25b-01c80cedfa4f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ce16788a50374bb1df62b95d1cb80aaea26d5f8a8f6245e2ea19764db4b7832e', text='Deepfake\\nDeepfake (дипфейк) — результат работы ряда алгоритмов для синтеза изображений человеческого лица или голоса. Основные алгоритмы применяемые для решения данной задачи основаны на Генеративно-состязательных сетях. Современные алгоритмы позволяют генерировать не только лицо человека, но и его голос. C таким примером можно ознакомится по ссылке [1]\\nСодержание\\nВведение\\nЗадача замены лиц или генерация Deepfake изображений состоит в том, чтобы перенести лицо с исходного (source) изображения на нужное (target) изображение. Такой перенос должен быть бесшовным и незаметным человеческому глазу. Реконструкция лица заключается в изменении лица из source изображения, так чтобы мимика и любая лицевая геометрия была соблюдена и соответствовала target изображению. Методы решаюшие данную задачу в прошлом были основаны на детектировании ключевых точек лица и соответствующей анимацией на основе построения триангуляции Делоне. В основе современных алгоритмов лежат Генеративно-Состязательные Сети с различными модификациями. Так же некоторые из используюмых методов используют основаны на попытке аппроксимации некого распределения признаков. Данные методы пытаются вычисляют данное распределение и переносят с помощью нейронных сетей эти скрытые представления в результате генерируется новое фотореалистичное лицо, которое соответствует необходимым характеристикам и метрикам.\\nПервые методы как было сказано выше были основаны на детектировании ключевых точек, одним из известных алгоритмов в этой области является Face2Face, метод вычисляет меш лица и с помощью алгоритма 3D morphable face model переносит геометрию. Методам на основе Генеративно-состязательных сетей не требуется никакие многоуровеные эвристические методы, они берут исходное изображение и сразу делают перенос в end-to-end стиле.\\nРеконструкция лица и сегментация\\nПервый этап рассмотренного алгоритма является сегментацией лица в target и source изображениях, изменение геометрии из source лица, чтобы оно соответствовало target геометрии лица. Имея изображение $I \\\\in {\\\\rm I\\\\!R}^{3 \\\\times H \\\\times W}$ и тепловую карту лицевых точек $H(p) \\\\in {\\\\rm I\\\\!R}^{N \\\\times H \\\\times W}, p \\\\in {\\\\rm I\\\\!R}^{N \\\\times D}$, где $N$ - число точек, $D$ - размерность точек, обычно она равна 2, а число точек не превышает 70, мы обучаем генератор, чтобы он делал трансформацию данной тепловой карты и входного изображения в изображение с необходимой нам геометрией $G_r : \\\\{ {\\\\rm I\\\\!R}^{3 \\\\times H \\\\times W}, {\\\\rm I\\\\!R}^{N \\\\times H \\\\times W} \\\\} \\\\to {\\\\rm I\\\\!R}^{3 \\\\times H \\\\times W} $ Пусть $v_s, v_t \\\\in {\\\\rm I\\\\!R}^{70 \\\\times 3}$ и $e_s, e_t \\\\in {\\\\rm I\\\\!R}^{3}$ будут $3$ мерными ключевыми лицевыми точками лица и углами Эйлера в соответствии к $F_s$ и $F_t$. Тогда мы построим 2D проекцию $p_j$ интерполируя между $e_s$ и $e_t$ и центроидами $v_s$ и $v_t$ и используя промежуточные точки мы обратно спроецируем $v_s$ на $I_s$. Другими словами алгоритм реконструкции является рекурсивным для каждой итерации\\n$i < j < n$\\n$I_{r_{j}}, S_{r_{j}} = G_r(I_{r_{j - 1}};H(p_j)), I_{r_{0}} = I_s$\\nНаша модель $G_r$ имеет 2 выхода, первый на выходе выдает изображение с перенесенной геометрией, второй выход маску для сегментации. Так же стоить заметить что маска для сегментации умеет различать часть лица с кожей и часть с волосами отдельно. Такой подход позволяет увеличить точность.\\nТакой генератор обучается следующую функцию потерь\\n$Loss(G_r) = \\\\lambda_{stepwise} Loss_{rec}(I_{r_{n}}, I_{t}) + \\\\lambda_{rec}Loss_{rec}(I_{r}, I_{t}) + \\\\lambda_{adv}Loss_{adv} + \\\\lambda_{seg}Loss_{pixel}(S_r, S_t)$\\n$Loss(G_s) = Loss_(CE) + \\\\lambda_{reenact}Loss_{pixe}(S_t, S_{t}^{r})$\\nГде $G_r$ - генератор переноса геометрии, $G_s$ - генератор сегментации лица.\\nПеренос сгенерированного лица\\nОбщеизвестным способ переноса одной геометрии одной текстуры на другую является перенос полигонов из сеток с одной геометрии на другую. Однако существуют более современные способы. Имея множество исходных изображения $\\\\{ I_{s_0}, ..., I_{s_{n}} \\\\}$, углов Эйлера $ \\\\{e_1, ..., e_n \\\\}$ соответствующих лиц $\\\\{ F_{s_{0}}, ..., F_{s_{n}} \\\\}$ строится карта внешнего вида (appearance map). Строится она следующим образом. В начале проецируются соответствующие углы Эйлера на плоскость. Далее используя K-D дерево данные точки в пространстве сегментируются и удаляются слишком близкие, поскольку они не несут в себе много полезной информации, а вычислительная сложность разительно увеличивается. В конце используя оставшиеся точки мы строим меш лица используя триангуляцию Делоне. Для каждого угла $e_t$ лица $F_t$ и точки $x_t$ мы ищем треугольник $T$ соответствующий данной точке. Пусть $x_{i_{1}}, x_{i_{2}}, x_{i_{3}}$ будут трисом $T$ и $I_{s_{i_{1}}}, I_{s_{i_{2}}}, I_{s_{i_{3}}}$ соответствующие лица. Необходимо вычислить барицентрические координаты $\\\\lambda_{1}, \\\\lambda_{2}, \\\\lambda_{3}$ от $x_t$ относительно $x_{i_{1}}, x_{i_{2}}, x_{i_{3}}$. Тогда результат интерполяции\\n$I_r = \\\\sum_{k=1}^{3} \\\\lambda_k G_r(I_{s_{i_{k}}}; H(p_t))$\\nгде $p_t$ 2D ключевая точка лица $F_t$.\\nВписывание лица\\nПоскольку из-за разницы в углах поворота или прически сегментированные маски могут отличаться видимыми регионами, поэтому нам необходимо \"дорисовать\" или \"стереть\" участки которые не могут быть перенесены напрямую. Чтобы решить данную задачу мы обучим еще одну модель $G_c$. $G_c$ принимает в себя лицо $F_s$, такое что все необходимые участки будут дорисованы, а ненужные удалены. Функция потерь такой сети\\n$Loss(G_c) = \\\\lambda_{rec}Loss_{rec}(I_c, I_t) + \\\\lambda_{adv}Loss_{adv}$\\nОтрисовка полученного лица\\nНа самом последнем шаге мы уже имеем лицо которое правильно повернуто и на нем присутствуют только регионы лица, что и на нужном нам изображении. Нам остается только применить цветокоррекцию и последние минимальные правки чтобы отрисованное лицо выглядело натурально.\\nПусть $I_t$ будет исходным лицом, а $I_{r}^{t}$ будет нужным нам лицом для переноса и $S_t$ маской сегментации. Тогда используя уравнене Пуассона мы можем выполнить цветокоррекцию следующим образом\\n$P(I_t;I_{r}^{t};S_t) = arg min ||\\\\nabla f - \\\\nabla I^{t}_{r}||^{2}_{2}$\\n$f(i, j) = I_t(i, j), \\\\forall S_t(i, j) = 0$\\n$\\\\nabla$ - оператор взятия градиента.\\nДанное уравнения используется в качестве функции для оптимизации нашего генератора $G_b$, который и будет заниматься отрисовкой финальной версии нашего Deepfake изображения.\\n$Loss(G_b) = \\\\lambda_{rec}Loss_{rec}(I_t;I_{r}^{t};S_t), P(I_t;I_{r}^{t};S_t)) + \\\\lambda_{adv}Loss_{adv}$\\nДанные для обучения и процесс обучения\\nВ качестве обучающего множества можно использовать множество датасетов с размеченными лицами, одним из таких служит IJB-C. На нем обучается генератор $G_r$. Данный датасет состоит из более чем $11$ тысяч видео, $5500$ из которых выского качества. Обучая наш алгоритм кадры из $I_s$ и $I_t$ берутся из двух случайных видео. Так же для начального шага нам был необходим perceptual loss, он может быть получен обучив VGG-19 модель или взяв готовую обученную на ImageNet или VGGFace2, второй датасет предпочтительный, поскольку для его обучения используются только лица. В качестве оптимизатора рекомендуется использовать Adam с параметром скорости обучения (learning rate) = $0.0002$. $\\\\lambda_{perc} = 1, \\\\lambda_{pixel} = 0.1, \\\\lambda_{adv} = 0.001, \\\\lambda_{seg} = 0.1, \\\\lambda_{stepwise} = 1$, параметр $\\\\lambda_{reenact}$ возрастает линейно от $0-1$.\\nОбщее время составляет около 2-3 дней на Nvidia Tesla V100. Скорость работы всего алгоритма состовляет около ~$10$ fps на Nvidia Tesla V100.\\nРеализация\\nГотовую реализацию можно найти по ссылке FSGAN, так же существуют альтернативные, но не менее продвинутые алгоритмы DeepFaceLab, faceswap.\\nИсточники информации\\n- Nirkin, Yuval, Yosi Keller, and Tal Hassner. \"FSGAN: Subject agnostic face swapping and reenactment.\" In Proceedings of the IEEE international conference on computer vision, pp. 7184-7193. 2019.\\n- Nirkin, Y., Masi, I., Tuan, A. T., Hassner, T., & Medioni, G. (2018, May). On face segmentation, face swapping, and face perception. In 2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018) (pp. 98-105). IEEE.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='4228a1d0-2b46-4120-81b3-08fb267f17d9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d9073de947d077fda0249434d706b4801ca8a90e8cabe4a1b55792579e6199a6', text='Представление знаний\\nПредставление знаний (англ. knowledge representation) — направление в исследованиях искусственного интеллекта, посвящённое представлению информации о мире в форме, которую было бы возможно использовать в компьютерных системах для решения сложных прикладных задач. Таковыми являются, например, диагностирование заболеваний или ведение диалога на естественном языке. Представление знаний включает в себя психологические исследования по решению задач человеком для построения формализмов, которые упростили бы работу со сложными системами. Примерами формализмов представления знаний являются семантические сети, архитектуры систем, правила и онтологии.\\nСодержание\\n- 1 Графы знаний\\n- 2 Онтология\\n- 3 Построение при помощи методов машинного обучения\\n- 3.1 Векторные представления графов знаний\\n- 3.2 Обучение онтологий\\n- 3.3 Лингвистические методы\\n- 3.4 Статистические методы\\n- 3.5 Индуктивное логическое программирование\\n- 3.6 Оценка онтологии\\n- 4 Особенности применения онтологии для конкретных задач\\n- 5 См. также\\n- 6 Примечания\\n- 7 Источники информации\\nГрафы знаний\\nИстория\\nСемантические сети[1] (рис. 1) были разработаны в 1960 году из-за растущей необходимости в инструменте для представления знаний, который мог бы охватить широкий спектр сущностей: объекты реального мира, события, ситуации и отвлечённые концепты и отношения, — в конце концов будучи применённым в задаче поддержания диалога на естественном языке. Основной целью разработки семантических сетей было решение множества задач, например, представление планов, действий, времени, верований и намерений. При этом способ решения этих задач должен был быть достаточно обобщённым.\\nВ 1980-х гг. Гронингенский университет и университет Твенте начали работу над совместным проектом, названным \"Графы знаний\", базируясь на устройстве семантических сетей с рёбрами, ограниченными наперёд заданным количеством отношений — для упрощения алгебры на графах. В последовавшие десятилетия граница между понятиями \"Графов знаний\" и \"Семантических сетей\" размывалась всё больше.\\nВ 2012 году Google представили свою версию графа знаний[2].\\nОпределение\\nНе существует формального определения графа знаний. Однако есть ряд требований, которых следует придерживаться при его построении[3]:\\n- Граф знаний определяется своей структурой (сущностями и связями между ними).\\n- Утверждения внутри графа знаний являются однозначными.\\n- Граф знаний использует конечный набор типов отношений.\\n- Все указанные сущности внутри графа знаний, включая типы и отношения, должны быть определены с использованием глобальных идентификаторов с однозначными обозначениями.\\n- Утверждения в графе знаний должны иметь явно указанные (лучше всего, проверенные) источники.\\n- Граф знаний может иметь оценки неопределённостей (вероятности, с которыми истинны те или иные утверждения[4]).\\nПрименение\\nВопросно-ответные системы. Самым распространённым применением графов знаний являются вопросно-ответные системы. Графы знаний располагают огромным количеством информации, доступ к которой проще всего получать посредством схемы вопрос-ответ.\\nХранение информации исследований. Многие компании используют графы знаний для хранения результатов, полученных на разных стадиях исследований, которые могут быть использованы для построения понятных моделей, просчёта рисков, слежения за различными процессами и подобных задач.\\nРекомендательные системы. Некоторые компании используют графы знаний как фундамент для своих рекомендательных систем. Здесь графы знаний позволяют находить связи между фильмами, телепрограммами, персоналиями и другими объектами. По выявленным связям можно пытаться предсказать индивидуальные предпочтения пользователя.\\nУправление цепочками поставок. Компании могут эффективно следить за перечнями различных составляющих, задействованного персонала, времени и других характеристик, что позволяет им передавать вещи более выгодно.\\nОткрытые проблемы\\n- Выявление лучших практик для построения графов знаний. Важной проблемой является создание единого набора эвристик и практик, которые можно было бы применить для построения графов знаний. Такой набор мог бы помочь разработчикам и исследователям в понимании и использовании графов знаний.\\n- Динамически изменяемые знания. Знания не статичны, они зависят от времени. Например, некоторое утверждение, которое было истинным в один момент времени, может перестать быть таковым в другой. Поэтому открытой проблемой является поддержка изменений в знаниях.\\n- Оценка корректности и полноты графа знаний. Не выработаны объективные критерии оценки графов знаний. Открытой проблемой является ответ на вопрос, какое качество более важно для графа знаний: корректность (непротиворечивость), полнота или другое.\\nОнтология\\nПонятие онтологии существует как в информатике, так и в философии, однако эти понятия похожи.\\n|Определение:\\n|Онтология (в информатике) — формализация знаний, включающая в себя представление, формальное именование и определение категорий, свойств и отношений между понятиями, данными и сущностями некоторой области знаний.\\nТермин «онтология» применительно к графам знаний это, прежде всего, способ моделирования и формального представления схемы данных, обеспечивающий гораздо большие возможности, чем традиционные базы данных или объектно-ориентированный подход.\\nСогласно общепринятому определению в компьютерных науках, онтология — это способ формализации знаний, абстрактных или специфических, в какой-либо предметной области, реализованный на основе формального описания объектов, фактов и отношений между ними.\\nФормализация\\nДля формализации используется концептуальная схема.\\n|Определение:\\n|Концептуа́льная схе́ма[5] — семантическая сеть из взаимосвязанных по определенным правилам понятий и концепций. Обычно такая схема состоит из структуры данных, содержащей все релевантные классы объектов, их связи и правила (теоремы, ограничения), принятые в этой области.\\nФилософия\\nТермин «онтология» в информатике является производным от соответствующего древнего философского понятия.\\nОбщее с философским понятием:\\n- И то, и другое — попытка представить сущности, идеи и события со всеми их взаимозависимыми свойствами и отношениями в соответствии с системой категорий.\\n- В обеих областях существует значительная работа по проблемам онтологической инженерии[6].\\nОтличия от философского понятия:\\n- Онтология в информатике должна иметь формат, который компьютер сможет легко обработать.\\n- Информационные онтологии создаются всегда с конкретными целями — решения конструкторских задач; они оцениваются больше с точки зрения применимости, чем полноты.\\nВ каждой научной дисциплине или области знаний создают онтологии для организации данных в виде информации и знаний. С новыми онтологиями упрощается решение задач в этих областях. Однако при решении задач возникают определённые сложности, например, языковой барьер между исследователями разных стран. Эта сложность может быть нивелирована поддержкой контролируемых словарей[7] жаргона.\\nОбщие компоненты онтологий\\n|Название\\n|Описание\\n|Пример\\n|Экземпляры (объекты)\\n|Базовые или \"наземные\" объекты (индивиды).\\n|Мария, 1, Солнце.\\n|Классы (понятия)\\n|Наборы, коллекции, концепции, классы в программировании, типы объектов или виды вещей.\\n|Человек, Число, Звезда.\\n|Атрибуты\\n|Аспекты, свойства, признаки, характеристики или параметры, которые могут иметь объекты (и классы).\\n|Возраст: 21, Чётность: нет, Спектральная классификация: жёлтый карлик.\\n|Отношения\\n|Способы, которыми классы и индивиды могут быть связаны друг с другом.\\n|Люди являются Животными.\\n|Правила\\n|Высказывания в форме \"Если ..., то ...\" (антецедент-консеквент), описывающие логические выводы, которые могут быть сделаны из утверждения в определенной форме.\\n|Еслисмертен, то умрёт.\\n|Аксиомы\\n|Утверждения (включая правила) в логической форме, которые вместе составляют общую теорию, описываемую онтологией в её области применения. Это определение отличается от определения \"аксиом\" в формальной логике. В ней аксиомы включают только утверждения, утверждаемые как априорное знание. Здесь же \"аксиомы\" также включают в себя теорию, полученную из аксиоматических утверждений.\\n|Человек смертен. Сократ — человек.\\n|События\\n|Изменение атрибутов или отношений.\\n|умер ( больше не является живым).\\nОнтологии обычно кодируются с помощью языков онтологий — специализированных формальных языков.\\nПримерами таковых являются OWL[8] , KIF[9] , Common Logic[10] , CycL[11] , DAML+OIL[12].\\nПостроение при помощи методов машинного обучения\\nВекторные представления графов знаний\\nВекторные представления графов знаний (англ. Knowledge graph embeddings, KGE) являются малоразмерными представлениями объектов-узлов и связей между ними в графе знаний. Они обобщают информацию о семантике и локальной структуре вершин.\\nСуществует множество различных моделей KGE, таких как TransE[13], TransR[14], RESCAL[15], DistMult[16], ComplEx[17], и RotatE[18].\\nКак пример для представления графовых данных может использоваться семантика Cреды описания ресурса (англ. Resource Description Framework, RDF)[19] где связи представляются триплетом \"субъект — предикат — объект\". Для моделирования бинарных отношений на графе удобно использовать трехсторонний тензор , в котором две размерности образованы на основе связываемых объектов-узлов, а третья размерность содержит отношения между ними (рис. 2). Элемент тензора , когда существует отношение (i-й объект, k-е отношение, j-й объект). В противном случае для несуществующих или неизвестных отношений .\\nОбучение онтологий\\nПроцесс получения онтологий начинается с вынесения множества термов из текста и получения их синонимов. Далее они преобразуются во множество концептов. После чего выявляются связи между концептами, и в итоге формируются схемы аксиом и извлекаются аксиомы. Данный процесс называют слоеным пирогом обучения онтологии (рис. 3).\\nАлгоритмы, используемые в разных слоях при построении онтологии разбивают на 3 основные группы:\\n- лингвистические;\\n- статистические;\\n- логические.\\nЛингвистические методы\\nЛингвистические методы основаны на различных особенностях языка и играют ключевую роль на начальных стадиях обучения. В основном их используют для предобработки текста, а также в извлечении термов, концептов и связей.\\nПредобработка текста\\nНа первой стадии текст предобрабатывается для уменьшения размерности и повышения точности обучаемой модели. Обычно для этого используют такие методы, как:\\n- частеречная разметка[на 09.01.21 не создан] (англ. Part-Of-Speech tagging POS tagging)[20];\\n- лемматиза́ция (англ. Lemmatization)[21].\\nИзвлечение термов и концептов\\nЛингвистические техники также часто используют на этапе извлечения термов и концептов. Чтобы извлечь термы и концепты при помощи синтаксических структур слова помечают как части речи. Эта информация используется для извлечения синтаксических структур из предложений, таких как словосочетания и глагольные группы. Данные структуры анализируются на наличие различных слов и морфем для нахождения термов. К примеру словосочетание ‘acute appendicitis’ может быть извлечено в качестве кандидата на терм, так как является гипонимом к терму ‘appendicitis’. На китайских текстах данный метод достиг точности в [22].\\nРаспространёнными методами данного подхода являются:\\n- рамки валентностей (англ. Subcategorization Frames)[23];\\n- извлечение коренных слов (англ. Seed Words Extraction).\\nНахождение связей\\nС помощью анализа зависимостей можно находить связи между термами используя информацию, предоставленную в деревьях разбора. Таким образом, с помощью кратчайшего пути между двумя концептами в дереве разбора можно выявить связи между ними.\\nТакже можно использовать регулярные выражения. Например, правило \" , как например , , … , \" (где — именная группа[24]) может выявить такие образцы как \"сезоны года, как например лето, осень, весна и зима\". Данный подход полезен для выявления связей \"является\" к примеру (лето — сезон года).\\nСтатистические методы\\nСтатистические методы основаны на статистике и не полагаются на семантику языка. Большинство статистических методов преимущественно используют вероятностные техники и в основном применяются после предобработки текста лингвистическими методами на ранних этапах обучения (извлечение термов, концептов и связей).\\nИзвлечение термов и концептов\\nНа этом этапе используются следующие статистические методы:\\n- C/NC value[25] используют для извлечения многословных терминологий — групп термов, образующих концепты. Алгоритму на вход подаётся несколько многословных термов, для каждого из которых вычисляется оценка в форме C value и NC value. C value использует частоту встречаемости терма для его извлечения, что делает его эффективным для нахождения вложенных термов, а NC value по сути является модификацией C value, которая учитывает контекст.\\n- В процессе извлечения термов могут быть получены термы, не относящиеся к целевой области. Для фильтрации таких термов применяется метод сравнительного анализа (англ. Contrastive analysis)[26]. Он присуждает оценку для каждого терма, в зависимости от того, насколько он релевантен для целевой области, и насколько он нерелевантен в других областях.\\n- Латентно-семантический анализ (англ. Latent Semantic Analysis, LSA) используют для извлечения концептов. Этот метод основан на том, что термы, встречающиеся вместе, будут схожи по значению. LSA уменьшает размерность данных, сохраняя структуру подобия, после чего к оставшимся термам применяется мера сходства (например косинусное сходство[27]) для поиска похожих слов.\\n- Кластеризация группирует множества объектов на подмножества (кластеры) таким образом, чтобы объекты из одного кластера были более похожи друг на друга, чем на объекты из других кластеров.\\nНахождение связей\\nСтатистические методы также используют для выявления связей. Распространёнными техниками являются:\\n- Категоризация термов (англ. Term subsumption) находит связи между термами при помощи условной вероятности. Этот алгоритм ищет термы, являющиеся наиболее общими. Терм считается более общим, чем терм если , где обозначает вероятность встречи терма при наличии терма .\\n- Анализ формальных понятий (англ. Formal Concept Analysis, FCA)[28] основан на том, что объекты могут иметь схожие атрибуты. Алгоритм на вход принимает матрицу связей объектов и атрибутов и находит в ней все естественные кластеры, что позволяет построить иерархию концептов и атрибутов.\\n- Иерархическая кластеризация группирует термы в кластеры для нахождения концептов и построения иерархий.\\n- Добыча ассоциативных правил (англ. Association rule mining, ARM) находит правила, предугадывающие совпадение элементов в различных базах данных, для чего обычно применяют алгоритмы Apriori[29] и FPG[30]. Тут правило подразумевает импликацию , где и — непустые подмножества множества всех элементов, такие, что .\\nИндуктивное логическое программирование\\nНа последней стадии построения онтологии используется индуктивное логическое программирование (англ. Inductive Logic Programming, ILP)[31] — раздел машинного обучения, который использует логическое программирование как форму представления примеров, фоновых знаний и гипотез. ILP необходимо для генерации аксиом по схемам аксиом (положительным и отрицательным примерам и фоновым знаниям).\\nОценка онтологии\\nОценка качества получения онтологии является важной частью процесса обучения. Благодаря ей можно уточнить или перестроить модели, не удовлетворяющие требованиям. Так как обучение состоит из различных этапов, процесс оценки онтологий является достаточно сложной задачей. По этой причине предлагались многочисленные техники оценки, однако их все можно разбить на следующие группы:\\nЗолотой стандарт\\nОценка с использованием золотого стандарта основана на наличии базовой онтологии. Золотой стандарт представляет собой пример идеальной онтологии в какой-то конкретной области. Сравнивая и оценивая обученную онтологию с золотым стандартом можно эффективно определить степень покрытия области знаний и консистентность. Золотым стандартом может быть как независимая онтология, так и статистическая модель, сформированная экспертами в данной области. Наличие золотого стандарта позволяет проводить регулярные и крупномасштабные оценки на различных этапах обучения. Однако получение золотого стандарта может оказаться проблемой, так как он должен быть смоделирован в условиях и с целью похожими на соответственно условия и цель обучаемой онтологии. Очень часто это приводит к выбору моделей, созданных человеком вручную.\\nЭкспертная оценка\\nЭкспертная оценка основана на определении различных критериев. По каждому критерию выставляется числовая оценка, после чего считается взвешенная сумма оценок. Основным недостатком данного способа являются огромные затраты времени и усилий на ручную работу, однако данный метод устарел и крайне редко применяется в оценке современных онтологий.\\nОценка, основанная на конкретной задаче\\nДанная оценка применяется при построении онтологии для конкретных задач. Результаты, полученные в процессе решения задачи, определяют качество построенной онтологии, независимо от её структуры. Данная оценка позволяет выявить неустойчивые концепты и определить адаптивность конкретной онтологии, анализируя её эффективность в контексте различных задач.\\nК примеру, создаётся онтология для улучшения поиска документов. В таком случае можно проверить, получило ли приложение более релевантные документы после применения данной онтологии. Для этого можно применить традиционные методы оценки, такие как F мера.\\nОднако стоит отметить, что использование оценок, основанных на конкретных задачах, имеет несколько недостатков. К примеру:\\n- Онтология может являться лишь малой частью приложения, и её эффект на общий результат может быть незначительным.\\n- Онтология оценивается путём применения конкретным образом для конкретной задачи, а значит модель достаточно сложно обобщить.\\nОценка с использованием конкретных источников знаний\\nЭта оценка использует источники знаний конкретной области, чтобы определить степень покрытия этой области обучаемой онтологией. Главным преимуществом данной оценки является возможность сравнивать одну или несколько целевых онтологий с конкретными данными. Однако возникает проблема нахождения подходящего источника знаний (как и в оценке золотым стандартом).\\nОсобенности применения онтологии для конкретных задач\\nCистема автоматической обработки текста\\nЛингвистическая онтология является одним из ключевых элементов в системе обработки текста и ее построение необходимо для решения задачи.\\nКак описано выше — для построения современных онтологий всегда является актуальным извлечение термов и концептов, в данном случае семантически связанных слов из текста на естественном языке. Однако общим недостатком таких онтологий является отсутствие специализированных терминов, специфичных для данной предметной области. В следствие этого появляется проблема дополнения существующей онтологии, а именно семантической сети узлами и связями из внешних источников. И так как имеется множество публичных ресурсов для дополнения новых узлов и связей, то выделяют следующие задачи:\\n- Автоматизированный поиск новых узлов, связанных семантическими отношениями.\\n- Добавление новых узлов и связей в онтологию при обнаружении сущностей, признаки которых удовлетворяют заданным критериям.\\nДля решения данных задач существует множество способов анализа текстовой информации для извлечения из нее семантических отношений:\\n- Методы извлечения связей, основанные на шаблонах такие как \"Top down\" и \"Bottom up\"[32].\\n- Группа методов, основанная на форматировании или на DOM[33].\\n- Методы, основанные на машинном обучении. Одним из самых явных примеров реализации является word2vec, основанный на нейронных сетях.\\nПоследняя группа методов является наиболее современной и показывает наилучшую точность, но не позволяет достичь приемлимой точности и полноты в общем случае, так как данные методы используются для конкретной предметной области. Таким образом поиск наиболее подходящих признаков для обучения нейронных сетей необходим для применения лингвистической онтологии в данной задаче.\\nОбработка текста на русском языке\\nЧтобы применить онтологию для автоматической обработки текстов, необходимо понятиям онтологии сопоставить набор языковых выражений (слов и словосочетаний), которыми понятия могут выражаться в тексте. Для русского языка, как и для многих других языков, содержащие многозначные понятия, имеется ряд проблем.\\nХоть понятие, лексическое значение относятся к категориям мышления, при этом между ними есть существенные различия. Значение включает в себя помимо понятийного содержания (сигнификативно-денотативного[34][35] компонента значения), такие компоненты как оценочный, стилистический, сочетаемостный. Также значение включает лишь различительные черты объектов, иногда относительно поверхностные, а понятия охватывают их наиболее глубокие существенные свойства. Поэтому описать значения многих слов как совокупности общих и одновременно существенных признаков может быть очень трудно. В целом, считается, что значение и понятие совпадают лишь в сфере терминологии.\\nМногие понятия в русском языке сложно представить в виде формальной системы, пригодной для логического вывода, например, описать таксономические связи, по следующим причинам:\\n- Из-за их нечеткости, расплывчатости.\\n- Контекстной зависимости, когда реализация некоторых компонентов значения существенно зависит от контекста.\\n- Существования значительных рядов синонимов, отличающихся оттенками значений, что затрудняет разбиение таких рядов на совокупность взаимосвязанных понятийных единиц. Например, сколько понятий онтологии оптимально (и на основе каких принципов) сопоставить следующему ряду слов со значением ОШИБКА: ошибка, погрешность, недосмотр, просмотр, ляп, промах, оплошность, осечка, прокол, упущение, недочет, а также ослышка, описка, опечатка, оговорка. Таким словам обычно трудно найти точные слова-соответствия в других языках, то есть слова, имеющие такой же оттенок значения и такие же особенности употребления.\\nНесмотря на описанные проблемы, разработка моделей представления знаний о мире и о языке в рамках онтологий имеет смысл. Так например появился РуТез[36] — онтология для автоматической обработки текста на русском языке, которая представила свое решение[37] для данных проблем.\\nСм. также\\nПримечания\\n- ↑ Wikipedia — Semantic Network\\n- ↑ Wikipedia — Google Knowledge Graph\\n- ↑ Wikipedia — Knowledge graph definition\\n- ↑ Wikipedia — Fuzzy logic\\n- ↑ Википедия — Концептуальная схема\\n- ↑ Wikipedia — Онтологическая инженерия\\n- ↑ Wikipedia — Контролируемый словарь\\n- ↑ Wikipedia — OWL\\n- ↑ Wikipedia — KIF\\n- ↑ Wikipedia — Common Logic\\n- ↑ Wikipedia — CycL\\n- ↑ Wikipedia — DAML+OIL\\n- ↑ Translating Embeddings for Modeling Multi-relational Data — Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko (2013)\\n- ↑ Learning Entity and Relation Embeddings for Knowledge Graph Completion — Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, Xuan Zhu (2015)\\n- ↑ A Three-Way Model for Collective Learning on Multi-Relational Data — Nickel Maximilian, Tresp Volker, Kriegel Hans-Peter (2011)\\n- ↑ Embedding Entities and Relations for Learning and Inference in Knowledge Bases — Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, Li Deng (2015)\\n- ↑ Complex Embeddings for Simple Link Prediction — Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric Gaussier, Guillaume Bouchard (2016)\\n- ↑ RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space — Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, Jian Tang (2019)\\n- ↑ Wikipedia — Resource Description Framework\\n- ↑ Wikipedia — Part-of-speech tagging\\n- ↑ Wikipedia — Lemmatisation\\n- ↑ The head-modifier principle and multilingual term extraction — Hippisley A., Cheng D. и Ahmad K. (2005)\\n- ↑ Wikipedia — Subcategorization Frames\\n- ↑ Википедия — Именная группа\\n- ↑ Automatic Recognition of Multi-Word Terms: the C-value/NC-value Method — Katerina Frantziy, Sophia Ananiadouy, Hideki Mimaz (2000)\\n- ↑ Wikipedia — Contrastive analysis\\n- ↑ Wikipedia — Cosine Simularity\\n- ↑ Wikipedia — Formal concept analysis\\n- ↑ Wikipedia — Apriori algorithm\\n- ↑ Wikibooks — FP-Growth Algorithm\\n- ↑ Wikipedia — Inductive Logic Programming\\n- ↑ Bottom-up and Top-down Approaches to Text Analysis\\n- ↑ Wikipedia — Document Object Model\\n- ↑ Wikipedia — Сигнификат\\n- ↑ Wikipedia — Денонат\\n- ↑ О лингвистической онтологии \"Тезаурус РуТез\"\\n- ↑ RuThes Linguistic Ontology vs. Russian Wordnets\\nИсточники информации\\n- Wikipedia — Semantic network\\n- Википедия — Семантическая сеть\\n- Wikipedia — Knowledge graph\\n- Towards Data Science — Knowledge graph\\n- Authorea — What is a Knowledge Graph\\n- Wikipedia — Ontology\\n- Википедия — Онтология\\n- Training knowledge graph embeddings at scale with the Deep Graph Library — Phi Nguyen, Xiang Song (2020)\\n- A Three-Way Model for Collective Learning on Multi-Relational Data — Maximilian Nickel, Volker Tresp, Hans-Peter Kriegel (2011)\\n- A survey of ontology learning techniques and applications — Muhammad Nabeel Asim, Muhammad Wasim, Muhammad Usman Ghani Khan, Waqar Mahmood, Hafiza Mahnoor Abbasi (2018)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='eb69be4c-8c44-477c-a759-3d03c64661eb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='05f521bc9f52da44115d7d2272ec7a3eae5194c3c4cb412951eede4a456efcaf', text='Задача планирования движения\\nПланирование движения (также известное как планирование пути и проблема навигации) — это вычислительная задача поиска последовательности допустимых конфигураций, которая перемещает объект от источника к месту назначения.\\nСодержание\\n- 1 Постановка задачи\\n- 2 Этапы\\n- 3 Предсказание траекторий движения объектов\\n- 4 Решение задачи для беспилотных автомобилей (англ. Self-driving cars)\\n- 5 Области применения\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nПостановка задачи\\nПусть задано непустое множество препятствий кинематическая цепь , где — множество твердотельных звеньев (элементов кинематической цепи), а — множество кинематических ограничений таких, что при корректной конфигурации цепи предикаты ограничений принимают истинное значение. Под конфигурацией здесь понимается набор значений параметров, однозначно определяющий положение точек объекта в пространстве сцены. Обычно используется минимальный набор параметров, соответствующий количеству степеней свободы объекта и определяющий пространство состояний или конфигурационное пространство объекта .в области евклидова пространства . Пусть также задано твердое тело , либо\\n|Определение:\\n|Пространством допустимых состоянийназовем множество всех конфигураций объекта , удовлетворяющих кинематическим ограничениям и исключающих столкновения с препятствиями сцены. для кинетической цепи; для простого твердого тела.\\nТогда постановка задачи поиска пути может быть сформулирована следующим образом. Для пары заданных бесконфликтных конфигураций требуется найти непрерывный путь такой, что и , где — момент времени.\\nПоскольку планирование маршрута, как правило, допускает бесконечное множество решений (хотя может не существовать ни одного решения), иногда данную задачу формулируют в постановке оптимизационной задачи с целевой функцией, соответствующей минимальной длине маршрута или максимальной удаленности перемещаемого объекта от препятствий. На практике поиск пути даже в простых сценах с относительно небольшим количеством препятствий становится трудноразрешимой задачей, если перемещаемый объект имеет сложную геометрию или высокое число степеней свободы. В современных индустриальных приложениях часто требуется моделировать поведение сложных кинематических систем с шестью и более степенями свободы в статическом или динамическом окружении, насчитывающим тысячи препятствий.\\nЭтапы\\nВосприятие/анализ обстановки (англ. Perception)\\nАнализ данных об окружении, выделение объектов и препятствий, определение их размеров, скоростей, и расстояний до них. Зачастую осуществляется путем применения алгоритмов машинного обучения для распознавания объектов на изображениях и прочих массивах данных (таких как данные с датчиков).\\nПредсказание движения объектов (англ. Prediction)\\nАнализ собранных за время наблюдения данных об окружающих объектах для последующего построение модели их движения и предсказания их траекторий. Этот этап будет подробно рассмотрен далее.\\nПринятие решения/планирование траектории движения (англ. Planning)\\nПостроение потенциальных траекторий движения и выбор итоговой на основе собранных на предыдущих этапах данных. Как правило осуществляется с помощью дискретизации пространства и последующего применения алгоритмов на графах, например различных вариаций RRT алгоритмов, для поиска оптимальной траектории. В последнее время также становятся более актуальными решения с применением машинного обучения — в частности, подходы на основе имитационного обучения и обратного обучения с подкреплением[6][7], обученные на большом количестве примеров, предоставленных человеком[2].\\nПредсказание траекторий движения объектов\\nПоскольку в общем случае мы не можем определить, как будут двигаться объекты, для предсказания траекторий их движений необходимо строить модели на основе прошлых измерений. Эти модели могут представлять из себя как простые предсказания (например, “объект продолжит двигаться с неизменной скоростью/ускорением”), так и более сложные алгоритмы.\\nСтандартный подход\\nОдна из основных сложностей в предсказании траекторий движения объектов заключается в неопределенности, которая появляется из-за погрешностей в измерениях сенсоров и невозможности однозначно предсказать действия объектов. Для смягчения этой проблемы применяются фильтры, которые приближают текущую позицию исходя из измерений сенсоров и наших предсказаний, а также степени уверенности в результатах обоих.\\nТакже проблематичным является тот факт, что одной модели (особенно простой) как правило недостаточно для описания траектории движения объекта. В связи с этим существует алгоритм, использующий множество взаимодействующих моделей (англ. Interacting Multiple Model, IMM) — подход применения сразу нескольких моделей, для каждой из которых поддерживается актуальная (меняющаяся по мере прошествия времени и получения новых измерений) вероятность того, что объект двигается согласно этой модели. Таким образом, используя, например, модель для каждого возможного движения, такого как поворот или ускорение, мы можем делать более точные предположения о том, где объект будет находиться в будущем.\\nСуществуют и другие, более специализированные, подходы, опирающиеся на ряд заранее заданных правил, моделей и предположений об используемом пространстве.\\nПрименение машинного обучения\\nСтандартные инженерные подходы (в том числе IMM) также обладают своими недостатками как в точности (особенно при необходимости долговременного предсказания), так и в скорости, в связи с чем стали применяться и подходы, использующие машинное обучение, в частности — рекуррентные нейронные сети.\\nОни применяются как для улучшения производительности самого алгоритма IMM (например, для улучшения точности в пересчете вероятностей[10]), так и для его замены (иногда применяя тот же самый принцип[11]).\\nСуществуют и другие алгоритмы, основанные на машинном обучении (в основном использующие сверточные нейронные сети), и не опирающиеся на принцип работы IMM, вместо этого по большей части использующие большие массивы данных, собранные на основе передвижений автомобилей, которые управлялись людьми вручную[12][13][14].\\nРешение задачи для беспилотных автомобилей (англ. Self-driving cars)\\nДля организации управления беспилотным автомобилем можно воспользоваться классическим подходом из робототехники. Задача самостоятельного передвижения разбивается на четыре модуля.\\n- Модуль локализации отвечает за определение положения автомобиля в пространстве.\\n- Модуль распознавания — за анализ окружающей обстановки.\\n- Модуль планирования — за планирование маршрута исходя из обстановки и цели.\\n- Модуль управления — за определение траектории движения в выбранном направлении.\\nТем не менее такая модель все еще имеет множество проблем, которые необходимо решить. Автомобиль обладает рядом довольно существенных ограничений. У автомобиля есть текущее направление, угол поворота колес, и он не может просто оказаться на два метра левее от текущего местоположения, это очень сложно. Он может ехать примерно вперед, поворачивая на какой-то угол, но тем не менее, перемещение очень сильно ограничено. И на траекторию движения влияют ограничениям, которые следуют из кинематики. Например, невозможно мгновенно разогнаться и мгновенно увеличить свое ускорение.\\nДля планирования дальнейшего движения автомобиля можно использовать нейронные сети, передавая информацию со всех датчиков и камер в сеть, предварительно ее обучив на человеческих перемещениях. Обучить, в каких ситуациях куда нужно крутить руль, увеличивать или снижать скорость. В теории такой подход представляется хорошим решением задачи, но на практике выяснилось, что нужно слишком много данных и слишком большая нейросеть, чтобы успешно повторять все за человеком в различных ситуациях. В этом направлении ведется активная работа, и пока большинство успешных решений задачи опирается на нейросети лишь частично, доверяя бо́льшую часть работы проверенным алгоритмам.\\nАлгоритмы на графах\\nСуществует несколько алгоритмов на графах, позволяющих решить задачу, но для их использования нужно понять, как построить граф по имеющейся информации. Для этого аналогично существует несколько подходов:\\n- Разбиение пространства на клетки и построение графа на них.\\n- Построение графа из регулярных примитивов движения (например, дуг).\\n- Другие, более специализированные подходы, основанные на особенностях конкретной системы.\\nСамым популярным и зачастую самым оптимальным является алгоритм А*.\\nПреимущества:\\n- Гарантированно находит кратчайший (в дискретизированном пространстве) путь.\\nНедостатки:\\n- В пространствах малой размерности путь редко является кинематически выполнимым (зависит от метода построения графа).\\n- В пространствах большой размерности наблюдается заметное увеличение времени работы.\\nОптимизационные алгоритмы\\nИдея оптимизационных алгоритмов заключается в следующем: рассмотрим траекторию нашего положения во времени, и — координаты, зависящие от времени , то есть поймем, в какой точке мы хотим оказаться в момент времени . Можно сказать, что оптимальной в этом случае будет траектория, которая минимизирует функционал , являющийся интегралом некоторой функции от траектории по времени.\\n, где — траектория.\\nФункция от траекторииздесь каким-либо образом нас штрафует за резкие повороты, резкие разгоны, нахождение близко к препятствиям. Тогда, если просуммировать вдоль траектории все необходимые штрафы и попытаться это минимизировать с помощью стандартного математического аппарата, никак не связанного с автомобилями в целом и беспилотными автомобилями в частности, это решит задачу в общем виде.\\nЧто лучше рассмотреть в качестве штрафов? Например, можно сказать, что не нужно подъезжать близко к препятствиям, учитывать это с каким-то весом, или что скорость не должна быть гораздо выше или ниже заранее определенной скорости. Можно штрафовать за вторую производную, которая является ускорением, потому что машина не должна резко ускоряться или замедляться.\\nМожно рассмотреть третью производную, которая является рывком, то есть не нужно, чтобы ускорение тоже менялось достаточно резко, поскольку это может сказаться на состоянии пассажиров. Если ускорение фиксированное и машина просто все время разгоняется, то, как показывают исследования, людей не укачивает. Также можно избегать крутых поворотов, ограничивая угол. Есть дополнительные ограничения, которые говорят, что машина физически не может разгоняться быстрее какого-то ускорения. Если все это учтется, то можно решить задачу с помощью абстрактного алгоритма минимизации функции и получить некий результат.\\nБольшинство методов оптимизации предпочитают работать с хорошо дифференцируемыми функциями, в то время как автомобиль — объект довольно сложной формы, и препятствия, которые он объезжает, это тоже объекты непростых форм. Поэтому нужно производить какие-то упрощения. Например, можно сказать, что машина — не что-то сложное, а просто пять окружностей.\\nОт окружностей очень легко считать расстояния до чего угодно и очень легко проверять окружность на пересечения с остальными геометрическими примитивами. Если расстояние до центра меньше, чем радиус, можно утверждать, что объекты пересекаются.\\nЧто нужно, чтобы плавно изменялось расстояние? Евклидово расстояние до невыпуклых многоугольников не обладает необходимыми свойствами и плохо дифференцируемо в местах, где наблюдается отсутствие выпуклости. Поэтому можно построить псевдорасстояние по градиентному полю до ломаной, которая обозначена на Рис. 10 красным и представляет собой препятствие. Введем поле расстояний от каждой точки до этой ломаной, которое направлено в сторону ломаной и обладает необходимыми свойствами дифференцируемости — пусть и не являясь строго кратчайшим. Это позволит построить гладкую и аккуратную траекторию.\\nПреимущества:\\n- Пространство управления непрерывно.\\nНедостатки:\\n- Сходится к локальным минимумам.\\n- Ограничения должны быть заданы дифференцируемыми функциями.\\nСтохастические алгоритмы\\nСуществуют также стохастические алгоритмы, которые работают некоторым случайным образом и позволяют построить приближенный маршрут достаточно быстро и удобно. Алгоритм не ищет оптимальные способы объехать препятствие, а просто в разных направлениях исследует пространство, но каждый раз делая это из наиболее исследованного участка к наименее изученному.\\nСамым распространенным стохастическим алгоритмом является построение быстро исследующего случайного дерева (Rapidly-exploring Random Tree, RRT) или деревьев на его основе (RRT*[17] и прочие).\\nПринцип заключается в итеративном построении дерева. На каждой итерации происходят следующие действия:\\n- Выбор случайной точки пространства.\\n- Нахождения ближайшего к этой точке узла уже построенного дерева.\\n- Построение ребра в сторону новой точки с помощью симуляции проезда нескольких метров.\\nВ результате достаточно быстро строится карта путей, которая некоторым (вероятнее всего, не оптимальным) образом покрывают пространство. Можно продолжать ее строить до тех пор, пока не найдется путь до искомой точки или пока не будет сочтено нужным остановиться.\\nПреимущества:\\n- Высокая скорость работы в пространствах большой размерности.\\n- Пути можно подавать практически напрямую в управляющий блок.\\nНедостатки:\\n- Отсутствие гарантий на оптимальность.\\n- Высокая вероятность того, что траектория движения будет сильно извилистой (зависит от выбора дерева; например, RRT* лишен этого недостатка).\\nСпециализированные алгоритмы\\nВ городе нет абстрактных точек А и Б и неструктурированного окружения со случайными препятствиями. На подобных сценах все относительно понятно: есть конкретные полосы и движение машины почти всегда заключается в том, что автомобиль едет примерно по центру полосы; иногда смещается левее или правее, чтобы объехать препятствие; иногда перестраивается, чтобы по правилам дорожного движения повернуть в нужном направлении.\\nВ связи с этим не всегда есть необходимость в деревьях (хотя они все еще нужны, например, во время парковки или сложных маневров). Когда автомобиль едет на полосе, ему достаточно построить сравнительно плавную траекторию, следующую к центру этой полосы или с каким-то смещением влево/вправо. Это сделать гораздо проще, чем искать путь в графе. Поэтому простым решением будет взять текущее положение машины, посмотреть на путь, по которому хотелось бы ехать, и плавно свернуть на этот путь.\\nОбласти применения\\n- Роботизированная хирургия — хирургия с использованием робота во время операции. Поскольку один из способов проведения такого рода операций — автоматический, возникает необходимость решения задачи планирования движения робота.\\n- Компьютерная анимация — вид трехмерной анимации, создаваемый при помощи компьютерной графики. Процедурная анимация полностью или частично рассчитывается компьютером, например:\\n- Симуляция физического взаимодействия твёрдых тел.\\n- Имитация движения систем частиц, жидкостей и газов.\\n- Имитация взаимодействия мягких тел (ткани, волос).\\n- Расчёт движения иерархической структуры связей (скелета персонажа) под внешним воздействием.\\n- Имитация автономного движения персонажа.\\n- Фолдинг белка — процесс спонтанного свертывания полипептидной цепи в уникальную пространственную структуру. Механизм сворачивания белков до конца не изучен, но аминокислотная последовательность белка обычно известна. Поэтому учёные пытаются использовать различные биофизические методы, чтобы предсказать пространственную структуру белка.\\nСм. также\\n- Сверточные нейронные сети\\n- Рекуррентные нейронные сети\\n- Алгоритм A*\\n- Задача нахождения объектов на изображении\\n- Анализ видео\\nПримечания\\n- ↑ 1,0 1,1 Казаков К.А. и Семенов В.А. (2016) \"Обзор современных методов планирования движения\"\\n- ↑ 2,0 2,1 Peter Ondruska, Sammy Omari (2020) \"The Next Frontier in Self-Driving: Using Machine Learning to Solve Motion Planning\"\\n- ↑ Christoph Hammerschmidt (2020) \"Deep learning method improves environment perception of self-driving cars\"\\n- ↑ Sacha Arnoud, Peter Ondruska (2020) \"Fueling Self-Driving Research with Level 5’s Open Prediction Dataset\"\\n- ↑ Robert Morgan, Mason Lee (2020) \"Virtual Validation: A Scalable Solution to Test & Navigate the Autonomous Road Ahead\"\\n- ↑ Alexandre Gonfalonieri (2018) \"Inverse Reinforcement Learning — Introduction and Main Issues\"\\n- ↑ Abbeel P., Ng A.Y. (2011) \"Inverse Reinforcement Learning\"\\n- ↑ \"Tracking Maneuvering Targets\", MathWorks\\n- ↑ Jongwon Park, Jaeho Choi, Kunsoo Huh (2019) \"Interacting Multiple Model Filter for Multi-Sensor Data Fusion System\"\\n- ↑ Lichuan Deng, Da Li and Ruifang Li (2020) \"Improved IMM Algorithm based on RNNs\"\\n- ↑ Stefan Becker, Ronny Hug, Wolfgang Hübner, and Michael Arens (2019) \"An RNN-based IMM Filter Surrogate\"\\n- ↑ Nemanja Djuric, Vladan Radosavljevic, Henggang Cui, Thi Nguyen, Fang-Chieh Chou, Tsung-Han Lin, Nitin Singh, Jeff Schneider (2020) \"Uncertainty-aware Short-term Motion Prediction of Traffic Actors for Autonomous Driving\"\\n- ↑ Henggang Cui, Thi Nguyen, Fang-Chieh Chou, Tsung-Han Lin, Jeff Schneider, David Bradley, Nemanja Djuric (2020) \"Deep Kinematic Models for Kinematically Feasible Vehicle Trajectory Predictions\"\\n- ↑ Mustafa Ozan Tezcan (2017) \"Motion Estimation Using Convolutional Neural Networks\"\\n- ↑ 15,0 15,1 15,2 Клюев Л. (2017) \"Алгоритмы построения пути для беспилотного автомобиля. Лекция Яндекса\", Хабр\\n- ↑ Rapidly-exploring random tree\\n- ↑ Tim Chin (2019) \"Robotic Path Planning: RRT and RRT*: Exploring the optimized version of a orthodox path planning algorithm\"\\nИсточники информации\\n- \"Motion Planning\", Wikipedia\\n- Казаков К.А. и Семенов В.А. (2016) \"Обзор современных методов планирования движения\"\\n- Клюев Л. (2017) \"Алгоритмы построения пути для беспилотного автомобиля. Лекция Яндекса\", Хабр\\n- Brian Douglas (2019) \"Understanding Sensor Fusion and Tracking, Part 4: Tracking a Single Object With an IMM Filter\", YouTube\\n- Brian Douglas (2020) \"Autonomous Navigation, Part 4: Path Planning with A* and RRT\", YouTube', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='74730d2c-0df5-4f0d-aca6-67677e275fda', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='61be59245bc5062d11d6c5b15f0c43fc8e5492dc2217a977e8c64dca28218133', text='Машинное обучение в астрономии\\nАстрономия переживает стремительный рост объема и сложности данных. Существует множество проектов, исследующих и собирающих многоспектральные изображения неба, разновременную и многоволновую информацию, например, Слоановский цифровой небесный обзор (англ. Sloan Digital Sky Survey, SDSS). Такие проекты предоставляют оцифрованные изображения неба, соответственно, в последние годы алгоритмы машинного обучения становятся все более популярными среди астрономов и в настоящее время используются для решения самых разнообразных задач; причиной этому служит большое количество доступных данных. В этой статье кратко приводится практическая информация о применении инструментов машинного обучения к астрономическим данным.\\nСодержание\\n- 1 Классификация астрономических объектов по изображениям\\n- 2 Анализ астрономических явлений по спектральным данным\\n- 3 Изучение астрономических параметров\\n- 4 Изучение астрономических явлений\\n- 5 Обучение без учителя\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nКлассификация астрономических объектов по изображениям\\nНаличие в наборах данных большого количества объектов одного типа, но различных подтипов позволяет применить машинное обучение для решения задачи классификации на этих объектах.\\nМорфологическая классификация галактик\\nОдной из самых популярных тем классификации является морфологическая классификация галактик (англ. Morphology galaxy classification), позволяющая разделить их на различные типы по визуальным признакам (Рис. 1). Для обучения моделей, призванных решать эту задачу, часто используют набор данных Galaxy Zoo, который является результатом волонтерского сотрудничества (ручной классификации галактик). Существует множество работ на эту тематику, использующих различные алгоритмы машинного обучения, как то: случайные леса[1], метод опорных векторов[2], нейронные сети[3]. Применение подходов машинного обучения в этом случае довольно прямолинейно, а разница между работами состоит в основном в представлении данных, выборе гиперпараметров и признаков классификации. Дополнительной сложностью вышеприведённых и прочих работ на ту же тему являются визуальные ограничения имеющихся изображений, такие, как мерцание, смещение, размытие и красное смещение. В настоящее время существуют методы, обеспечивающие вероятность неверной классификации объекта в задаче морфологической классификации галактик в [4].\\nЭтой задачей следует заниматься, так как возможность находить тип галактик необходима для изучения их эволюции, а также является необходимым умением для множества задач наблюдательной космологии (англ. Observational cosmology), например, для нахождения кривых блеска.\\nВыявление аномалий\\nВ астрономии могут использоваться методы поиска трудно классифицируемых объектов выборки, например, для нахождения в больших объемах данных объектов, не похожих на большинство других, для отдельного их изучения. В частности, с помощью такого алгоритма можно найти необычные типы галактик[6].\\nКлассификация звезд и галактик\\nКлассификация звезд и галактик (англ. Star Galaxy Classification) является базовым шагом любой классификации на звездах или галактиках, соответственно, имеет большое практическое значение. Существует много работ на эту тему, связанных с машинным обучением, использующих различные алгоритмы: случайный лес[8], метод опорных векторов[9], нейронные сети[10], алгоритмы кластеризации[11](пример распределения можно наблюдать на Рис. 2).\\nГлавная проблема классификации звезд и галактик состоит в том, что, по мере удаления объекта от телескопа различные атмосферные или космогенные эффекты могут повлиять на свет, который отражается от тела и захватывается телескопом. Детерминированные алгоритмы классификации обычно проверяют звездную величину объекта на соответствие известным шаблонам звезд и галактик и работают только с объектом как таковым. В то же время кажется логичным, что результат классификации объекта может зависеть не только от того, как он выглядит на изображении, но и от того, как выглядит на изображении участок неба, в котором он находится (потому что на этот участок, скорее всего, влияют такие же эффекты искажения изображения). Алгоритмы машинного обучения, натренированные на изображениях, способны учесть эти зависимости.\\nАнализ астрономических явлений по спектральным данным\\nКлассификация корональных выбросов массы\\nМашинное обучение может быть использовано для классификации[12] корональных выбросов массы на Солнце, определения их силы, источника и направления. Метод состоит в выборке определенного набора параметров выброса по данным спектрометрического коронографа LASCO, а затем применения к этим данным метода опорных векторов. В таблице ниже приведены признаки корональных выбросов массы, на которых обучается алгоритм. Здесь и — области исследуемых изображений.\\n|Номер\\n|Описание признака\\n|1\\n|The exposure time of theimage\\n|2\\n|The time interval between the current and the previous image\\n|3\\n|The pixel size of the LASCO image\\n|4\\n|The mean brightness value of the reference image\\n|5\\n|The mean brightness value of the current image\\n|6\\n|The mean brightness value of the running difference\\n|7\\n|The standard deviation of the running difference\\n|8\\n|The number of pixels for\\n|9\\n|The threshold for segmentingAfrom the running difference\\n|10\\n|The maximum height (arcsecs from disk center) of\\n|11\\n|The height of the center of\\n|12\\n|The minimum height of\\n|13\\n|The starting angle of. The angle is calculated from North 0 clockwise\\n|14\\n|The angle of the center of\\n|15\\n|The ending angle of\\n|16\\n|The angular width of\\n|17\\n|The height difference () between the maximum height of and\\n|18\\n|The height of the new moving region () which is obtained by subtracting from\\n|19\\n|The speed which is computed using, divided by the interval time cadence\\n|20\\n|The speed which is computed usingdivided by the interval time cadence\\n|21\\n|The span width of the new moving region\\n|22\\n|The center angle of the new moving region\\nРабота имеет большое практическое значение, так как корональные выбросы массы могут прерывать радиопередачу, наносить повреждения спутникам и линиям электропередачи, если они направлены в сторону Земли и имеют достаточную скорость и объем, чтобы достичь ее атмосферы[13].\\nИзучение астрономических параметров\\nКрасное смещение\\nКрасное смещение (англ. redshift) — астрономическое явление изменения длины волны наблюдаемого объекта. Важным свойством величины красного смещения является то, что через него, пользуясь законом Хаббла, можно высчитать примерное расстояние до объекта (Рис. 3). Соответственно, красное смещение является важным астрономическим параметром, и при исследовании некоторых объектов будет полезным знать эту величину для вычисления других признаков объекта или заключения выводов о каких-либо закономерностях в наличествующих данных.\\nКрасное смещение может быть вычислено при помощи спектральных данных объекта (англ. spectroscopic redshift), однако существуют другие методики, позволяющие в некоторых случаях определить примерную величину смещения по фотографии, пользуясь цветовыми характеристиками и яркостью объекта (англ. photometric redshift). Задачу нахождения величины фотометрического красного смещения можно переформулировать как задачу регрессии на соответствующих данных. Для решения такой задачи на популярных астрономических данных может быть использовано множество известных моделей машинного обучения, к примеру, случайные леса[14], нейронные сети[15] и идеи композиции нескольких моделей[16]. В настоящее время существуют алгоритмы, основанные на сверточных нейронных сетях, по предсказаниям которых можно восстановить расстояния до галактик, отличающихся от расстояний, вычисленных при помощи значений спектроскопического красного смещения, на несколько мегапарсек[17], что является высокой точностью в астрономических масштабах (примерно 10 процентов от среднего размера войда)\\nКривые блеска\\nКривая блеска (англ. light curve) — функция изменения звездной величины (в базовом понимании яркости) во времени (Рис. 4). Кривая блеска позволяет определить целый ряд физических свойств тела, в частности, период обращения, продолжительность затмения, отношение радиуса звезды к радиусу орбиты тела. Соответственно, разделение кривых блеска на типы позволяет лучше изучить структуры астрономических систем.\\nКлассифицировать кривые блеска можно при помощи сверточных нейронных сетей[18]. Для этого необходимо представить функцию блеска в виде объекта, на котором можно обучать алгоритм, к примеру, в виде изображения. Это преобразование проводится следующим образом:\\n- Для каждых двух точек кривой блеска , где — момент времени, — значение звездной величины, , где , — некий временной интервал, пара значений помещается в массив (Рис. 5).\\n- Полученные величины\\n, тем самым перемещаясь в пространство .\\nокругляются до ближайших из значений ,\\n- Строится изображение размера , где интенсивность каждого пикселя пропорциональна количеству соответствующего элемента в полученном выше массиве (Рис. 6).\\nПосле этого на полученных изображениях обучается сверточная нейронная сеть, которая может классифицировать тип кривой блеска с точностью 84.5%.\\nИзучение астрономических явлений\\nКратковременные астрономические явления\\nВвиду невозможности круглосуточно наблюдать за данными, поступающими с телескопов, вполне вероятной является возможность пропустить или не заметить появление сверхновой или активность переменной звезды. Как следствие, естественной целью оказывается обработка таких событий круглосуточно, в автоматическом режиме.\\nДля классификации астрономических явлений необходимо иметь данные о каком-то участке неба на протяжении какого-то времени. Существуют два подхода, связанные с обработкой последовательностей изображений неба, связанные с машинным обучением:\\n- Закодировать изменения во времени при помощи признаков искусственного объекта, после чего можно обучить классификатор на таких объектах, и результаты получать путем кодирования данных в объекты такого же типа. Классификатор может быть любым, к примеру, можно использовать случайный лес[19].\\n- Использовать алгоритмы, способные обрабатывать последовательности объектов, например, рекуррентные нейронные сети, или, в частности, LSTM[20] (Рис. 7), которые можно обучить на нескольких последовательных результатах измерения излучения участка неба. В вышеупомянутой работе, к примеру, объектами являются данные о гамма-излучении на протяжении 20 временных интервалов.\\nАстрономические феномены\\nНейронные сети можно использовать для определения и классификация стадий астрономических феноменов галактик [21], связанных со звездообразованием в них. Особенностью таких задач является необходимость генерировать для них искусственные наборы объектов для обучения ввиду недостаточного количества наблюдаемых феноменов такого типа в реальных данных.\\nОбучение без учителя\\nАлгоритмы обучения без учителя применительно к астрономии имеют особое значение для научных исследований, поскольку они могут быть использованы для извлечения новых знаний из существующих наборов данных и могут способствовать новым открытиям.\\nКлассификация гамма-всплесков\\nГамма-всплески (англ. gamma ray bursts) (Рис. 8) — масштабные космические выбросы энергии взрывного характера. На сегодняшний день различают два основных подвида гамма-всплесков: длинные и короткие, имеющие существенные различия в спектрах и наблюдательных проявлениях. Однако, многие авторы указывают на наличие третьего их типа с длиной события между длинными и короткими. Для проверки гипотезы о существовании гамма-всплесков можно использовать алгоритмы кластеризации. Достаточно зафиксировать модель, метрику и функцию ошибки, и можно будет оценить правдоподобность наличия третьего типа всплесков в каком-либо наборе данных. Было установлено[22], что на данных SWIFT допущение наличия третьего типа гамма-всплесков уменьшает ошибку в раза.\\nИзучение данных\\nЧасто кластеризация применяется к данным для прогресса в их изучении: Для того, чтобы получить новые знания о данных, необходимо их отсортировать и классифицировать. Так, например, K-means применяется в астрономии в разных контекстах, например, для изучения спектральных классов звезд, галактик и астероидов, рентгеновского спектра объектов. [23][24][25]\\nИерархическая кластеризация также применима к астрономическим данным, например, к рентгеновским спектрам, изображениям галактик и спектрам поглощения межзвездного газа.[26][27][28][29]\\nСм. также\\nПримечания\\n- arXiv.org: Machine Learning in Astronomy: a practical overview — обзор астрономических работ, связанных с машинным обучением\\n- https://www.astroml.org/ — библиотека алгоритмов машинного обучения, заточенная под астрономические данные\\n- https://github.com/dalya/WeirdestGalaxies — алгоритм нахождения необычных галактик при помощи случайных лесов\\nИсточники информации\\n- ↑ Baron, D., & Poznanski, D. 2017, MNRAS, 465,4530\\n- ↑ Huertas-Company, M., Rouan, D., Tasca, L.,Soucail, G., & Le F`evre, O. 2008, A&A, 478,971\\n- ↑ Banerji, M., Lahav, O., Lintott, C. J., et al. 2010,MNRAS, 406, 342\\n- ↑ Miller, A. A., Kulkarni, M. K., Cao, Y., et al.2017, AJ, 153, 73\\n- ↑ Barchi, P.H., de Carvalho, R.R., Rosa, R.R., Sautter, R.A., Soares-Santos, M., Marques, B.A.D., Clua, E., Gonçalves, T.S., de Sá-Freitas, C., Moura, T.C., 2020, Astronomy and Computing, 30, 100334\\n- ↑ Baron, D., & Poznanski, D. 2017, MNRAS, 465,4530\\n- ↑ C. H. A. Logan and S. Fotopoulou A&A, 633 (2020) A154\\n- ↑ Miller, A. A., Kulkarni, M. K., Cao, Y., et al.2017, AJ, 153, 73\\n- ↑ Kov ́acs, A., & Szapudi, I. 2015, MNRAS, 448,1305\\n- ↑ Noble Kennamer, David Kirkby, Alexander Ihler, Francisco Javier Sanchez-Lopez ; Proceedings of the 35th International Conference on Machine Learning, PMLR 80:2582-2590, 2018.\\n- ↑ C. H. A. Logan and S. Fotopoulou A&A, 633 (2020) A154\\n- ↑ Qu, M., Shih, F.Y., Jing, J. et al. Automatic Detection and Classification of Coronal Mass Ejections. Sol Phys 237, 419–431 (2006)\\n- ↑ https://en.wikipedia.org/wiki/Coronal_mass_ejection\\n- ↑ Carliles, S., Budav ́ari, T., Heinis, S., Priebe, C., &Szalay, A. S. 2010, ApJ, 712, 511\\n- ↑ Vanzella, E., Cristiani, S., Fontana, A., et al.2004, A&A, 423, 761\\n- ↑ A. D’Isanto and K. L. Polsterer, A&A, 609 (2018) A111\\n- ↑ M. Shuntov, J. Pasquet, S. Arnouts, O. Ilbert, M. Treyer, E. Bertin, S. de la Torre, Y. Dubois, D. Fouchez, K. Kraljic, C. Laigle, C. Pichon and D. Vibert, A&A, 636 (2020) A90\\n- ↑ Mahabal, A., Sheth, K., Gieseke, F., et al. 2017,ArXiv e-prints, arXiv:1709.06257\\n- ↑ Bloom, J. S., Richards, J. W., Nugent, P. E., et al.2012, PASP, 124, 1175\\n- ↑ Sadeh, I., ArXiv e-prints, arXiv:1902.03620\\n- ↑ Huertas-Company, M., Primack, J. R., Dekel, A.,et al. 2018, ApJ, 858, 114\\n- ↑ Kulkarni, S., Desai, S., Astrophys Space Sci 362, 70 (2017)\\n- ↑ Hojnacki, S. M., Kastner, J. H., Micela, G.,Feigelson, E. D., & LaLonde, S. M. 2007, ApJ,659, 585\\n- ↑ Galluccio, L., Michel, O., Bendjoya, P., & Slezak,E. 2008, in American Institute of Physics\\n- ↑ Simpson, J. D., Cottrell, P. L., & Worley, C. C.2012, MNRAS, 427, 1153\\n- ↑ Hojnacki, S. M., Kastner, J. H., Micela, G.,Feigelson, E. D., & LaLonde, S. M. 2007, ApJ,659, 585\\n- ↑ Baron, D., Poznanski, D., Watson, D., et al. 2015,MNRAS, 451, 332\\n- ↑ Hocking, A., Geach, J. E., Davey, N., & Sun, Y.2015, ArXiv e-prints: 1507.01589,arXiv:1507.01589\\n- ↑ Peth, M. A., Lotz, J. M., Freeman, P. E., et al.2016, MNRAS, 458, 963', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='cd3a6f17-8f51-4143-9d3c-c98363805fd1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8bd8e00999d29c5e952c24ae04cdc6e603b405b005941e2e02167f40188f932e', text='Компьютерное зрение в микроскопии\\nКомпьютерное зрение помогает автоматизировать обработку изображений, полученных с помощью микроскопии. С его появлением стало возможным эффективно и с хорошей точностью классифицировать клетки, сегментировать полученные изображения, улучшать их качество и решать другие задачи без участия человека[1].\\nСодержание\\n- 1 Задачи компьютерного зрения в микроскопии\\n- 1.1 Классификация клеток\\n- 1.2 Сегментация изображений\\n- 1.3 Детекция клеток\\n- 1.4 Склеивание изображений\\n- 1.5 Улучшение качества изображений\\n- 2 См. также\\n- 3 Примечания\\n- 4 Источники информации\\nЗадачи компьютерного зрения в микроскопии\\nНа данный момент компьютерное зрение нашло применение в большинстве направлений, где есть необходимость обрабатывать и анализировать изображения. Микроскопия не стала исключением. Теперь задачи, направленные непосредственно на работу с изображениями, можно решить используя методы глубокого обучения, например, построить подходящую сверточную нейронную сеть[2].\\nКлассификация клеток\\nКлассификация клеток является базовой задачей микроскопии. Обычно для этого используются изображения, полученные на флуоресцентных микроскопах (рисунок 1), так как классификаторы для изображений с обычных оптических микроскопов не способны отразить биологическое разнообразие различных типов клеток. Клетки можно делить по фазе в клеточном цикле, типу (повержденные или нет, раковые или нормальные), физиологическому состоянию, виду и другим признакам. Для большинства задач классификации уже существуют готовые архитектуры сверточных сетей[4][5][6][7][8][9][10].\\nОпределение фазы клеточного цикла\\nОдним из признаков, по которым можно разделить клетки, является определение фазы клеточного цикла, в которой находится клетка. Эта задача имеет практическое применение для обнаружения поврежденных клеток, которые при визуализации будут кластеризоваться отдельно от остальных. Сверточная сеть для решения задачи изображена на рисунке 2. Она обучается на изображениях с флуоресцентными метками, о которых было сказано ранее, и дает на выходе не только классификацию каждой клетки, а также визуализирует процесс клеточного цикла, используя нелинейное уменьшение размерности[5]. Классификация и визуализация являются всего лишь различными способами интерпретации результатов, поэтому строятся на основе одних и тех же выведенных закономерностей.\\nОсобенностью работы описанной сверточной сети является необходимость разметить только небольшую часть данных, на основании чего она далее учится размечать самостоятельно. Интересно, что при визуализации фазы становятся упорядочены в хронологически правильном порядке, несмотря на то, что информация о порядке фаз не передавалась в сеть напрямую. Это говорит об эффективности использования флуоресцентных меток в качестве категориальных.\\nИдентификация раковых клеток\\nДругой задачей классификации является обнаружение раковых клеток. Для ее решения используется сверточная нейронная сеть, изображенная на рисунке 3. Она имеет архитектуру VGG-16, в которой дополнительно после каждой функции активации добавлена пакетная нормализация для регуляризации[6]. Сеть, как и остальные классификаторы изображений микроскопии, принимает на вход изображения с флуоресцентными метками.\\nОсобенностью при обучении представленной сети является использование из-за недостаточного объема данных трансферного обучения, то есть модель предварительно обучается на другом огромном объеме данных. В данном случае первые 14 слоев сначала обучаются на наборе данных классификации ImageNet, а потом уже происходит обучение для классификации раковых и нормальных клеток. Такая сверточная сеть лучше справляется с задачей классификации клеток по сравнению с экспертом-человеком, особенно на изображениях с недостаточно хорошим качеством.\\nКлассификация лейкоцитов\\nЭта задача отличается от предыдущих тем, что не требует предварительной обработки материалов и использования флуоресцентного микроскопа, для ее решения достаточно изображений с оптического микроскопа. Лейкоциты важно уметь классифицировать, потому что они играют значительную роль в организме человека (иногда в крови могут образоваться злокачественные лейкоциты, которые способны вызывать лейкемию). Автоматическая классификация лейкоцитов может помочь специалистам в лабораториях, где нет достаточного количества квалифицированных сотрудников для проведения анализа крови.\\nДля решения задачи используется сеть VGGNet, похожая на ту, что идентифицирует раковые клетки, и так же трансферное обучение. Отличительной деталью является использования для оптимизации статистически усиленного алгоритма сальпового роя (англ. Statistically Enhanced Salp Swarm Algorithm, SESSA)[7] для выбора наиболее важных функций, извлеченных с помощью сети VGGNet, и удаления сильно коррелированных и шумных функций. Общая структура алгоритма представлена на рисунке 4. Такая оптимизация позволяет сократить время обучения, повысить точность и избавиться от переобучения. Результаты этого гибридного подхода к классификации являются самыми эффективными среди всех известных опубликованных работ по тому же набору данных.\\nСегментация изображений\\nЗадача сегментации изображений, полученных с микроскопа, состоит в том, чтобы аннотировать их, то есть отмечать границы объектов (клеток, ядер). Имея сегментированное изображение, легче проводить дальнейший анализ и изучать конкретные части клетки[11].\\nСеть U-Net\\nДля решения задачи сегментации обычно используется модифицированная полносвязная сверточная сеть U-Net[13]. Сеть U-Net получила широкое распространение благодаря способности последовательно распознавать как большие, так и мелкие частицы, а также устойчивости к различным условиям визуализации и наборам данных. Также она показывает хорошие результаты, даже если размер набора даных для обучения небольшой, что является частой проблемой анализа изображений, полученных с микроскопа. Однако минусом сети U-Net является ограничение на размер входного изображения, в то время как разрешение микроскопических изображений только растет с течением времени.\\nСегментация ядер клеток\\nСеть U-Net хоть и является универсальной, но для решения некоторых задач удобнее использовать более специализированные сети. Для задачи точной сегментации ядер клеток строится сеть глубокой остаточной агрегации (англ. Deep Residual Aggregation Network, DRAN)[12]. Она имеет типичную для сегментирующих сетей архитектуру, представленную на рисунке 5, и состоит из нескольких слоев, понижающих степень дискретизации данных, затем нескольких расширяющих слоев с тремя декодерами.\\nОсобенностью данных микроскопии является разный масштаб ядер на изображениях, поэтому в сеть подаются не только исходные изображения, а еще и уменьшенные и увеличенные в 2 раза. Такой подход частично решает проблему влияния существенно различающегося масштаба и получил название многомасштабной сети глубокой остаточной агрегации (англ. Multiscale Deep Residual Aggregation Network, MDRAN)[12].\\nДетекция клеток\\nВо многих биологических экспериментах необходимо уметь детектировать клетки, за которыми ведется наблюдение, понимать сколько их, как они расположены относительно друг друга. Для решения этих задач в компьютерном зрении используется несколько разных подходов[14]. Одни используют сверточные сети, чтобы предсказывать карту плотности, другие основаны на построении деревьев максимально устойчивых экстремальных областей. Вне зависимости от реализации, методы детекции клеток направлены на оценку количества клеток и учитывают перекрывания, неравномерность распредления клеток и другие факторы, специфичные для микроскопических изображений.\\nПодсчет клеток на основе сверточных сетей\\nК автоматическому подсчету клеток можно подойти с разных сторон. Первый подход основан на детекции с предварительной сегментацией изображения. Процесс сегментации сам по себе сложен и существует более эффективный способ. В его основе лежит регрессия и оценка плотности без непосредственной детекции и сегментации. По карте плотности можно с хорошей точностью оценить количество клеток.\\nОсобенностью изображений микроскопии является то, что клетки в большинстве случаев имеют размер значительно меньший, чем размер изображения, то есть нет необходимости использовать сложные глубокие сети, которые способны выучить высоко семантическую информацию. Поэтому используются полносверточные регрессионные сети (англ. Fully Convolutional Regression Networks, FCRN)[15]. Различия в архитектурах состоят в размерах ядер и количестве слоев (рисунок 6). Такие сети на выходе дают карту плотности клеток.\\nТакой подход позволяет проводить непрерывное обучение с изображениями произвольных размеров, что важно в том числе для покадровой съемки и изучения длительных процесоов. Он также обеспечивает интуитивное понимание представлений функций из FCRN, визуализируя, в какой степени информация была закодирована на разных уровнях.\\nРаспознавание перекрывающихся объектов на основе деревьев экстремальных областей\\nКлетки на изображениях микроскопии могут быть распределены неравномерно, группироваться, перекрываться, что затрудняет подсчет количества клеток и их дальнейшее изучение, так как стандартные методы применимы либо к изображениям с высокой плотностью объектов и не пытаются их разделить, либо наоборот эффективно работают только с изображениями с низкой плотностью.\\nЧтобы учесть все особенности изображения используется метод, основанный на древовидной дискретной графической модели, которая позволяет выбрать и промаркировать набор непересекающихся участков изображения с помощью глобальной оптимизации[16]. Каждый регион маркируется в соответствии с количеством объектов, которые он содержит. В условиях низкой плотности объектов метод, как правило, находит и выделяет отдельные клетки, а в местах, где клетки перекрываются, предложенный метод выделяет группы клеток (рисунок 7). Подобное адаптивное поведение, управляемое оптимизационным процессом, является уникальным для данного метода.\\nНужно также отметить, что вывод модели эффективен с точки зрения вычислений и требует всего нескольких сотен оценок классификатора, за которыми следует динамическое программирование на поддеревьях.\\nСклеивание изображений\\nНе всегда изучаемый объект полностью помещается на один снимок микроскопа. В связи с этим стоит задача склеивания изображений для дальнейшего исследования целых клеточных культур, используя различные методы визуализации. Эту задачу может решить инструмент для сшивания изображений микроскопии (англ. Microscopy Image Stitching Tool, MIST)[17]. Программа предназначена для быстрого и точного склеивания больших двумерных сеток перекрывающихся изображений покадровых снимков микроскопа. В основе работы MIST лежит оценка параметров модели на основе вычисленных попарных перемещений, а затем минимизация ошибок склеивания путем оптимизации перемещений в пределах квадратной области.\\nАлгоритм MIST состоит из четырех шагов[18]. Сначала вычисляются всевозможные перемещения между соседними покадровыми изображениями. После чего, если параметры модели не указаны пользователем, оценивается модель механического предметного столика на основе вычисленных перемещений. Затем оптимизируются перемещения между изображениями для уменьшения ошибок склеивания и составляется полученное изображение (рисунок 8).\\nНеобходимо помнить, что MIST был разработан для склеивания микроскопических изображений, полученных с помощью механического предметного столика, который перемещает образец по повторяющейся сетке, что накладывает ограничение на его использование.\\nУлучшение качества изображений\\nЗачастую изображения, полученные с помощью микроскопии, не имеют достаточно хорошее для дальнейшей работы качество. Есть разные способы борьбы с этим. Можно улучшать качество двумерных изображений стандартными методами, не имеющих отличий, связанных со специфичностью данных, или же заранее пытаться получить высококачественное изображение, предсказывая положение фокуса.\\nПредсказание положения фокуса\\nПри покадровой съемке длительного непрерывного процесса необходимо постоянно следить за положением фокуса микроскопа, чтобы не получать размытые изображения. Процесс выставления фокуса можно автоматизировать, построив сеть, которая будет предсказывать нужное положение. Эту задачу можно свести к задаче классификации изображений по фокусному расстоянию во время съемки. Для ее решения используется сверточная сеть (рисунок 9), которая состоит из двух блоков свертки и двух полносвязных блоков для классификации[19].\\nТакая сверточная сеть показывает большую точность, чем группа людей-экспертов. По сравнению с другими подходами к автофокусировке, сеть не требует физической калибровки и устойчива к шуму, оптическим артефактам и другим особенностям.\\nВосстановление рассеянных трехмерных изображений\\nТрехмерная флуоресцентная микроскопия является важным инструментом для современных исследований, но ее более широкому применению препятствует рассеяние света биологическими образцами. В основе подхода, который способен восстановить размытое и рассеянное светом трехмерное изображение глубоких тканей, лежит сеть ScatNet[21].\\nВ течение каждой эпохи обучения ScatNet учится, как лучше восстанавливать высококачественные изображения из размытых входных данных. Сгенерированный промежуточный результат для каждой эпохи сравнивается с данными фиксированной метки для оптимизации функции потерь сети[20]. Более детальная схема работы представлена на рисунке 10. ScatNet способствует простому и быстрому восстановлению изображений и не требует трудоемких ручных операций.\\nТакой подход позволяет с помощью вычислений увеличить глубину визуализации изображений трехмерной флуоресцентной микроскопии без добавления сложной оптики или моделей оптического рассеяния, так как основан только на мощных возможностях прогнозирования сверточной нейронной сети.\\nСм. также\\n- Компьютерное зрение\\n- Глубокое обучение\\n- Сверточные нейронные сети\\n- Batch-normalization\\n- Сегментация изображений\\nПримечания\\n- ↑ Gaudenz Danuser — Computer Vision in Cell Biology, 2011\\n- ↑ Nikita V Orlov — Computer Vision for Microscopy Applications, 2007\\n- ↑ Википедия: Флуоресценция в биологических исследованиях\\n- ↑ Håkan Öhrn — General image classifier for fluorescence microscopy using transfer learning , 2019\\n- ↑ 5,0 5,1 5,2 Philipp Eulenberg — Reconstructing cell cycle and disease progression using deep learning, 2017\\n- ↑ 6,0 6,1 6,2 Ronald Wihal Oei — Convolutional neural network for cell classification using microscope images of intracellular actin networks, 2019\\n- ↑ 7,0 7,1 7,2 Ahmed T. Sahlol — Efficient Classification of White Blood Cell Leukemia with Improved Swarm Optimization of Deep Features, 2020\\n- ↑ Samuel Berryman — Image-based Cell Phenotyping Using Deep Learning, 2019\\n- ↑ Nan Meng — Computational single-cell classification using deep learning on bright-field and phase images, 2017\\n- ↑ Sachin Mehta — Y-Net: Joint Segmentation and Classification for Diagnosis of Breast Biopsy Images, 2018\\n- ↑ James P. Horwath — Understanding important features of deep learning models for segmentation of high-resolution transmission electron microscopy images, 2020\\n- ↑ 12,0 12,1 12,2 Quoc Dang Vu — Methods for Segmentation and Classification of Digital Microscopy Tissue Images, 2019\\n- ↑ Olaf Ronneberger— Reconstructing cell cycle and disease progression using deep learning, 2015\\n- ↑ Takeo Kanade — Cell image analysis: Algorithms, system and applications, 2011\\n- ↑ 15,0 15,1 Weidi Xie — Microscopy cell counting and detection with fully convolutional regression networks, 2016\\n- ↑ 16,0 16,1 Carlos Arteta — Detecting Overlapping Instances in Microscopy Images Using Extremal Region Trees, 2016\\n- ↑ Joe Chalfoun — MIST: Microscopy Image Stitching Tool, 2015\\n- ↑ 18,0 18,1 Joe Chalfoun — MIST: Accurate and Scalable Microscopy Image Stitching Tool with Stage Modeling and Error Minimization, 2017\\n- ↑ 19,0 19,1 Ling Wei — Reconstructing cell cycle and disease progression using deep learning, 2018\\n- ↑ 20,0 20,1 Le Xiao — Deep learning-enabled efficient image restoration for 3D microscopy of turbid biological specimens, 2020\\n- ↑ ScatNet: homepage of the project\\nИсточники информации\\n- Википедия: Флуоресцентная микроскопия\\n- Deep learning takes on tumours\\n- Deep Learning on Microscopy Imaging\\n- Leonhard Möckl — Deep learning in single-molecule microscopy: fundamentals, caveats, and recent developments, 2020\\n- Реконструкция нейронных карт по данным электронной микроскопии с помощью глубокого обучения\\n- Глубокое обучение помогло визуализировать биологические процессы\\n- Микроскоп с нейросетью и дополненной реальностью упростит обнаружение рака\\n- Mei Chen — Computer Vision for Microscopy Image Analysis, 1st Edition, 2019\\n- Бхарат Рамсундар — Глубокое обучение в биологии и медицине, 2020, C. 99-122', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='fa4e990b-7fea-40b0-8046-4dc7c3143789', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c3b2f62121c41717c825a3fc67ca5d0c07b1613072f1f4e57d9f235e8e98b21d', text='Обучение на больших данных\\nОбучение на больших данных — раздел машинного обучения, специализирующийся на построении моделей, обрабатывающих большие объёмы данных. Также встречаются термины \"big data\" или \"большие данные\".\\nСодержание\\n- 1 Понятие больших данных\\n- 2 Особенности работы с большими данными\\n- 3 Обработка разнородных данных в рамках одной системы\\n- 4 Работа с комплексом Apache Spark для обучения на больших данных\\n- 5 Практическое применение Big Data\\n- 6 См. также\\n- 7 Примечания\\n- 8 Источники информации\\nПонятие больших данных\\nТерминология и история\\nСам термин \"большие данные\" часто трактуется очень неоднозначно, так как в ходе истории компьютерной техники объём данных и носителей этих данных возрастал в геометрической прогрессии. 50 лет назад жёсткий диск на 5 мегабайт нельзя было поднять без помощи автопогрузчика. В наши же дни маленькая коробочка весом в полкило может вмещать до нескольких терабайт данных (а то и десятков терабайт), а данные, хранящиеся на различных серверах можно исчислять петабайтами. Поэтому вопрос, какие же данные считать большими, довольно запутанный.\\nВ качестве универсального решения было принято, что те данные, которые невозможно уместить на одном сервере, можно называть \"большими\". Но это далеко не все признаки \"больших\" данных. В наше время на серверных кластерах информация постоянно двигается, существует понятие \"поток данных\", генерируется много новой информации, и всё это постоянно записывается и перезаписывается. Из-за этого также возникает ряд проблем, но об этом позже.\\nПризнаки больших данных. Правило VVV\\nЧтобы массив информации обозначить приставкой «big» он должен обладать следующими признаками[1]:\\n- Volume (Объем) — данные измеряются по физической величине и занимаемому пространству на цифровом носителе. К «big» относят массивы свыше 150 Гб в сутки;\\n- Velocity (Скорость, обновление) — информация регулярно обновляется и для обработки в реальном времени необходимы интеллектуальные технологии [2] в рамках больших данных;\\n- Variety (Разнообразие) — информация в массивах может иметь неоднородные форматы, быть структурированной частично, полностью и скапливаться бессистемно. Например, социальные сети используют большие данные в виде текстов, видео, аудио, финансовых транзакций, картинок и прочего.\\nВ современных системах рассматриваются два дополнительных фактора:\\n- Variability (Изменчивость) — потоки данных могут иметь пики и спады, сезонности, периодичность. Всплески неструктурированной информации сложны в управлении, требует мощных технологий обработки;\\n- Value (Значение данных) — информация может иметь разную сложность для восприятия и переработки, что затрудняет работу интеллектуальным системам. Например, массив сообщений из соцсетей — это один уровень данных, а транзакционные операции — другой. Задача машин определить степень важности поступающей информации, чтобы быстро структурировать.\\nОсобенности работы с большими данными\\nПорядок работы с большими данными\\nЧтобы эффективно обрабатывать и анализировать большие данные, существуют такие инструменты как \"аналитические модели\"[3]. Их решения ищутся в замкнутом виде, в виде функциональных зависимостей. Такие модели способны строить гипотезы на основе больших данных, искать в них зависимости и закономерности — всю самую полезную для большинства бизнес-задач информацию. Кроме того, важна хорошая интерпретируемость построенной модели, так как это позволяет упростить её анализ без повторного её построения, что при работе с большими данными крайне важно. Для этого большие данные проходят через несколько этапов:\\n1. Чистка данных (англ. data cleaning) — поиск и исправление ошибок в первичном наборе информации, например, ошибки ручного ввода (опечатки) или некорректные значения с измерительных приборов из-за кратковременных сбоев;\\n2. Работа с признаками (англ. feature engineering) — генерация переменных для построения аналитических моделей;\\n3. Построение и обучение аналитической модели (англ. model selection) для предсказания целевой (таргетной) переменной. Так проверяются гипотезы о зависимости таргетной переменной от предикторов.\\nНа практике это помогает решить множество задач. Например, проанализировать, как связаны отказы оборудования с условиями подачи напряжения, или определить вероятность своевременного возврата кредита частным заемщиком.\\nМетоды обработки больших данных\\nК основным методам сбора и анализа больших данных относят следующие:\\n- глубинный анализ или \"добыча\" данных (англ. data mining[4]) – обучение ассоциативным правилам, классификация, кластерный и регрессионный анализ;\\n- краудсорсинг — категоризация и обогащение данных с добровольной помощью сторонних лиц;\\n- смешение и интеграция разнородных данных, таких как, цифровая обработка сигналов и обработка естественного языка;\\n- машинное обучение, включая искусственные нейронные сети, сетевой анализ, методы оптимизации и генетические алгоритмы;\\n- распознавание образов;\\n- прогнозная аналитика;\\n- имитационное моделирование;\\n- пространственный и статистический анализ;\\n- визуализация аналитических данных — рисунки, графики, диаграммы, таблицы.\\nЗдесь ещё стоит отметить, что чаще всего любой процесс обработки больших данных является распределённым. Это достигается за счёт того, что большие данные практически всегда хранятся на кластерах серверов, а не на одном сервере. Каждый из них может производить вычисления и операции над данными. Например, задачу подсчёта минимального значения в больших данных можно распараллелить на те сервера, где эти данные хранятся, а затем уже их результаты сравнить и получить глобальный минимум. Этот процесс неплохо масштабируется, если говорить об объединении кластеров серверов в ещё большие кластеры.\\nТрудности работы с большими данными\\nПри работе с большими данными важно помнить некоторые их особенности:\\n- Данных очень много. Поэтому необходимо хранилище соответствующего размера, которое, как правило, является распределённым;\\n- Любая попытка обработать большие данные целиком скорее всего приведёт к очень длительному ожиданию результата, если обработка происходит традиционными способами (например, чтение массива в цикле);\\n- В связи с большим потоком данных, конечный их набор постоянно изменяется, поэтому необходимо анализировать данные особым образом. Так, чтобы своевременно актуализировать информацию о них;\\n- При возникновении ошибок в модели приходится тратить очень много ресурсов на их поиск и устранение, так как объёмы данных очень велики;\\n- Возникает проблема разнородности данных. Необходимо уметь обрабатывать данные различных форматов в рамках одной системы. Например, описания книг, фильмов и музыки;\\nТакже стоит отметить, что в связи с большой популярностью \"больших данных\", эта сфера очень быстро развивается, постоянно появляются всё новые технологии и инструменты для работы. Для развивающегося бизнеса внедрение систем по работе с большими данными приводит к дополнительным материальным затратам. А от специалистов в этой сфере требуется быстро овладевать новыми навыками, что также может вызвать затруднения.\\nПрименение машинного обучения к большим данным. Поиск в больших данных\\nПри работе с большими данными иногда возникает ситуация, когда пользователю нужно найти какие-то конкретные данные. Возникает задача эффективного поиска информации в больших данных. В силу большого объёма всех данных большинство известных методов поиска будут работать неэффективно. Например, поиск перебором[5] (англ. exhaustive search) — широко распространенный алгоритм не подходит для больших данных вследствие плохой оптимизации по времени исполнения и используемому месту. Также не подходят алгоритмы поиска с ориентиром (индексирование) (англ. beacon guided searching, BGS) и метод \"ближайших соседей\" (англ. nearest neighbour search). В случае первого на больших данных хранение индексов этих данных становится проблемой, так как данных слишком много, а в случае со вторым алгоритмом будут сильно мешать различные шумы и отклонения, коих в больших данных зачастую очень много.\\nЗдесь на помощь приходят генетические алгоритмы. Процедура поиска в больших данных производится довольно часто, следовательно такие алгоритмы довольно быстро приспособятся к поиску наиболее часто используемых данных. Также к плюсам генетических алгоритмов можно отнести возможность кастомизации и устойчивость к шумам, а также хорошую масштабируемость для задач с более высокой размерностью. Всё это как раз то, что нужно в случае больших данных.\\nКроме того, при поиске в больших данных может помочь кластеризация этих данных. Таким образом они будут разбиты на группы \"похожести\", когда данные в каждой группе обладают сходными признаками, по которым можно существенно снизить круг дальнейшего поиска, что существенно ускоряет процесс поиска.\\nС той же целью может применятся и оценка важности признака при перестановке[6] (англ. permutation feature importance, PFI). Этот приём позволяет выделить наиболее значимые признаки объектов. Заключается он в том, что после первоначального обучения некоторой модели происходит случайная перестановка значений признаков у объектов. За итерацию берётся некоторый признак, который есть у всех объектов, и происходит случайная перестановка значений этого признака между объектами. При этом оставшиеся признаки не изменяются. Далее происходит повторный запуск модели и производится расчёт отклонений её результатов от первичных. Такая процедура выполняется для всех признаков, чтобы можно было выделить наиболее значимые. Это может существенно помочь в задаче поиска, когда можно снизить количество рассматриваемых признаков, принимая во внимание только наиболее значимые. Например, существует некоторый набор данных, содержащий информацию о продаваемой недвижимости. Каждый объект недвижимости имеет множество признаков: местоположение относительно объектов инфраструктуры, уровень благополучия данного района города, и многие другие. В этом случае при помощи приёма PFI можно рассчитать, какие из этих признаков имеют большее влияние на цену объекта недвижимости.\\nОбработка разнородных данных в рамках одной системы\\n\"Озеро\" данных\\nПри работе с большими данными часто возникает ситуация, когда одна и та же модель должна уметь обрабатывать данные различного формата. Это позволяет строить аналитические модели точнее и получать более достоверную информацию о данных в дальнейшем. Также отметим, что в данной ситуации данные берутся из множества различных источников, которые и определяют формат получаемых данных.\\nРассмотрим модель распределенного хранения разнородных данных в концепции «озеро данных»[7].\\n- :\\n- — множество шаблонов данных;\\n- — методы разбиения разнородных данных;\\n- — множество исполнителей задач сбора данных;\\n- — количество шаблонов данных;\\n- — количество типов данных;\\n- — метод индексирования данных в хранилище озера данных;\\n- — структура озера разнородных данных.\\nДанная модель позволяет хранить как сырые разнородные данные, так и структурированные данные в соответствии с предопределенной схемой. Такой результат достигается наличием шаблонов объектов и шаблонов параметров объектов. Также это позволяет снизить временные затраты на доступ к данным.\\nСхема модели хранения разнородных данных\\nРассмотрим схему модели, изображённую на рисунке 1:\\n- Object template — шаблон некоторого объекта . Каждый объект может иметь множество источников данных . Структуру объекта можно представить следующим образом: .\\n- Data source template — шаблон источника данных. Каждый источник данных может иметь множество параметров с различными типами данных . Структуру источника данных можно представить следующим образом: ;\\n- Parameter template — шаблон параметра, хранимого в источнике данных;\\nЧтобы реализовать такую модель хранения, необходимо выполнить следующие действия:\\n- 1. Определение требуемой схемы данных:\\n- Наблюдаемые объекты описываются набором гетерогенных данных. Схема данных для хранения такого рода данных представлена в соответствии с форматом:\\n, в котором:\\n- — глобальный идентификатор объекта (уникален);\\n- — его временная метка;\\n- — координаты его местоположения на временной отметке;\\n- — словарь, описывающий функции объекта и его значения.\\n- 2. Описание источников данных и настроек сборщиков данных:\\n- Высокоуровневое описание произвольных источников данных определяется форматом:\\n, в котором:\\n- — уникальный идентификатор источника данных;\\n- — список значений ключа для источника данных;\\n- — внутренняя схема данных полученных от источника данных.\\n- 3. Построение схем привязки данных:\\n- На этом этапе создается связь между исходной схемой источника данных и требуемой схемой. Эта ссылка представлена в виде набора\\n, содержащего пары атрибутов из набора схемы и атрибутов из набора в схеме :\\n- ,\\n- .\\n- Здесь также следует помнить, что:\\n- ,\\n- .\\n- 4. Реализация алгоритмов преобразования данных:\\n- В соответствии с настройками привязки\\nи алгоритмами реализовано преобразование данных из исходной схемы в желаемую:\\n- ,\\n- , где — значение атрибута.\\n- 5. Разделение данных:\\n- Схема\\nдля разделения потоков данных в микро-потоки:\\n- .\\n- Здесь — исходный поток данных, — -й l поток данных в памяти для определенного алгоритма , – количество потоков. Данные разбиваются на потоки данных, подлежащие обработке в распределенной архитектуре, в соответствии с предопределенными задачами.\\n- 6. Вставка обработанных данных в базу данных:\\n- Когда данные преобразуются в соответствии с определенной схемой, они вставляются в базу данных. Это позволяет извлекать разнородные данные из базы данных без дополнительных манипуляций с данными.\\n- Здесь также следует помнить, что:\\nДанная модель позволяет обрабатывать массивы данных различных по структуре за счёт их преобразования к нужному формату. В дальнейшем аналитическая модель, работающая с этими данными сможет делать более точные прогнозы и гипотезы, так как по каждому объекту будет значительно больше различной информации.\\nПрименение методов машинного обучения для построения \"озера\" данных\\nПредставленная выше модель хорошо описывает схему хранения разнородных данных путём создания некоторого шаблона, который мог бы описывать все эти данные. Построение такого шаблона может быть очень трудоёмкой задачей, так как данных много и их форматов тоже может быть много. Возникает задача метапрофилирования данных. Этот процесс направлен на структуризацию разносортных данных и различных метаданных. Без этого большинство действий с данными будут попросту невозможны – будь то построение запросов для СУБД, очистка данных, их классификация и кластеризация. Кроме того, когда объёмы данных слишком велики, в БД может быть огромное количество таблиц, чьи метаданные могут сильно различаться. В таких условиях получение полной информации даже по одному объекту будет практически невыполнимой задачей.\\nМета-профайл (англ. metadata-profile) — особая структура данных, призванная собрать воедино различную информацию о конкретном объекте. Сюда так же входят и различные представления этого объекта. Например, музыкальную композицию можно идентифицировать по-разному, от названия и автора до жанра и года создания:\\n- — уникальное имя мета-профайла, , где — все возможные имена объектов;\\n-\\n— множество атрибутов мета-профайла . :\\n- — уникальное имя атрибута, , где — все возможные имена атрибутов.\\n- — простой тип данных, , где — все возможные типы данных. Важно, что типы являются простыми, то есть числами, символами или строками.\\n- — вероятность принадлежности атрибута некоторому случайно отобранному представлению .\\nПостроение этой структуры можно произвести различными методами машинного обучения. Сюда входят логистическая регрессия, наивная байесовская классификация, глубокое обучение. Фактически, здесь стоит задача классификации, в которой мы должны понять, какие атрибуты относятся к описываемому объекту, а какие нет.\\nПредположим, что у нас имеется некоторая выборка данных из одного источника. В данной выборке для каждого объекта имеется лишь одно представление, достаточно полное для однозначной его идентификации. Также имеется выборка данных, относящихся к объектам совсем другого типа, но имеющих похожие атрибуты, её размер должен быть примерно таким же, как и у предыдущей, чтобы убедиться в том, что данные для обучения сбалансированы. Это необходимо, чтобы отметать неверные варианты при обучении. Опираясь на эти выборки, происходит обучение на остальных данных (различные источники данных), представленных в виде векторов, содержащих в себе имена различных атрибутов объекта и значения этих атрибутов. На основе вероятностей, имен, типов атрибутов принимается решение, отнести их к объекту или нет. Таким образом, шаблон объекта обрастает новыми атрибутами, по которым его можно идентифицировать.\\nРабота с комплексом Apache Spark для обучения на больших данных\\nОб инструментах Apache Spark\\nМногие компании на сегодняшний день уже столкнулись с необходимостью обработки больших массивов данных. Для этой цели они начали использовать проекты экосистемы Apache Hadoop. Данная экосистема базируется на MapReduce, парадигме параллельного программирования, разработанного компанией Google. Основные достоинства MapReduce:\\n- масштабируемость;\\n- устойчивость к сбоям;\\n- простота использования.\\nНо при всех достоинствах данного инструмента, наблюдалась низкая производительность на итеративных алгоритмах (например, алгоритмы машинного обучения). Решение проблемы было найдено в университете Беркли: была разработана модель распределенных вычислений, которая имеет устойчивость к сбоям при пользовании распределенной коллекцией данных (англ. resilient distributed dataset, RDD). На основе RDD по сей день развивается система Apache Spark, которая обладает сравнительно высокой эффективностью при работе итеративных алгоритмов за счет кэширования результатов в памяти. На основе концепции распределенных коллекций разрабатываются распределенные системы:\\n- Shark — хранилище данных;\\n- GraphX — система обработки графовых данных;\\n- Spark Streaming — система обработки потоковых данных;\\n- Spark MLlib — библиотека алгоритмов машинного обучения.\\nВсе из перечисленных систем совместимы со стеком технологий Hadoop. MLlib — основная библиотека Spark. Она предоставляет множество служебных программ, полезных для задач машинного обучения:\\n- классификация;\\n- регрессия;\\n- кластеризация;\\n- моделирование;\\n- сингулярное разложение и анализ по методу главных компонент;\\n- проверка гипотез и статистической выборки.\\nПримеры реализации алгоритмов с использованием Spark MLlib\\nРассмотрим удобство использования Apache Spark на примере. Задача нашей модели — предугадать: захочет ли клиент оформить срочный вклад. Для этого воспользуемся данными из Machine Learning Repository. Напишем нашу модель на Python. Для начала работы с Apache Spark его необходимо установить, выполнив\\npip install pyspark\\nСчитаем данные из нашего файла и выведем информацию о датасете на экран:\\nfrom pyspark.sql import SparkSession spark = SparkSession.builder.appName(\\'ml-bank\\').getOrCreate() df = spark.read.csv(\\'bank.csv\\', header = True, inferSchema = True) df.printSchema()\\nРезультат:\\nroot |-- age: integer (nullable = true) |-- job: string (nullable = true) |-- marital: string (nullable = true) |-- education: string (nullable = true) |-- default: string (nullable = true) |-- balance: integer (nullable = true) |-- housing: string (nullable = true) |-- loan: string (nullable = true) |-- contact: string (nullable = true) |-- day: integer (nullable = true) |-- month: string (nullable = true) |-- duration: integer (nullable = true) |-- campaign: integer (nullable = true) |-- pdays: integer (nullable = true) |-- previous: integer (nullable = true) |-- poutcome: string (nullable = true) |-- deposit: string (nullable = true)\\nКак видно наши данные состоят из множества столбцов, содержащих числа и строки Для большей информации выведем наши данные с помощью таблицы pandas. Для примера выведем 7 первых значений:\\nimport pandas as pd pd.DataFrame(df.take(7), columns=df.columns).transpose()\\nНас будут интересовать только численные данные. Для них построим таблицу с основной информацией (количество/ среднее по всей таблице/ среднеквадратичное отклонение / минимальное значение / максимальное значение):\\nnumeric_features = [t[0] for t in df.dtypes if t[1] == \\'int\\'] df.select(numeric_features).describe().toPandas().transpose()\\nОценим корреляцию между оставшимися данными:\\nfrom pandas.plotting import scatter_matrix numeric_data = df.select(numeric_features).toPandas() axs = scatter_matrix(numeric_data, figsize=(8, 8)) n = len(numeric_data.columns) for i in range(n): v = axs[i, 0] v.yaxis.label.set_rotation(0) v.yaxis.label.set_ha(\\'right\\') v.set_yticks(()) h = axs[n-1, i] h.xaxis.label.set_rotation(90) h.set_xticks(())\\nНа данных графиках можно увидеть зависимость, к примеру, между возрастом и балансом на карте. Не будем учитывать эти корреляции при построении наших моделей, однако избавимся от дня и месяца рождения, так как эти параметры не влияют на желание клиента оформить быстрый кредит.\\ndf = df.select(\\'age\\', \\'job\\', \\'marital\\', \\'education\\', \\'default\\', \\'balance\\', \\'housing\\', \\'loan\\', \\'contact\\', \\'duration\\', \\'campaign\\', \\'pdays\\', \\'previous\\', \\'poutcome\\', \\'deposit\\') cols = df.columns\\nПодготовим оставшиеся данные для построения моделей.\\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder categoricalColumns = [\\'job\\', \\'marital\\', \\'education\\', \\'default\\', \\'housing\\', \\'loan\\', \\'contact\\', \\'poutcome\\'] stages = [] for categoricalCol in categoricalColumns: stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + \\'Index\\') encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"]) stages += [stringIndexer, encoder] label_stringIdx = StringIndexer(inputCol = \\'deposit\\', outputCol = \\'label\\') stages += [label_stringIdx] numericCols = [\\'age\\', \\'balance\\', \\'duration\\', \\'campaign\\', \\'pdays\\', \\'previous\\'] assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\") stages += [assembler] from pyspark.ml import Pipeline pipeline = Pipeline(stages = stages) pipelineModel = pipeline.fit(df) df = pipelineModel.transform(df) selectedCols = [\\'label\\', \\'features\\'] + cols df = df.select(selectedCols) df.printSchema()\\nНаконец, поделим нашу выборку на обучающую и тестирующую\\ntrain, test = df.randomSplit([0.7, 0.3], seed = 2018)\\nПостроим модели и выведем точность для:\\nLogistic Regression\\nfrom pyspark.ml.classification import LogisticRegression lr = LogisticRegression(featuresCol = \\'features\\', labelCol = \\'label\\', maxIter=10) lrModel = lr.fit(train) trainingSummary = lrModel.summary print(\"Точность: \" + str(trainingSummary.areaUnderROC))\\nТочность: 0.8865478305561797\\nBinary Classification\\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator evaluator = BinaryClassificationEvaluator() print(\"Точность: \", evaluator.evaluate(predictions))\\nТочность: 0.8837112925002687\\nDecision Tree\\nfrom pyspark.ml.classification import DecisionTreeClassifier dt = DecisionTreeClassifier(featuresCol = \\'features\\', labelCol = \\'label\\', maxDepth = 3) dtModel = dt.fit(train) predictions = dtModel.transform(test) evaluator = BinaryClassificationEvaluator() print(\"Точность: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\\nТочность: 0.7808118726917547\\nRandom Forest\\nfrom pyspark.ml.classification import RandomForestClassifier rf = RandomForestClassifier(featuresCol = \\'features\\', labelCol = \"green\">\\'label\\'</font>) rfModel = rf.fit(train) predictions = rfModel.transform(test) evaluator = BinaryClassificationEvaluator() print(\"Точность: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\\nТочность: 0.8777131493473223\\nGradient-Boosted Tree\\nfrom pyspark.ml.classification import GBTClassifier gbt = GBTClassifier(maxIter=10) gbtModel = gbt.fit(train) predictions = gbtModel.transform(test) evaluator = BinaryClassificationEvaluator() print(\"Точность: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\\nТочность: 0.8935091626908479\\nПрактическое применение Big Data\\nНа сегодняшний день работа с большими данными популярна во многих рабочих сферах. Как правило, бизнес-приложения обрабатывают огромные потоки данных из различных источников, после чего создается предсказание следующего предполагаемого события. Программисты бизнес-приложений получают в два раза больше программистов других приложений. А программист бизнес-приложений, умеющий работать с большими данными по методологии SCRUM, получает ещё больше. Можно выделить несколько областей, где использование больших данных набирает популярность:\\n- Бизнес и Маркетинг. С помощью анализа последних произведенных транзакций алгоритмы с достаточно высокой точностью могут предсказать повышение спроса на определенный товар;\\n- Социальные сети. У некоторых соцсетей уже есть встроенные алгоритмы анализа истории активности пользователей. Исходя из предпочтений пользователя и популярности некоторых сообществ, которые приближены к его интересам, создается предложение для конкретного человека вступить в сообщество, прослушать новую композицию;\\n- Здравоохранение. Перебор симптомов болезней и эффектов лекарственных препаратов позволяет создавать новые средства по борьбе с новыми заболеваниями;\\n- Предупреждение природных катастроф. Одна из важнейших сфер, где используются большие данные. Алгоритмы в этой сфере ежедневно обрабатывают огромные потоки данных в виде показаний датчиков с разных станций, чтобы приблизительно вычислить место и время предполагаемой катастрофы;\\n- Правоохранительные органы. Даже небольшое повышение преступности в каком-либо регионе будет отслежено с помощью программ, изучающих статистику преступлений. Обработка больших массивов данных машиной позволяет быстрее реагировать и принимать соответствующие меры по предотвращению новых преступлений;\\n- Сельское хозяйство. Фермерам доступны данные о погоде, состоянии почвы, влажности, созревании плодов, ходе роста и условиях для скота. Эта информация позволяет максимизировать и оптимизировать производство продукции под потребности рынка в реальном времени.\\nОднако внедрению Big Data мешает два фактора. Для мелких и средних компаний – это долгий и дорогой процесс сбора данных. А некоторая информация и вовсе относится к персональной – ее сбор без согласия гражданина запрещен.\\nСм. также\\n- Общие понятия\\n- Вариации регрессии\\n- Обучение в реальном времени\\n- Кластеризация\\n- Автоматическое машинное обучение\\nПримечания\\nИсточники информации\\n- Блог компании Хабр Карьера — Большие данные — большая ответственность, большой стресс и большие деньги\\n- Блог компании ProductStar — Что такое «Big Data»?\\n- О системе Apache Spark\\n- Документация от Microsoft — Создание конвейера машинного обучения Apache Spark\\n- A survey of different search techniques for big data — 4th International Conference on Innovations in Information, Embedded and Communication Systems, 2017;\\n- Методы обработки разнородных данных в проактивных системах управления транспортной инфраструктурой — Чан Ван Фу, Волгоградский государственный технический университет, 2019г;\\n- Towards Interactive Large-scale Structured Data Profiling — Rituparna Khan, Michael Gubanov — Department of Computer Science, Florida State University, 2020г.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='62db1523-a406-4a71-9ac9-b4ae3b48452d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8092fe88105cb5f81318634f0aaf473f72123c3c399bd57ef3180f6cb260b9ad', text='Дополнение к ранжированию\\nПри рассмотрении различных ситуаций, связанных с извлечением экспертных знаний, возникает потребность каким-либо упорядочить все множество оценок, затрагивая уже понятие группового ранжирования. Положим, имеется конечное множество объектов (например, экспертных оценок или критериев) и экспертов, пронумерованных индексами . Каждый й эксперт выставляет рейтинг, порождая порядок. Подобные тип задач в машинном обучении обозначается как ранжирование.\\nРанжирование (англ. learning to rank) — особый тип задач машиного обучения , связанный с постороением некой ранжирующей модели по обучащей выборке. Отличие от классификации и регрессии состоит в том, что для обучающей выборки не заданы ответы, однако задано отношение порядка для пары объектов. Стоит отметить, что от отношения порядка на множестве объектов изменяется и подход к ранжированию.\\nСодержание\\n- 1 Слабое ранжирование.Представления\\n- 2 Частичное ранжирование\\n- 3 Сильное ранжирование\\n- 4 Supervised алгоритмы ранжирования\\n- 5 Примечания\\n- 6 Источники информации\\nСлабое ранжирование.Представления\\nСтрогое слабое упорядовачивание\\n|Определение:\\n|Бинарное отношение на множестве , которое является частично упорядоченным, называется слабым упорядочиванием (англ. weak ordering), если оно обладает следующими свойствами:\\nРассмотрим случаи, определеяющее частичное упорядочение как:\\n- Сильное: и , то есть если ~ .\\n- Слабое[1]: если , то и .\\nМожно заключить, что любое cильное упорядовачивание есть слабое. Отношение несравнимости является отношением эквивалентности для всех своих разбиений на множестве , что являются линейно упорядоченными.\\nСильный подпорядок\\n|Определение:\\n|Сильный подпорядок — такой подпорядок, на котором присутствует отношение связанности.\\nСильный подпорядокобладает рядом следующих свойств:\\n- Транзитивность: если и .\\n- Связанности: выполнимо либо , либо .\\nЕсли в любом сильном подпорядке отношение эквивалентности. Поскольку операция определена для всех элементов, такие подпорядки еще называют отношением предпочтения[2].и , то на нем определено\\nСравнения\\nВещественная функция\\nУдобство использования слабого ранжирования в том, что его элементы могут быть представлены единственным образом с помощью вещественных функций. Рассмотрим следующую теорему.\\n|Теорема:\\nДля любого частичного упорядочиванияслабое тогда и только тогда, когда существует и отображение если , то и наоборот.\\nТаким образом, чтобы имели место быть:\\n- частичный подпорядок: для тогда и только тогда, когда .\\n- эквивалентность: для тогда и только тогда, когда .\\nОграничения:\\nЛексикографические предпочтения. Ранжирующая функция может быть определена на любом конечном множестве, однако для случая лексикографического порядка функция не определена на .\\nИнъективность. В случае, если бы являлась бы инъективной функцией, то класс эквивалентности двух элементов множества мог бы переходить в более широкий соответствующий класс на множестве .\\nСюрьективность. Если на вводятся ограничения, чтобы быть сюръективной функцией, то при отображении элементов некого класса на возможно соответствие ему меньшего или вовсе пустого класса на .\\nКусочная последовательность\\nДля любого конечного множества, на котором задано отношение слабого упорядовачивания и , может быть применимо моделирование с помощью кусочных последовательностей. Рассмотрим пример. Положим, что\\nТогда слабое ранжированиепредставляется в виде следующего:\\nЧастичное ранжирование\\n|Определение:\\n|Бинарное отношение на множестве , для некоторых элементов которого определена несравнимость ,называется частичным упорядочиванием (англ. semiorder), если оно обладает следующими свойствами:\\nСравнения\\nВещественная функция\\nЧастичное ранжирование поддается тому же функциональному подходу к сравнению за тем лишь исключением, что для численных значений объектов вводится некоторая погрешность, внутри которой объекты считаются сравнимы, снаружи - нет. Зачастую такую погрешность выбирают нормированной к .\\n|Теорема:\\nДля любого конечного частичного упорядочиваниемвозможно определить такое и функционал если , то и наоборот.\\nИнтервальный метод\\nИмея заданный функционали возможно использование интервального сравнения, а именно — объекты считаются сравнимы, если значения их оценок лежат в некотором интервале. Так, например, если , то .\\nОграничения:\\nЕсли у данного частичного ранжирования существует несчетное множество строго упорядоченных объектов, то невозможно подобрать такую. В противовес, любое конечное частичное ранжирование может быть описано с помощью .\\nСильное ранжирование\\n|Определение:\\n|Бинарное отношение на множестве , для некоторых элементов которого определена несравнимость ,называется сильным ранжированием (англ. total order), если оно обладает следующими свойствами:\\nТаким образом, сильное ранжирование — строгое слабое, для которого.\\nСравнения\\nВещественная функция\\nСильное ранжирование сравнивается с помощью функционала.\\n|Лемма:\\nДля любого конечного сильного упорядочиваниявозможно определить такой функционал если , то и наоборот.\\nПоследовательность\\nДля любого конечного множества, на котором задано отношение сильного упорядочивания и , может быть применимо моделирование с помощью порождения последовательности значений элементов. Иными словами, задается новый функционал , что все оценки образуют последовательность.\\nОграничения:\\nКак и для частичного, множество должно быть конечно.\\nSupervised алгоритмы ранжирования\\nOC-SVM\\nOrdinal Classification SVM — алгоритм поточечного ранжирования, рассматривающий каждый объект обособленно. В основе стоит использования идеи метода опорных векторов о проведении разделяющей гиперплоскости над множеством оценок.\\nПостановка задачиПусть имеется некое число градаций (оценок, предпочтений) , тогда — ранжирующая функция с порогами\\nОсновное отличие от классического подхода в том, что на имеющееся рисунке 1.границ необходимо найти зазоров. Иными словами, необходимо найти один направляющий вектор числа гиперплоскостей. Исходим от предположения, что найдется такое направление, в котором объекты удовлетворительно отранжировались. Пример такого разделения для представлен на\\nПодход\\nПоскольку теперь увеличилось число зазоров, классического значения штрафанедостаточно — необходимы штрафы и для нарушение с левой и правой сторон соответственно ой границы. Ограничительное условие для такого случая состоит в том, что произвольный объект , оказавшийся между разделяющими полосами, не должен выйти за их пределы ни слева, ни справа, что можно записать как:\\nДля случая крайних границ, для объектовможет существовать только нарушение слева от границы, когда для объектов — только справа от границы. Таким образом, задача может быть сформирована как задача минимизации с ограничениями:\\nRanking SVM\\nАлгоритм для попарного подхода[3] к ранжированию. Основное отличие от алгоритма SVM в том, что теперь объекты нумеруются попарно.\\nПостановка задачи\\nСчитаем, что теперь решаем следующую оптимизационную задачу:\\nПодход\\nПоскольку теперь все операции выполяняются уже для пары объектов, то строгая система ограничений будет отличаться в соответствующих местах:\\nRankNet, LambdaRank\\nДанные алгоритмы применяются для списочного ранжирования, хотя по сути своей используют попарный подход, который был расширен до случая списка.\\nПостановка задачи\\nСчитаем, что у нас есть некий гладкий функционал качества, который необходимо оптимизировать:\\nКонкретную функцию потерь в оригинальной работе[4] выбирают как логистическую функцию потерь, те\\nмасштабирующий параметр для пересчета значения отступа в вероятностное значение.\\nПодход\\nВоспользовавшись методом стохастического градиентного спуска, выбираем на каждойой итерации случайным образом запрос и пару документов из запроса , получаем итеративную формулу вычисления весов:\\nЧтобы перейти к использованию негладких функционалов MAP, NDCD, pFound необходимо домножить рисунке 2.на изменение данного функционала при перестановке местами и в каждой итерации. Это означает, как изменится веса модели, если в задаче ранжирования поменять местами два документа. Результаты оценки алгоритма с разным функционалом представлены на\\nLambdaRank моделирует следующий итеративный процесс:\\nОптмизируется тем самым по функционалу NDCD.\\nSoftRank\\nSoftRank — списочный метод ранжирования, который предполагает использовать сглаживание[5] для возможности диффиренцирования значения сложной метрики.\\nПостановка задачи\\nСперва необходимо перейти от поиска изначально детерминированного положения документа в отранижрованном порядке к случайной величине, распределенной по нормальному закону так, чтобы центр распределения лежал в предсказании функции ранжирования, как представлено на рисунке 3. Величина дисперсии теперь также параметр модели:\\nВозможно оценить вероятность того, что некий документй окажется выше го.\\nТеперь задача формулируется следующим образом: оценить вероятность того, чтой документ окажется на позиции .\\nПодход\\nВычисления происходят рекурсивно для каждого\\n. Оценить вероятность оказаться на м месте для элемента:\\n. Тогда вероятность оказаться на м и м месте для двух документов:\\n. Для выборки из х элементов, вероятность оказаться на первом месте:\\nи т.д.\\nГрафическая интерпритация вычислительного процесса представлена на рисунке 4.\\nЧтобы использовать метрику NDCG необходимо учесть математическое ожидание ассесорской оценки , что уже дает гладкий функционал:\\nДанное выражения уже возможно оптимизировать градиентом:\\nвычислятся через :', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='1cbbc429-d87e-44ee-a108-26152855363b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5b642a9abcde4f7dcd3f3923fc76747116a64f9cdfdcdff743fd5c84ade9581e', text='Расположение объектов на изображении\\nРасположение объектов на изображении — область компьютерного зрения, в которую входят такие задачи, как замена или добавление объекта на изображение, также к этой области относят задачи расположения объектов на изображении по их текстовому описанию и генерации изображений по тексту.\\nСодержание\\nОсновные технологии\\nДля решения задач данной области в основном используются разновидности порождающих состязательных сетей (англ. Generative adversarial network, GAN), такие как ST-GAN[1], LayoutGAN[2], GCC-GAN[3]. Также широко используются сверточные нейронные сети (англ. Convolutional neural network, CNN). Для обучения моделей в основном используются наборы данных Visual Genome[4] и MS COCO[5].\\nГенерация объектов на изображении по тексту\\nРассмотрим модель[6] генерации объектов по тексту. На вход она получает граф сцены (англ. scene graph), полученный с помощью графовой сверточной сети (англ. Graph convolutional network, сокращенно GCN). Граф сцены определяет объекты и отношения между ними, по нему строятся векторные представления (англ. embedding vector) для каждого объекта. Векторные представления используются для предсказания баундинг боксов (англ. bounding box) и масок сегментации (англ. segmentation mask), которые объединяются для формирования макета сцены (англ. scene layout). Каскадная сеть уточнения (англ. cascaded refinement network, сокращенно CRN) преобразует макет сцены в изображение. Модель обучается на состязательной основе против пары дискриминаторных сетей.\\nДля получения макета объекта векторные представления каждого объекта подаются в сеть макетов объектов (англ. object layout network). Сеть макетов объектов состоит из двух сетей: первая (mask regression network) предсказывает маску объекта и состоит из нескольких транспонированных сверточных слоев с сигмоидой, вторая (box regression network) предсказывает баундинг бокс и представляет из себя многослойный нейрон. Векторное представление объекта умножается на маску, в результате чего получается маскированное представление объекта (англ. masked embedding), которое затем вписывается в предсказанный баундинг бокс с помощью билинейной интерполяции. Суммируя все макеты объектов, получаем макет сцены. Схема получения макета сцены представлена на рисунке 2. Также для получения макета сцены можно использовать модель LayoutVAE.\\nПримеры работы модели представлены на рисунке 3, первые 4 изображения получены на наборе данных Visual Genome, а последние 4 изображения были получена на наборе данных MS COCO.\\nКомпоновка изображений\\nКомпоновка изображений — это метод, используемый для создания реалистичных, но поддельных изображений, путем замены содержимого одного изображения на другое. Рассмотрим модель[7] компоновки изображений. На вход подается исходное изображение и его макет, модель предсказывает расположение баундинг бокса для вставки объекта, ищет сегмент, подходящий по контексту, на других изображениях и вставляет его на исходное изображение.\\nПредсказание расположения баундинг бокса (Рис. 5) состоит из двух ветвей: первая предсказывает местоположение, а вторая — размер. Сначала изображение и его макет проходят через общие слои (англ. shared layers) — это слой свертки, слой пулинга и еще три слоя свертки. Выход общих слоев (англ. shared feature map) проходит через две ветви. Первая (location branch) нужна для предсказания местоположения баундинг бокса, она состоит из двух слоев свертки, а вторая (size branch) нужна для определения размера, она состоит из слоя пулинга, слоя свертки и двух полносвязных слоев.\\nПример работы модели представлен на рисунке 6.\\nИзображение для вставки можно генерировать, а не вырезать с других изображений.\\nДля генерации используется модель[8], которая получает на вход три условия: шаблон (вектор шумов), цвет (цвета объектов) и геометрию (маска частей тела) и выдает сгенерированный по этим условиям объект. Схема работы подели представлена на рисунке 8.\\nЧтобы при компоновке получить реалистичное изображение, необходимо учитывать не только цветовую, но и геометрическую целостность полученного изображения. Для этого используют такие порождающие состязательные сети, как GCC-GAN[3] и ST-GAN[1].\\nGCC-GAN\\nМодель получает на вход фон, на который надо вставить объект, сам объект и его маску. Генератор, состоящий из сетей преобразования и уточнения, учится создавать композиционные изображения, чтобы обмануть дискриминатор и сегментационную сеть. Дискриминатор в свою очередь пытается определить настоящее или нет изображение, поступившее ему на вход, а сегментационная сеть пытается отделить вставленный объект от фона. Схема работы модели и примеры представлены на рисунках 9 и 10 соответсвенно.\\nST-GAN\\nВ качестве генератора (рис. 11) в данной архитектуре используются сети с пространственными трансформаторами (англ. Spatial Transformer Networks, сокращенно STN). В данной модели используется стратегия последовательного обучения, которая показывает лучшее результаты по сравнению с наивным обучением одного генератора. Схема работы модели и примеры представлены на рисунках 12 и 13 соответсвенно.\\nГенерация макета\\nСоздание макета – задача, решение которой применимо в таких областях, как изображения, документы, мобильные приложения. Макет — это набор графических элементов, принадлежащих к одной или нескольким категориям, размещенных вместе осмысленным образом. Для этой задачи используют модели на основе порождающих состязательных сетей или трансформеров (англ. transformer).\\nLayoutGAN\\nРассмотрим модель[2], которая получает набор случайно расположенных графических объектов со случайными вероятностями классов, кодировщик передает векторные представления объектов в модуль составных отношений (англ. stacked relation module), который уточняет векторные представления, учитывая пространственные и семантические отношения между всеми элементами. После этого декодер возвращает обратно вероятности классов и геометрические параметры. Получившийся макет визуализируется и подается на вход дискриминатору, представляющему из себя сверточную нейронную сеть. Архитектура модели и примеры работы с различными способами визуализации представлены на рисунках 14 и 15 соответсвенно.\\nLayoutTransformer\\nРассмотрим модель[9], которая получает на вход последовательность элементов макета, которые преобразуются в векторные представления и поступают на вход модуля внимания, предсказывающего новую последовательность элементов макета. Схема работы модели и примеры представлены на рисунках 16 и 17 соответсвенно.\\nСм. также\\n- Задача нахождения объектов на изображении\\n- Сверточные нейронные сети\\n- Глубокое обучение\\n- Generative Adversarial Nets (GAN)\\n- Компьютерное зрение\\n- Графовые нейронные сети\\nПримечания\\n- ↑ 1,0 1,1 1,2 1,3 1,4 ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing, Chen-Hsuan Lin, Ersin Yumer, Oliver Wang, Eli Shechtman, Simon Lucey 2018\\n- ↑ 2,0 2,1 2,2 2,3 LayoutGAN: Generating Graphic Layouts With Wireframe Discriminators, Jianan Li, Jimei Yang, Aaron Hertzmann, Jianming Zhang, Tingfa Xu 2019\\n- ↑ 3,0 3,1 3,2 3,3 Toward Realistic Image Compositing with Adversarial Learning, Bor-Chun Chen, Andrew Kae 2019\\n- ↑ Visual Genome Connecting Language and Vision Using Crowdsourced Dense Image Annotations, Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A. Shamma, Michael S. Bernstein, Li Fei-Fei 2016\\n- ↑ Microsoft COCO: Common Objects in Context, Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, Piotr Dollar 2015\\n- ↑ 6,0 6,1 6,2 Image Generation from Scene Graphs, Justin Johnson, Agrim Gupta, Li Fei-Fei 2018\\n- ↑ 7,0 7,1 7,2 Where and Who? Automatic Semantic-Aware Person Composition, Fuwen Tan, Crispin Bernier, Benjamin Cohen, Vicente Ordonez, Connelly Barnes 2017\\n- ↑ 8,0 8,1 MISC: Multi-condition Injection and Spatially-adaptive Compositing for Conditional Person Image Synthesis, Shuchen Weng, Wenbo Li, Dawei Li, Hongxia Jin, Boxin Shi 2020\\n- ↑ 9,0 9,1 9,2 Layout Generation and Completion with Self-attention, Kamal Gupta, Alessandro Achille, Justin Lazarow, Larry Davis, Vijay Mahadevan, Abhinav Shrivastava 2020', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='5d772344-9cbf-4e21-869b-866049ac0000', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='104500d57d24654432752ad032dc72e9ca23742fcd5ce13f093e32adfc4087d8', text='Распознавание текста на изображении\\nРаспознавание текста на изображениях (оптическое распознавание символов (англ. optical character recognition, OCR[1])) — одно из направлений распознавания образов, задача которого заключается в переводе изображений рукописного, машинного или печатного текста в текстовые данные, использующиеся для представления символов в компьютере (например, в текстовом редакторе).\\nСодержание\\n- 1 Общая информация\\n- 2 История\\n- 3 Применение систем распознавания текстов\\n- 4 Наиболее распространенные задачи OCR\\n- 5 Процесс распознавания текста\\n- 6 Алгоритмы распознавания символов\\n- 7 Алгоритмы распознавания текста\\n- 8 См. также\\n- 9 Источники информации\\nОбщая информация\\nРаспознавание текста на изображениях является важной задачей машинного обучения, так как это позволяет организовать удобное взаимодействие с данными: редактирование, анализ, поиск слов или фраз и т.д.\\nВ последние десятилетия, благодаря использованию современных достижений компьютерных технологий, были развиты новые методы обработки изображений и распознавания образов, благодаря чему стало возможным создание таких промышленных систем распознавания печатного текста, как, например, FineReader[2], которые удовлетворяют основным требованиям систем автоматизации документооборота.\\nТем не менее, создание приложения в данной области по-прежнему остается творческой задачей и требует дополнительных исследований в связи со специфическими требованиями по разрешению, быстродействию, надежности распознавания и объему памяти, которыми характеризуется каждая конкретная задача.\\nИстория\\nРазработка OCR-систем основана на технологиях, связанных с телеграфией и созданием считывающих устройств для слепых. В 1914 году Эммануэль Гольдберг разработал устройство, считывающее символы и преобразовывающее их в стандартный телеграфный код. Одновременно Эдмунд Фурнье д\\'Альбе разработал «Оптофон», ручной сканер, который, при перемещении по напечатанной странице, вырабатывал тональные сигналы, соответствующие определенным буквам или символам.\\nВ 1974 году Рэй Курцвейл создал компанию «Kurzweil Computer Products, Inc» и начал работать над развитием первой системы оптического распознавания символов, способной распознавать текст, напечатанный любым шрифтом. Курцвейл считал, что лучшее применение этой технологии — создание машины чтения для слепых, которая позволила бы слепым людям иметь компьютер, умеющий читать текст вслух. Данное устройство требовало изобретения сразу двух технологий — ПЗС (прибор с зарядовой связью[3]) планшетного сканера и синтезатора, преобразующего текст в речь.\\nПервой коммерчески успешной программой, распознающей кириллицу, стала программа «AutoR» российской компании «ОКРУС». Алгоритм «AutoR» был компактный, быстрый и шрифтонезависимый. Этот алгоритм разработали и испытали ещё в конце 60-х два молодых биофизика, выпускники МФТИ — Г. М. Зенкин и А. П. Петров. В настоящее время алгоритм Зенкина-Петрова применяется в нескольких прикладных системах, решающих задачу распознавания графических символов.\\nВ 1993 году вышла технология распознавания текстов российской компании ABBYY. На её основе создан ряд корпоративных решений и программ для массовых пользователей. Технологии распознавания текстов ABBYY OCR лицензируют международные ИТ-компании, такие как Fujitsu, Panasonic, Xerox, Samsung, EMC и другие.\\nВ 2000-х годах производительность и компактность OCR-системы позволила представить на рынок онлайн-сервисы по переводу текста с одного языка на другой. Со временем такие программы получили возможность обрабатывать изображения как печатного, так и рукописного текста.\\nС развитием технологий производства мобильных устройств и упрощения процесса разработки мобильных приложений, OCR-системы стали неотъемлемой частью разнообразных программ: от развлекательных до обучающих, от мобильных помощников до систем управления.\\nПрименение систем распознавания текстов\\nСистемы OCR применяются во многих областях. Вот некоторые из задач, которые решают системы распознавания текстов:\\n- Считывание данных с бланков и анкет.\\n- Автоматическое распознавание номерного знака.\\n- Распознавание паспортных данных.\\n- Извлечение информации из визитных карточек в список контактов.\\n- Создание цифровых версий печатных и рукописных документов, например, сканирование книг для проекта \"Гутенберг\"[4].\\n- Технология для помощи слепым и слабовидящим.\\nНаиболее распространенные задачи OCR\\nС задачей распознавания символов связаны следующие проблемы:\\n- Разнообразие форм начертания символов: документ может содержать несколько шрифтов сразу, а символы могут быть схожи по начертанию.\\n- Искажение изображения, содержащего текст:\\n- Шумы при печати.\\n- Плохое качество изображения (засвеченность, размытость).\\n- Вариации размеров, масштаба и положения символов на странице.\\n- Влияние исходного масштаба печати: система оптического распознавания текста должна быть нечувствительной по отношению к способу верстки, расстоянию между строками и другим параметрам печати.\\nПроцесс распознавания текста\\nСистема распознавания текста предполагает наличие на входе изображения с текстом (в формате данных графического файла). На выходе система должна выдать текст, выделенный из входных данных. Весь процесс распознавания текста состоит из нескольких задач.\\nОбработка изображения\\nПеред началом распознавания текста изображение должно быть очищено от шума и приведено к виду, позволяющему эффективно выделять символы и распознавать их. Обычно у изображения повышают резкость, контрастность, выравнивают его и преобразовывают в используемый системой формат (например, 8-битное изображение в градациях серого).\\nРаспознавание символов\\nДОБАВИТЬ ОБЩИЕ СЛОВА\\nАлгоритмы распознавания символов\\nРаспознавание при помощи метрик\\nЭтой способ лучше всего работает с машинописным текстом, но при обработке новых шрифтов точность распознавания падает. Метрика является признаком символа, поэтому иногда в контексте данного способа говорят о процессе выявления признаков. В качестве метрики используют расстояние Хэмминга, которое показывает, на сколько пикселей различаются изображения. Если признаки двух символов максимально похожи, то разность между их метриками (то есть расстояние между ними) стремится к нулю. Дальнейшая классификация символа происходит по методу ближайшего соседа.\\nОднако, одной метрики недостаточно для распознавания символа, так как некоторые очень похожи между собой, (например, “j” и “i”, “Z” и “2”) что может привести к ошибке. Для избежания этого, используют следующие техники:\\n1) Группировка символов\\n$\\\\;$Некоторые символы (“O”, “H”, “I”) обладают суперсимметрией, (полностью совпадают со своими отражениями, значимые пиксели распределены равномерно по всему изображению) и их можно выделить в отдельный класс. Это значительно сокращает перебор метрик.\\n2) Контекстное распознавание\\n$\\\\;$В качестве помощи алгоритмам распознавания в систему включают словари. Они предоставляют справки во многих случаях, но быстро отказывают, когда, например, имеют дело с именами собственными, которые не находятся в словаре.\\nРаспознавание с применением нейронных сетей\\nНейронные сети – это структура связанных элементов, на которых заданы функции преобразования сигнала, а также коэффициенты, которые могут быть настроены на определенный характер работы.\\nЧасть элементов структуры выделены как входные: на них поступают сигналы извне, таким образом, они описывают значения пикселя изображения. То есть, если имеется изображение 16х16, входов у сети должно быть 256. Другая часть – выходные, они формируют результирующие сигналы.\\nСигнал, проходящий через нейронную сеть, преобразуется согласно формулам на элементах сети, на выходе формируется ответ. Так как все нейроны поименованы значениями букв, следовательно, среагировавший нейрон и несет ответ распознавания.\\nНейронная сеть может быть использована в системе распознавания текста в качестве классификатора. При обучении, сеть получает на вход изображения, анализирует все позиции черных пикселей и выравнивает коэффициенты, минимизируя ошибку. Таким образом, достигается лучший результат распознавания.\\nПример нейронной сети\\nНа картинке в качестве примера схематически показана двухслойная нейронная сеть, включающая в себя 35 входов (каждый символ — матрица 7x5, соответственно, вектор, описывающий матрицу, состоит из 35 элементов), 26 выходов (количество букв) и 10 нейронов скрытого слоя. В качестве функции активации в данной сети используется сигмоидная функция[5], выход которой представлен в диапазоне от 0 до 1, что потом удобно перевести в булеву алгебру.\\nПример на синтаксисе скриптового языка MATLAB\\nS1 = 10; % количество нейронов на скрытом слое [S2,Q] = size(targets); % количество нейронов на втором слое (количество выходов сети) P = alphabet; % входная матрица, содержащая информацию о буквах % создаем новую сеть с использованием диалогового окна net = newff(minmax(P), % матрица минимальных и максимальных значений строк входной матрицы [S1 S2], % количество нейронов на слоях {’logsig’ ’logsig’}, % функция активации ’traingdx’ % алгоритм подстройки весов и смещений (обучающий алгоритм) );\\nНедостатки нейронных сетей\\nНейронные сети с успехом могут применяться в системах распознавания текста, однако обладают существенными недостатками, препятствующими их широкому применению:\\n- Затраты памяти: необходимо построить достаточно большую сеть элементов, что приводит к большим затратам памяти.\\n- Затраты ресурсов системы: в процессе распознавания используются большие объемы ресурсов системы, так как функции на элементах сети работают с числами с плавающей точкой.\\n- Необходимость в обучении: для достижения более точного результата нейронную сеть необходимо обучать, однако и это не гарантирует идеальный результат.\\n- Сложность построения: так как работа нейронной сети во многом зависит от ее конфигурации, требуется больше усилий для создания наиболее эффективной архитектуры.\\nАлгоритмы распознавания текста\\nE2E-MLT\\n|Определение:\\n|E2E-MLT[6] — метод, позволяющий решать задачи локализации и распознавания текста на изображениях, содержащих фрагменты на разных языках. Основан на FCN-сети с общими слоями для обеих задач.\\nРеализация размещена в Github репозитории[7] одного из авторов проекта.\\nСм. также\\nИсточники информации\\n- ↑ https://en.wikipedia.org/wiki/Optical_character_recognition\\n- ↑ https://www.abbyy.com/ru/finereader/\\n- ↑ https://ru.wikipedia.org/wiki/ПЗС\\n- ↑ https://ru.wikipedia.org/wiki/Проект_«Гутенберг»\\n- ↑ https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%B3%D0%BC%D0%BE%D0%B8%D0%B4%D0%B0\\n- ↑ https://arxiv.org/abs/1801.09919\\n- ↑ https://github.com/MichalBusta/E2E-MLT', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='62014cb6-c7eb-466d-9b5a-144354ea44d9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='37bc4f3b957f07098a18523069eb1b532c05628fa4d895e23b2681b770c417a3', text='Определение геометрии изображения\\nОпределение геометрии изображения — одна из ключевых подзадач компьютерного зрения, заключающаяся в определении основных геометрических фигур на изображении, их взаимном расположении и пространстве.\\nСодержание\\nОбласти применения\\nИзвлечение информации об изображенных на изображении геометрических фигурах позволяет решать множество прикладных задач, таких как:\\n- Навигация беспилотных транспортных средств: Определение плоскости дороги, определение линии горизонта и объектах на дороге позволяют системам управления осуществлять работу.\\n- Дополненная реальность: определение различных плоскостей позволяет приложениям с дополненной реальностью взаимодействовать с пространством и дополнять его максимально реалистично.\\n- Построение 3D моделей по изображениям: имея плоское изображение, например фотографию комнаты, можно создать 3D модель, определив плоскости и карту глубин изображения.\\nОпределения геометрии изображения с использованием машинного обучения\\nДля определения геометрии изображения необходимо предсказать нормали поверхности (англ. surface normal prediction). В настоящее время для этого активно используются сверточных нейронных сетей (англ. Convolutional Neural Network, CNN), например GroundNet[1], позволяющая определить линию горизонта по изображению улицы.\\nДанная сеть сначала сегментирует участок земли, а затем независимо предсказывает нормали к участку земли и карту глубин для этого участка. По карте глубин вычисляются нормали, используя метод наименьших квадратов (Least squares) или метод RANSAC. Затем нормали, вычисленные ранее сравнивают, чтобы разница между ними была минимальна и после этого определяется линия горизонта.\\nРазличные улучшения сетей\\nSpatial Transformer Networks\\nSpatial Transformer Networks (STN)[2] — модуль, который можно встроить для улучшения нейросети. STN, применяя обучаемое аффинное преобразование с последующей интерполяцией, лишает изображения пространственной инвариантности. Задача STN состоит в том, чтобы так повернуть или уменьшить-увеличить исходное изображение, чтобы основная сеть-классификатор смогла проще определить нужный объект. Использование данного модуля в сетях, предназначенных для в сетях для определения геометрии, позволяет получать более качественные результат.\\nDense Conditional Random Field\\nDense Conditional Random Field (DCRF) [3] — еще один встраиваемый модуль для улучшения нейронных сетей, предназначенный для осуществления согласованности между картой глубин изображения и картой нормалей.\\nДанные для обучения\\n- KITTI[1] — популярный набор данных с изображениями улиц и дорог.\\n- ApolloScape [2] — другой известный и большой набор данных с различными разметками.\\n- NYU v2 [3] — набор с изображениями помещений. Помимо RGB изображений, содержит записи с глубинных камер.\\n- SharinGAN[4] — метод, позволяющий объединять наборы из реальных и синтетических изображений, основанный на отбрасывании нерелевантных свойств каждого из типа данных и объединении релевантных. В конечном итоге данный метод позволяет легко получать наборы данных путем синтетического создания, так как их легко получить и разметить, но при этом эти наборы будут применимы для обучения сети, пригодной к использованию на реальных данных.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='990b3001-0ac5-41d0-b11a-ba565750dd67', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f4ad435f2a72ee39abfd8a91caef4046e3f6b3a3d45b5dbd01b494cd805110ee', text='Анализ видео\\nТрекинг — определение местоположения объекта (нескольких объектов) во времени.\\nЗадача отслеживания объектов на видео является одной из самых интересных задач в информационных технологиях. На первый взгляд, видеопоток можно рассматривать как последовательность отдельных кадров, поэтому применимы многие алгоритмы, использующиеся для обработки обычных изображений. Сегодня к задаче распознавания объектов также широко применяются методы классификации, а именно, строятся системы, которые определяют к какому классу (изображение содержит объект или изображение не содержит объект) относится изображение.\\nС другой стороны, видеопоток обладает свойством связности: каждый последующий кадр не сильно отличается от предыдущего, поэтому возможно применение алгоритмов, основанных на этом свойстве. Одной из интересных задач в этой области является трекинг перемещений объектов на видео. В работе [1] алгоритмы отслеживания разделены на четыре основные категории: отслеживание областей, отслеживание по активному контуру, отслеживание по характерным признакам, отслеживание по модели.\\nСодержание\\n- 1 Распознавание изображений\\n- 2 Отслеживание объекта\\n- 2.1 Visual object tracking\\n- 2.2 Multiple object tracking\\n- 2.3 Основные трудности\\n- 3 См. также\\n- 4 Примечания\\n- 5 Источники информации\\nРаспознавание изображений\\nДля детектирования объекта на изображении применяются алгоритмы распознавания. Алгоритм распознавания изображений принимает картинку в качестве входных данных и выводит, что содержится на данном изображении.\\nКлассификация изображений производится поэтапно. На первом шаге входное изображение зачастую предварительно обрабатывается для нормализации контраста и яркости, а также на этом шаге входное изображение обрезается и масштабируется до фиксированного размера.\\nНа втором шаге необходимо упростить изображение путем извлечения важной информации, так как исходное изображение содержит слишком много дополнительной информации, которая не требуется для классификации. Этот шаг называется извлечением признаков. Существует достаточно большое количество признаков, используемых в компьютерном зрении, — это признаки Хаара, HOG (Histogram of Oriented Gradients), SIFT (Scale-Invariant Feature Transform), SURF (Speeded Up Robust Feature) и другие.\\nНа третьем шаге алгоритм классификации принимает вектор признаков в качестве входных данных и выводит к какому классу принадлежит изображение.\\nМетод Виолы-Джонса\\nОсновной принцип алгоритмы Виолы-Джонса, основанный на признаках Хаара, заключается в сканировании изображения с помощью сканирующего окна, которое позволяет обнаружить заданный объект. Однако признаки, предложенные Виолой и Джонсом, содержат более одной прямоугольной области и несколько сложнее. На иллюстрации показано четыре различных типа признаков. Величина каждого признака вычисляется как сумма пикселей в белых прямоугольниках, из которой вычитается сумма пикселей в чёрных областях. Прямоугольные признаки более примитивны, чем steerable filter, и, несмотря на то, что они чувствительны к вертикальным и горизонтальным особенностям изображений, результат их поиска более груб. Однако, при хранении изображения в интегральном формате проверка прямоугольного признака на конкретной позиции проводится за константное время, что является их преимуществом по сравнению с более точными вариантами. Каждая прямоугольная область в используемых признаках всегда смежна с другим прямоугольником, поэтому расчёт признака с двумя прямоугольниками состоит из шести обращений в интегральный массив, для признака с тремя прямоугольниками - из восьми, и с четырьмя прямоугольниками - из девяти.\\nОтслеживание объекта\\nОтслеживанием называется поиск объекта в последовательных кадрах видео. Отслеживание объекта в некоторых случаях может выполняться при помощи алгоритмов детектирования. При детектировании основная идея заключается в том, чтобы сначала определить регионы интереса (ключевые точки), которые будут независимы к преобразованиям. Затем для каждого региона интереса строится его векторное представление — дескриптор. Далее на каждом кадре будет выполняться поиск объекта и выделение его местоположения прямоугольником.\\nПри трекинге целью является нахождение объекта в текущем кадре, если он успешно отслеживался во всех предыдущих кадрах. Так как объект был отслежен до текущего кадра, известны параметры модели движения: скорость и направление движения объекта в предыдущих кадрах. Поэтому можно предсказать новое местоположение объекта, опираясь на его модель движения, и оно будет очень близко к реальному новому положению объекта.\\nVisual object tracking\\nVOT (Visual object tracking)\\n- Рассматривается отслеживание одного объекта\\n- Объект уже выделен на первом кадре\\n- \"Model-free\" — нет ничего, кроме одного изображения на первом кадре, т.е. не можем детектировать объект\\n- \"Short-term\" — отслеживаем на коротких промежутках времени, не применяем повторное обнаружение\\n- Не используются будущие кадры, только предыдущие\\nПример алгоритма\\n- Инициализация\\n- Находим 100 контрольных точек с помощью метода поиска локальных особенностей (Harris corners) в рамке руки\\n- Вычисляем медиану\\n- Вычисляем цветовую статистику в окрестности центра\\n- Разметить в рамке руки все пиксели, похожие на кожу\\n- Слежение\\n- Отслеживаем контрольные точки\\n- Если точка нарушает условия стаи, то удаляем её\\n- Инициализация новых контрольных точек\\n- Ищем особенности (Harris corners)\\n- Если точка не на коже, то удаляем её\\nInput : Pretrained CNN filters {,..., } Initial target state Output: Estimated target states 1: Randomly initialize the last layer . 2: Train a bounding box regression model. 3: Draw positive samples and negative samples . 4: Update { } using and ; 5: {1} and {1}. 6: repeat 7: Draw target candidate samples ; 8: Find the optimal target state by Eq. (1). 9: if > 0.5 then 10: Draw training samples and . 11: { }, { }. 12: if | | > then \\\\ { }. 13: if | | > then \\\\ { }. 14: Adjust using bounding box regression. 15: if < 0.5 then 16: Update { } using and . 17: else if mod 10 = 0 then 18: Update { } using and . 19: until end of sequence\\n(1):.\\nMultiple object tracking\\nMOT (Multiple object tracking)\\n- Задача \"выделения и сопровождения множества объектов\"\\n- Нужно найти все объекты на кадрах\\n- Определить сколько у нас разных \"экземпляров\" объектов\\n- Найти на каких кадрах виден каждый экземпляр и где он именно\\n- Обобщение задачи \"выделение объектов на изображении\" на случайном видео\\n- В отличие от VOT:\\n- Работает со множеством объектов\\n- На длительных промежутках времени\\n- Есть модель объектов (возможность повторного обнаружения)\\n- Разрешено \"заглядывать в будущее\"\\nПример алгоритма\\n- Поиск голов на ключевых кадрах\\n- Построение треклетов\\n- Визуальное сопровождение\\n- Получаем гипотезы движения объектов между ключевыми кадрами (треклеты)\\n- Объединение треклетов в траектории\\n- Алгоритм MCMC DA\\n- Построение выборки из распределения\\n- Алгоритм Метрополиса — Гастингса\\n- Элемент с максимальной вероятностью\\n- Восстановление положения на промежуточных кадрах\\n- Алгоритм MCMC DA\\nMultiple Object Tracking Tutorial\\nfunction MultipleObjectTrackingExample() // Create objects used for reading video and displaying the results. videoObjects = setupVideoObjects(\\'atrium.mp4\\'); // Create objects used for detecting objects in the foreground of the video. minBlobArea = 400; % Minimum blob size, in pixels, to be considered as a detection detectorObjects = setupDetectorObjects(minBlobArea);\\nCreate the Multi-Object Tracker\\ntracker = multiObjectTracker(... \\'FilterInitializationFcn\\', @initDemoFilter, ... \\'AssignmentThreshold\\', 30, ... \\'DeletionThreshold\\', 22, ... \\'ConfirmationThreshold\\', [6 10] ... );\\nDefine a Kalman Filter\\nfunction filter = initDemoFilter(detection) // Initialize a Kalman filter for this example. // Define the initial state. state = [detection.Measurement(1); 0; detection.Measurement(2); 0]; // Define the initial state covariance. stateCov = diag([50, 50, 50, 50]); // Create the tracking filter. filter = trackingKF(\\'MotionModel\\', \\'2D Constant Velocity\\', ... \\'State\\', state, ... \\'StateCovariance\\', stateCov, ... \\'MeasurementNoise\\', detection.MeasurementNoise(1:2,1:2) ... ); end // Count frames to create a sense of time. frameCount = 0; while hasFrame(videoObjects.reader) // Read a video frame and detect objects in it. frameCount = frameCount + 1; // Promote frame count frame = readFrame(videoObjects.reader); // Read frame [detections, mask] = detectObjects(detectorObjects, frame); // Detect objects in video frame // Run the tracker on the preprocessed detections. confirmedTracks = updateTracks(tracker, detections, frameCount); // Display the tracking results on the video. displayTrackingResults(videoObjects, confirmedTracks, frame, mask); end\\nCreate Video Objects\\nfunction videoObjects = setupVideoObjects(filename) // Initialize video I/O // Create objects for reading a video from a file, drawing the tracked // objects in each frame, and playing the video. // Create a video file reader. videoObjects.reader = VideoReader(filename); // Create two video players: one to display the video, // and one to display the foreground mask. videoObjects.maskPlayer = vision.VideoPlayer(\\'Position\\', [20, 400, 700, 400]); videoObjects.videoPlayer = vision.VideoPlayer(\\'Position\\', [740, 400, 700, 400]); end\\nCreate Detector Objects\\nfunction detectorObjects = setupDetectorObjects(minBlobArea) // Create System objects for foreground detection and blob analysis // The foreground detector segments moving objects from the // background. It outputs a binary mask, where the pixel value of 1 // corresponds to the foreground and the value of 0 corresponds to // the background. detectorObjects.detector = vision.ForegroundDetector(\\'NumGaussians\\', 3, ... \\'NumTrainingFrames\\', 40, \\'MinimumBackgroundRatio\\', 0.7); // Connected groups of foreground pixels are likely to correspond to // moving objects. The blob analysis System object finds such // groups (called \\'blobs\\' or \\'connected components\\') and computes // their characteristics, such as their areas, centroids, and the // bounding boxes. detectorObjects.blobAnalyzer = vision.BlobAnalysis(\\'BoundingBoxOutputPort\\', true, ... \\'AreaOutputPort\\', true, \\'CentroidOutputPort\\', true, ... \\'MinimumBlobArea\\', minBlobArea); end\\nDetect Objects\\nfunction [detections, mask] = detectObjects(detectorObjects, frame) // Expected uncertainty (noise) for the blob centroid. measurementNoise = 100*eye(2); // Detect foreground. mask = detectorObjects.detector.step(frame); // Apply morphological operations to remove noise and fill in holes. mask = imopen(mask, strel(\\'rectangle\\', [6, 6])); mask = imclose(mask, strel(\\'rectangle\\', [50, 50])); mask = imfill(mask, \\'holes\\'); // Perform blob analysis to find connected components. [~, centroids, bboxes] = detectorObjects.blobAnalyzer.step(mask); // Formulate the detections as a list of objectDetection objects. numDetections = size(centroids, 1); detections = cell(numDetections, 1); for i = 1:numDetections detections{i} = objectDetection(frameCount, centroids(i,:), ... \\'MeasurementNoise\\', measurementNoise, ... \\'ObjectAttributes\\', {bboxes(i,:)}); end end\\nDisplay Tracking Results\\nfunction displayTrackingResults(videoObjects, confirmedTracks, frame, mask) % Convert the frame and the mask to uint8 RGB. frame = im2uint8(frame); mask = uint8(repmat(mask, [1, 1, 3])) .* 255; if ~isempty(confirmedTracks) // Display the objects. If an object has not been detected // in this frame, display its predicted bounding box. numRelTr = numel(confirmedTracks); boxes = zeros(numRelTr, 4); ids = zeros(numRelTr, 1, \\'int32\\'); predictedTrackInds = zeros(numRelTr, 1); for tr = 1:numRelTr // Get bounding boxes. boxes(tr, :) = confirmedTracks(tr).ObjectAttributes{1}{1}; // Get IDs. ids(tr) = confirmedTracks(tr).TrackID; if confirmedTracks(tr).IsCoasted predictedTrackInds(tr) = tr; end end predictedTrackInds = predictedTrackInds(predictedTrackInds > 0); // Create labels for objects that display the predicted rather // than the actual location. labels = cellstr(int2str(ids)); isPredicted = cell(size(labels)); isPredicted(predictedTrackInds) = {\\' predicted\\'}; labels = strcat(labels, isPredicted); // Draw the objects on the frame. frame = insertObjectAnnotation(frame, \\'rectangle\\', boxes, labels); // Draw the objects on the mask. mask = insertObjectAnnotation(mask, \\'rectangle\\', boxes, labels); end // Display the mask and the frame. videoObjects.maskPlayer.step(mask); videoObjects.videoPlayer.step(frame); end end\\nОсновные трудности\\n- Вычислительная нагрузка\\n- Нужно обрабатывать кадров в секунду\\n- Изменение по времени\\n- Вид объекта меняется от кадра к кадру из-за ракурса, изменения освещения, внутренний изменений\\n- Взаимодействие объектов\\n- Перекрытие объектов\\n- Визуальное сходство объектов\\n- Для оценки качества работы алгоритмов слежения и настройки параметров требуются размеченные эталонные данные\\n- Подготовить эталонные данные для видео существенно сложнее, чем для изображения\\n- Один эталонный пример для выделения объектов — одно изображение\\n- Один эталонный пример для отслеживания объектов — одно видео\\n- Сейчас есть хорошие конкурсы, но объём данных по прежнему ограничен, особенно для MOT\\nСм. также\\nПримечания\\nИсточники информации\\n1. Hu W. M., Tan T. N., Wang L., Maybank S. A survey of visual surveillance of object motion and behaviors // IEEE Transactions on System, Man, and Cybernetics (T-SMC), Part C. – 2004. Vol. 34(3). – P. 334-352.\\n2. Лавелина Е.С., Закуанова М.Р., Масловская М.А. ОТСЛЕЖИВАНИЕ ОБЪЕКТОВ В ВИДЕОПОТОКЕ // Научное сообщество студентов XXI столетия. ТЕХНИЧЕСКИЕ НАУКИ: сб. ст. по мат. LIV междунар. студ. науч.-практ. конф. № 6(53). URL: https://sibac.info/archive/technic/6(53).pdf (дата обращения: 20.04.2020)\\n3. Анализ изображений и видео. Часть 2\\n4. Learning Multi-Domain Convolutional Neural Networks for Visual Tracking\\n5. Multiple object tracking tutorial', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='07d4f701-02f9-4f18-b136-8e67707d9673', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7ffbee6993d81129e1f0f7c3986a7c5f80f654296982c243ff7e0c497095140e', text='Обнаружение и обработка дорожных знаков и пешеходов\\nОбнаружение объектов является хорошо известной проблемой в области компьютерного зрения и глубокого обучения. Существует два компонента в модели обнаружения объекта, а именно, базовая нейронная сеть и нейронная сеть обнаружения. Во-первых, базовые нейтральные сети -это CNN, которые извлекают объекты из изображения, из объектов низкого уровня, таких как линии, ребра или круги, в объекты более высокого уровня, такие как лицо, человек, светофор или знак стоп и т. д. Несколько хорошо известных базовых нейронных сетей-это LeNet, InceptionNet(он же. GoogleNet), ResNet, VGG-Net, AlexNet, MobileNet и др. Эта превосходная статья обсуждает различия между этими базовыми нейтральными сетями ниже.\\nЗатем нейронные сети обнаружения присоединяются к концу базовой нейронной сети и используются для одновременной идентификации нескольких объектов из одного изображения с помощью извлеченных признаков. Некоторые из популярных сетей обнаружения-SSD (Single Shot MultiBox Detector), R-CNN (регион с функциями CNN), более быстрый R-CNN и YOLO (вы смотрите только один раз) и т. д. В этой статье рассматриваются различия между этими нейронными сетями обнаружения.\\nСодержание\\nModeling training\\nВыделим несколько этапов связанных с модельным обучением.\\n- Сбор и маркировка изображений (20-30 мин)\\n- Выбор модели\\n- Трансферное обучение / модельное обучение (3-4 часа)\\n- Сохранить вывод модели в формате Edge TPU (5 мин)\\n- Запуск вывода модели на Raspberry Pi\\nСбор и маркировка изображенийУ нас есть 6 типов объектов, а именно: красный свет, зеленый свет, знак остановки, ограничение скорости 40 миль в час, ограничение скорости 25 миль в час и несколько фигурок Lego в качестве пешеходов.labelImg (для Windows / Mac / Linux) это можно сделать довольно быстро и просто.\\nВыбор модели\\nНа Raspberry Pi, так как мы имеем ограниченные вычислительные мощности, мы должны выбрать модель, которая работает относительно быстро и точно. После экспериментов с несколькими моделями, свой выбор остановим на MobileNet v2 SSD COCO как на модели с оптимальным балансом между скоростью и точностью.\\nТрансферное Обучение / Модельное Обучение\\nДля этого шага будем использовать Google Colab.\\nПодготовка данных для обучения:\\nrepo_dir_path = \\'/content/DeepPiCar\\' % cd{ repo_dir_path} / models/ object_detection # Convert train folder annotation xml files to a single csv file, # generate the `label_map.pbtxt` file to `data/` directory as well. !python code/xml_to_csv.py -i data/ images/ train - o data/ annotations/ train_labels.csv -l data/ annotations # Convert test folder annotation xml files to a single csv. !python code/xml_to_csv.py -i data/ images/ test -o data/ annotations/ test_labels.csv # Generate `train.record` !python code/generate_tfrecord.py --csv_input=data/annotations/train_labels.csv - - output_path= data/ annotations/ train.record -- img_path=data/images/train --label_map data/annotations/label_map.pbtxt # Generate `test.record` !python code/generate_tfrecord.py --csv_input=data/annotations/test_labels.csv - - output_path= data/ annotations/ test.record -- img_path=data/images/test --label_map data/annotations/label_map.pbtxt\\nПриведенный выше код преобразует xml-файлы меток, созданные инструментом LabelImg, в двоичный формат, так что TensorFlow может обрабатывать быстро.\\nЗагружаем Pre-trained Model:\\nMODEL_FILE = MODEL + \\'.tar.gz\\' DOWNLOAD_BASE = \\'http://download.tensorflow.org/models/object_detection/\\' DEST_DIR = \\'/content/models/research/pretrained_model\\' if not( os.path.exists( MODEL_FILE)): urllib.request.urlretrieve( DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE) tar = tarfile.open( MODEL_FILE) tar.extractall() tar.close() os.remove( MODEL_FILE) if(os.path.exists( DEST_DIR)): shutil.rmtree(DEST_DIR) os.rename( MODEL, DEST_DIR) fine_tune_checkpoint = os.path.join( DEST_DIR, \"model.ckpt\") print( fine_tune_checkpoint)\\nПриведенный выше код загрузит предварительно обученные файлы модели для ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03 модель и мы будем только использовать model.ckpt файл.\\nТренируем модель:\\nnum_steps = 2000 num_eval_steps = 50 model_dir = \\'/content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training\\' pipeline_file = \\'ssd_mobilenet_v2_quantized_300x300_coco.config\\' !python /content/models/research/object_detection/model_main.py \\\\ - - pipeline_config_path= { pipeline_fname} \\\\ --model_dir=\\'{model_dir}\\' \\\\ --alsologtostderr \\\\ --num_train_steps={num_steps} \\\\ --num_eval_steps={num_eval_steps}\\nЭтот шаг занимает 3-4 часа, в зависимости от количества шагов, которые вы тренируете (они же эпохи или num_steps). После того, как тренировка будет завершена, вы увидите кучу файлов в model_dir. Мы ищем самое последнее model.ckpt-xxxx.meta файл.Во время обучения мы можем отслеживать прогрессирование потерь и точности с помощью TensorBoard.Тестируем обученную модель:\\nПосле тренировки прогоняем несколько изображений из тестового набора данных через нашу новую модель. Как и ожидалось, практически все объекты на изображении были идентифицированы с относительно высокой достоверностью. Более отдаленные объекты становились больше и легче обнаружить, когда наша машина приближалась к ним.\\nСохраняем вывод модели в формате Edge TPU:\\nПосле того, как модель обучена, мы должны экспортировать модель meta файл в диаграмму вывода в формате Google ProtoBuf, а затем в формат, который Edge TPU accelerator может понимать и обрабатывать.\\nПланирование и управление движением\\nТеперь, когда DeepPiCar может обнаружить и определить, какие объекты находятся перед ним, нам все еще нужно сказать ему, что с ними делать, т. е. управление движением. Существует два подхода к управлению движением, т. е. основанный на правилах и сквозной.\\n- Подход, основанный на правилах значит, нам нужно точно сказать машине, что делать, когда она сталкивается с каждым объектом. Например, скажите автомобилю остановиться, если он видит красный свет или пешехода, или ехать медленнее, если он видит более низкий знак ограничения скорости и т. д. Это сродни тому, что мы сделали в части 4, где мы рассказали автомобилю, как перемещаться по полосе движения с помощью набора кодов/правил.\\n- Сквозной подход просто кормит автомобиль большим количеством видеоматериалов хороших водителей, и автомобиль, через глубокое обучение, выясняет сам по себе, что он должен остановиться перед красными огнями и пешеходами или замедлиться, когда ограничение скорости падает.\\nВ статье рассматривается первый подход.\\nПравила довольно просты: если ни один объект не обнаружен, то привод на последнем известном ограничении скорости. Если какой-то объект обнаружен, этот объект изменит скорость автомобиля или ограничение скорости.\\nВо-первых, определяем базовый класс, TrafficObject, который представляет собой любые дорожные знаки или пешеходов, которые могут быть обнаружены на дороге. Он содержит метод, set_car_state(car_state). car_stateСловарь содержит две переменные, а именно: speed, и speed_limit, который будет изменен этим методом. Он также имеет вспомогательный метод, is_close_by(), который проверяет, находится ли обнаруженный объект достаточно близко. (Ну, поскольку наша единственная камера не может определить расстояние, приближаем расстояние с высотой объекта. Чтобы точно определить расстояние, нам понадобится лидар или его маленький кузен, ультразвуковой датчик или система камер стереовидения, как в Тесле.)\\nclass TrafficObject(object): def set_car_state( self, car_state): pass @staticmethod def is_close_by( obj, frame_height, min_height_pct= 0,05): # default: if a sign is 10% of the height of frame obj_height = obj.bounding_box[ 1] [1] - obj.bounding_box[0][1] return obj_height / frame_height >> min_height_pct\\nРеализация для красного света и пешехода тривиальны, просто устанавливают скорость автомобиля 0.\\nclass RedTrafficLight(TrafficObject): def set_car_state( self, car_state): logging.debug(\\'red light: stopping car\\') car_state[\\'speed\\'] = 0 class Pedestrian(TrafficObject): def set_car_state( self, car_state): logging.debug(\\'pedestrian: stopping car\\') car_state[\\'speed\\'] = 0\\nКак 25 миль в час, так и 40 миль в час ограничения скорости могут использовать только один класс SpeedLimit, который принимает speed_limit в качестве параметра инициализации. Когда знак обнаружен, просто установливаем ограничение скорости автомобиля до соответствующего предела.\\nclass SpeedLimit( TrafficObject): def __init__(self, speed_limit): self.speed_limit = speed_limit def set_car_state( self, car_state): logging.debug(\\'speed limit: set limit to %d\\' % self.speed_limit) car_state[\\'speed_limit\\'] = self.speed_limit\\nРеализация зеленого света еще проще, так как он ничего не делает, но печать зеленого света обнаруживается (код не показан).\\nПосле того, как мы определили поведение для каждого дорожного знака, нам нужен класс, чтобы связать их вместе, который является ObjectsOnRoadProcessor класс. Этот класс сначала загружает обученную модель для Edge TPU, затем обнаруживает объекты в живом видео с моделью и, наконец, вызывает каждый объект трафика для изменения скорости и ограничения скорости автомобиля.\\nclass ObjectsOnRoadProcessor(object): \"\"\" This class 1) detects what objects (namely traffic signs and people) are on the road and 2) controls the car navigation (speed/steering) accordingly \"\"\" def __init__(self, car= None, speed_limit=40, model= \\'/home/pi/DeepPiCar/models/object_detection/data/model_result/road_signs_quantized_edgetpu.tflite\\', label= \\'/home/pi/DeepPiCar/models/object_detection/data/model_result/road_sign_labels.txt\\', width= 640, height= 480): # model: This MUST be a tflite model that was specifically compiled for Edge TPU. # https://coral.withgoogle.com/web-compiler/ logging.info(\\'Creating a ObjectsOnRoadProcessor...\\') self.width = width self.height = height # initialize car self.car = car self.speed_limit = speed_limit self.speed = speed_limit # initialize TensorFlow models with open(label, \\'r\\') as f: pairs = (l.strip().split(maxsplit= 1) for l in f.readlines()) self.labels = dict((int(k), v) for k, v in ) # initial edge TPU engine logging.info(\\'Initialize Edge TPU with model %s...\\' % model) self.engine = edgetpu.detection.engine.DetectionEngine(model) self.min_confidence = 0.30 self.num_of_objects = 3 logging.info(\\'Initialize Edge TPU with model done.\\') self.traffic_objects = {0: GreenTrafficLight(), 1: Person(), 2: RedTrafficLight(), 3: SpeedLimit(25), 4: SpeedLimit(40), 5: StopSign()} def process_objects_on_road(self, frame): # Main entry point of the Road Object Handler objects, final_frame = self.detect_objects(frame) self.control_car(objects) return final_frame def control_car(self, objects): logging.debug(\\'Control car...\\') car_state = {\"speed\": self.speed_limit, \"speed_limit\": self.speed_limit} if len(objects) == 0: logging.debug(\\'No objects detected, drive at speed limit of %s.\\' % self.speed_limit) contain_stop_sign = False for obj in objects: obj_label = self.labels[obj.label_id] processor = self.traffic_objects[obj.label_id] if processor.is_close_by(obj, self.height): processor.set_car_state(car_state) else: logging.debug(\"[%s] object detected, but it is too far, ignoring. \" % obj_label) if obj_label == \\'Stop\\': contain_stop_sign = True if not contain_stop_sign: self.traffic_objects[5].clear() self.resume_driving(car_state) def resume_driving(self, car_state): old_speed = self.speed self.speed_limit = car_state[\\'speed_limit\\'] self.speed = car_state[\\'speed\\'] if self.speed == 0: self.set_speed(0) else: self.set_speed(self.speed_limit) logging.debug(\\'Current Speed = %d, New Speed = %d\\' % (old_speed, self.speed)) if self.speed == 0: logging.debug(\\'full stop for 1 seconds\\') time.sleep(1) def set_speed(self, speed): # Use this setter, so we can test this class without a car attached self.speed = speed if self.car is not None: logging.debug(\"Actually setting car speed to %d\" % speed) self.car.back_wheels.speed = speed\\nОбратите внимание, что каждый объект TrafficObject просто изменяет speed и speed_limit в car_state объекте, но на самом деле не меняет скорость автомобиля. Это ObjectsOnRoadProcessor изменяет фактическую скорость автомобиля, после обнаружения и обработки всех дорожных знаков и пешеходов.\\nПолный исходный код интереса находится на Github DeepPiCar.\\nИтоги\\nВ этой статье мы научили наш DeepPiCar распознавать дорожные знаки и пешеходов, а также реагировать на них соответствующим образом. Это не маленький подвиг, так как большинство автомобилей на дороге еще не могут этого сделать. Мы выбрали кратчайший путь и использовали предварительно обученную модель обнаружения объекта и применили обучение передачи на нем. Действительно, трансфертное обучение широко распространено в индустрии ИИ, когда не удается собрать достаточное количество обучающих данных для создания модели глубокого обучения с нуля или не хватает мощности GPU для обучения моделей в течение нескольких недель или месяцев.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='a620e8da-08e3-4097-94d8-434f8fd678d0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='736bf0ae8c24c06dd5498536844f34b26eeec5c0fe65ccdc309b3eb5f3914652', text='Трансформер\\nТрансформер (англ. transformer) — архитектура глубоких нейронных сетей, основанная на механизме внимания без использования рекуррентных нейронных сетей (сокр. RNN). Самое большое преимущество трансформеров по сравнению с RNN заключается в их высокой эффективности в условиях параллелизации. Впервые модель трансформера была предложена в статье Attention is All You Need[1] от разработчиков Google в 2017 году.\\nСодержание\\nАрхитектура трансформера\\nУстройство трансформера состоит из кодирующего и декодирующего компонентов. На вход принимается некая последовательность, создается ее векторное представление (англ. embedding), прибавляется вектор позиционного кодирования, после чего набор элементов без учета порядка в последовательности поступает в кодирующий компонент (параллельная обработка), а затем декодирующий компонент получает на вход часть этой последовательности и выход кодирующего. В результате получается новая выходная последовательность.\\nВнутри кодирующего и декодирующего компонента нет рекуррентности. Кодирующий компонент состоит из кодировщиков, которые повторяются несколько раз, аналогично устроен декодирующий компонент. Трансформер — это поставленные друг за другом модели внимания, которые позволяют исходную последовательность векторов перевести в новую последовательность векторов, которые кодируют информацию о контексте каждого элемента. Трансформер-кодировщик переводит исходные векторы в скрытые, которые правильно сохраняют в себе информацию о контексте каждого элемента. Далее трансформер-декодировщик декодирует результат кодировщика в новую последовательность, которая состоит из эмбедингов элементов выходного языка. После по эмбедингам генерируются сами итоговые элементы с помощью вероятностной языковой модели.\\nНиже рассмотрим архитектуру кодировщика и декодировщика подробнее.\\nАрхитектура трансформера-кодировщика\\nРассмотрим последовательно шаг за шагом этапы работы кодировщика:\\n1. На вход поступает последовательность элементов, по ней создается последовательность эмбедингов, где каждый это векторное представление элемента .\\n2. Добавляются позиционные векторы: , . Это необходимо для того, чтобы отобразить информацию о позиции элемента в исходной последовательности. Основное свойство позиционного кодирования — чем дальше два вектора будут стоять друг от друга в последовательности, тем больше между ними будет расстояние. Более подробное устройство позиционного кодирования будет рассмотрено ниже.\\n3. Полученный векторподается на вход в блок многомерного самовнимания (англ. multi-headed self-attention). , где обучаемые матрицы: для запроса, для ключа, для значения. Подробное объяснения работы механизма self-attention будет разобрано ниже.\\n4. Затем необходима конкатенация, чтобы вернуться в исходную размерность:\\n5. Добавим сквозные связи (англ. skip connection) — по факту просто добавление из входного вектора к выходному (). После делаем нормализацию слоя (англ. layer normalization): . У нее два обучаемых параметра, для каждой размерности вектора вычисляется среднее и дисперсия.\\n6. Теперь добавим преобразование, которое будет обучаемым — полносвязную двухслойную нейронную сеть:\\n7. Повторим пункт 5 еще раз: добавим сквозную связь и нормализацию слоя:\\nПосле, в кодирующем компоненте пункты кодировщика 3--7 повторяются еще несколько раз, преобразовывая друг за другом из контекста контекст. Тем самым мы обогащаем модель и увеличиваем в ней количество параметров.\\nПозиционное кодирование\\nТак как в архитектуре трансформер обработка последовательности заменяется на обработку множества мы теряем информацию о порядке элементов последовательности. Чтобы отобразить информацию о позиции элемента в исходной последовательности мы используем позиционное кодирование.\\nПозиционное кодирование (англ. positional encoding) — позволяет модели получить информацию о порядке элементов в последовательности путем прибавления специальных меток к вектору входных элементов. Позиции элементовкодируются векторами , , так, что чем больше , тем больше , и не ограничено. Пример такого кодирования:\\nSelf-attention\\nSelf-Attention — разновидность механизма внимания, задачей которой является выявление закономерности между входными данными.\\nБудем для каждого элементаполучать обучаемым преобразованием три вектора:\\n- Запрос (query)\\n- Ключ (key)\\n- Значение (value)\\nВекторыи будем использовать, чтобы посчитать важность элемента для элемента . Чтобы понять, насколько для пересчета вектора элемента важен элемент мы берем (вектор ключа элемента ) и умножаем на (вектор запроса элемента ). Так мы скалярно перемножаем вектор запроса на все векторы ключей, тем самым понимаем, насколько каждый входной элемент нам нужен, чтобы пересчитать вектор элемента .\\nДалее считаем важность элементадля кодирования элемента : , где — размерность векторов и , а — число элементов во входной последовательности.\\nТаким образом, новое представление элементасчитаем как взвешенную сумму векторов значения: , где — входные векторы. По факту self-attention — это soft-arg-max с температурой . Мы перемешиваем все входные векторы, чтобы получить новые векторы всех элементов, где каждый элемент зависит от всех входных элементов.\\nMulti-headed self-attention\\nMulti-headed self-attention — улучшенная модификация self-attention.\\nСлой внимания снабжается множеством «подпространств представлений» (англ. representation subspaces). Теперь у нас есть не один, а множество наборов матриц запроса/ключа/значения. Каждый из этих наборов создается случайным образом. Далее после обучения каждый набор используется для отображения входящих векторов в разных подпространствах представлений. Также появляется способность модели фокусироваться на разных аспектах входной информации.\\nТо есть параллельно независимо несколько раз делаем attention. Потом результат каждого attention по элементам конкатенируем, затем сжимаем получившуюся матрицу и получаем для каждого элемента свой вектор той же размерности.\\n, где , — число разных моделей внимания, — входные векторы, а — обучаемые матрицы.\\nАрхитектура трансформера-декодировщика\\nНа вход декодировщику подается выход кодировщика. Главное отличие архитектуры декодировщика заключается в том, что дополнительно имеется attention к вектору, который получен из последнего блока кодирующего компонента. Компонент декодировщика тоже многослойный и каждому блоку компонента на вход подается вектор именно с последнего блока кодирующего компонента. Разберем по порядку этапы работы декодировщика:\\n1. Для того, чтобы распараллелить декодировщик и уйти от рекуррентности, но тем не менее генерировать элементы друг за другом, используется прием маскирования данных из будущего. Идея в том, что мы запрещаем себе подглядывать в те элементы, которые еще не сгенерированы с учетом порядка. Когда генерируем элемент под номером , имеем право смотреть только первые элементов: ;\\n2. Далее идет этап многомерного самовнимания: линейная нормализация и multi-headed self-attention. Особенность в том, что в attention ключи и значения применяются не ко всем векторам, а только к тем, значения которых уже синтезировали (): , где — композиция.\\n3. На следующем этапе мы делаем многомерное внимание на кодировку, результат работы компонента кодировщика:\\n4. Линейная полносвязная сеть (по аналогии с кодировщиком):\\n5. В самом конце мы хотим получить вероятностную порождающую модель для элементов. Результат (индекс слова с наибольшей вероятностью):, где , — обучаемые параметры линейного преобразования. Для каждой позиции выходной последовательности мы строим вероятностную модель языка, то есть все элементы из выходного словаря получают значение вероятности. Эти значения как раз получаются из векторов из предыдущего пункта, которые мы берем с последнего блока трансформера-декодировщика.\\nПоследний этап выполняется только после того, когда повторились пункты 1--4 для всех декодировщиков. На выходе получаем вероятности классов, по факту для каждой позиции решаем задачу многоклассовой классификации, для того, чтобы понять какие элементы лучше поставить на каждые позиции.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='f96f1e0f-411d-406f-9953-30579f4cc2d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5677d4089d5bd23ebfd335f27bd3b981ccd81fd9b96ae84a47e801421326c0f4', text='Категории\\nСледующие категории содержат страницы или медиафайлы. Здесь не показаны неиспользуемые категории. См. также список требуемых категорий.(первая | последняя) Просмотреть (предыдущие 50 | следующие 50) (20 | 50 | 100 | 250 | 500)\\n- Computer vision (0 объектов)\\n- NP (12 объектов)\\n- Автоматическое машинное обучение (5 объектов)\\n- Автоматы и регулярные языки (29 объектов)\\n- Активное обучение (1 объект)\\n- Алгебра (3 объекта)\\n- Алгебра и геометрия. 1 курс (0 объектов)\\n- Алгебра и геометрия 1 курс (22 объекта)\\n- Алгоритмы (12 объектов)\\n- Алгоритмы алгебры и теории чисел (5 объектов)\\n- Алгоритмы во внешней памяти (1 объект)\\n- Алгоритмы и структура данных (0 объектов)\\n- Алгоритмы и структуры данных (290 объектов)\\n- Алгоритмы на графах (11 объектов)\\n- Алгоритмы на марковских цепях (0 объектов)\\n- Алгоритмы на строках (3 объекта)\\n- Алгоритмы поиска (8 объектов)\\n- Алгоритмы разбора (4 объекта)\\n- Алгоритмы сжатия (21 объект)\\n- Алгоритмы сжатия без потерь (0 объектов)\\n- Алгоритмы сжатия с использованием словаря (0 объектов)\\n- Алгоритмы сортировки (0 объектов)\\n- Амортизационный анализ (18 объектов)\\n- Анализ временных рядов (1 объект)\\n- Анализ социальных сетей (1 объект)\\n- Аналитическая теория чисел (3 объекта)\\n- Ансамбли (4 объекта)\\n- Аффинное пространство (1 объект)\\n- Базовые определения (3 объекта)\\n- Базовые понятия о грамматиках (7 объектов)\\n- Базы данных (21 объект)\\n- Большие данные (1 объект)\\n- Булевы функции (17 объектов)\\n- В разработке (113 объектов)\\n- Введение в Java (1 объект)\\n- Вероятностные алгоритмы (1 объект)\\n- Вероятностные сложностные классы (2 объекта)\\n- Виды обучения (1 объект)\\n- Восходящий разбор (3 объекта)\\n- Всё (20 объектов)\\n- Вырезание объекта на изображении (1 объект)\\n- Вычислимость (0 объектов)\\n- Вычислительная геометрия (45 объектов)\\n- Вычислительные формализмы (11 объектов)\\n- Гамильтоновы графы (10 объектов)\\n- Генерация комбинаторных объектов (3 объекта)\\n- Генерация объектов (5 объектов)\\n- Генетические алгоритмы (0 объектов)\\n- Глубокое обучение (10 объектов)\\n- Графы (0 объектов)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='da6b8b14-a2fa-4c62-815b-7473c04defb7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0a83efd4caf2512e9b77ad9badf7ec639ed02b75310c2b0bc622b1eb7ae93ce2', text='Категория:Машинное обучение\\nПодкатегории\\nВ этой категории отображается 18 подкатегорий из имеющихся 18.\\nСтраницы в категории «Машинное обучение»\\nПоказано 114 страниц из 114, находящихся в данной категории.\\nC\\nX\\nА\\nВ\\nГ\\nД\\nИ\\nК\\nМ\\n- Машинное обучение\\n- Машинное обучение в астрономии\\n- Машинное обучение в медицине\\n- Машинное обучение на мобильных телефонах\\n- Мета-обучение\\n- Метод главных компонент (PCA)\\n- Метод опорных векторов (SVM)\\n- Методы policy gradient и алгоритм асинхронного актора-критика\\n- Метрический классификатор и метод ближайших соседей\\n- Механизм внимания\\n- Многопоточность в машинном обучении\\n- Модель алгоритма и её выбор\\nО\\n- Обзор библиотек для машинного обучения на Python\\n- Обработка естественного языка\\n- Обратное распространение ошибки\\n- Обучение в реальном времени\\n- Обучение на больших данных\\n- Обучение с подкреплением\\n- Обучение с частичным привлечением учителя\\n- Общие понятия\\n- Определение геометрии изображения\\n- Определение положения человека\\n- Отслеживание направления взгляда пользователя в браузере\\n- Оценка качества в задачах классификации и регрессии\\n- Оценка качества в задаче кластеризации\\nП\\n- Поиск архитектуры нейронной сети\\n- Поиск ближайших соседей с помощью иерархического маленького мира\\n- Порождающие модели\\n- Практики реализации нейронных сетей\\n- Представление знаний\\n- Примеры кода на Java\\n- Примеры кода на Kotlin\\n- Примеры кода на Kotlin в Jupyter Notebook\\n- Примеры кода на R\\n- Примеры кода на Scala\\n- Проблемы нейронных сетей', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='fd03bb22-b5d1-4b30-9d8f-91d07c8fa8b3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ea9c5909bcdcf2e3f95ca53a877b4ae79993c3323d3fa35e4a4a9ffdd6b4c467', text='Создать учётную запись\\nПерейти к:\\nнавигация\\n,\\nпоиск\\nИмя учётной записи\\nПароль\\nПодтвердите пароль\\nАдрес электронной почты (необязательно)\\nНастоящее имя (необязательно)\\nВводить настоящее имя необязательно. Если вы заполните его, оно может быть использовано для указания авторства ваших работ.\\nВ целях защиты от автоматического создания учётных записей просим вас ответить на вопрос, показанный ниже (\\nподробнее…\\n):\\nUnfortunately editing pages is not possible in current situation due to mass vandalism. I am sorry\\nСоздать учётную запись\\nВикиконспекты — совместный труд таких же людей, как вы.\\n84 949\\n84 949 правок\\n1482\\n1482 статей\\n22\\n22 участников за последнее время\\nИсточник — «\\nhttp://neerc.ifmo.ru/wiki/index.php?title=Служебная:Создать_учётную_запись\\n»\\nНавигация\\nПерсональные инструменты\\nСоздать учётную запись\\nВойти\\nПространства имён\\nСлужебная страница\\nВарианты\\nПросмотры\\nЕщё\\nПоиск\\nНавигация\\nЗаглавная страница\\nСвежие правки\\nСлучайная статья\\nСправка\\nИнструменты\\nСпецстраницы\\nВерсия для печати\\nПолитика конфиденциальности\\nО Викиконспекты\\nОтказ от ответственности\\nМобильная версия', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='88e7cba5-90fc-4e64-badf-dd6611f4302a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='29f1d8295f64858fe2ac9d762be065c20fbe086d1ff98adf7a777786bd3e9a33', text='Войти\\nПерейти к:\\nнавигация\\n,\\nпоиск\\nИмя учётной записи\\nПароль\\nОставаться в системе\\nВойти\\nПомощь по входу\\nСбросить ваш пароль?\\nНет учётной записи?\\nПрисоединиться к проекту\\nИсточник — «\\nhttp://neerc.ifmo.ru/wiki/index.php?title=Служебная:Вход\\n»\\nНавигация\\nПерсональные инструменты\\nСоздать учётную запись\\nВойти\\nПространства имён\\nСлужебная страница\\nВарианты\\nПросмотры\\nЕщё\\nПоиск\\nНавигация\\nЗаглавная страница\\nСвежие правки\\nСлучайная статья\\nСправка\\nИнструменты\\nСпецстраницы\\nВерсия для печати\\nПолитика конфиденциальности\\nО Викиконспекты\\nОтказ от ответственности\\nМобильная версия', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='cf42b143-1180-4670-a5b8-9c56167e2de5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e2b15ce62a97ab4051e9e789fd086fe186b1ea6aad705c3ba391c0a074060ac3', text='Машинное обучение\\nСодержание\\n- 1 Общие понятия\\n- 2 Классификация и регрессия\\n- 3 Кластеризация\\n- 4 Ансамбли\\n- 5 Нейронные сети\\n- 6 Работа с данными\\n- 7 Виды обучения\\n- 8 Реализация\\n- 9 Применение машинного обучения на практике\\n- 10 В разработке\\nОбщие понятия\\n- Общие понятия\\n- Переобучение\\n- Кросс-валидация\\n- Стохастический градиентный спуск\\n- Регуляризация\\n- Ранжирование\\n- Рекомендательные системы\\n- Интерпретируемые модели\\n- Жизненный цикл модели машинного обучения\\n- Анализ временных рядов\\nКлассификация и регрессия\\n- Метрический классификатор и метод ближайших соседей\\n- Дерево решений и случайный лес\\n- Вариации регрессии\\n- Линейная регрессия\\n- Логистическая регрессия\\n- Метод опорных векторов (SVM)\\n- Ядра\\n- Оценка качества в задачах классификации и регрессии\\n- Байесовская классификация\\n- Байесовские сети\\n- Поиск ближайших соседей с помощью иерархического маленького мира\\nКластеризация\\n- Кластеризация\\n- EM-алгоритм\\n- Иерархическая кластеризация\\n- Оценка качества в задаче кластеризации\\n- Эволюционные алгоритмы кластеризации\\nАнсамбли\\nНейронные сети\\n- Нейронные сети, перцептрон\\n- Обратное распространение ошибки\\n- Практики реализации нейронных сетей\\n- Графовые нейронные сети\\n- Рекурсивные нейронные сети\\nГлубокое обучение\\n- Глубокое обучение\\n- Настройка глубокой сети\\n- Batch-normalization\\n- Проблемы нейронных сетей\\n- Рекуррентные нейронные сети\\n- Сиамская нейронная сеть\\n- Автокодировщик\\n- Сети глубокого доверия\\nСверточные сети\\nКомпьютерное зрение\\n- Компьютерное зрение\\n- Сегментация изображений\\n- Задача нахождения объектов на изображении\\n- Оценка положения\\n- Определение положения человека\\n- Распознавание изогнутого текста\\n- Карта глубины\\n- Вписывание части изображения\\n- Блендинг изображений\\nПорождающие модели\\n- Порождающие модели\\n- Генерация объектов\\n- Порождающие состязательные сети, Generative Adversarial Networks (GAN)\\n- PixelRNN и PixelCNN\\n- Вариационный автокодировщик\\n- Задача трансляции изображений\\n- Генерация текста\\n- Генерация изображения по тексту\\nОбработка естественного языка\\n- Распознавание речи\\n- Обработка естественного языка\\n- Векторное представление слов\\n- Классификация текстов и анализ тональности\\n- Долгая краткосрочная память\\n- Механизм внимания\\n- BERT (языковая модель)\\n- Синтез речи\\n- Диалоговые системы\\nРабота с данными\\n- Уменьшение размерности\\n- Выброс\\n- Алгоритмы сэмплирования\\n- Известные наборы данных\\n- Метод главных компонент (PCA)\\n- Стохастическое вложение соседей с t-распределением\\n- Синтетические наборы данных\\nВиды обучения\\nАвтоматическое машинное обучение\\n- Автоматическое машинное обучение\\n- Настройка гиперпараметров\\n- Модель алгоритма и ее выбор\\n- Мета-обучение\\n- Поиск архитектуры нейронной сети\\nОбучение с подкреплением\\nРеализация\\n- Обзор библиотек для машинного обучения на Python\\n- Многопоточность в машинном обучении\\n- Примеры кода на Java\\n- Примеры кода на R\\n- Примеры кода на Scala\\n- Примеры кода на Kotlin\\n- Примеры кода на Kotlin в Jupyter Notebook\\n- Машинное обучение на мобильных телефонах\\nПрименение машинного обучения на практике\\n- Анализ социальных сетей\\n- Машинное обучение в медицине\\n- Генерация дипфейков с помощью нейронных сетей\\n- Представление знаний\\n- Задача планирования движения\\n- Машинное обучение в астрономии\\n- Компьютерное зрение в микроскопии\\n- Обучение на больших данных\\n- Дополнение к ранжированию', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='12dc08b6-bedf-4fcf-aaea-6a37f7da6b85', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e2b15ce62a97ab4051e9e789fd086fe186b1ea6aad705c3ba391c0a074060ac3', text='Машинное обучение\\nСодержание\\n- 1 Общие понятия\\n- 2 Классификация и регрессия\\n- 3 Кластеризация\\n- 4 Ансамбли\\n- 5 Нейронные сети\\n- 6 Работа с данными\\n- 7 Виды обучения\\n- 8 Реализация\\n- 9 Применение машинного обучения на практике\\n- 10 В разработке\\nОбщие понятия\\n- Общие понятия\\n- Переобучение\\n- Кросс-валидация\\n- Стохастический градиентный спуск\\n- Регуляризация\\n- Ранжирование\\n- Рекомендательные системы\\n- Интерпретируемые модели\\n- Жизненный цикл модели машинного обучения\\n- Анализ временных рядов\\nКлассификация и регрессия\\n- Метрический классификатор и метод ближайших соседей\\n- Дерево решений и случайный лес\\n- Вариации регрессии\\n- Линейная регрессия\\n- Логистическая регрессия\\n- Метод опорных векторов (SVM)\\n- Ядра\\n- Оценка качества в задачах классификации и регрессии\\n- Байесовская классификация\\n- Байесовские сети\\n- Поиск ближайших соседей с помощью иерархического маленького мира\\nКластеризация\\n- Кластеризация\\n- EM-алгоритм\\n- Иерархическая кластеризация\\n- Оценка качества в задаче кластеризации\\n- Эволюционные алгоритмы кластеризации\\nАнсамбли\\nНейронные сети\\n- Нейронные сети, перцептрон\\n- Обратное распространение ошибки\\n- Практики реализации нейронных сетей\\n- Графовые нейронные сети\\n- Рекурсивные нейронные сети\\nГлубокое обучение\\n- Глубокое обучение\\n- Настройка глубокой сети\\n- Batch-normalization\\n- Проблемы нейронных сетей\\n- Рекуррентные нейронные сети\\n- Сиамская нейронная сеть\\n- Автокодировщик\\n- Сети глубокого доверия\\nСверточные сети\\nКомпьютерное зрение\\n- Компьютерное зрение\\n- Сегментация изображений\\n- Задача нахождения объектов на изображении\\n- Оценка положения\\n- Определение положения человека\\n- Распознавание изогнутого текста\\n- Карта глубины\\n- Вписывание части изображения\\n- Блендинг изображений\\nПорождающие модели\\n- Порождающие модели\\n- Генерация объектов\\n- Порождающие состязательные сети, Generative Adversarial Networks (GAN)\\n- PixelRNN и PixelCNN\\n- Вариационный автокодировщик\\n- Задача трансляции изображений\\n- Генерация текста\\n- Генерация изображения по тексту\\nОбработка естественного языка\\n- Распознавание речи\\n- Обработка естественного языка\\n- Векторное представление слов\\n- Классификация текстов и анализ тональности\\n- Долгая краткосрочная память\\n- Механизм внимания\\n- BERT (языковая модель)\\n- Синтез речи\\n- Диалоговые системы\\nРабота с данными\\n- Уменьшение размерности\\n- Выброс\\n- Алгоритмы сэмплирования\\n- Известные наборы данных\\n- Метод главных компонент (PCA)\\n- Стохастическое вложение соседей с t-распределением\\n- Синтетические наборы данных\\nВиды обучения\\nАвтоматическое машинное обучение\\n- Автоматическое машинное обучение\\n- Настройка гиперпараметров\\n- Модель алгоритма и ее выбор\\n- Мета-обучение\\n- Поиск архитектуры нейронной сети\\nОбучение с подкреплением\\nРеализация\\n- Обзор библиотек для машинного обучения на Python\\n- Многопоточность в машинном обучении\\n- Примеры кода на Java\\n- Примеры кода на R\\n- Примеры кода на Scala\\n- Примеры кода на Kotlin\\n- Примеры кода на Kotlin в Jupyter Notebook\\n- Машинное обучение на мобильных телефонах\\nПрименение машинного обучения на практике\\n- Анализ социальных сетей\\n- Машинное обучение в медицине\\n- Генерация дипфейков с помощью нейронных сетей\\n- Представление знаний\\n- Задача планирования движения\\n- Машинное обучение в астрономии\\n- Компьютерное зрение в микроскопии\\n- Обучение на больших данных\\n- Дополнение к ранжированию', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='b614d907-a318-4a7d-8b4b-2c87bc25df6b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5ab7b23e898ff3d8d705fbe38875b04be4c79808cb9d023045e669831eb7ce7d', text='Просмотр исходного текста страницы Машинное обучение\\nУ вас нет прав на редактирование этой страницы по следующей причине:\\nЗапрошенное действие могут выполнять только участники из группы «Администраторы»\\nВы можете просмотреть и скопировать исходный текст этой страницы.\\nВозврат к странице Машинное обучение.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='985e9af2-882b-443e-a785-29c46d93bbb5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='01f1102cde74d3cf4a933060f874dee5d32144bb5e0a3b4081a5026c71246771', text='Машинное обучение — история изменений\\nВыбор версий: отметьте версии страницы, которые вы хотите сравнить, и нажмите Сравнить.\\nПояснения: (текущ.) — отличия от текущей версии; (пред.) — отличия от предшествующей версии; м — незначительные изменения.\\nВыбор версий: отметьте версии страницы, которые вы хотите сравнить, и нажмите Сравнить.\\nПояснения: (текущ.) — отличия от текущей версии; (пред.) — отличия от предшествующей версии; м — незначительные изменения.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='b2ad2872-4e05-4316-9de7-5ab673717801', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='59958171741349ece92116333fc874f5f24458bfd102938536e6768ab351cd21', text='Заглавная страница\\nДобро пожаловать на сайт вики-конспектов!\\nСодержание\\n- 1 Проверяемые конспекты\\n- 1.1 Дискретная математика\\n- 1.2 Теория вероятностей\\n- 1.3 Теория формальных языков\\n- 1.4 Теория матроидов\\n- 1.5 Теория расписаний\\n- 1.6 Теория вычислимости\\n- 1.7 Теория сложности\\n- 1.8 Алгоритмы и структуры данных\\n- 1.9 Теория графов\\n- 1.10 Алгоритмы на строках\\n- 1.11 Методы трансляции\\n- 1.12 Вычислительная геометрия\\n- 1.13 Язык программирования Java\\n- 1.14 Параллельное программирование\\n- 1.15 Машинное обучение\\n- 2 Непроверяемые конспекты\\nПроверяемые конспекты\\nДискретная математика\\n- Отношения\\n- Булевы функции\\n- Схемы из функциональных элементов\\n- Представление информации\\n- Алгоритмы сжатия данных\\n- Комбинаторика\\n- Производящая функция\\nТеория вероятностей\\nТеория формальных языков\\nТеория матроидов\\nТеория расписаний\\n- Задачи с одним станком\\n- Специальные случаи задач для двух станков\\n- Задачи для произвольного числа станков\\nТеория вычислимости\\nТеория сложности\\n- Детерминированные и недетерминированные вычисления, сложность по времени и по памяти\\n- Схемная сложность\\n- Вероятностные сложностные классы\\nАлгоритмы и структуры данных\\n- Амортизационный анализ\\n- Персистентные структуры данных\\n- Приоритетные очереди\\n- Система непересекающихся множеств\\n- Поисковые структуры данных\\n- Запросы на отрезках\\n- Дерево Фенвика\\n- Задача о наименьшем общем предке\\n- Хеширование\\n- Сортировки\\n- Сортирующие сети\\n- Алгоритмы поиска\\n- Динамическое программирование\\n- Алгоритмы во внешней памяти\\nТеория графов\\n- Основные определения теории графов\\n- Связность в графах\\n- Остовные деревья\\n- Обходы графов\\n- Укладки графов\\n- Раскраски графов\\n- Обход в глубину\\n- Кратчайшие пути в графах\\n- Задача о паросочетании\\n- Задача о максимальном потоке\\n- Задача о потоке минимальной стоимости\\n- Cлучайные графы\\nАлгоритмы на строках\\nМетоды трансляции\\nВычислительная геометрия\\n- Основание вычислительной геометрии\\n- Вычисление геометрических предикатов\\n- Пересечение отрезков\\n- Выпуклые оболочки\\n- Поиск\\n- Триангуляция\\n- ППЛГ и РСДС\\n- Алгоритмы локализации\\n- Триангуляция Делоне и диаграмма Вороного\\n- Планирование движения (Motion planning)\\nЯзык программирования Java\\n- Основная информация о языкe\\n- Программирование по контракту\\n- Обработка ошибок и исключения\\n- Generics\\n- Перечисления\\nПараллельное программирование\\nМашинное обучение\\nНепроверяемые конспекты\\n- Алгебра и геометрия — 1, 2 семестр\\n- Математический анализ — 1, 2 семестр\\n- Математический анализ — 3, 4 семестр\\n- Математическая логика — 3 семестр\\n- С++ — 2, 3 семестр\\n- Дифференциальные уравнения — 3 семестр\\n- Assembler — 4 семестр\\n- Алгоритмы алгебры и теории чисел — 4 семестр\\n- Функциональный анализ — 5, 6 семестр\\n- Параллельное программирование — 6 семестр\\n- Базы данных — 7 семестр\\n- Компьютерные сети — 7, 8 семестр\\n- Эволюционные алгоритмы — 10 семестр', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='e2b78f66-6cf9-4239-85a6-dd142c203d10', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='59958171741349ece92116333fc874f5f24458bfd102938536e6768ab351cd21', text='Заглавная страница\\nДобро пожаловать на сайт вики-конспектов!\\nСодержание\\n- 1 Проверяемые конспекты\\n- 1.1 Дискретная математика\\n- 1.2 Теория вероятностей\\n- 1.3 Теория формальных языков\\n- 1.4 Теория матроидов\\n- 1.5 Теория расписаний\\n- 1.6 Теория вычислимости\\n- 1.7 Теория сложности\\n- 1.8 Алгоритмы и структуры данных\\n- 1.9 Теория графов\\n- 1.10 Алгоритмы на строках\\n- 1.11 Методы трансляции\\n- 1.12 Вычислительная геометрия\\n- 1.13 Язык программирования Java\\n- 1.14 Параллельное программирование\\n- 1.15 Машинное обучение\\n- 2 Непроверяемые конспекты\\nПроверяемые конспекты\\nДискретная математика\\n- Отношения\\n- Булевы функции\\n- Схемы из функциональных элементов\\n- Представление информации\\n- Алгоритмы сжатия данных\\n- Комбинаторика\\n- Производящая функция\\nТеория вероятностей\\nТеория формальных языков\\nТеория матроидов\\nТеория расписаний\\n- Задачи с одним станком\\n- Специальные случаи задач для двух станков\\n- Задачи для произвольного числа станков\\nТеория вычислимости\\nТеория сложности\\n- Детерминированные и недетерминированные вычисления, сложность по времени и по памяти\\n- Схемная сложность\\n- Вероятностные сложностные классы\\nАлгоритмы и структуры данных\\n- Амортизационный анализ\\n- Персистентные структуры данных\\n- Приоритетные очереди\\n- Система непересекающихся множеств\\n- Поисковые структуры данных\\n- Запросы на отрезках\\n- Дерево Фенвика\\n- Задача о наименьшем общем предке\\n- Хеширование\\n- Сортировки\\n- Сортирующие сети\\n- Алгоритмы поиска\\n- Динамическое программирование\\n- Алгоритмы во внешней памяти\\nТеория графов\\n- Основные определения теории графов\\n- Связность в графах\\n- Остовные деревья\\n- Обходы графов\\n- Укладки графов\\n- Раскраски графов\\n- Обход в глубину\\n- Кратчайшие пути в графах\\n- Задача о паросочетании\\n- Задача о максимальном потоке\\n- Задача о потоке минимальной стоимости\\n- Cлучайные графы\\nАлгоритмы на строках\\nМетоды трансляции\\nВычислительная геометрия\\n- Основание вычислительной геометрии\\n- Вычисление геометрических предикатов\\n- Пересечение отрезков\\n- Выпуклые оболочки\\n- Поиск\\n- Триангуляция\\n- ППЛГ и РСДС\\n- Алгоритмы локализации\\n- Триангуляция Делоне и диаграмма Вороного\\n- Планирование движения (Motion planning)\\nЯзык программирования Java\\n- Основная информация о языкe\\n- Программирование по контракту\\n- Обработка ошибок и исключения\\n- Generics\\n- Перечисления\\nПараллельное программирование\\nМашинное обучение\\nНепроверяемые конспекты\\n- Алгебра и геометрия — 1, 2 семестр\\n- Математический анализ — 1, 2 семестр\\n- Математический анализ — 3, 4 семестр\\n- Математическая логика — 3 семестр\\n- С++ — 2, 3 семестр\\n- Дифференциальные уравнения — 3 семестр\\n- Assembler — 4 семестр\\n- Алгоритмы алгебры и теории чисел — 4 семестр\\n- Функциональный анализ — 5, 6 семестр\\n- Параллельное программирование — 6 семестр\\n- Базы данных — 7 семестр\\n- Компьютерные сети — 7, 8 семестр\\n- Эволюционные алгоритмы — 10 семестр', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='f146e8ad-3e5c-4ba2-97dc-121641db5b0b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a52344b07f2310a8016d9bac8e4ce59fbca8a2defd99d04aff4b152d36e6f362', text='Свежие правки\\nНиже в хронологическом порядке перечислены последние изменения на страницах Викиконспекты.\\n2 марта 2024\\n|13:44\\n|Список заданий по теории сложности 2024 (разн. | история) . . (+3296) . . Admin (обсуждение | вклад)\\n1 марта 2024\\n|09:58\\n|Список заданий по ДМ 2к 2024 весна (разн. | история) . . (+6282) . . Admin (обсуждение | вклад)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='6721b718-55f6-4725-968a-b9d29429d040', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='57c86050bdca04f28f9689517d45f93b9d1fa35d7c816df22af80382d28572a5', text='Пересечение отрезков на сфере\\nПостановка задачи\\nДано два отрезка на сфере. Необходимо узнать пересекаются ли они.\\nАлгоритм\\n1) Проверим отрезки на то что они лежат в одной плоскости, если лежат перейдем к плоскости и разберем случаи, иначе перейдем к шагу 2.\\n2) Построим из концов отрезков тетраэдр.\\n3) Проверим центр сферы на принадлежность тетраэдру. Если принадлежит то отрезки не пересекаются, иначе перейдем к шагу 4.\\n4) Проверим с помощью поворота отрезки на пересечение.\\nПроверка на пересечение двух отрезков на сфере\\nСопоставим каждой точке на сфере луч, исходящий из центра сферы(точка) и проходящий через эту точку. Тогда лучи сопоставляемые двум точкам будут образовывать плоскость. Необходимо проверять лежит ли точка в плоскости образованной лучами точек и . Вспомним о повороте. Необходимо посчитать определитель матрицы поворота и сравнить его знак с нулем.\\nРассмотрим три случая:\\n- тогда точка лежит над плоскостью, образованной точками , и .\\n- тогда точка лежит под плоскостью, образованной точками , и .\\n- тогда точка лежит на плоскости, образованной точками , и .\\n|Лемма (1):\\nЕсли два отрезка на сфере пересекаются, то все их четыре точки находятся в одной полусфере.\\n|Доказательство:\\n|\\nПусть есть отрезки:Далее повторим рассуждения для точек и . Точка пересечения . Центр сферы - начало координат . Найдем нужную полусферу. Это будет полусфера от плоскости, образованной точками , и , ориентированная так, чтобы содержать .Проведем плоскость , пересечем ее со сферой. На полученной окружности возьмем точку - диаметрально противоположную точке . Точка находится в нашей полусфере, потому что она находится \"ближе\" точки . Если бы она была дальше точки , то мы бы провели отрезок через другую половину сферы, и соответственно, точка была бы не в выбранной полусфере. и .\\nПроверим лежат ли точки в одной плоскости, если лежат проведем эту плоскость, пересечение сферы и этой плоскости это окружность, на которой лежат 4 точки(начала и концы отрезков). Далее необходимо выбрать из 2ух отрезков любой, посчитать поворот его концов относительно центра окружности, а дальше сравнить поворот оставшихся точек, если хотя бы одна точка из второго отрезка попадает в диапазон значений между концами выбранного нами отрезка, то прямые пересекаются, иначе необходимо взять другой отрезок и проверить это же утверждение для него(так как 1ый взятый нами отрезок мог содержаться во втором), в случае если оба случая не дали положительного результата - отрезки не пересекаются.\\nИначе, если точки не лежат в одной плоскости, рассмотрим следующий алгоритм.\\nСоединим концы отрезков, результатом будет тетрэдр.\\n|Утверждение:\\nЕсли центр шара принадлежит тетраэдру, образованному концами отрезков, то отрезки лежат в разных полушариях.\\nДля того чтобы определить принадлежит ли центр шара тетраэдру, необходимо найти грань тетраэдра, которая будет отсекать тетрэдр от центра шара, если такой грани не существует, то центра шара принадлежит тетраэдру, следовательно отрезки находятся в разных полушариях, следовательно они не пересекаются. Для того, чтобы найти такую грань, необходимо для каждой грани тетраэдра проверить поворот противоположной точки и центра окружности, и если знаки определителей матриц поворота оказались разные, то такая грань найдена.\\nДля того, чтобы проверить существование грани, отсекающей тетраэдрот центра сферы, необходимо посчитать определитель матрицы поворота для четырех точек.\\nГде, , - точки задающие плоскость, точка для которой надо вычислить поворот.\\nРассмотрим отрезки и . Проверим их на пересечение. Для этого возьмем отрезок и посчитаем для него следующее соотношение\\nгде вместонеобходимо поочередно подставить и . И если хотя бы для одной точки , то отрезки пересекаются и точка пересечения лежит на .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='01c78067-19db-4423-8386-f8857ad7c63a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f1dcb6f491b4952de57d74bf722e2110bf71272c183dcdba22ce35485b9c0eb5', text='Страницы, ссылающиеся на «Машинное обучение»\\nСледующие страницы ссылаются на «Машинное обучение»:Просмотреть (предыдущие 50 | следующие 50) (20 | 50 | 100 | 250 | 500)\\n- Заглавная страница (← ссылки)\\n- Обработка естественного языка (← ссылки)\\n- Дополнение к ранжированию (← ссылки)\\n- Анализ социальных сетей (← ссылки)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='05825400-b228-4036-8f0b-5ba28079a4eb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c2909e6588349fbb9e2c99fea0ba8de9183c889d6c0774aed292e81e1b756ed6', text='Спецстраницы\\nОтчёты технического обслуживания\\n- Двойные перенаправления\\n- Длинные страницы\\n- Защищённые названия\\n- Защищённые страницы\\n- Короткие страницы\\n- Неиспользуемые категории\\n- Неиспользуемые файлы\\n- Неиспользуемые шаблоны\\n- Некатегоризованные категории\\n- Некатегоризованные страницы\\n- Некатегоризованные файлы\\n- Некатегоризованные шаблоны\\n- Разорванные перенаправления\\n- Статьи по дате последнего редактирования\\n- Страницы без интервики-ссылок\\n- Страницы с наименьшим количеством версий\\n- Страницы-сироты\\n- Требуемые категории\\n- Требуемые страницы\\n- Требуемые файлы\\n- Требуемые шаблоны\\n- Тупиковые страницы', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='7d1d9a81-8617-4f3c-91b1-7bd728c8e448', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e2b15ce62a97ab4051e9e789fd086fe186b1ea6aad705c3ba391c0a074060ac3', text='Машинное обучение\\nСодержание\\n- 1 Общие понятия\\n- 2 Классификация и регрессия\\n- 3 Кластеризация\\n- 4 Ансамбли\\n- 5 Нейронные сети\\n- 6 Работа с данными\\n- 7 Виды обучения\\n- 8 Реализация\\n- 9 Применение машинного обучения на практике\\n- 10 В разработке\\nОбщие понятия\\n- Общие понятия\\n- Переобучение\\n- Кросс-валидация\\n- Стохастический градиентный спуск\\n- Регуляризация\\n- Ранжирование\\n- Рекомендательные системы\\n- Интерпретируемые модели\\n- Жизненный цикл модели машинного обучения\\n- Анализ временных рядов\\nКлассификация и регрессия\\n- Метрический классификатор и метод ближайших соседей\\n- Дерево решений и случайный лес\\n- Вариации регрессии\\n- Линейная регрессия\\n- Логистическая регрессия\\n- Метод опорных векторов (SVM)\\n- Ядра\\n- Оценка качества в задачах классификации и регрессии\\n- Байесовская классификация\\n- Байесовские сети\\n- Поиск ближайших соседей с помощью иерархического маленького мира\\nКластеризация\\n- Кластеризация\\n- EM-алгоритм\\n- Иерархическая кластеризация\\n- Оценка качества в задаче кластеризации\\n- Эволюционные алгоритмы кластеризации\\nАнсамбли\\nНейронные сети\\n- Нейронные сети, перцептрон\\n- Обратное распространение ошибки\\n- Практики реализации нейронных сетей\\n- Графовые нейронные сети\\n- Рекурсивные нейронные сети\\nГлубокое обучение\\n- Глубокое обучение\\n- Настройка глубокой сети\\n- Batch-normalization\\n- Проблемы нейронных сетей\\n- Рекуррентные нейронные сети\\n- Сиамская нейронная сеть\\n- Автокодировщик\\n- Сети глубокого доверия\\nСверточные сети\\nКомпьютерное зрение\\n- Компьютерное зрение\\n- Сегментация изображений\\n- Задача нахождения объектов на изображении\\n- Оценка положения\\n- Определение положения человека\\n- Распознавание изогнутого текста\\n- Карта глубины\\n- Вписывание части изображения\\n- Блендинг изображений\\nПорождающие модели\\n- Порождающие модели\\n- Генерация объектов\\n- Порождающие состязательные сети, Generative Adversarial Networks (GAN)\\n- PixelRNN и PixelCNN\\n- Вариационный автокодировщик\\n- Задача трансляции изображений\\n- Генерация текста\\n- Генерация изображения по тексту\\nОбработка естественного языка\\n- Распознавание речи\\n- Обработка естественного языка\\n- Векторное представление слов\\n- Классификация текстов и анализ тональности\\n- Долгая краткосрочная память\\n- Механизм внимания\\n- BERT (языковая модель)\\n- Синтез речи\\n- Диалоговые системы\\nРабота с данными\\n- Уменьшение размерности\\n- Выброс\\n- Алгоритмы сэмплирования\\n- Известные наборы данных\\n- Метод главных компонент (PCA)\\n- Стохастическое вложение соседей с t-распределением\\n- Синтетические наборы данных\\nВиды обучения\\nАвтоматическое машинное обучение\\n- Автоматическое машинное обучение\\n- Настройка гиперпараметров\\n- Модель алгоритма и ее выбор\\n- Мета-обучение\\n- Поиск архитектуры нейронной сети\\nОбучение с подкреплением\\nРеализация\\n- Обзор библиотек для машинного обучения на Python\\n- Многопоточность в машинном обучении\\n- Примеры кода на Java\\n- Примеры кода на R\\n- Примеры кода на Scala\\n- Примеры кода на Kotlin\\n- Примеры кода на Kotlin в Jupyter Notebook\\n- Машинное обучение на мобильных телефонах\\nПрименение машинного обучения на практике\\n- Анализ социальных сетей\\n- Машинное обучение в медицине\\n- Генерация дипфейков с помощью нейронных сетей\\n- Представление знаний\\n- Задача планирования движения\\n- Машинное обучение в астрономии\\n- Компьютерное зрение в микроскопии\\n- Обучение на больших данных\\n- Дополнение к ранжированию', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='1236be1d-4765-4909-ba6f-6fa9f462e2de', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3804bfc84b59d6f5c0a22549ac41e455050e37b942cf017a0b0bf65e967ac8b0', text='Машинное обучение\\nВерсия от 19:36, 4 сентября 2022; Maintenance script (обсуждение | вклад) (rollbackEdits.php mass rollback)\\nСодержание\\n- 1 Общие понятия\\n- 2 Классификация и регрессия\\n- 3 Кластеризация\\n- 4 Ансамбли\\n- 5 Нейронные сети\\n- 6 Работа с данными\\n- 7 Виды обучения\\n- 8 Реализация\\n- 9 Применение машинного обучения на практике\\n- 10 В разработке\\nОбщие понятия\\n- Общие понятия\\n- Переобучение\\n- Кросс-валидация\\n- Стохастический градиентный спуск\\n- Регуляризация\\n- Ранжирование\\n- Рекомендательные системы\\n- Интерпретируемые модели\\n- Жизненный цикл модели машинного обучения\\n- Анализ временных рядов\\nКлассификация и регрессия\\n- Метрический классификатор и метод ближайших соседей\\n- Дерево решений и случайный лес\\n- Вариации регрессии\\n- Линейная регрессия\\n- Логистическая регрессия\\n- Метод опорных векторов (SVM)\\n- Ядра\\n- Оценка качества в задачах классификации и регрессии\\n- Байесовская классификация\\n- Байесовские сети\\n- Поиск ближайших соседей с помощью иерархического маленького мира\\nКластеризация\\n- Кластеризация\\n- EM-алгоритм\\n- Иерархическая кластеризация\\n- Оценка качества в задаче кластеризации\\n- Эволюционные алгоритмы кластеризации\\nАнсамбли\\nНейронные сети\\n- Нейронные сети, перцептрон\\n- Обратное распространение ошибки\\n- Практики реализации нейронных сетей\\n- Графовые нейронные сети\\n- Рекурсивные нейронные сети\\nГлубокое обучение\\n- Глубокое обучение\\n- Настройка глубокой сети\\n- Batch-normalization\\n- Проблемы нейронных сетей\\n- Рекуррентные нейронные сети\\n- Сиамская нейронная сеть\\n- Автокодировщик\\n- Сети глубокого доверия\\nСверточные сети\\nКомпьютерное зрение\\n- Компьютерное зрение\\n- Сегментация изображений\\n- Задача нахождения объектов на изображении\\n- Оценка положения\\n- Определение положения человека\\n- Распознавание изогнутого текста\\n- Карта глубины\\n- Вписывание части изображения\\n- Блендинг изображений\\nПорождающие модели\\n- Порождающие модели\\n- Генерация объектов\\n- Порождающие состязательные сети, Generative Adversarial Networks (GAN)\\n- PixelRNN и PixelCNN\\n- Вариационный автокодировщик\\n- Задача трансляции изображений\\n- Генерация текста\\n- Генерация изображения по тексту\\nОбработка естественного языка\\n- Распознавание речи\\n- Обработка естественного языка\\n- Векторное представление слов\\n- Классификация текстов и анализ тональности\\n- Долгая краткосрочная память\\n- Механизм внимания\\n- BERT (языковая модель)\\n- Синтез речи\\n- Диалоговые системы\\nРабота с данными\\n- Уменьшение размерности\\n- Выброс\\n- Алгоритмы сэмплирования\\n- Известные наборы данных\\n- Метод главных компонент (PCA)\\n- Стохастическое вложение соседей с t-распределением\\n- Синтетические наборы данных\\nВиды обучения\\nАвтоматическое машинное обучение\\n- Автоматическое машинное обучение\\n- Настройка гиперпараметров\\n- Модель алгоритма и ее выбор\\n- Мета-обучение\\n- Поиск архитектуры нейронной сети\\nОбучение с подкреплением\\nРеализация\\n- Обзор библиотек для машинного обучения на Python\\n- Многопоточность в машинном обучении\\n- Примеры кода на Java\\n- Примеры кода на R\\n- Примеры кода на Scala\\n- Примеры кода на Kotlin\\n- Примеры кода на Kotlin в Jupyter Notebook\\n- Машинное обучение на мобильных телефонах\\nПрименение машинного обучения на практике\\n- Анализ социальных сетей\\n- Машинное обучение в медицине\\n- Генерация дипфейков с помощью нейронных сетей\\n- Представление знаний\\n- Задача планирования движения\\n- Машинное обучение в астрономии\\n- Компьютерное зрение в микроскопии\\n- Обучение на больших данных\\n- Дополнение к ранжированию', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='53ac5f1f-928d-428f-8909-e82dd842df4a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6bf3d7633406490b642794cabc13c9f6d10d3a1c1a2c600f5d744f4d1f3ebaf1', text='|Отображаемый заголовок\\n|Машинное обучение\\n|Ключ сортировки по умолчанию\\n|Машинное обучение\\n|Длина страницы (в байтах)\\n|7554\\n|Идентификатор страницы\\n|5217\\n|Язык страницы\\n|ru - русский\\n|Модель содержимого страницы\\n|вики-текст\\n|Индексация поисковыми роботами\\n|Разрешено\\n|Количество перенаправлений на эту страницу\\n|0\\n|Учитывается счётчиком как содержательная страница\\n|Да\\n|Создатель страницы\\n|91.64.57.97 (обсуждение)\\n|Дата создания страницы\\n|13:18, 7 октября 2018\\n|Последний редактор\\n|Maintenance script (обсуждение | вклад)\\n|Дата последней правки\\n|19:36, 4 сентября 2022\\n|Общее число правок\\n|122\\n|Общее число различных авторов\\n|42\\n|Правок за последнее время (в течение 90 дней)\\n|0\\n|Уникальных авторов за последнее время\\n|0', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='913d459c-6fb8-48ef-a1f2-e13af96ae9fc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='333087863a2ab6eec580f5448ec3e159efd346f955db585f074885e3b430db9a', text='Викиконспекты:Описание\\nНа сайте представлены конспекты, которые написаны самостоятельно студентами кафедры компьютерных технологий Университета ИТМО.\\nНекоторые конспекты проверяются преподавателями и кураторами вики-конспектов, они размещены в разделе «Проверяемые конспекты». Это не значит, что в них нет ошибок, но, в целом, сделана попытка поддерживать их в адекватном состоянии.\\nКонспекты, которые студенты пишут самостоятельно, размещены в разделе «Непроверяемые конспекты».\\nМы стараемся следить, чтобы содержимое конспектов было адекватным, конспекты не содержали плагиата и содержали ссылки на источники. Но не всегда этого удается добиться. Если вы обнаружили ошибку, исправьте её в соответствии с принципами wiki. Если вы обнаружили плагиат, вы можете обратиться к Андрею Сергеевичу Станкевичу.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='6d8dae1c-d255-45af-a230-a46b84b839ba', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='87635d9438bc768badde139dd30e66679cd212c5f6b010caf3248e33c9cd6f72', text='Викиконспекты:Отказ от ответственности\\nМатериал из Викиконспекты\\nПерейти к:\\nнавигация\\n,\\nпоиск\\nВикиконспекты не гарантируют истинность\\nИсточник — «\\nhttp://neerc.ifmo.ru/wiki/index.php?title=Викиконспекты:Отказ_от_ответственности&oldid=65990\\n»\\nНавигация\\nПерсональные инструменты\\nСоздать учётную запись\\nВойти\\nПространства имён\\nО проекте\\nОбсуждение\\nВарианты\\nПросмотры\\nЧитать\\nПросмотр вики-текста\\nИстория\\nЕщё\\nПоиск\\nНавигация\\nЗаглавная страница\\nСвежие правки\\nСлучайная статья\\nСправка\\nИнструменты\\nСсылки сюда\\nСвязанные правки\\nСпецстраницы\\nВерсия для печати\\nПостоянная ссылка\\nСведения о странице\\nЭта страница последний раз была отредактирована 14 июня 2018 в 05:21.\\nПолитика конфиденциальности\\nО Викиконспекты\\nОтказ от ответственности\\nМобильная версия', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_documents = []\n",
    "for i in os.listdir(websites_dir):\n",
    "    with open(os.path.join(websites_dir, i), \"r\") as t:\n",
    "        web_documents += TrafilaturaWebReader().load_data(t.read().split(\"\\n\"))\n",
    "web_documents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T06:29:23.114599Z",
     "start_time": "2024-03-04T06:28:11.575106Z"
    }
   },
   "id": "cdda7b5423da10f5",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Document(id_='83bbd08f-38b8-467b-8119-17f621034611', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7f0c7c46425cbf78a1472a7d2761aac358ec7c7d6b0823d38a84c140653ebc21', text='Регуляризация\\n|Определение:\\n|Регуляризация (англ. regularization) в статистике, машинном обучении, теории обратных задач — метод добавления некоторых дополнительных ограничений к условию с целью решить некорректно поставленную задачу или предотвратить переобучение. Чаще всего эта информация имеет вид штрафа за сложность модели.\\nСодержание\\n- 1 Мотивация\\n- 2 Основные виды регуляризации\\n- 3 Вероятностная интерпретация регуляризации\\n- 4 Регуляризация в линейной регрессии\\n- 5 Регуляризация в алгоритмах\\n- 6 Другие использования регуляризации\\n- 7 См. также\\n- 8 Примечания\\n- 9 Источники информации\\nМотивация\\nКак говорилось ранее, регуляризация полезна для борьбы с переобучением. Если вы выбрали сложную модель, и при этом у вас недостаточно данных, то легко можно получить итоговую модель, которая хорошо описывает обучающую выборку, но не обобщается на тестовую.\\nНа примере линейной регрессии\\nВ качестве наглядного примера рассмотрим линейные регрессионные модели. Восстановить зависимость для нескольких точек можно пытаться полиномами разной степени $M$.\\nНа Рис. 1 представлена зависимость, которая хорошо подходит для описания данных, а на Рис. 2 — модель, слишком сильно заточенная под обучающую выборку.\\nОднин из способов бороться с негативным эффектом излишнего подстраивания под данные — использование регуляризации, т. е. добавление некоторого штрафа за большие значения коэффициентов у линейной модели. Тем самым запрещаются слишком \"резкие\" изгибы, и предотвращается переобучение.\\nНа примере логистической регрессии\\nНеобходимость регуляризации можно увидеть и на другом примере — при использовании логистической регресии. Представьте, что ваша обучающая выборка была линейно разделима. В таком случае в процессе оптимизации значения весов модели уйдут в бесконечность, и вместо сигмойды получится \"ступенька\", представленная на Рис. 3.\\nЭто плохо, ибо произошло затачивание под обучающую выборку. Как и в предыдущем примере, побороться с этим можно путем добавления регуляризатора, не дающего весам принимать слишком большие значения.\\nОсновные виды регуляризации\\nПереобучение в большинстве случаев проявляется в том, что итоговые модели имеют слишком большие значения параметров. Соответственно, необходимо добавить в целевую функцию штраф за это. Наиболее часто используемые виды регуляризации —и , а также их линейная комбинация — эластичная сеть.\\nВ представленных ниже формулах для эмпирического риска модели алгоритма, а — неотрицательный гиперпараметр, являющийся коэффициентом регуляризации.: является функцией потерь, а — вектором параметров из\\n-регуляризация\\n|Определение:\\n|-регуляризация, или регуляризация Тихонова (англ. ridge regularization или Tikhonov regularization):\\nМинимизация регуляризованного cоответствующим образом эмпирического риска приводит к выбору такого вектора параметров, которое не слишком сильно отклоняется от нуля. В линейных классификаторах это позволяет избежать проблем мультиколлинеарности и переобучения.\\n-регуляризация\\n|Определение:\\n| манхэттенское расстояние:\\n-регуляризация (англ. lasso regularization), или регуляризация через\\nДанный вид регуляризации также позволяет ограничить значения вектора. Однако, к тому же он обладает интересным и полезным на практике свойством — обнуляет значения некоторых параметров, что в случае с линейными моделями приводит к отбору признаков.\\nЗапишем задачу настройки вектора параметров:\\n- ,\\nгде— некоторая ограниченная гладкая функция потерь. Сделаем замену переменных, чтобы функционал стал гладким. Каждой переменной поставим в соответствие две новые неотрицательные переменные:\\nТогда:\\nВ новых переменных функционал становится гладким, но добавляются ограничения-неравенства:\\nДля любогохотя бы одно из ограничений и обращается в равенство, иначе второе слагаемое в можно было бы уменьшить, не изменив первое. Если гиперпараметр устремить к , в какой-то момент все ограничений обратятся в равенство. Постепенное увеличение гиперпараметра приводит к увеличению числа таких , для которых , откуда следует, что . Как говорилось ранее, в линейных моделях это означает, что значения -го признака игнорируются, и его можно исключить из модели.\\nЭластичная сеть\\n|Определение:\\n|Эластичная сеть (англ. elastic net regularization):\\nПриведенная регуляризация использует как, так и регуляризации, учитывая эффективность обоих методов. Ее полезной особенностью является то, что она создает условия для группового эффекта при высокой корреляции переменных, а не обнуляет некоторые из них, как в случае с -регуляризацией.\\nВероятностная интерпретация регуляризации\\nЭквивалентная вероятностная задача\\nПеред нами стоит задача — минимизировать эмпирический риск:\\nВероятностная модель данных дает возможность по-другому взглянуть на задачу. Пусть — является вероятностным пространством. Тогда вместо задана совместная плотность распределение объектов и классов .\\nДля настройки вектора параметров $\\\\beta$ воспользуемся принципом максимума правдоподобия:\\nУдобнее рассматривать логарифм правдоподобия:\\nМожно заключить, что задачи в исходном и вероятностном представлении эквивалентны, если положить:\\nПринцип максимума совместного правдоподобия данных и модели\\nДопустим, что наряду с параметрической моделью плотности распределенияимеется еще и априорное распределение в пространстве параметров модели . Чтобы ослабить априорные ограничения, вместо фиксированной функции вводится параметрическое семейство априорных распределений , где — гиперпараметр.\\nПринцип максимума правдоподобия теперь будет записываться по-другому, так как не только появление выборки, но и появление модели также является случайным. Их совместное появление описывается, согласно формуле условной вероятности, плотностью распределения:\\nТаким образом, приходим к принципу максимума совместного правдоподобия данных и модели:\\nФункционалраспадается на два слагаемых: логарифм правдоподобия и регуляризатор, не зависящий от данных. Второе слагаемое ограничивает вектор параметров модели, не позволяя ему быть каким угодно.\\nВ итоге мы получили, что с байесовской точки зрения многие методы регуляризации соответствуют добавлению некоторых априорных распределений на параметры модели. При этом можно определить распределения, которые соответствуют представленным ранееи регуляризаторам.\\nНормальный регуляризатор\\nПусть вектор [1], все его компоненты независимы и имеют равные дисперсии:имеет нормальное распределение\\nЛогарифмируя, получаем квадратичный регуляризатор:\\nгде— слагаемое, не зависящее от , которым можно пренебречь, поскольку оно не влияет на решение оптимизационной задачи. В итоге имеем -регуляризатор.\\nЛапласовский регуляризатор\\nПусть вектор [2], все его компоненты независимы и имеют равные дисперсии:имеет распределение Лапласа\\nТогда:\\nАналогично случаю с нормальным регуляризатором,можно опустить и, таким образом, получаем -регуляризатор.\\nРаспределение Лапласа имеет более острый пик и более тяжёлые «хвосты», по сравнению с нормальным распределением, как можно видеть на Рис. 4. Дисперсия Лапласовского распределения равна.\\nРегуляризация в линейной регрессии\\nВ линейной регрессии моделируется линейная зависимость между зависимой и независимой переменной. Каждому объекту $x \\\\in X^l$ соответствует признаковое описание $(f_{1}(x),\\\\dots,f_{n}(x))$, где $f_{j}:X \\\\rightarrow \\\\mathbb{R}$ — числовые признаки. Модель алгоритмов для линейной регрессии состоит из функций вида:\\n- $g(x, \\\\beta) = \\\\sum\\\\limits_{j}^n \\\\beta_{j} \\\\,f_{j}(x)$\\nВ итоге оптимизируемый функционал эмпирического риска выглядит следующим образом:\\n- $Q(a) = \\\\|F\\\\beta - y\\\\|^2$,\\nгде $F = (f_{j}(x_{i}))_{l \\\\times n}$ — матрица объекты-признаки, $y = (y_{i})_{l \\\\times 1}$ — целевой вектор, $\\\\beta = (\\\\beta_{j})_{n \\\\times 1}$ — вектор параметров. Приравняв нулю производную $Q(\\\\beta)$ по параметру $\\\\beta$, получаем:\\n- $\\\\beta^* = (F^TF)^{-1}F^Ty$\\nВ итоге, используя сингулярное разложение для представления $F$ и проведя МНК-аппроксимизацию целевого вектора $y$, имеем выражение для нормы вектора $\\\\beta$:\\n- $\\\\|\\\\beta^*\\\\|^2 = \\\\sum\\\\limits_{j=1}^n \\\\dfrac{1}{\\\\lambda_{j}}(v_{j}^Ty)^2$\\nК сожалению, могут возникнуть проблемы мультиколлинеарности и переобучения в случае, если ковариационная матрица $\\\\sum = F^T F$ плохо обусловлена. Одним из способов борьбы с этими проблемами, как говорилось ранее, является регуляризация.\\nВ статье о вариациях регрессии представлены модификации линейной регресиии с различными регуляризаторами ($L_{1}$ и $L_{2}$) и их отличие. Описание в данном разделе будет похожим, однако здесь будет рассмотрен эффект от добавления регуляризаторов немного подробнее.\\nГребневая регрессия\\nВ гребневой регрессии к функционалу $Q$ добавляется $L_{2}$-регуляризатор.\\nИтоговый минимизируемый функционал с поправкой:\\nИтоговое выражение для параметра $\\\\beta$:\\nТаким образом, перед обращением матрицы к ней добавляется \"гребень\" — диагональная матрица $\\\\tau I_{n}$. При этом все её собственные значения увеличиваются на $\\\\tau$, а собственные векторы не изменяются. В результате матрица становится хорошо обусловленной, оставаясь в то же время «похожей» на исходную.\\nОценим эффект, который оказывает добавление гребня. Выразим регуляризованное МНК-решение через сингулярное разложение:\\n- $\\\\beta_{t}^* = (UD^2U^T + \\\\tau I_{n})^{-1}UDV^{T}y=U(D^2+\\\\tau I_{n})^{-1}DV^Ty=\\\\sum\\\\limits_{j=1}^n \\\\dfrac{\\\\sqrt{\\\\lambda_{j}}}{\\\\lambda_{j} + \\\\tau}u_{j}(v_{j}^Ty)$\\nТеперь найдём регуляризованную МНК-аппроксимацию целевого вектора y:\\n- $F \\\\beta_{\\\\tau}^* = VDU^T \\\\beta_{\\\\tau}^* = V diag \\\\left(\\\\dfrac{\\\\lambda_{j}}{\\\\lambda_{j} + \\\\tau} \\\\right)V^Ty = \\\\sum\\\\limits_{j=1}^n \\\\dfrac{\\\\lambda_{j}}{\\\\lambda_{j} + \\\\tau}v_{j}(v_{j}^Ty)$\\nКак можно видеть, проекции на собственные векторы сокращаются, умножаясь $\\\\dfrac{\\\\lambda_{j}}{\\\\lambda_{j} + \\\\tau} \\\\in (0, 1)$.\\nВ сравнении с нерегуляризованным случаем, уменьшается и норма вектора $\\\\beta$:\\n- $\\\\|\\\\beta_{\\\\tau}^*\\\\|^2 = \\\\| D^2(D^2 + \\\\tau I_{n})^{-1}D^{-1}V^{T}y)\\\\|^2 = \\\\sum\\\\limits_{j=1}^n \\\\dfrac{1}{\\\\lambda_{j} + \\\\tau}(v_{j}^Ty)^2 < \\\\sum\\\\limits_{j=1}^n \\\\dfrac{1}{\\\\lambda_{j}}(v_{j}^Ty)^2 = \\\\|\\\\beta^*\\\\|^2$\\nПоэтому данный метод называют также сжатие или сокращение весов.\\nИз формул видно, что по мере увеличения параметра $\\\\tau$ вектор коэффициентов $\\\\beta_{\\\\tau}^*$ становится всё более устойчивым и жёстко определённым. Фактически, происходит понижение эффективной размерности решения — это второй смысл термина сжатие. Роль размерности играет след проекционной матрицы.\\nВ нерегуляризованном случае:\\n- $n_{effective} = tr\\\\:F(F^TF)^{-1}F^T = tr\\\\:(F^TF)^{-1}F^TF = tr\\\\:I_{n} = n$\\nВ случае с гребнем:\\n- $n_{effective} = tr\\\\:F(F^TF + \\\\tau I_{n})^{-1}F^T = tr\\\\:diag \\\\left(\\\\dfrac{\\\\lambda_{j}}{\\\\lambda_{j} + \\\\tau}\\\\right) = \\\\sum\\\\limits_{j=1}^n \\\\dfrac{1}{\\\\lambda_{j}} < n$\\nЛассо регрессия\\nВ лассо регрессии к функционалу $Q$ добавляется $L_{1}$-регуляризатор.\\nИтоговый минимизируемый функционал с поправкой:\\nЗапишем систему для этой регрессии в виде минимизации неизменного функционала $Q$ при неравенстве-ограничении:\\n- $\\\\begin{cases} Q(\\\\beta) = \\\\| F\\\\beta - y \\\\|^2 \\\\rightarrow \\\\min\\\\limits_{\\\\beta} \\\\\\\\ \\\\sum\\\\limits_{j=1}^n|\\\\beta_{j}| \\\\leq \\\\chi \\\\\\\\ \\\\end{cases}$\\nТак как используется $L_{1}$-регуляризатор, коэффициенты $\\\\beta_{j}$ постепенно обнуляются с уменьшением $\\\\chi$. Происходит отбор признаков, поэтому параметр $\\\\chi$ называют еще селективностью. Параметр $\\\\chi$ \"зажимает\" вектор коэффициентов $\\\\beta$, отсюда и название метода — лассо (англ. LASSO, least absolute shrinkage and selection operator).\\nСравнение гребневой и лассо регрессий\\nОсновное различие лассо и гребневой регрессий заключается в том, что первая может приводить к обращению некоторых независимых переменных в ноль (используется $L_{1}$-регуляризатор), тогда как вторая уменьшает их до значений, близких к нулю (используется $L_{2}$-регуляризатор).\\nПродублируем наглядный пример из статьи о вариациях регрессии. Рассмотрим для простоты двумерное пространство независимых переменных. В случае лассо регрессии органичение на коэффициенты представляет собой ромб ( ), в случае гребневой регрессии — круг ( ). Необходимо минимизировать функцию ошибки, но при этом соблюсти ограничения на коэффициенты. С геометрической точки зрения задача состоит в том, чтобы найти точку касания линии, отражающей функцию ошибки с фигурой, отражающей ограничения на . Из Рис. 5 интуитивно понятно, что в случае лассо регрессии эта точка с большой вероятностью будет находиться на углах ромба, то есть лежать на оси, тогда как в случае гребневой регрессии такое происходит очень редко. Если точка пересечения лежит на оси, один из коэффициентов будет равен нулю, а значит, значение соответствующей независимой переменной не будет учитываться.\\nТакже полезно будет рассмотреть простую модельную задачу. Пусть $l = n$ и матрица объекты-признаки является единичной $F = I$. Тогда МНК-решение дает вектор коэффициентов $\\\\beta$:\\n- $\\\\beta^* = argmin \\\\left(\\\\sum\\\\limits_{i=1}^l(\\\\beta_{i} - y_{i})^2\\\\right)$\\n- $\\\\beta_{j}^* = y_{j}$\\nВ случае с гребневой регрессией:\\n- $\\\\beta_{j}^* = \\\\dfrac{y_{j}}{1 + \\\\lambda}$\\nВ случае с лассо регрессией:\\n- $\\\\beta_{j}^* = \\\\begin{cases} y_{j} - \\\\lambda / 2, y_{j} > \\\\lambda / 2 \\\\\\\\ y_{j} + \\\\lambda / 2, y_{j} < -\\\\lambda / 2 \\\\\\\\ 0, |y_{j}| \\\\leq \\\\lambda / 2 \\\\end{cases}$\\nВ итоге на Рис. 6 на графиках с зависимостями $\\\\beta_{j}^*$ от $y_{j}$ можно увидеть описанные ранее особенности данных регуляризованных линейных регрессий.\\nРегуляризация в алгоритмах\\nГрадиентный спуск\\nАлгоритм градиентного спуска используют для нахождения аппроксимирующей зависимости, определяя вектор весов , при котором достигается минимум эмпирического риска:\\nВ этом методе выбирается некоторое начальное приближение для вектора весов, затем запускается итерационный процесс, на каждом шаге которого вектор $w$ изменяется в направлении наиболее быстрого убывания функционала $Q$ — противоположно вектору градиента :\\n- ,\\nгде— величина шага в направлении антиградиента.\\nРегуляризация — одна из эвристик улучшения градиентных методов обучения. Основным способом уменьшить переобучение является квадратичная регуляризация, называемая также сокращением весов. Чтобы ограничить рост абсолютных значений весов, к минимизируемому функционалудобавляется штрафное слагаемое:\\nЭто приводит к появлению аддитивной поправки в градиенте:\\nВ результате правило обновления весов принимает вид:\\nТаким образом, вся модификация сводится к появлению неотрицательного множителя, приводящего к постоянному уменьшению весов.\\nРегуляризация предовтращает паралич, повышает устойчивость весов в случае мультиколлинеарности, повышает обобщающую способность алгоритма и снижает риск переобучения. Однако есть и недостатки — параметр кросс-валидации, что связано с большими вычислительными затратами.необходимо выбирать с помощью\\nМетод опорных векторов\\nМетод опорных векторов (SVM) используется для задач классификации и регрессии. В нем строится гиперплоскость, разделяющая объекты выборки оптимальным образом.\\nК сожалению, зачастую выборка является линейно неразделимой. В таком случае приходится \"ослаблять ограничения\", позволяя некоторым объектам попадать на территорию другого класса. Для каждого объекта от отступа отнимается некоторая положительная величина $\\\\xi_i$, но требуется, чтобы введенные поправки были минимальны. В итоге постановка задачи SVM с мягким отступом (англ. soft-margin SVM) выглядит следующим образом: $\\\\begin{cases} \\\\dfrac{1}{2} \\\\lVert w \\\\rVert^2 + C \\\\sum\\\\limits_{i=1}^l \\\\xi_i \\\\to \\\\min\\\\limits_{w, b, \\\\xi} \\\\\\\\ M_i(w, b) \\\\geq 1 - \\\\xi_i, \\\\quad i = 1, \\\\ldots, l \\\\\\\\ \\\\xi_i \\\\geq 0, \\\\quad i = 1, \\\\ldots, l \\\\\\\\ \\\\end{cases}$\\nКак показано в соответствующем данному методу разделе, эквивалентной задачей безусловной минимизации является: $Q(w, b) = \\\\dfrac{1}{2C} \\\\lVert w \\\\rVert^2 + \\\\sum\\\\limits_{i=1}^l \\\\left(1 - M_i(w, b)\\\\right)_+ \\\\to \\\\min\\\\limits_{w, b}$\\nВ силу неравенства $[M_{i} < 0] \\\\leq (1 - M_{i})_{+}$, функционал $Q(w, b)$ можно рассматривать как верхнюю оценку эмпирического риска, к которому добавлен регуляризатор $\\\\dfrac{1}{2C} \\\\|w\\\\|^2$.\\nС введением регуляризатора устраняется проблема мультиколлинеарности, повышается устойчивость алгоритма, улучшается его обобщающая способность.\\nВ результате получаем, что принцип оптимальной разделяющей гиперплоскости или максимизации ширины разделяющей полосы в случае неразделимой выборки тесно связан с $L_{2}$-регуляризацией, которая возникает естественным образом из постановки задачи.\\nТакже существуют разновидности SVM с другими регуляризаторами.\\n- Метод релевантных векторов (англ. RVM, Relevance vector Machine):\\n- $\\\\dfrac{1}{2}\\\\sum\\\\limits_{i=1}^l\\\\left(\\\\ln w_{i} + \\\\dfrac{\\\\lambda_{i}^2}{w_{i}}\\\\right)$\\n- Метод опорных векторов с лассо (англ. LASSO SVM):\\n- $\\\\mu \\\\sum\\\\limits_{i=1}^n|w_{i}|$\\n- Метод опорных признаков (англ. Support feature machine):\\n- $\\\\sum\\\\limits_{i=1}^nR_{\\\\mu}(w_{i}), \\\\begin{cases} 2 \\\\mu |w_{i}|, |w_{i}|<\\\\mu \\\\\\\\ \\\\mu^2 + w_{i}^2, |w_{i}| \\\\geq \\\\mu \\\\end{cases}$\\nДругие использования регуляризации\\nЛогистическая регрессия\\nКак было показано в мотивационном примере, для логистической регрессии может быть полезно использовать регуляризацию.\\nДля настройки вектора коэффициентов $\\\\beta$ по обучающей выборке $X^l$ максимизируют логарифм правдоподобия:\\n- $L(\\\\beta, X^l) = log_{2}\\\\prod\\\\limits_{i=1}^lp(x_{i}, y_{i}) \\\\rightarrow \\\\max\\\\limits_{\\\\beta}$\\n- $L(\\\\beta, X^l) = \\\\sum\\\\limits_{i=1}^{l}log_{2}\\\\sigma(\\\\langle \\\\beta, x_{i} \\\\rangle y_{i}) + const(\\\\beta) \\\\rightarrow \\\\max\\\\limits_{\\\\beta}$\\n$L_{2}$-регуляризация:\\n- $L(\\\\beta, X^l) = \\\\sum\\\\limits_{i=1}^{l}log_{2}\\\\sigma(\\\\langle \\\\beta, x_{i} \\\\rangle y_{i}) - \\\\lambda \\\\| \\\\beta \\\\|^2 + const(\\\\beta) \\\\rightarrow \\\\max\\\\limits_{\\\\beta}$\\n$L_{1}$-регуляризация:\\n- $L(\\\\beta, X^l) = \\\\sum\\\\limits_{i=1}^{l}log_{2}\\\\sigma(\\\\langle \\\\beta, x_{i} \\\\rangle y_{i}) - \\\\lambda \\\\|\\\\beta \\\\|_{1} + const(\\\\beta) \\\\rightarrow \\\\max\\\\limits_{\\\\beta}$\\nАналогично можно использовать и другие регуляризаторы.\\nНейронные сети\\nРегуляризация также используется и в нейронных сетях для борьбы со слишком большими весами сети и переобучением. Однако, в этом случае зануление коэффициентов при использовании $L_{1}$-регуляризатора не несет в себе смысл \"отбора признаков\", как в случае с линейными моделями. К сожалению, регуляризация не снижает число параметров и не упрощает структуру сети.\\nДля нейронной сети помимо добавления штрафного слагаемого к эмпирическому риску активно используют и другой метод борьбы с переобучением — прореживание сети (англ. dropout), в ходе которого упрощают сеть, руководствуясь правилом — если функция ошибки не изменяется, то сеть можно упрощать и дальше. Подробнее об этом можно почитать в статье, рассказывающей о практике реализации нейронных сетей.\\nСм. также\\n- Переобучение\\n- Модель алгоритма и её выбор\\n- Байесовская классификация\\n- Вариации регрессии\\n- Линейная регрессия\\n- Логистическая регрессия\\n- Стохастический градиентный спуск\\n- Метод опорных векторов (SVM)\\n- Нейронные сети, перцептрон\\n- Практики реализации нейронных сетей\\nПримечания\\nИсточники информации\\n- Воронцов К.В. — Математические методы обучения по прецедентам\\n- Википедия — Регуляризация (математика)\\n- coursea.org — Регуляризация\\n- machinelearning.ru — L1-регуляризация линейной регрессии\\n- medium.com — 5 видов регрессии и их свойства\\n- Wikipedia — Elastic net regularization\\n- Keng B. — A Probabilistic Interpretation of Regularization', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_documents[23]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:42:39.403873Z",
     "start_time": "2024-03-04T09:42:39.380875Z"
    }
   },
   "id": "2c26654613c4e79",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "from lxml import etree"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:40:11.314536Z",
     "start_time": "2024-03-04T09:40:11.295536Z"
    }
   },
   "id": "4e6709d8ebf7a4e3",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n"
     ]
    }
   ],
   "source": [
    "print(\"%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:40:35.528Z",
     "start_time": "2024-03-04T09:40:35.520999Z"
    }
   },
   "id": "5edbaa6a2718a74b",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Машинное_обучение\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import unquote\n",
    "\n",
    "print(unquote('%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:46:45.837590Z",
     "start_time": "2024-03-04T09:46:45.820074Z"
    }
   },
   "id": "bff1e88565d2f811",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "base_url = \"https://neerc.ifmo.ru\"\n",
    "dataset_path = \"dataset\"\n",
    "ALL_URL = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T14:31:36.169988Z",
     "start_time": "2024-03-04T14:31:36.149993Z"
    }
   },
   "id": "6528830b8fa60622",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "#mw-head\n",
      "#p-search\n",
      "#.D0.9E.D0.B1.D1.89.D0.B8.D0.B5_.D0.BF.D0.BE.D0.BD.D1.8F.D1.82.D0.B8.D1.8F\n",
      "#.D0.9A.D0.BB.D0.B0.D1.81.D1.81.D0.B8.D1.84.D0.B8.D0.BA.D0.B0.D1.86.D0.B8.D1.8F_.D0.B8_.D1.80.D0.B5.D0.B3.D1.80.D0.B5.D1.81.D1.81.D0.B8.D1.8F\n",
      "#.D0.9A.D0.BB.D0.B0.D1.81.D1.82.D0.B5.D1.80.D0.B8.D0.B7.D0.B0.D1.86.D0.B8.D1.8F\n",
      "#.D0.90.D0.BD.D1.81.D0.B0.D0.BC.D0.B1.D0.BB.D0.B8\n",
      "#.D0.9D.D0.B5.D0.B9.D1.80.D0.BE.D0.BD.D0.BD.D1.8B.D0.B5_.D1.81.D0.B5.D1.82.D0.B8\n",
      "#.D0.93.D0.BB.D1.83.D0.B1.D0.BE.D0.BA.D0.BE.D0.B5_.D0.BE.D0.B1.D1.83.D1.87.D0.B5.D0.BD.D0.B8.D0.B5\n",
      "#.D0.A1.D0.B2.D0.B5.D1.80.D1.82.D0.BE.D1.87.D0.BD.D1.8B.D0.B5_.D1.81.D0.B5.D1.82.D0.B8\n",
      "#.D0.9A.D0.BE.D0.BC.D0.BF.D1.8C.D1.8E.D1.82.D0.B5.D1.80.D0.BD.D0.BE.D0.B5_.D0.B7.D1.80.D0.B5.D0.BD.D0.B8.D0.B5\n",
      "#.D0.9F.D0.BE.D1.80.D0.BE.D0.B6.D0.B4.D0.B0.D1.8E.D1.89.D0.B8.D0.B5_.D0.BC.D0.BE.D0.B4.D0.B5.D0.BB.D0.B8\n",
      "#.D0.9E.D0.B1.D1.80.D0.B0.D0.B1.D0.BE.D1.82.D0.BA.D0.B0_.D0.B5.D1.81.D1.82.D0.B5.D1.81.D1.82.D0.B2.D0.B5.D0.BD.D0.BD.D0.BE.D0.B3.D0.BE_.D1.8F.D0.B7.D1.8B.D0.BA.D0.B0\n",
      "#.D0.A0.D0.B0.D0.B1.D0.BE.D1.82.D0.B0_.D1.81_.D0.B4.D0.B0.D0.BD.D0.BD.D1.8B.D0.BC.D0.B8\n",
      "#.D0.92.D0.B8.D0.B4.D1.8B_.D0.BE.D0.B1.D1.83.D1.87.D0.B5.D0.BD.D0.B8.D1.8F\n",
      "#.D0.90.D0.B2.D1.82.D0.BE.D0.BC.D0.B0.D1.82.D0.B8.D1.87.D0.B5.D1.81.D0.BA.D0.BE.D0.B5_.D0.BC.D0.B0.D1.88.D0.B8.D0.BD.D0.BD.D0.BE.D0.B5_.D0.BE.D0.B1.D1.83.D1.87.D0.B5.D0.BD.D0.B8.D0.B5\n",
      "#.D0.9E.D0.B1.D1.83.D1.87.D0.B5.D0.BD.D0.B8.D0.B5_.D1.81_.D0.BF.D0.BE.D0.B4.D0.BA.D1.80.D0.B5.D0.BF.D0.BB.D0.B5.D0.BD.D0.B8.D0.B5.D0.BC\n",
      "#.D0.A0.D0.B5.D0.B0.D0.BB.D0.B8.D0.B7.D0.B0.D1.86.D0.B8.D1.8F\n",
      "#.D0.9F.D1.80.D0.B8.D0.BC.D0.B5.D0.BD.D0.B5.D0.BD.D0.B8.D0.B5_.D0.BC.D0.B0.D1.88.D0.B8.D0.BD.D0.BD.D0.BE.D0.B3.D0.BE_.D0.BE.D0.B1.D1.83.D1.87.D0.B5.D0.BD.D0.B8.D1.8F_.D0.BD.D0.B0_.D0.BF.D1.80.D0.B0.D0.BA.D1.82.D0.B8.D0.BA.D0.B5\n",
      "#.D0.92_.D1.80.D0.B0.D0.B7.D1.80.D0.B0.D0.B1.D0.BE.D1.82.D0.BA.D0.B5\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D1%89%D0%B8%D0%B5_%D0%BF%D0%BE%D0%BD%D1%8F%D1%82%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%9F%D0%B5%D1%80%D0%B5%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%9A%D1%80%D0%BE%D1%81%D1%81-%D0%B2%D0%B0%D0%BB%D0%B8%D0%B4%D0%B0%D1%86%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA\n",
      "/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%A0%D0%B0%D0%BD%D0%B6%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B\n",
      "/wiki/index.php?title=%D0%98%D0%BD%D1%82%D0%B5%D1%80%D0%BF%D1%80%D0%B5%D1%82%D0%B8%D1%80%D1%83%D0%B5%D0%BC%D1%8B%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8\n",
      "/wiki/index.php?title=%D0%96%D0%B8%D0%B7%D0%BD%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9_%D1%86%D0%B8%D0%BA%D0%BB_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D1%85_%D1%80%D1%8F%D0%B4%D0%BE%D0%B2\n",
      "/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80_%D0%B8_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4_%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B8%D1%85_%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9\n",
      "/wiki/index.php?title=%D0%94%D0%B5%D1%80%D0%B5%D0%B2%D0%BE_%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D0%B9_%D0%B8_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BB%D0%B5%D1%81\n",
      "/wiki/index.php?title=%D0%92%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D0%B8_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%BF%D0%BE%D1%80%D0%BD%D1%8B%D1%85_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BE%D0%B2_(SVM)\n",
      "/wiki/index.php?title=%D0%AF%D0%B4%D1%80%D0%B0\n",
      "/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0_%D0%B2_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0%D1%85_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8_%D0%B8_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%91%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%91%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B5_%D1%81%D0%B5%D1%82%D0%B8\n",
      "/wiki/index.php?title=%D0%9F%D0%BE%D0%B8%D1%81%D0%BA_%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B8%D1%85_%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9_%D1%81_%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E_%D0%B8%D0%B5%D1%80%D0%B0%D1%80%D1%85%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B3%D0%BE_%D0%BC%D0%B0%D0%BB%D0%B5%D0%BD%D1%8C%D0%BA%D0%BE%D0%B3%D0%BE_%D0%BC%D0%B8%D1%80%D0%B0\n",
      "/wiki/index.php?title=%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F\n",
      "/wiki/index.php?title=EM-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC\n",
      "/wiki/index.php?title=%D0%98%D0%B5%D1%80%D0%B0%D1%80%D1%85%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0_%D0%B2_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B5_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%AD%D0%B2%D0%BE%D0%BB%D1%8E%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%92%D0%B8%D0%B4%D1%8B_%D0%B0%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B5%D0%B9\n",
      "/wiki/index.php?title=%D0%91%D1%83%D1%81%D1%82%D0%B8%D0%BD%D0%B3,_AdaBoost\n",
      "/wiki/index.php?title=XGBoost\n",
      "/wiki/index.php?title=CatBoost\n",
      "/wiki/index.php?title=%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8,_%D0%BF%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B8\n",
      "/wiki/index.php?title=%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B8_%D1%80%D0%B5%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D0%B5%D0%B9\n",
      "/wiki/index.php?title=%D0%93%D1%80%D0%B0%D1%84%D0%BE%D0%B2%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8\n",
      "/wiki/index.php?title=%D0%A0%D0%B5%D0%BA%D1%83%D1%80%D1%81%D0%B8%D0%B2%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8\n",
      "/wiki/index.php?title=%D0%93%D0%BB%D1%83%D0%B1%D0%BE%D0%BA%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%9D%D0%B0%D1%81%D1%82%D1%80%D0%BE%D0%B9%D0%BA%D0%B0_%D0%B3%D0%BB%D1%83%D0%B1%D0%BE%D0%BA%D0%BE%D0%B9_%D1%81%D0%B5%D1%82%D0%B8\n",
      "/wiki/index.php?title=Batch-normalization\n",
      "/wiki/index.php?title=%D0%9F%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D1%8B_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D0%B5%D0%B9\n",
      "/wiki/index.php?title=%D0%A0%D0%B5%D0%BA%D1%83%D1%80%D1%80%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8\n",
      "/wiki/index.php?title=%D0%A1%D0%B8%D0%B0%D0%BC%D1%81%D0%BA%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C\n",
      "/wiki/index.php?title=%D0%90%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA\n",
      "/wiki/index.php?title=%D0%A1%D0%B5%D1%82%D0%B8_%D0%B3%D0%BB%D1%83%D0%B1%D0%BE%D0%BA%D0%BE%D0%B3%D0%BE_%D0%B4%D0%BE%D0%B2%D0%B5%D1%80%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%A1%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8\n",
      "/wiki/index.php?title=Neural_Style_Transfer\n",
      "/wiki/index.php?title=%D0%9A%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BD%D0%BE%D0%B5_%D0%B7%D1%80%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%A1%D0%B5%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%86%D0%B8%D1%8F_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9\n",
      "/wiki/index.php?title=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BD%D0%B0%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2_%D0%BD%D0%B0_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D0%BF%D0%BE%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%9E%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BF%D0%BE%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F_%D1%87%D0%B5%D0%BB%D0%BE%D0%B2%D0%B5%D0%BA%D0%B0\n",
      "/wiki/index.php?title=%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%B8%D0%B7%D0%BE%D0%B3%D0%BD%D1%83%D1%82%D0%BE%D0%B3%D0%BE_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0\n",
      "/wiki/index.php?title=%D0%9A%D0%B0%D1%80%D1%82%D0%B0_%D0%B3%D0%BB%D1%83%D0%B1%D0%B8%D0%BD%D1%8B\n",
      "/wiki/index.php?title=%D0%92%D0%BF%D0%B8%D1%81%D1%8B%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D1%87%D0%B0%D1%81%D1%82%D0%B8_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%91%D0%BB%D0%B5%D0%BD%D0%B4%D0%B8%D0%BD%D0%B3_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9\n",
      "/wiki/index.php?title=%D0%9F%D0%BE%D1%80%D0%BE%D0%B6%D0%B4%D0%B0%D1%8E%D1%89%D0%B8%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8\n",
      "/wiki/index.php?title=%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D1%8F_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2\n",
      "/wiki/index.php?title=Generative_Adversarial_Nets_(GAN)\n",
      "/wiki/index.php?title=PixelRNN_%D0%B8_PixelCNN\n",
      "/wiki/index.php?title=%D0%92%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B0%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA\n",
      "/wiki/index.php?title=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D1%82%D1%80%D0%B0%D0%BD%D1%81%D0%BB%D1%8F%D1%86%D0%B8%D0%B8_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9\n",
      "/wiki/index.php?title=%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D1%8F_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0\n",
      "/wiki/index.php?title=%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D1%8F_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BF%D0%BE_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D1%83\n",
      "/wiki/index.php?title=%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D1%80%D0%B5%D1%87%D0%B8\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D0%B5%D1%81%D1%82%D0%B5%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D1%8F%D0%B7%D1%8B%D0%BA%D0%B0\n",
      "/wiki/index.php?title=%D0%92%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BD%D0%BE%D0%B5_%D0%BF%D1%80%D0%B5%D0%B4%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81%D0%BB%D0%BE%D0%B2\n",
      "/wiki/index.php?title=%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2_%D0%B8_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D1%82%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8\n",
      "/wiki/index.php?title=%D0%94%D0%BE%D0%BB%D0%B3%D0%B0%D1%8F_%D0%BA%D1%80%D0%B0%D1%82%D0%BA%D0%BE%D1%81%D1%80%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BF%D0%B0%D0%BC%D1%8F%D1%82%D1%8C\n",
      "/wiki/index.php?title=%D0%9C%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%B7%D0%BC_%D0%B2%D0%BD%D0%B8%D0%BC%D0%B0%D0%BD%D0%B8%D1%8F\n",
      "/wiki/index.php?title=BERT_(%D1%8F%D0%B7%D1%8B%D0%BA%D0%BE%D0%B2%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C)\n",
      "/wiki/index.php?title=%D0%A1%D0%B8%D0%BD%D1%82%D0%B5%D0%B7_%D1%80%D0%B5%D1%87%D0%B8\n",
      "/wiki/index.php?title=%D0%94%D0%B8%D0%B0%D0%BB%D0%BE%D0%B3%D0%BE%D0%B2%D1%8B%D0%B5_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B\n",
      "/wiki/index.php?title=%D0%A3%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B5%D0%BD%D0%B8%D0%B5_%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8\n",
      "/wiki/index.php?title=%D0%92%D1%8B%D0%B1%D1%80%D0%BE%D1%81\n",
      "/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B_%D1%81%D1%8D%D0%BC%D0%BF%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%98%D0%B7%D0%B2%D0%B5%D1%81%D1%82%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D1%8B_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85\n",
      "/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D1%8B%D1%85_%D0%BA%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82_(PCA)\n",
      "/wiki/index.php?title=%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%B2%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9_%D1%81_t-%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC\n",
      "/wiki/index.php?title=%D0%A1%D0%B8%D0%BD%D1%82%D0%B5%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D1%8B_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85\n",
      "/wiki/index.php?title=%D0%90%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%87%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%BD%D1%8B%D0%BC_%D0%BF%D1%80%D0%B8%D0%B2%D0%BB%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8F\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2_%D1%80%D0%B5%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%BC_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%B8\n",
      "/wiki/index.php?title=%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%9D%D0%B0%D1%81%D1%82%D1%80%D0%BE%D0%B9%D0%BA%D0%B0_%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2\n",
      "/wiki/index.php?title=%D0%9C%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B0_%D0%B8_%D0%B5%D0%B5_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80\n",
      "/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%B0-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%9F%D0%BE%D0%B8%D1%81%D0%BA_%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%BE%D0%B9_%D1%81%D0%B5%D1%82%D0%B8\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D0%BF%D0%BE%D0%B4%D0%BA%D1%80%D0%B5%D0%BF%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC\n",
      "/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_policy_gradient_%D0%B8_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%B0%D1%81%D0%B8%D0%BD%D1%85%D1%80%D0%BE%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%B0%D0%BA%D1%82%D0%BE%D1%80%D0%B0-%D0%BA%D1%80%D0%B8%D1%82%D0%B8%D0%BA%D0%B0\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D0%B7%D0%BE%D1%80_%D0%B1%D0%B8%D0%B1%D0%BB%D0%B8%D0%BE%D1%82%D0%B5%D0%BA_%D0%B4%D0%BB%D1%8F_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BD%D0%B0_Python\n",
      "/wiki/index.php?title=%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D0%BF%D0%BE%D1%82%D0%BE%D1%87%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D0%B2_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%BC_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D1%8B_%D0%BA%D0%BE%D0%B4%D0%B0_%D0%BD%D0%B0_Java\n",
      "/wiki/index.php?title=%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D1%8B_%D0%BA%D0%BE%D0%B4%D0%B0_%D0%BD%D0%B0_R\n",
      "/wiki/index.php?title=%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D1%8B_%D0%BA%D0%BE%D0%B4%D0%B0_%D0%BD%D0%B0_Scala\n",
      "/wiki/index.php?title=%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D1%8B_%D0%BA%D0%BE%D0%B4%D0%B0_%D0%BD%D0%B0_Kotlin\n",
      "/wiki/index.php?title=%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D1%8B_%D0%BA%D0%BE%D0%B4%D0%B0_%D0%BD%D0%B0_Kotlin_%D0%B2_Jupyter_Notebook\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BD%D0%B0_%D0%BC%D0%BE%D0%B1%D0%B8%D0%BB%D1%8C%D0%BD%D1%8B%D1%85_%D1%82%D0%B5%D0%BB%D0%B5%D1%84%D0%BE%D0%BD%D0%B0%D1%85\n",
      "/wiki/index.php?title=%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D1%81%D0%BE%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D0%B5%D0%B9\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2_%D0%BC%D0%B5%D0%B4%D0%B8%D1%86%D0%B8%D0%BD%D0%B5\n",
      "/wiki/index.php?title=Deepfake\n",
      "/wiki/index.php?title=%D0%9F%D1%80%D0%B5%D0%B4%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B7%D0%BD%D0%B0%D0%BD%D0%B8%D0%B9\n",
      "/wiki/index.php?title=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BF%D0%BB%D0%B0%D0%BD%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F_%D0%B4%D0%B2%D0%B8%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2_%D0%B0%D1%81%D1%82%D1%80%D0%BE%D0%BD%D0%BE%D0%BC%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%9A%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BD%D0%BE%D0%B5_%D0%B7%D1%80%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2_%D0%BC%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%BA%D0%BE%D0%BF%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BD%D0%B0_%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D1%85_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85\n",
      "/wiki/index.php?title=%D0%94%D0%BE%D0%BF%D0%BE%D0%BB%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BA_%D1%80%D0%B0%D0%BD%D0%B6%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8E\n",
      "/wiki/index.php?title=%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2_%D0%BD%D0%B0_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0_%D0%BD%D0%B0_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%9E%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B3%D0%B5%D0%BE%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D0%B8_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F\n",
      "/wiki/index.php?title=%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%B2%D0%B8%D0%B4%D0%B5%D0%BE\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D0%BD%D0%B0%D1%80%D1%83%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B8_%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D0%B4%D0%BE%D1%80%D0%BE%D0%B6%D0%BD%D1%8B%D1%85_%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D0%B2_%D0%B8_%D0%BF%D0%B5%D1%88%D0%B5%D1%85%D0%BE%D0%B4%D0%BE%D0%B2\n",
      "/wiki/index.php?title=%D0%A2%D1%80%D0%B0%D0%BD%D1%81%D1%84%D0%BE%D1%80%D0%BC%D0%B5%D1%80\n",
      "http://neerc.ifmo.ru/wiki/index.php?title=Машинное_обучение&oldid=85597\n",
      "/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:%D0%9A%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D0%B8\n",
      "/wiki/index.php?title=%D0%9A%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D1%8F:%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:%D0%A1%D0%BE%D0%B7%D0%B4%D0%B0%D1%82%D1%8C_%D1%83%D1%87%D1%91%D1%82%D0%BD%D1%83%D1%8E_%D0%B7%D0%B0%D0%BF%D0%B8%D1%81%D1%8C&returnto=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5+%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:%D0%92%D1%85%D0%BE%D0%B4&returnto=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5+%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%9E%D0%B1%D1%81%D1%83%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5:%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5&action=edit&redlink=1\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5&action=edit\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5&action=history\n",
      "/wiki/index.php?title=%D0%97%D0%B0%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D0%B0\n",
      "/wiki/index.php?title=%D0%97%D0%B0%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D0%B0\n",
      "/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:%D0%A1%D0%B2%D0%B5%D0%B6%D0%B8%D0%B5_%D0%BF%D1%80%D0%B0%D0%B2%D0%BA%D0%B8\n",
      "/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:%D0%A1%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D0%B0\n",
      "https://www.mediawiki.org/wiki/Special:MyLanguage/Help:Contents\n",
      "/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:%D0%A1%D1%81%D1%8B%D0%BB%D0%BA%D0%B8_%D1%81%D1%8E%D0%B4%D0%B0/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:%D0%A1%D0%B2%D1%8F%D0%B7%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5_%D0%BF%D1%80%D0%B0%D0%B2%D0%BA%D0%B8/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:%D0%A1%D0%BF%D0%B5%D1%86%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D1%8B\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5&printable=yes\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5&oldid=85597\n",
      "/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5&action=info\n",
      "/wiki/index.php?title=%D0%92%D0%B8%D0%BA%D0%B8%D0%BA%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%D1%8B:%D0%9F%D0%BE%D0%BB%D0%B8%D1%82%D0%B8%D0%BA%D0%B0_%D0%BA%D0%BE%D0%BD%D1%84%D0%B8%D0%B4%D0%B5%D0%BD%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8\n",
      "/wiki/index.php?title=%D0%92%D0%B8%D0%BA%D0%B8%D0%BA%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%D1%8B:%D0%9E%D0%BF%D0%B8%D1%81%D0%B0%D0%BD%D0%B8%D0%B5\n",
      "/wiki/index.php?title=%D0%92%D0%B8%D0%BA%D0%B8%D0%BA%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%D1%8B:%D0%9E%D1%82%D0%BA%D0%B0%D0%B7_%D0%BE%D1%82_%D0%BE%D1%82%D0%B2%D0%B5%D1%82%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D0%B8\n",
      "http://neerc.ifmo.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5&mobileaction=toggle_view_mobile\n",
      "//www.mediawiki.org/\n"
     ]
    }
   ],
   "source": [
    "data = requests.get('https://neerc.ifmo.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5').text\n",
    "\n",
    "parser = etree.HTMLParser()\n",
    "tree   = etree.parse(io.StringIO(data), parser)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T14:30:08.691690Z",
     "start_time": "2024-03-04T14:30:08.098859Z"
    }
   },
   "id": "d2309ad517a84d29",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for im in tree.xpath('//a'):\n",
    "    if im.get('href') is None:\n",
    "        continue\n",
    "    if \"title\" in im.get('href'):\n",
    "        name = unquote(im.get('href').split(\"title=\")[1])\n",
    "        if \"/\" in name:\n",
    "            continue\n",
    "        with open(os.path.join(dataset_path, name + \".txt\"), \"wb\") as t:\n",
    "            doc = TrafilaturaWebReader().load_data([base_url + im.get('href')])\n",
    "            if len(doc):\n",
    "                t.write(\n",
    "                    doc[0].text.replace(\"\\u2236\", \":\").replace(\"\\u2192\", \"->\").replace(\"\\u2282\", \"sub\").replace(\"\\u2212\", \"-\").replace(\"\\u2191\", \"\").replace(\"\\xd7\", \")\").replace(\"\\u0301\", \"`\").replace(\"\\u0176\", \"Y\").replace(\"\\u237a\", \"a\").replace(\"\\xb2\", \"2\").replace(\"\\u03b2\", \"B\").replace(\"\\u03b5\", \"e\").replace(\"\\xe0\", \"a`\").replace(\"\\u2010\", \"-\").replace(\"\\xe9\", \"e\").replace(\"\\u0131\", \"1\").replace(\"\\u2208\", \"e\").replace(\"\\xe1\", \"a`\").replace(\"\\xf3\", \"o`\").encode(\"utf-8\")\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T15:13:19.666265Z",
     "start_time": "2024-03-04T15:12:14.942454Z"
    }
   },
   "id": "dfb45197b65754f4",
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T15:02:55.456934Z",
     "start_time": "2024-03-04T15:02:55.439935Z"
    }
   },
   "id": "b618c9fc40462fae",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "b'\\xd0\\xbe\\xd0\\xb4\\xd0\\xb5\\xd0\\xbb\\xd1\\x8c \\xe2\\x80\\x94 \\xd1\\x8d\\xd1\\x82\\xd0\\xbe \\xd1\\x84\\xd1\\x83\\xd0\\xbd\\xd0\\xba\\xd1\\x86\\xd0\\xb8\\xd1\\x8f, \\xd0\\xbf\\xd1\\x80\\xd0\\xb8\\xd0\\xbd\\xd0\\xb8\\xd0\\xbc\\xd0\\xb0\\xd1\\x8e\\xd1\\x89'"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].text[2430:2460]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T15:00:21.904516Z",
     "start_time": "2024-03-04T15:00:21.899517Z"
    }
   },
   "id": "9113ca4340fbe577",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"и\" == 'и'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T14:35:06.722843Z",
     "start_time": "2024-03-04T14:35:06.717843Z"
    }
   },
   "id": "23524fce83bc47df",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: eb76738c-bdf4-4d04-a110-cf7b74617533\n",
      "Text: # Переобучение  Материал из Викиконспекты  Перейти к: навигация,\n",
      "поиск  **Переобучение** (англ. overfitting) — негативное явление,\n",
      "возникающее, когда алгоритм обучения вырабатывает предсказания,\n",
      "которые слишком близко или точно соответствуют конкретному набору\n",
      "данных и поэтому не подходят для применения алгоритма к дополнительным\n",
      "данным или буду...\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:12:45.227508Z",
     "start_time": "2024-03-01T10:12:45.216497Z"
    }
   },
   "id": "30e689ecd73a2ab3",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import llama_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:09:34.263405Z",
     "start_time": "2024-03-01T10:09:34.246408Z"
    }
   },
   "id": "d30e47a67ed2ec30",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'0.9.27'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_index.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:09:34.581497Z",
     "start_time": "2024-03-01T10:09:34.561505Z"
    }
   },
   "id": "5baebbb20a59665e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T05:41:12.502172Z",
     "start_time": "2024-03-03T05:41:11.817383Z"
    }
   },
   "id": "1ad8f3ad44895477",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"sites/ifmo.txt\", \"w\") as t:\n",
    "    t.write(\"\\n\".join(ALL_URL))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T06:45:20.984482Z",
     "start_time": "2024-03-03T06:45:20.972907Z"
    }
   },
   "id": "973437a8eed693dc",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b14b0c8f48169195"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(im.get('href'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T05:45:13.823399Z",
     "start_time": "2024-03-03T05:45:13.814710Z"
    }
   },
   "id": "61813ddb29773e14",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cf6f43ecf2e0dbb2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a4d6d7811b17cfc2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-01T10:09:28.188225Z"
    }
   },
   "id": "4d1b23568c0e8c23"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-01T10:09:28.190224Z"
    }
   },
   "id": "a2545c41d7c66c6a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "43088a1f67d0dd39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
