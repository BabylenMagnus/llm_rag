Примеры кода на Java
Содержание
- 1 Популярные библиотеки
- 2 Основные особенности использования Java для задач машинного обучения
- 3 Примеры кода
- 3.1 Вариации регрессии
- 3.2 Метрический классификатор и метод ближайших соседей
- 3.3 Классификация при помощи MLP
- 3.4 Рекуррентные нейронные сети
- 3.5 Долгая краткосрочная память
- 3.6 Метод опорных векторов
- 3.7 Деревья решений, случайный лес
- 3.8 Бустинг, Ada-boost
- 3.9 EM-алгоритм
- 3.10 Уменьшение размерности
- 3.11 Байесовская классификация
- 4 См. также
- 5 Примечания
Популярные библиотеки
-
Weka[1] — популярная библиотека, написанная на языке
Javaи содержащая в себе множество алгоритмов машинного обучения для задач анализа данных. Предоставляет инструменты для решения задач классификации, кластеризации данных, регрессионного анализа и др. Основные возможности
Wekaможно сгруппировать в 3 категории: инструменты пре-процессинга данных, алгоритмы машинного обучения и инструменты оценки модели. Инструменты пре-процессинга в
Wekaназываются фильтрами,
Wekaсодержит фильтры для дискретиации, нормализации, уменьшения размерности, трансформации и комбинирования признаков.
Weka Machine Learning Toolkitсодержит алгоритмы классификации, регрессии, кластеризации. Реализованы следующие алгоритмы обучения: деревья решений, метод опорных векторов,
MLP, логистическая регрессия, Байесовские сети, и др., мета-алгоритмы включают в себя: бэггинг, бустинг, стекинг, алгоритмы выбора признаков: PCA[на 28.01.19 не создан], фильтрующие методы, основанные на information gain, коэффициенте корреляции Пирсона и
OneRклассификаторе.
-
Smile[2] —
Javaфреймворк для машинного обучения, анализа естественного языка, линейной алгебры и визуализации данных.
Smileпокрывает все основные аспекты машинного обучения и предоставляет высокопроизводительные алгоритмы и структуры данных.
-
deeplearning4j[3] —
Javaбиблиотека для глубокого обучения, создания рекуррентых (в том числе распределенных) нейронных сетей.
Основные особенности использования Java для задач машинного обучения
В отличие от
Python,
Java не обладает столь обширной экосистемой, ориентированной на решение задач машинного обучения и анализа данных. Большинство имеющихся инструментов являются узко специализированными (по сравнению, например, с
scikit-learn[4]) и хуже документированы. Ввиду более низкой популярности языка в сфере
ML большинство онлайн курсов и обучающих материалов ориентированы на
Python. Однако, несмотря на вышеперечисленные факторы,
Java остается
популярной альтернативой, особенно при необходимости интеграции с существующими
JVM проектами. Также к достоинствам
Java можно отнести статическую типизацию (и как следствие уменьшенную вероятность ошибок времени исполнения) и заметно более развитую поддержку в IDE.
Примеры кода
Для работы с приведенными ниже примерами необходим
JDK версии не ниже 10 и система сборки
Maven.
Каждый пример структурирован следующим образом:
-
Mavenзависимость на необходимые библиотеки
- Список необходимых
importдиректив
- Код примера с комментариями
Вариации регрессии
Линейная регрессия
Логистическая регрессиия
Гребневая регрессия (ридж-регрессия)
Лассо-регрессия
Метрический классификатор и метод ближайших соседей
Классификация при помощи MLP
Рекуррентные нейронные сети
Долгая краткосрочная память
Метод опорных векторов
Деревья решений, случайный лес
Бустинг, Ada-boost
EM-алгоритм
Пример кластеризации с применением
weka.clusterers.EM[5]
<dependency> <groupId>nz.ac.waikato.cms.weka</groupId> <artifactId>weka-stable</artifactId> <version>3.8.0</version> </dependency>
import weka.clusterers.ClusterEvaluation; import weka.clusterers.EM; import weka.core.Instances; import java.io.BufferedReader; import java.io.FileReader; import java.util.Random;
//load data var data = new Instances(new BufferedReader(new FileReader("data/bank-data.arff"))); // new instance of clusterer var model = new EM(); // build the clusterer model.buildClusterer(data); System.out.println(model); var logLikelihood = ClusterEvaluation.crossValidateModel(model, data, 10, new Random(1));